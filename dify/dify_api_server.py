#!/usr/bin/env python3
"""
Dify å·¥ä½œæµåº“ API æœåŠ¡å™¨
ç«¯å£: 4002
"""

import os
import json
import re
import yaml
from pathlib import Path
from flask import Flask, jsonify, request, send_from_directory, send_file
from flask_cors import CORS

app = Flask(__name__, static_folder='static', static_url_path='/static')
CORS(app)

# å·¥ä½œæµç›®å½•é…ç½®
WORKFLOW_DIRS = [
    'Awesome-Dify-Workflow-main/Awesome-Dify-Workflow-main/DSL',
    'é—²é±¼difyå·¥ä½œæµ/å¯å‚è€ƒçš„difyå·¥ä½œæµæ¨¡æ¿',
    'é—²é±¼difyå·¥ä½œæµ/å·¥ä½œæµ/å·¥ä½œæµ',
    'é—²é±¼difyå·¥ä½œæµ/é—²é±¼difyå·¥ä½œæµ/workflow'
]

BASE_DIR = Path(__file__).parent

# åˆ†ç±»å…³é”®è¯æ˜ å°„
CATEGORY_KEYWORDS = {
    'translation': {
        'name': 'ç¿»è¯‘&è¯­è¨€',
        'keywords': ['ç¿»è¯‘', 'è¯‘', 'translate', 'translation', 'è‹±è¯‘ä¸­', 'ä¸­è¯‘è‹±', 'å¤šè¯­è¨€', 'language']
    },
    'content': {
        'name': 'å†…å®¹åˆ›ä½œ',
        'keywords': ['æ–‡ç« ', 'æ ‡é¢˜', 'å†™ä½œ', 'æ–‡æ¡ˆ', 'åˆ›ä½œ', 'seo', 'ä»¿å†™', 'å°çº¢ä¹¦', 'æŠ–éŸ³', 'è¿è¥', 'åšå®¢']
    },
    'ai-art': {
        'name': 'AI ç»˜ç”»',
        'keywords': ['ç»˜ç”»', 'ç”»å›¾', 'å›¾åƒ', 'flux', 'å³æ¢¦', 'æ’ç”»', 'ç»˜æœ¬', 'å›¾ç‰‡', 'image', 'art', 'draw']
    },
    'data-analysis': {
        'name': 'æ•°æ®åˆ†æ',
        'keywords': ['æ•°æ®', 'åˆ†æ', 'ç»Ÿè®¡', 'è‚¡ç¥¨', 'excel', 'è¡¨æ ¼', 'chart', 'å›¾è¡¨', 'matplotlib']
    },
    'document': {
        'name': 'æ–‡æ¡£å¤„ç†',
        'keywords': ['æ–‡æ¡£', 'å‘ç¥¨', 'åˆåŒ', 'pdf', 'çŸ¥è¯†åº“', 'æ–‡ä»¶', 'file', 'document', 'è§£æ']
    },
    'chatbot': {
        'name': 'èŠå¤©æœºå™¨äºº',
        'keywords': ['èŠå¤©', 'å®¢æœ', 'å¯¹è¯', 'æ„å›¾', 'è®°å¿†', 'chat', 'bot', 'é—®ç­”', 'æœºå™¨äºº']
    },
    'code': {
        'name': 'ä»£ç å¼€å‘',
        'keywords': ['ä»£ç ', 'code', 'python', 'coding', 'api', 'sql', 'ç¼–ç¨‹', 'å¼€å‘']
    },
    'research': {
        'name': 'æœç´¢&ç ”ç©¶',
        'keywords': ['æœç´¢', 'ç ”ç©¶', 'search', 'research', 'jina', 'çˆ¬è™«', 'ç½‘é¡µ', 'web']
    },
    'agent': {
        'name': 'Agent&å·¥å…·',
        'keywords': ['agent', 'mcp', 'å·¥å…·', 'tool', 'æ™ºèƒ½ä½“', 'flow']
    },
    'education': {
        'name': 'æ•™è‚²å­¦ä¹ ',
        'keywords': ['å­¦ä¹ ', 'æ•™è‚²', 'æ•™å­¦', 'é¢˜ç›®', 'é¢è¯•', 'åŸ¹è®­', 'è¯¾ç¨‹', 'å­¦ç”Ÿ']
    },
    'media': {
        'name': 'åª’ä½“&è§†é¢‘',
        'keywords': ['è§†é¢‘', 'éŸ³é¢‘', 'è¯­éŸ³', 'tts', 'æ’­å®¢', 'youtube', 'åª’ä½“', 'video', 'audio']
    },
    'utility': {
        'name': 'å®ç”¨å·¥å…·',
        'keywords': ['å·¥å…·', 'json', 'æ˜¥è”', 'æ€ç»´å¯¼å›¾', 'é‚®ä»¶', 'è¡¨å•', 'form', 'ç”Ÿæˆå™¨']
    }
}

def get_category(filename, content=''):
    """æ ¹æ®æ–‡ä»¶åå’Œå†…å®¹åˆ¤æ–­åˆ†ç±»"""
    text = (filename + ' ' + content).lower()
    
    for cat_id, cat_info in CATEGORY_KEYWORDS.items():
        for keyword in cat_info['keywords']:
            if keyword.lower() in text:
                return cat_id
    return 'utility'

def parse_workflow_file(filepath):
    """è§£æå·¥ä½œæµæ–‡ä»¶"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
            data = yaml.safe_load(content)
            
        if not data:
            return None
            
        # æå–åŸºæœ¬ä¿¡æ¯
        app_info = data.get('app', {})
        name = app_info.get('name', '') or data.get('name', '') or filepath.stem
        description = app_info.get('description', '') or data.get('description', '') or ''
        icon = app_info.get('icon', 'ğŸ¤–')
        mode = app_info.get('mode', 'workflow')  # workflow, chatflow, agent-chat, completion
        
        # æ ‡å‡†åŒ–æ¨¡å¼æ˜¾ç¤º
        mode_display = {
            'workflow': 'Workflow',
            'chatflow': 'Chatflow', 
            'agent-chat': 'Agent',
            'advanced-chat': 'Agent',
            'completion': 'Completion'
        }.get(mode, mode)
        
        # è·å–å·¥ä½œæµå›¾
        workflow = data.get('workflow', {})
        graph = workflow.get('graph', {})
        
        # ç»Ÿè®¡èŠ‚ç‚¹
        nodes = graph.get('nodes', [])
        node_count = len(nodes) if isinstance(nodes, list) else 0
        
        # ç»Ÿè®¡è¿æ¥æ•°
        edges = graph.get('edges', [])
        edge_count = len(edges) if isinstance(edges, list) else 0
        
        # æå–èŠ‚ç‚¹ç±»å‹å’Œä½¿ç”¨çš„æ¨¡å‹
        node_types = {}
        models_used = set()
        llm_count = 0
        code_count = 0
        
        if isinstance(nodes, list):
            for node in nodes:
                node_data = node.get('data', {})
                node_type = node_data.get('type', '') or node.get('type', '')
                
                if node_type:
                    # ç»Ÿè®¡èŠ‚ç‚¹ç±»å‹
                    if node_type not in ['custom', 'custom-note', 'custom-iteration-start']:
                        node_types[node_type] = node_types.get(node_type, 0) + 1
                    
                    # ç»Ÿè®¡ LLM èŠ‚ç‚¹
                    if node_type == 'llm':
                        llm_count += 1
                        # æå–æ¨¡å‹ä¿¡æ¯
                        model_info = node_data.get('model', {})
                        model_name = model_info.get('name', '')
                        provider = model_info.get('provider', '')
                        if model_name:
                            models_used.add(f"{provider}/{model_name}" if provider else model_name)
                    
                    # ç»Ÿè®¡ä»£ç èŠ‚ç‚¹
                    if node_type == 'code':
                        code_count += 1
        
        # æ ¼å¼åŒ–èŠ‚ç‚¹ç±»å‹æ˜¾ç¤º
        node_type_list = []
        type_display = {
            'llm': 'LLM',
            'code': 'ä»£ç ',
            'start': 'å¼€å§‹',
            'end': 'ç»“æŸ',
            'iteration': 'è¿­ä»£',
            'if-else': 'æ¡ä»¶',
            'variable-assigner': 'å˜é‡',
            'template-transform': 'æ¨¡æ¿',
            'http-request': 'HTTP',
            'tool': 'å·¥å…·',
            'knowledge-retrieval': 'çŸ¥è¯†åº“'
        }
        for t, count in node_types.items():
            display = type_display.get(t, t)
            node_type_list.append(f"{display}Ã—{count}")
        
        return {
            'name': name,
            'description': description,
            'icon': icon,
            'mode': mode,
            'mode_display': mode_display,
            'node_count': node_count,
            'edge_count': edge_count,
            'llm_count': llm_count,
            'code_count': code_count,
            'node_types': node_type_list[:6],
            'models_used': list(models_used)[:3],
            'raw_content': content
        }
    except Exception as e:
        return None

def scan_workflows():
    """æ‰«ææ‰€æœ‰å·¥ä½œæµæ–‡ä»¶"""
    workflows = {}
    
    for dir_path in WORKFLOW_DIRS:
        full_path = BASE_DIR / dir_path
        if not full_path.exists():
            continue
            
        for filepath in full_path.rglob('*.yml'):
            # è·³è¿‡å·²å¤„ç†çš„åŒåæ–‡ä»¶
            filename = filepath.name
            if filename in workflows:
                continue
                
            parsed = parse_workflow_file(filepath)
            if parsed:
                category = get_category(filename, parsed.get('description', ''))
                workflows[filename] = {
                    'filename': filename,
                    'name': parsed['name'] or filename.replace('.yml', ''),
                    'description': parsed['description'] or 'æš‚æ— æè¿°',
                    'icon': parsed.get('icon', 'ğŸ¤–'),
                    'mode': parsed.get('mode', 'workflow'),
                    'category': category,
                    'node_count': parsed['node_count'],
                    'edge_count': parsed.get('edge_count', 0),
                    'llm_count': parsed.get('llm_count', 0),
                    'code_count': parsed.get('code_count', 0),
                    'node_types': parsed.get('node_types', []),
                    'models_used': parsed.get('models_used', []),
                    'source_dir': dir_path,
                    'full_path': str(filepath)
                }
    
    return workflows

# ç¼“å­˜å·¥ä½œæµæ•°æ®
WORKFLOWS_CACHE = None

def get_workflows():
    global WORKFLOWS_CACHE
    if WORKFLOWS_CACHE is None:
        WORKFLOWS_CACHE = scan_workflows()
    return WORKFLOWS_CACHE

@app.route('/')
def index():
    return send_from_directory('static', 'index.html')

@app.route('/api/stats')
def get_stats():
    workflows = get_workflows()
    total_nodes = sum(w['node_count'] for w in workflows.values())
    total_llm = sum(w['llm_count'] for w in workflows.values())
    total_edges = sum(w['edge_count'] for w in workflows.values())
    
    # ç»Ÿè®¡æ‰€æœ‰ä½¿ç”¨çš„æ¨¡å‹
    all_models = set()
    for w in workflows.values():
        all_models.update(w.get('models_used', []))
    
    return jsonify({
        'total': len(workflows),
        'total_nodes': total_nodes,
        'total_llm': total_llm,
        'total_edges': total_edges,
        'unique_models': len(all_models),
        'categories': len(CATEGORY_KEYWORDS)
    })

@app.route('/api/categories')
def get_categories():
    return jsonify({
        'categories': [{'id': k, 'name': v['name']} for k, v in CATEGORY_KEYWORDS.items()]
    })

@app.route('/api/workflows')
def list_workflows():
    workflows = get_workflows()
    
    # ç­›é€‰å‚æ•°
    q = request.args.get('q', '').lower()
    category = request.args.get('category', 'all')
    page = int(request.args.get('page', 1))
    per_page = int(request.args.get('per_page', 20))
    
    # è¿‡æ»¤
    filtered = []
    for w in workflows.values():
        if category != 'all' and w['category'] != category:
            continue
        if q and q not in w['name'].lower() and q not in w['description'].lower():
            continue
        filtered.append(w)
    
    # æ’åº
    filtered.sort(key=lambda x: x['node_count'], reverse=True)
    
    # åˆ†é¡µ
    total = len(filtered)
    start = (page - 1) * per_page
    end = start + per_page
    paginated = filtered[start:end]
    
    return jsonify({
        'workflows': paginated,
        'total': total,
        'page': page,
        'pages': (total + per_page - 1) // per_page
    })

@app.route('/api/workflows/<filename>')
def get_workflow(filename):
    workflows = get_workflows()
    if filename not in workflows:
        return jsonify({'error': 'Not found'}), 404
    
    w = workflows[filename]
    filepath = Path(w['full_path'])
    
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        raw_yaml = yaml.safe_load(content)
    except:
        raw_yaml = {}
    
    return jsonify({
        **w,
        'raw_yaml': raw_yaml
    })

@app.route('/api/workflows/<filename>/download')
def download_workflow(filename):
    workflows = get_workflows()
    if filename not in workflows:
        return jsonify({'error': 'Not found'}), 404
    
    filepath = Path(workflows[filename]['full_path'])
    return send_file(filepath, as_attachment=True, download_name=filename)

@app.route('/api/category-counts')
def get_category_counts():
    workflows = get_workflows()
    counts = {}
    for cat_id in CATEGORY_KEYWORDS:
        counts[cat_id] = 0
    
    for w in workflows.values():
        cat = w.get('category', 'utility')
        if cat in counts:
            counts[cat] += 1
    
    return jsonify({'counts': counts})

if __name__ == '__main__':
    print("æ­£åœ¨æ‰«æ Dify å·¥ä½œæµ...")
    workflows = get_workflows()
    print(f"æ‰¾åˆ° {len(workflows)} ä¸ªå·¥ä½œæµ")
    print("å¯åŠ¨æœåŠ¡å™¨: http://localhost:4003")
    app.run(host='0.0.0.0', port=4003, debug=True)
