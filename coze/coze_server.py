#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Coze å·¥ä½œæµå±•ç¤ºæœåŠ¡å™¨ - Neubrutalism é£æ ¼
ç«¯å£: 4004
"""

from flask import Flask, jsonify, send_from_directory, request
from flask_cors import CORS
import os
import json
import zipfile
import re
from pathlib import Path

app = Flask(__name__, static_folder='static')
CORS(app)

# é…ç½®è·¯å¾„
BASE_DIR = Path(__file__).parent
WORKFLOWS_DIR = BASE_DIR / 'cozeworkflows-main' / 'cozeworkflows-main' / 'å·¥ä½œæµ200+åˆé›†åˆ†äº«'
MAPPING_FILE = BASE_DIR / 'workflow_mapping_simple.json'

# åŠ è½½å·¥ä½œæµæ˜ å°„ï¼ˆåŸºäº X ç¼–å·ï¼‰
WORKFLOW_MAPPING = {}
if MAPPING_FILE.exists():
    with open(MAPPING_FILE, 'r', encoding='utf-8') as f:
        WORKFLOW_MAPPING = json.load(f)

# åˆ†ç±»æ˜ å°„
CATEGORY_MAP = {
    'V': 'è§†é¢‘',
    'P': 'å›¾ç‰‡',
    'W': 'æ–‡æ¡£',
    'T': 'è¡¨æ ¼',
    'M': 'éŸ³é¢‘',
    'S': 'æœç´¢',
    'A': 'AI',
}

def extract_workflow_info(filename):
    """ä»æ–‡ä»¶åæå–å·¥ä½œæµä¿¡æ¯"""
    try:
        # æ–‡ä»¶åæ ¼å¼: Workflow-X178_S_search_2_buy_407_1-draft-4281.zip
        # æˆ–è€…: Workflow-X201_xhs_get_user_note_excel_1-draft-5169.zip
        # æˆ–è€…å¤šæ­¥éª¤: Workflow-X100_Vyuerhuibenpro_step2video_1-draft-6353.zip
        
        # æå– X ç¼–å·ï¼ˆæ”¯æŒ X åé¢ç›´æ¥è·Ÿæ•°å­—ï¼Œæˆ–è€… X_æ•°å­—ï¼‰
        x_match = re.match(r'Workflow-(X_?\d+)_(.+?)_\d+-draft', filename)
        if not x_match:
            x_match = re.match(r'Workflow-(X_?\d+)', filename)
            if not x_match:
                return None
        
        x_num_raw = x_match.group(1)  # å¦‚ X178 æˆ– X_201 æˆ– X100
        # æ ‡å‡†åŒ–ï¼šç§»é™¤ä¸‹åˆ’çº¿ï¼ˆX_201 -> X201ï¼‰
        x_num = x_num_raw.replace('_', '')  # å¦‚ X178 æˆ– X201 æˆ– X100
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¤šæ­¥éª¤å·¥ä½œæµ
        # é€šè¿‡æ–‡ä»¶åä¸­çš„å…³é”®è¯åŒ¹é…åˆ°æ­£ç¡®çš„ X ç¼–å·
        filename_lower = filename.lower()
        
        # æ£€æµ‹æ­¥éª¤ç¼–å·
        step_num = None
        if 'step1' in filename_lower or 'step_1' in filename_lower:
            step_num = 1
        elif 'step2' in filename_lower or 'step_2' in filename_lower:
            step_num = 2
        elif 'step3' in filename_lower or 'step_3' in filename_lower:
            step_num = 3
        
        # ç‰¹æ®Šå¤„ç†ï¼šæ£€æµ‹ draft_01, draft_02 ç­‰æ¨¡å¼ï¼ˆä»…ç”¨äºå‰ªæ˜ ç³»åˆ— jy_draftï¼‰
        # åªæœ‰å½“æ–‡ä»¶ååŒ…å« jy_draft æˆ– Vjy_draft ä¸”åé¢è·Ÿç€ 01/02 æ—¶æ‰åº”ç”¨
        if 'jy_draft' in filename_lower or 'vjy_draft' in filename_lower:
            draft_pattern_match = re.search(r'(?:jy|vjy)_draft[_]?0(\d)', filename_lower)
            if draft_pattern_match:
                draft_step = int(draft_pattern_match.group(1))
                # å¦‚æœæ–‡ä»¶åæ˜¯ X140_jy_draft_02ï¼Œåº”è¯¥åŒ¹é…åˆ° X141
                if draft_step > 1:
                    x_num_int = int(x_num.replace('X', ''))
                    x_num = f'X{x_num_int + draft_step - 1}'
        
        # å°è¯•åœ¨æ˜ å°„ä¸­æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„åŒ¹é…
        best_match = None
        best_score = 0
        
        for mapped_x_num, workflow_info in WORKFLOW_MAPPING.items():
            original_id = workflow_info['original_id'].lower()
            
            # æå–åŸå§‹ ID ä¸­çš„å…³é”®éƒ¨åˆ†ï¼ˆå»æ‰ X ç¼–å·ï¼‰
            id_parts = original_id.split('_')[1:]  # è·³è¿‡ X ç¼–å·éƒ¨åˆ†
            id_key = '_'.join(id_parts)
            
            # è®¡ç®—åŒ¹é…åˆ†æ•°
            score = 0
            if id_key in filename_lower:
                score = len(id_key)  # åŒ¹é…çš„å­—ç¬¦è¶Šå¤šï¼Œåˆ†æ•°è¶Šé«˜
                
                # å¦‚æœå®Œå…¨åŒ¹é…ï¼Œç»™äºˆæ›´é«˜åˆ†æ•°
                if id_key == '_'.join(filename_lower.split('_')[1:-2]):  # å»æ‰ Workflow-X å’Œ draft éƒ¨åˆ†
                    score += 1000
                
                if score > best_score:
                    best_score = score
                    best_match = mapped_x_num
        
        # å¦‚æœæ‰¾åˆ°æ›´å¥½çš„åŒ¹é…ï¼Œä½¿ç”¨å®ƒ
        if best_match and best_score > 10:  # è‡³å°‘åŒ¹é…10ä¸ªå­—ç¬¦
            x_num = best_match
        
        workflow_id = x_num.replace('X', '')  # å¦‚ 178 æˆ– 201
        
        # æŸ¥æ‰¾æ˜ å°„
        if x_num in WORKFLOW_MAPPING:
            workflow_info = WORKFLOW_MAPPING[x_num]
            name = workflow_info['description']  # ä½¿ç”¨ç®€ä»‹ä½œä¸ºåç§°
            description = workflow_info['description']  # æè¿°ä¹Ÿæ˜¯ç®€ä»‹
            category = workflow_info['type']
            workflow_type = workflow_info['type_code']
            
            # å¦‚æœæœ‰æ­¥éª¤ç¼–å·ï¼Œä¸”åç§°ä¸­æ²¡æœ‰"ç¬¬Xæ­¥"ï¼Œåˆ™æ·»åŠ æ­¥éª¤ä¿¡æ¯
            if step_num and f'ç¬¬{["ä¸€", "äºŒ", "ä¸‰"][step_num-1]}æ­¥' not in name:
                name = f"{name} - ç¬¬{step_num}æ­¥"
                description = f"{description} - ç¬¬{step_num}æ­¥"
        else:
            # å¦‚æœæ²¡æœ‰æ˜ å°„ï¼Œä½¿ç”¨é»˜è®¤å€¼
            workflow_type = 'W'
            category = 'å…¶ä»–'
            name = f'å·¥ä½œæµ #{workflow_id}'
            description = f'Coze å·¥ä½œæµæ¨¡æ¿ #{workflow_id}'
            if step_num:
                name += f' - ç¬¬{step_num}æ­¥'
                description += f' - ç¬¬{step_num}æ­¥'
        
        # å¯¹äºä¸åŒ X ç¼–å·ä½†åŠŸèƒ½ç›¸åŒçš„æƒ…å†µï¼Œæ·»åŠ ç‰ˆæœ¬æ ‡è¯†
        # æ£€æŸ¥æ–‡ä»¶åä¸­æ˜¯å¦æœ‰ç‰ˆæœ¬å·æ ‡è¯†
        version_indicators = {
            'V54': 'V54ç‰ˆ',
            'v2': 'V2ç‰ˆ',
            'v3': 'V3ç‰ˆ',
            'pro': 'ä¸“ä¸šç‰ˆ',
            'new': 'æ–°ç‰ˆ',
            'max': 'å¢å¼ºç‰ˆ',
            '_mul': 'å¤šé¡µç‰ˆ',
            'by_file': 'æ–‡ä»¶ç‰ˆ',
            'by_url': 'é“¾æ¥ç‰ˆ',
        }
        
        for indicator, label in version_indicators.items():
            if indicator.lower() in filename_lower and label not in name:
                name = f"{name} ({label})"
                description = f"{description} ({label})"
                break
        
        # ç‰¹æ®Šå¤„ç†ï¼šæ ¹æ®æ–‡ä»¶åä¸­çš„ç‰¹å¾æ·»åŠ æ›´å¤šåŒºåˆ†ä¿¡æ¯
        special_cases = {
            # X7 vs X21 - å°çº¢ä¹¦ç¬”è®°ï¼ˆæ ¹æ®æ–‡ä»¶åä¸­çš„ W_ å’Œ T åŒºåˆ†ï¼‰
            ('X7', 'W_red_word'): '(æ–‡æ¡£ç‰ˆ)',
            ('X21', 'Tredbook_table'): '(è¡¨æ ¼ç‰ˆ)',
            
            # X147 vs X183 - URLè½¬æ¢ï¼ˆæ ¹æ®ç‰ˆæœ¬å·ï¼‰
            ('X147', '_32_'): '(V32)',
            ('X183', '_589_'): '(V589)',
            
            # X91 vs X125 - å„¿ç«¥å“„ç¡ï¼ˆæ ¹æ®æ–‡ä»¶åç‰¹å¾ï¼‰
            ('X91', 'ertonghongshui'): '(V1)',
            ('X125', 'children_to_leep'): '(V2)',
            
            # X66 vs X233 - ä¹¦å•è§†é¢‘ï¼ˆæ ¹æ®åºå·ï¼‰
            ('X66', 'shudananhei'): '(V1)',
            ('X233', 'V_shudan_anhei'): '(V2)',
            
            # X241 vs X242 - ç”µå•†å®£ä¼ ï¼ˆæ ¹æ®æ–‡ä»¶åï¼‰
            ('X241', 'Vflux_dianshang'): '(Fluxç‰ˆ)',
            ('X242', 'flux_video'): '(è§†é¢‘ç‰ˆ)',
        }
        
        for (target_x, keyword), label in special_cases.items():
            if x_num == target_x and keyword.lower() in filename_lower and label not in name:
                name = f"{name} {label}"
                description = f"{description} {label}"
                break
        
        # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœæ–‡ä»¶åä¸­çš„ X ç¼–å·ä¸åŒ¹é…åˆ°çš„ X ç¼–å·ä¸åŒï¼Œæ·»åŠ åŸå§‹ç¼–å·æ ‡è¯†
        original_x_match = re.match(r'Workflow-(X_?\d+)', filename)
        if original_x_match:
            original_x = original_x_match.group(1).replace('_', '')
            if original_x != x_num:
                # æ–‡ä»¶å X ç¼–å·ä¸åŒ¹é…åˆ°çš„ä¸åŒï¼Œæ·»åŠ åŸå§‹ç¼–å·
                name = f"{name} [åŸå§‹:X{original_x.replace('X', '')}]"
                description = f"{description} [åŸå§‹:X{original_x.replace('X', '')}]"
        
        return {
            'id': workflow_id,
            'filename': filename,
            'name': name,
            'category': category,
            'type': workflow_type,
            'source': 'community',
            'description': description,
            'tags': [category, 'Coze', 'AI'],
            'url': f'/api/download/{filename}'
        }
    except Exception as e:
        print(f"Error parsing {filename}: {e}")
        return None

def pinyin_to_chinese(pinyin):
    """æ‹¼éŸ³è½¬ä¸­æ–‡ï¼ˆç®€åŒ–æ˜ å°„ï¼‰"""
    mapping = {
        'shipintiqu': 'è§†é¢‘æå–',
        'yuerhuiben': 'æœˆå„¿ç»˜æœ¬',
        'xiangsufeng': 'åƒç´ é£',
        'laohuangli': 'è€é»„å†',
        'daojiaoxuanxue': 'é“æ•™ç„å­¦',
        'wordstudy': 'å•è¯å­¦ä¹ ',
        'xioarenguo': 'å°äººå›½',
        'children': 'å„¿ç«¥',
        'gangqing': 'æ„Ÿæƒ…',
        'jybgm': 'æ•™è‚²èƒŒæ™¯éŸ³ä¹',
        'xingzuo': 'æ˜Ÿåº§',
        'gushici': 'å¤è¯—è¯',
        'doubao': 'è±†åŒ…',
        'taobao': 'æ·˜å®',
        'expression': 'è¡¨æƒ…',
        'konggu': 'ç©ºè°·',
        'nutrition': 'è¥å…»',
        'gaixie': 'æ”¹å†™',
        'caipin': 'èœå“',
        'zhishi': 'çŸ¥è¯†',
        'removebg': 'å»èƒŒæ™¯',
        'nainai': 'å¥¶å¥¶',
        'mingyan': 'åè¨€',
        'Sinology': 'å›½å­¦',
        'jianli': 'ç®€å†',
        'guoming': 'å›½å',
        'qinggan': 'æƒ…æ„Ÿ',
        'video2mp3': 'è§†é¢‘è½¬éŸ³é¢‘',
        'xhs': 'å°çº¢ä¹¦',
        'super': 'è¶…çº§',
        'table': 'è¡¨æ ¼',
        'song': 'æ­Œæ›²',
        'down': 'ä¸‹è½½',
        'donghua': 'åŠ¨ç”»',
        'danci': 'å•è¯',
        'captions': 'å­—å¹•',
        'cure': 'æ²»æ„ˆ',
        'grandpa': 'çˆ·çˆ·',
        'YS': 'è¯­é€Ÿ',
        'stick': 'è´´çº¸',
        'psy': 'å¿ƒç†',
        'book': 'ä¹¦ç±',
        'legen': 'ä¼ è¯´',
        'img': 'å›¾ç‰‡',
        'Historical': 'å†å²',
        'story': 'æ•…äº‹',
        'ztc': 'èŒåœº',
        'guzhu': 'å¤ç­',
        'Mythical': 'ç¥è¯',
        'ifbook': 'å¦‚æœä¹¦',
        'canspeak': 'ä¼šè¯´è¯',
        'shudan': 'ä¹¦å•',
        'zhiyu': 'æ²»æ„ˆ',
        'girl': 'å¥³å­©',
        'anhei': 'æš—é»‘',
        'english': 'è‹±è¯­',
        'meinv': 'ç¾å¥³',
        'tiaowu': 'è·³èˆ',
        'chengshi': 'åŸå¸‚',
        'juex': 'è§‰é†’',
        'oumei': 'æ¬§ç¾',
        'katong': 'å¡é€š',
        'flux': 'æµåŠ¨',
        'dianshang': 'ç”µå•†',
        'zhexue': 'å“²å­¦',
        'xiangyan': 'é¦™çƒŸ',
        'hecheng': 'åˆæˆ',
        'luoyan': 'è½é›',
        '3D': '3D',
        'new': 'æ–°',
        'dongwu': 'åŠ¨ç‰©',
        'yundong': 'è¿åŠ¨',
        'shangpin': 'å•†å“',
        'xuanchuan': 'å®£ä¼ ',
        'lishi': 'å†å²',
        'renwu': 'äººç‰©',
        'gufeng': 'å¤é£',
        'yuer': 'è‚²å„¿',
        'jinri': 'ä»Šæ—¥',
        'yulu': 'è¯­å½•',
        'jumao': 'å·¨çŒ«',
        'litiv': 'åŠ±å¿—',
        'guan': 'è§‚',
        'tianyuan': 'ç”°å›­',
        'hongshui': 'æ´ªæ°´',
        'lizhi': 'åŠ±å¿—',
        'diyirencheng': 'ç¬¬ä¸€äººç§°',
        'mn': 'ç¾å¥³',
    }
    
    # å°è¯•åŒ¹é…
    for key, value in mapping.items():
        if key.lower() in pinyin.lower():
            return value
    
    # å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œè¿”å›åŸå§‹æ‹¼éŸ³ï¼ˆé¦–å­—æ¯å¤§å†™ï¼‰
    return pinyin.capitalize()

# å·²ç§»é™¤ get_icon_by_category å‡½æ•°ï¼Œä¸å†ä½¿ç”¨å›¾æ ‡

def scan_workflows():
    """æ‰«æå·¥ä½œæµæ–‡ä»¶"""
    workflows_dict = {}  # ç”¨äºå­˜å‚¨æ¯ä¸ªå”¯ä¸€é”®çš„æœ€æ–°ç‰ˆæœ¬
    
    if not WORKFLOWS_DIR.exists():
        print(f"Warning: Workflows directory not found: {WORKFLOWS_DIR}")
        return []
    
    for file in WORKFLOWS_DIR.glob('*.zip'):
        info = extract_workflow_info(file.name)
        if info:
            # æå– draft ç¼–å·
            draft_match = re.search(r'-draft-(\d+)\.zip$', file.name)
            draft_num = int(draft_match.group(1)) if draft_match else 0
            
            # åˆ›å»ºå”¯ä¸€é”®ï¼šä½¿ç”¨æ–‡ä»¶åä¸­çš„åŸå§‹ X ç¼–å·ï¼ˆä¸æ˜¯åŒ¹é…åçš„ï¼‰
            # è¿™æ ·å¯ä»¥é¿å…ä¸åŒçš„æ–‡ä»¶è¢«é”™è¯¯åœ°å»é‡
            # ä¾‹å¦‚: X137_Vjy_draft_08 å’Œ X144_Vdraft_03_01 ä¼šè¢«è§†ä¸ºä¸åŒçš„å·¥ä½œæµ
            
            # æå–æ–‡ä»¶åä¸­çš„åŸå§‹ X ç¼–å·
            original_x_match = re.match(r'Workflow-(X_?\d+)', file.name)
            if original_x_match:
                original_x = original_x_match.group(1).replace('_', '')
            else:
                original_x = info['id']
            
            # ä½¿ç”¨åŸå§‹ X ç¼–å· + æ–‡ä»¶åçš„å‰å‡ ä¸ªå…³é”®éƒ¨åˆ†ä½œä¸ºå”¯ä¸€é”®
            filename_parts = file.name.replace('Workflow-', '').split('_')
            
            # å–å‰3-4ä¸ªéƒ¨åˆ†ä½œä¸ºå”¯ä¸€é”®ï¼ˆåŒ…å«åŸå§‹ X ç¼–å·ï¼‰
            if len(filename_parts) >= 3:
                unique_key = f"{original_x}_{filename_parts[1]}_{filename_parts[2]}"
            else:
                unique_key = original_x
            
            # å¦‚æœè¿™ä¸ªé”®å·²ç»å­˜åœ¨ï¼Œæ¯”è¾ƒ draft ç¼–å·ï¼Œä¿ç•™è¾ƒæ–°çš„
            if unique_key in workflows_dict:
                existing_draft = workflows_dict[unique_key]['draft_num']
                if draft_num > existing_draft:
                    # æ–°ç‰ˆæœ¬æ›´æ–°ï¼Œæ›¿æ¢
                    workflows_dict[unique_key] = {
                        'info': info,
                        'draft_num': draft_num,
                        'filename': file.name
                    }
            else:
                # ç¬¬ä¸€æ¬¡é‡åˆ°è¿™ä¸ªé”®
                workflows_dict[unique_key] = {
                    'info': info,
                    'draft_num': draft_num,
                    'filename': file.name
                }
    
    # åªè¿”å›å·¥ä½œæµä¿¡æ¯ï¼Œä¸åŒ…å« draft_num
    return [item['info'] for item in workflows_dict.values()]

# ç¼“å­˜å·¥ä½œæµæ•°æ®
WORKFLOWS_CACHE = None

def get_workflows():
    """è·å–å·¥ä½œæµåˆ—è¡¨ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    global WORKFLOWS_CACHE
    if WORKFLOWS_CACHE is None:
        WORKFLOWS_CACHE = scan_workflows()
    return WORKFLOWS_CACHE

@app.route('/')
def index():
    """é¦–é¡µ"""
    return send_from_directory('static', 'index.html')

@app.route('/<path:path>')
def static_files(path):
    """é™æ€æ–‡ä»¶"""
    return send_from_directory('static', path)

@app.route('/api/workflows')
def api_workflows():
    """è·å–å·¥ä½œæµåˆ—è¡¨"""
    try:
        workflows = get_workflows()
        
        # è·å–æŸ¥è¯¢å‚æ•°
        query = request.args.get('q', '').lower()
        category = request.args.get('category', 'all')
        page = int(request.args.get('page', 1))
        per_page = int(request.args.get('per_page', 20))
        
        # ç­›é€‰
        filtered = workflows
        
        if category != 'all':
            filtered = [w for w in filtered if w['category'] == category]
        
        if query:
            filtered = [w for w in filtered if 
                query in w['name'].lower() or 
                query in w['description'].lower() or
                any(query in tag.lower() for tag in w['tags'])]
        
        # åˆ†é¡µ
        total = len(filtered)
        start = (page - 1) * per_page
        end = start + per_page
        paginated = filtered[start:end]
        
        return jsonify({
            'workflows': paginated,
            'total': total,
            'page': page,
            'per_page': per_page,
            'pages': (total + per_page - 1) // per_page
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/stats')
def api_stats():
    """è·å–ç»Ÿè®¡ä¿¡æ¯"""
    try:
        workflows = get_workflows()
        categories = set(w['category'] for w in workflows)
        
        return jsonify({
            'total': len(workflows),
            'categories': len(categories),
            'official': 0,  # ç¤¾åŒºç‰ˆæœ¬æ²¡æœ‰å®˜æ–¹æ•°æ®
            'community': len(workflows)
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/categories')
def api_categories():
    """è·å–åˆ†ç±»åˆ—è¡¨"""
    try:
        workflows = get_workflows()
        categories = sorted(set(w['category'] for w in workflows))
        
        return jsonify({
            'categories': [{'id': cat, 'name': cat} for cat in categories]
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/category-counts')
def api_category_counts():
    """è·å–å„åˆ†ç±»çš„å·¥ä½œæµæ•°é‡"""
    try:
        workflows = get_workflows()
        counts = {}
        
        for w in workflows:
            cat = w['category']
            counts[cat] = counts.get(cat, 0) + 1
        
        return jsonify({'counts': counts})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/download/<filename>')
def api_download(filename):
    """ä¸‹è½½å·¥ä½œæµæ–‡ä»¶"""
    try:
        file_path = WORKFLOWS_DIR / filename
        if file_path.exists():
            return send_from_directory(WORKFLOWS_DIR, filename, as_attachment=True)
        else:
            return jsonify({'error': 'File not found'}), 404
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/refresh')
def api_refresh():
    """åˆ·æ–°ç¼“å­˜"""
    global WORKFLOWS_CACHE
    WORKFLOWS_CACHE = None
    workflows = get_workflows()
    return jsonify({
        'message': 'Cache refreshed',
        'total': len(workflows)
    })

if __name__ == '__main__':
    print("=" * 60)
    print("ğŸ¤– Coze å·¥ä½œæµå±•ç¤ºæœåŠ¡å™¨ - Neubrutalism é£æ ¼")
    print("=" * 60)
    print(f"ğŸ“ å·¥ä½œæµç›®å½•: {WORKFLOWS_DIR}")
    print(f"ğŸŒ è®¿é—®åœ°å€: http://localhost:4004")
    print(f"ğŸ”„ API ç«¯ç‚¹: http://localhost:4004/api/workflows")
    print("=" * 60)
    
    # é¢„åŠ è½½å·¥ä½œæµ
    workflows = get_workflows()
    print(f"âœ… å·²åŠ è½½ {len(workflows)} ä¸ªå·¥ä½œæµ")
    
    # æ˜¾ç¤ºåˆ†ç±»ç»Ÿè®¡
    categories = {}
    for w in workflows:
        cat = w['category']
        categories[cat] = categories.get(cat, 0) + 1
    
    print("\nğŸ“Š åˆ†ç±»ç»Ÿè®¡:")
    for cat, count in sorted(categories.items()):
        print(f"  {cat}: {count}")
    
    print("\nğŸš€ æœåŠ¡å™¨å¯åŠ¨ä¸­...\n")
    
    app.run(host='0.0.0.0', port=4004, debug=True)
