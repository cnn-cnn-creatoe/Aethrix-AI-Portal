{
  "name": "变量Demo",
  "nodes": [
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        0,
        0
      ],
      "id": "7c56be90-c808-4550-b065-3cd6675b011a",
      "name": "When clicking ‘Test workflow’"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "14e7e528-ed11-4f0e-9dc6-f6ab90a7a696",
              "name": "=output",
              "value": "={{ $json.title }}{{ $json.pubDate }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        480,
        0
      ],
      "id": "2ad1a397-3d12-46bf-be0e-f7d7373a8a99",
      "name": "Edit Fields",
      "notesInFlow": true,
      "notes": "演示当前输入项"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "110b2e4c-3d3a-4568-a134-d4c548124625",
              "name": "test",
              "value": "={{ $('RSS1').item.json.title}}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        740,
        0
      ],
      "id": "e526d6dd-8f6d-43f0-a86c-227cd7caf8f5",
      "name": "Edit Fields1",
      "notesInFlow": true,
      "notes": "其他节点输出（跨节点获取数据）"
    },
    {
      "parameters": {
        "url": "https://rsshub.app/aibase/news",
        "options": {}
      },
      "type": "n8n-nodes-base.rssFeedRead",
      "typeVersion": 1.1,
      "position": [
        220,
        0
      ],
      "id": "b2a79497-5792-4ffe-b717-1f625a29151e",
      "name": "RSS1"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "334b90f1-f0ba-4cf1-b08a-83c89ef98738",
              "leftValue": "={{ $('RSS1').item.json.isoDate }}",
              "rightValue": "={{new Date(Date.now() - 24 * 60 * 60 * 1000).toISOString()}}",
              "operator": {
                "type": "dateTime",
                "operation": "after"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.filter",
      "typeVersion": 2.2,
      "position": [
        480,
        240
      ],
      "id": "8700e6c0-7233-44d5-9016-97005cca6ba3",
      "name": "Filter",
      "notesInFlow": true,
      "notes": "用时间变量筛选新闻"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "1ff20948-3b3d-4d69-b346-094c7fda4882",
              "name": "now",
              "value": "={{ $now.toUTC()}}",
              "type": "string"
            },
            {
              "id": "4c7c244a-1399-4e20-bf49-04445eafac9c",
              "name": "before24",
              "value": "={{ new Date(new Date().getTime() - 24*3600*1000).toISOString() }}",
              "type": "string"
            },
            {
              "id": "8ed006c5-1106-4e5f-b73d-c0402516afad",
              "name": "another24",
              "value": "={{ $now.minus(24,\"hours\") }}",
              "type": "string"
            },
            {
              "id": "3d30f606-0c0d-44f3-ac22-75a1976412b2",
              "name": "today",
              "value": "={{ $today }}",
              "type": "string"
            },
            {
              "id": "bfa01547-e247-451e-bf8e-cc9506a28f77",
              "name": "todayformat",
              "value": "={{ $today.toFormat(\"yyyy-MM-dd\") }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1000,
        0
      ],
      "id": "1c1b43e5-0430-4c1f-b7d8-8fbda5fe063a",
      "name": "Edit Fields2",
      "notesInFlow": true,
      "executeOnce": true,
      "notes": "时间和日期"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "e9f9b4ef-3824-48b7-8328-88c83e636f01",
              "name": "test",
              "value": "={{ $now.minus(24,\"hours\") }}",
              "type": "string"
            },
            {
              "id": "c3a5f531-5265-4cbc-bbba-c9a209585b33",
              "name": "num",
              "value": "=2",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1220,
        0
      ],
      "id": "4e9552bf-7f99-4b05-af83-b2572ea611ff",
      "name": "Edit Fields3",
      "notesInFlow": true,
      "notes": "数据转换函数"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "02b3e60e-02d0-4de5-b0ae-9e3ae4593906",
              "name": "newnum",
              "value": "={{ $json.num.quote() }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1440,
        0
      ],
      "id": "6b494271-3acf-4c13-bf61-f2024afddf6d",
      "name": "Edit Fields4"
    }
  ],
  "pinData": {
    "RSS1": [
      {
        "json": {
          "creator": "AI Base",
          "title": "甲骨文建设 OpenAI 数据中心进展缓慢 或将影响未来合作",
          "link": "https://www.aibase.com/zh/news/16934",
          "pubDate": "Tue, 08 Apr 2025 10:06:18 GMT",
          "author": "AI Base",
          "content": "<p>甲骨文（Oracle）在德克萨斯州阿比林市为 OpenAI 建设一座庞大的数据中心，项目规模相当于17个足球场。然而，令人担忧的是，该数据中心的建设进度缓慢，当前状态非常 “空旷”。据知情人士透露，如果建设迟迟未能完工，OpenAI 可能会考虑终止与甲骨文的合作协议，这无疑将给甲骨文带来数十亿美元的损失。</p><p>OpenAI 首席执行官山姆・奥特曼（Sam Altman）与甲骨文董事长拉里・埃里森(Larry Ellison)在这项合作中都寄予厚望。然而，随着时间的推移，建设进度的滞后给双方都带来了压力。负责甲骨文数据中心业务的高管马欣德・蒂亚加拉扬(Mahesh Thiyagarajan)在最近的会议上对建筑承包商们表达了不满，要求他们加快工期，即使这可能意味着需要增加工人和超支。</p><p style=\"text-align: center\"><img src=\"https://pic.chinaz.com/picmap/202302112107341554_1.jpg\" title=\"ChatGPT OpenAI  人工智能 (1) (图片版权所属：站长之家)\" alt=\"ChatGPT OpenAI  人工智能 (1)\" referrerpolicy=\"no-referrer\"></p><p>这次项目的推进面临着巨大的挑战，特别是在能源输送系统的建设上。甲骨文显然正处于一个陌生的领域，必须在客户的需求与自身能力之间找到平衡。自从 OpenAI 等公司对大型设施的需求不断增长以来，甲骨文和其他云服务提供商都承受着前所未有的风险，尤其是在现金流方面。</p><p>作为曾经以数据库软件闻名的公司，甲骨文如今几乎是偶然间进入了人工智能数据中心的热潮。埃里森在上个月的财报电话会议上表示，甲骨文预计将在不久的将来签署与 “星际之门” 项目的首个大型合同。这个项目的目标是建造价值高达5000亿美元的人工智能数据中心，OpenAI 和其他公司将共同参与其中。</p><p>不过，知情人士指出，除了阿比林的数据中心建设，甲骨文在星际之门项目中的角色可能会受到限制，OpenAI 正在与甲骨文的竞争对手进行潜在合作谈判。同时，特朗普政府最近宣布的全球关税政策也可能导致甲骨文新设施所需的服务器和材料成本大幅上涨。</p><p>自从 ChatGPT 在2022年推出以来，甲骨文的股价曾上涨77%，但由于新政策的影响，这一增幅在上周缩小至54%。投资者仍对甲骨文未来在人工智能领域的潜力抱有希望，但目前的项目延误无疑为公司的前景增添了不确定性。</p>",
          "contentSnippet": "甲骨文（Oracle）在德克萨斯州阿比林市为 OpenAI 建设一座庞大的数据中心，项目规模相当于17个足球场。然而，令人担忧的是，该数据中心的建设进度缓慢，当前状态非常 “空旷”。据知情人士透露，如果建设迟迟未能完工，OpenAI 可能会考虑终止与甲骨文的合作协议，这无疑将给甲骨文带来数十亿美元的损失。\nOpenAI 首席执行官山姆・奥特曼（Sam Altman）与甲骨文董事长拉里・埃里森(Larry Ellison)在这项合作中都寄予厚望。然而，随着时间的推移，建设进度的滞后给双方都带来了压力。负责甲骨文数据中心业务的高管马欣德・蒂亚加拉扬(Mahesh Thiyagarajan)在最近的会议上对建筑承包商们表达了不满，要求他们加快工期，即使这可能意味着需要增加工人和超支。\n\n这次项目的推进面临着巨大的挑战，特别是在能源输送系统的建设上。甲骨文显然正处于一个陌生的领域，必须在客户的需求与自身能力之间找到平衡。自从 OpenAI 等公司对大型设施的需求不断增长以来，甲骨文和其他云服务提供商都承受着前所未有的风险，尤其是在现金流方面。\n作为曾经以数据库软件闻名的公司，甲骨文如今几乎是偶然间进入了人工智能数据中心的热潮。埃里森在上个月的财报电话会议上表示，甲骨文预计将在不久的将来签署与 “星际之门” 项目的首个大型合同。这个项目的目标是建造价值高达5000亿美元的人工智能数据中心，OpenAI 和其他公司将共同参与其中。\n不过，知情人士指出，除了阿比林的数据中心建设，甲骨文在星际之门项目中的角色可能会受到限制，OpenAI 正在与甲骨文的竞争对手进行潜在合作谈判。同时，特朗普政府最近宣布的全球关税政策也可能导致甲骨文新设施所需的服务器和材料成本大幅上涨。\n自从 ChatGPT 在2022年推出以来，甲骨文的股价曾上涨77%，但由于新政策的影响，这一增幅在上周缩小至54%。投资者仍对甲骨文未来在人工智能领域的潜力抱有希望，但目前的项目延误无疑为公司的前景增添了不确定性。",
          "guid": "https://www.aibase.com/zh/news/16934",
          "isoDate": "2025-04-08T10:06:18.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "《人工智能指数报告2025》：全球AI创新引擎加速 中国多领域展现强劲上升势头",
          "link": "https://www.aibase.com/zh/news/16933",
          "pubDate": "Tue, 08 Apr 2025 09:51:24 GMT",
          "author": "AI Base",
          "content": "<p><span style=\"text-indent: 2em;\">&nbsp;2025年4月8日报道：&nbsp; 近日，斯坦福HAI发布的《人工智能指数报告2025》如同人工智能领域的一份“年度体检报告”，</span><strong style=\"text-indent: 2em;\">以前所未有的广度和深度揭示了全球AI研究、开发、部署和社会影响的<span class=\"spamTxt\">最新</span>动态</strong><span style=\"text-indent: 2em;\">。报告清晰地描绘出，全球人工智能正以惊人的速度发展，特别是在模型性能的飞跃、硬件效率的显著提升以及AI在各行各业的广泛落地等方面，都取得了令人瞩目的成就。这份报告不仅是AI领域从业者的重要参考，也为社会各界理解AI的未来走向提供了关键洞察。</span></p><p style=\"text-align: center;\"><span style=\"text-indent: 2em;\"><img src=\"https://upload.chinaz.com/2025/0408/6387973145579423498552099.png\" title=\"QQ_1744105856820.png\" alt=\"QQ_1744105856820.png\" referrerpolicy=\"no-referrer\"></span></p><p><strong>科研实力版图重塑：东亚领跑论文产出，中国专利“加速度”引人注目</strong></p><p>报告的<span class=\"spamTxt\">第一</span>章“研究与开发”就展现出全球AI科研力量的新格局。 2023 年，<strong>东亚和太平洋地区以34.5%的占比，傲视全球AI出版物产出</strong>。这一数据凸显了该地区在AI基础研究领域的强大活力。与此同时，欧洲和中亚（18.2%）以及北美（10.3%）也贡献了重要的研究成果。更值得关注的是，中国在AI专利授权数量方面呈现出显著的增长态势，其按每 10 万居民计算的变化百分比尤为突出。这预示着中国不仅在AI研究上持续发力，更在将科研成果转化为实际应用方面展现出强劲的“加速度”。此外，今年的报告还<span class=\"spamTxt\">首次</span>加入了对AI模型训练能源消耗、环境影响以及模型推理成本随时间变化的分析，这无疑为我们更全面地评估AI发展的可持续性提供了重要依据.</p><p><strong>明星模型竞相涌现：参数规模持续膨胀，工业界“钞能力”尽显</strong></p><p>自 2010 年代初以来，机器学习模型的参数数量经历了指数级的增长，这不仅仅是数字上的变化，更反映了模型架构的日益复杂精巧、海量数据的可获得性、硬件性能的突飞猛进以及更大模型在解决复杂问题上的卓越有效性。报告特别强调，<strong>高参数模型在工业界的广泛应用尤为显著</strong>。这清晰地表明，<strong>行业巨头们拥有承担大规模数据训练所需巨大计算成本的雄厚实力</strong>。在模型的可访问性方面， 2024 年，开放权重（非商业用途）和通过API访问的知名AI模型数量依然占据着重要的地位。这预示着AI技术的普及和 democratisation 仍在持续推进。</p><p><strong>硬件引擎效能飞跃：能效比惊人提升，绿色AI成为未来焦点</strong></p><p>支撑AI发展的基础设施——硬件生态系统也在不断进化，而能效正成为衡量其先进性的关键指标。报告中引用了一个令人振奋的例子： 2024 年 3 月发布的英伟达B100 的能效高达每瓦2. 5 万亿次浮点运算，与 2016 年 4 月发布的英伟达P100 的每瓦 740 亿次浮点运算相比，<strong>能效足足提升了33. 8 倍</strong>。这一巨大的飞跃不仅意味着更强大的计算能力，也为降低AI的能源消耗和环境足迹带来了希望。报告对AI训练的能源需求和环境影响进行了评估，并展示了部分AI模型的碳排放估算，<strong>预示着“绿色AI”将成为未来AI发展的重要方向</strong>.</p><p><strong>开源力量蓬勃发展：GitHub星光熠熠，美国引领社区贡献</strong></p><p>开源AI软件生态系统依然充满活力。截至 2024 年，美国在GitHub AI项目中贡献了<span class=\"spamTxt\">最高</span>的比例，达到23.42%，紧随其后的是欧洲（19.15%）和印度（19.91%）。GitHub的“Star”数量直观地反映了开发者社区对开源项目的认可和支持。TensorFlow、OpenCV、Keras和PyTorch等因其在开发者群体中的广泛流行而成为最受瞩目的项目。<strong> 2024 年，美国获得的GitHub Star总数高达 2110 万</strong>，再次证明其在开源AI领域的领先地位。</p><p><strong>技术能力持续突破：视频生成逼真度惊艳，自动驾驶安全性或超人类</strong></p><p>在技术性能方面，报告覆盖了语言、视觉、视频、代码和机器人等多个前沿领域。Chatbot Arena等开放评估平台被广泛用于衡量<span class=\"spamTxt\">顶级</span>AI系统的能力。<strong>尤其值得一提的是视频生成领域的飞速进展</strong>，报告中提到，Pika在 2025 年生成的“威尔·史密斯吃意大利面”的视频质量相比 2023 年的版本有了质的飞跃。在代码生成方面，SWE-bench等基准测试被用于评估AI模型解决实际软件工程问题的能力。自动驾驶技术也在快速演进，Waymo等公司在无人驾驶里程方面取得了显著成就。报告中一项初步研究甚至指出，<strong>自动驾驶汽车可能比人类驾驶的汽车更加安全</strong>，其数据显示，Waymo车辆每百万英里报告的事故数量显著低于人类驾驶的基准。中国的自动驾驶发展同样迅猛.</p><p><strong>负责任的AI日益重要：学术界企业界双向发力，AI事件敲响警钟</strong></p><p>“负责任的AI”（RAI）已成为AI发展不可忽视的关键议题。学术界对RAI的重视程度持续上升，<span class=\"spamTxt\">顶级</span>AI会议接受的RAI相关论文数量显著增加， 2024 年达到了 1278 篇，较 2023 年的 992 篇增长了28.8%。美国在RAI论文发表数量上处于领先地位。隐私和数据治理、公平性、透明度和可解释性以及安全是RAI研究的核心领域。企业界也开始加大对RAI的投入，尽管投资规模与公司收入有所关联。然而，一份调查显示，<strong>相当比例的组织报告曾经历过AI事件</strong>，这为AI的负责任发展敲响了警钟。网络安全、监管合规和个人隐私是企业认为最相关的AI风险。</p><p><strong>AI赋能经济与科研：人才需求持续攀升，生物医药潜力无限</strong></p><p>AI对经济的驱动作用日益凸显。报告分析了全球和美国的AI劳动力需求，以及不同技能和行业的AI人才分布。全球企业在AI领域的投资持续保持高位，<strong>仅 2024 年生成式AI的全球私人投资就高达33. 94 亿美元</strong>。全球新成立的AI公司数量也在不断增长。在科学和医学领域，AI展现出巨大的潜力。AlphaFold3 能够更精确地预测蛋白质与DNA、RNA等生物分子的相互作用，有望加速药物研发进程。大型语言模型在医疗保健任务中的性能评估也备受关注.</p><p><strong>政策与治理积极应对：公共部门投资加码，全球合作提上日程</strong></p><p>公共部门对AI的投资是推动AI发展的重要力量。报告分析了美国和欧洲在AI相关合同方面的公共支出以及美国的AI相关资助情况。全球范围内，包括G7 在内的国际组织也在积极探讨AI治理和监管框架.</p><p><strong>展望未来</strong></p><p>《人工智能指数报告2025》不仅记录了过去一年全球AI领域的显著进展，更预示着AI技术将在未来持续深刻地影响我们的生活和工作。面对AI带来的机遇与挑战，加强国际合作，推动负责任的AI发展，将是确保AI技术惠及全人类的关键。</p><p><strong>报告下载地址：</strong>https://hai-production.s3.amazonaws.com/files/hai_ai_index_report_2025.pdf</p><p><br></p>",
          "contentSnippet": "2025年4月8日报道：  近日，斯坦福HAI发布的《人工智能指数报告2025》如同人工智能领域的一份“年度体检报告”，以前所未有的广度和深度揭示了全球AI研究、开发、部署和社会影响的最新动态。报告清晰地描绘出，全球人工智能正以惊人的速度发展，特别是在模型性能的飞跃、硬件效率的显著提升以及AI在各行各业的广泛落地等方面，都取得了令人瞩目的成就。这份报告不仅是AI领域从业者的重要参考，也为社会各界理解AI的未来走向提供了关键洞察。\n\n科研实力版图重塑：东亚领跑论文产出，中国专利“加速度”引人注目\n报告的第一章“研究与开发”就展现出全球AI科研力量的新格局。 2023 年，东亚和太平洋地区以34.5%的占比，傲视全球AI出版物产出。这一数据凸显了该地区在AI基础研究领域的强大活力。与此同时，欧洲和中亚（18.2%）以及北美（10.3%）也贡献了重要的研究成果。更值得关注的是，中国在AI专利授权数量方面呈现出显著的增长态势，其按每 10 万居民计算的变化百分比尤为突出。这预示着中国不仅在AI研究上持续发力，更在将科研成果转化为实际应用方面展现出强劲的“加速度”。此外，今年的报告还首次加入了对AI模型训练能源消耗、环境影响以及模型推理成本随时间变化的分析，这无疑为我们更全面地评估AI发展的可持续性提供了重要依据.\n明星模型竞相涌现：参数规模持续膨胀，工业界“钞能力”尽显\n自 2010 年代初以来，机器学习模型的参数数量经历了指数级的增长，这不仅仅是数字上的变化，更反映了模型架构的日益复杂精巧、海量数据的可获得性、硬件性能的突飞猛进以及更大模型在解决复杂问题上的卓越有效性。报告特别强调，高参数模型在工业界的广泛应用尤为显著。这清晰地表明，行业巨头们拥有承担大规模数据训练所需巨大计算成本的雄厚实力。在模型的可访问性方面， 2024 年，开放权重（非商业用途）和通过API访问的知名AI模型数量依然占据着重要的地位。这预示着AI技术的普及和 democratisation 仍在持续推进。\n硬件引擎效能飞跃：能效比惊人提升，绿色AI成为未来焦点\n支撑AI发展的基础设施——硬件生态系统也在不断进化，而能效正成为衡量其先进性的关键指标。报告中引用了一个令人振奋的例子： 2024 年 3 月发布的英伟达B100 的能效高达每瓦2. 5 万亿次浮点运算，与 2016 年 4 月发布的英伟达P100 的每瓦 740 亿次浮点运算相比，能效足足提升了33. 8 倍。这一巨大的飞跃不仅意味着更强大的计算能力，也为降低AI的能源消耗和环境足迹带来了希望。报告对AI训练的能源需求和环境影响进行了评估，并展示了部分AI模型的碳排放估算，预示着“绿色AI”将成为未来AI发展的重要方向.\n开源力量蓬勃发展：GitHub星光熠熠，美国引领社区贡献\n开源AI软件生态系统依然充满活力。截至 2024 年，美国在GitHub AI项目中贡献了最高的比例，达到23.42%，紧随其后的是欧洲（19.15%）和印度（19.91%）。GitHub的“Star”数量直观地反映了开发者社区对开源项目的认可和支持。TensorFlow、OpenCV、Keras和PyTorch等因其在开发者群体中的广泛流行而成为最受瞩目的项目。 2024 年，美国获得的GitHub Star总数高达 2110 万，再次证明其在开源AI领域的领先地位。\n技术能力持续突破：视频生成逼真度惊艳，自动驾驶安全性或超人类\n在技术性能方面，报告覆盖了语言、视觉、视频、代码和机器人等多个前沿领域。Chatbot Arena等开放评估平台被广泛用于衡量顶级AI系统的能力。尤其值得一提的是视频生成领域的飞速进展，报告中提到，Pika在 2025 年生成的“威尔·史密斯吃意大利面”的视频质量相比 2023 年的版本有了质的飞跃。在代码生成方面，SWE-bench等基准测试被用于评估AI模型解决实际软件工程问题的能力。自动驾驶技术也在快速演进，Waymo等公司在无人驾驶里程方面取得了显著成就。报告中一项初步研究甚至指出，自动驾驶汽车可能比人类驾驶的汽车更加安全，其数据显示，Waymo车辆每百万英里报告的事故数量显著低于人类驾驶的基准。中国的自动驾驶发展同样迅猛.\n负责任的AI日益重要：学术界企业界双向发力，AI事件敲响警钟\n“负责任的AI”（RAI）已成为AI发展不可忽视的关键议题。学术界对RAI的重视程度持续上升，顶级AI会议接受的RAI相关论文数量显著增加， 2024 年达到了 1278 篇，较 2023 年的 992 篇增长了28.8%。美国在RAI论文发表数量上处于领先地位。隐私和数据治理、公平性、透明度和可解释性以及安全是RAI研究的核心领域。企业界也开始加大对RAI的投入，尽管投资规模与公司收入有所关联。然而，一份调查显示，相当比例的组织报告曾经历过AI事件，这为AI的负责任发展敲响了警钟。网络安全、监管合规和个人隐私是企业认为最相关的AI风险。\nAI赋能经济与科研：人才需求持续攀升，生物医药潜力无限\nAI对经济的驱动作用日益凸显。报告分析了全球和美国的AI劳动力需求，以及不同技能和行业的AI人才分布。全球企业在AI领域的投资持续保持高位，仅 2024 年生成式AI的全球私人投资就高达33. 94 亿美元。全球新成立的AI公司数量也在不断增长。在科学和医学领域，AI展现出巨大的潜力。AlphaFold3 能够更精确地预测蛋白质与DNA、RNA等生物分子的相互作用，有望加速药物研发进程。大型语言模型在医疗保健任务中的性能评估也备受关注.\n政策与治理积极应对：公共部门投资加码，全球合作提上日程\n公共部门对AI的投资是推动AI发展的重要力量。报告分析了美国和欧洲在AI相关合同方面的公共支出以及美国的AI相关资助情况。全球范围内，包括G7 在内的国际组织也在积极探讨AI治理和监管框架.\n展望未来\n《人工智能指数报告2025》不仅记录了过去一年全球AI领域的显著进展，更预示着AI技术将在未来持续深刻地影响我们的生活和工作。面对AI带来的机遇与挑战，加强国际合作，推动负责任的AI发展，将是确保AI技术惠及全人类的关键。\n报告下载地址：https://hai-production.s3.amazonaws.com/files/hai_ai_index_report_2025.pdf",
          "guid": "https://www.aibase.com/zh/news/16933",
          "isoDate": "2025-04-08T09:51:24.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "2025年全国大模型算法备案奖励补贴政策重磅发布，最高补贴5000万元！（附补贴一览表）",
          "link": "https://www.aibase.com/zh/news/16932",
          "pubDate": "Tue, 08 Apr 2025 08:31:02 GMT",
          "author": "AI Base",
          "content": "<p><strong>【导语】</strong></p><p>随着人工智能技术的迅猛发展，大模型与算法已成为推动各行业创新的核心力量。为规范技术应用并鼓励企业合规发展，全国各省市纷纷出台大模型算法备案奖励补贴政策，<span class=\"spamTxt\">最高</span>补贴金额达5000万元。以下是2025年全国各省市政策汇总详情。</p><h3><strong>一、政策背景与意义</strong></h3><p>大模型备案和算法备案是国家为规范生成式人工智能技术和算法推荐服务而推出的重要制度。通过备案，企业需披露技术细节，确保数据安全和算法透明，从而维护网络空间秩序、保障用户权益并促进行业健康发展。截至2025年3月，全国算法备案数量已达3234个，大模型备案数量为407个，覆盖金融、医疗、教育等多个领域。</p><p>全国大模型备案和算法备案区域分布：</p><ul><ul style=\"list-style-type: square;\"><li>算法备案：北京（27.64%）、广东（21.03%）、上海（14.29%）。</li><li>大模型备案：北京（ 117 款）、上海（ 123 款）、广东（ 40 款）。</li></ul></ul><h3><strong>二、全国各省市奖励补贴政策一览表</strong></h3><table><tbody><tr class=\"firstRow\"></tr></tbody></table><table><thead><tr class=\"firstRow\"><th>省市</th><th>地区</th><th>政策内容</th></tr></thead><tbody><tr><td>广东省</td><td>广州海珠区</td><td style=\"word-break: break-all;\">1. 企业<span class=\"spamTxt\">首次</span>完成<span class=\"spamTxt\">国家级</span>生成式人工智能上线备案（大语言模型备案），<span class=\"spamTxt\">最高</span>获100万元奖励2. <span class=\"spamTxt\">首次</span>完成<span class=\"spamTxt\">国家级</span>境内互联网信息服务算法备案或深度合成服务算法备案，<span class=\"spamTxt\">最高</span>拿20万元奖励3. 在办公房租、模型优化、人才、营收增量、示范发展等方面有补贴，单个企业每年<span class=\"spamTxt\">最高</span>奖励1000万元</td></tr><tr><td>广东省</td><td>广州天河区</td><td style=\"word-break: break-all;\">1. 新设立且纳入天河区规模以上统计的公司，获10万元一次性奖励2. 年度营业收入<span class=\"spamTxt\">首次</span>达1亿元及以上，再拿100万元奖励3. 新落户特定区域企业，根据经济发展贡献获不同比例奖励&lt;br&gt;4. 对获得风险投资、研发投入增长的企业有相应奖励</td></tr><tr><td>广东省</td><td>深圳龙岗区</td><td style=\"word-break: break-all;\">1. 算力补贴<span class=\"spamTxt\">最高</span>不超过1000万元2. 大模型调用扶持<span class=\"spamTxt\">最高</span>200万元3. 通过大模型备案的企业中，<span class=\"spamTxt\">前十</span>名<span class=\"spamTxt\">最高</span>补贴200万元&lt;br&gt;4. 在智能穿戴、人工智能软件应用、具身智能、公共服务平台、重大活动、房租等方面有补贴</td></tr><tr><td>广东省</td><td>深圳前海</td><td>1. 房租补贴<span class=\"spamTxt\">最高</span>300万元&lt;br&gt;2. 企业所得税减按15%征收，符合条件的个人所得税超过15%的部分予以补贴&lt;br&gt;3. 研发投入<span class=\"spamTxt\">最高</span>补贴500万元&lt;br&gt;4. 算力补贴<span class=\"spamTxt\">最高</span>2000万元&lt;br&gt;5. 大模型应用领域超过10个的，<span class=\"spamTxt\">最高</span>奖励100万元</td></tr><tr><td>北京市</td><td>石景山区</td><td>在算力建设、算力应用、数据流通、房租、场景示范应用、产业运营等方面给予补贴，<span class=\"spamTxt\">最高</span>补贴额度分别可达1000万元、1000万元、300万元、500万元、500万元、200万元</td></tr><tr><td>上海市</td><td>徐汇区</td><td>1. 从算力、数据要素供给、创新能力、大模型团队落户、企业营收晋级、大模型备案等维度支持&lt;br&gt;2. 有应用场景、大型活动、投贷等补贴以及人才配套服务&lt;br&gt;3. 通过大模型备案手续的企业，<span class=\"spamTxt\">最高</span>可补贴研发费用投入的30%，<span class=\"spamTxt\">最高</span>200万元</td></tr><tr><td>四川省</td><td>成都市</td><td>1. 对“首版次”软件产品、国家重点研发计划成果转化、大模型备案<span class=\"spamTxt\">前十</span>等给予补贴&lt;br&gt;2. 算法采购、新获批实验室等可获支持&lt;br&gt;3. 对企业营收突破、专精特新企业、风险投资、人才等方面有奖励政策&lt;br&gt;4. 对性能先进且成功通过国家大模型备案登记的<span class=\"spamTxt\">前十</span>名企业，给予100万元一次性奖励</td></tr><tr><td>浙江省</td><td>杭州市本级</td><td>每年设立5000万元的“算力券”支持中小企业购买算力服务；对参数量超过千亿的通用大模型，给予<span class=\"spamTxt\">最高</span>5000万元的训练成本补助</td></tr><tr><td>浙江省</td><td>金华市</td><td>对服务平台建设、企业研发、大模型建设等给予补助，对参数量不低于十亿个的AI大模型，给予算力成本50%的补助，<span class=\"spamTxt\">最高</span>不超过2000万元</td></tr><tr><td>浙江省</td><td>宁波市</td><td>对通过国家大模型备案登记的企业，给予100万元的奖励</td></tr><tr><td>福建省</td><td>厦门市</td><td style=\"word-break: break-all;\">1. 有算力补贴、对<span class=\"spamTxt\">国家级</span>和省级项目补助、创新平台奖励、公共服务平台运营补贴、企业研发投入奖励等政策2. 企业购买或租用符合条件的智能算力服务，年度实际支出费用5万元（含）以上的，<span class=\"spamTxt\">最高</span>补贴100万元</td></tr><tr><td>江苏省</td><td>嘉兴市</td><td style=\"word-break: break-all;\">1. 对使用智算、超算算力的企业给予算力补贴&lt;br&gt;2. 新获得中央网信办生成式人工智能模型备案的企业，年度算力补贴金额<span class=\"spamTxt\">最高</span>可达500万元3. 通过大模型备案的企业可一次性获得100万元奖励4. 新入选国家、浙江省人工智能应用场景的企业有相应奖励</td></tr><tr><td>贵州省</td><td>贵阳市</td><td style=\"word-break: break-all;\">1. 对通过国家网信办境内深度合成服务算法备案的大模型，按建设成本的30%给予一次性补助，<span class=\"spamTxt\">最高</span>不超过500万元2. 大模型应用场景和公告平台建设给予补助，鼓励企业购买数据用于训练</td></tr><tr><td>安徽省</td><td>/</td><td style=\"word-break: break-all;\">1. 通过“揭榜挂帅”等方式支持大模型研究2. 评选优秀场景应用案例给予补助3. 对落户企业匹配要素资源，对引进项目给予市奖补，单个项目<span class=\"spamTxt\">最高</span>资助5000万元</td></tr><tr><td>湖北省</td><td>武汉市</td><td>有关键技术突破、算力补贴，垂直行业模型研发和算力使用补助，公共服务平台奖励等政策</td></tr><tr><td>湖北省</td><td>汉阳区</td><td>在房租、营收、人才、研发、自研大模型应用等方面给予补贴，年营收超2000万元且年研发超300万元的企业，<span class=\"spamTxt\">最高</span>一次性补助不超100万元</td></tr></tbody></table><h3><strong>三、政策亮点分析</strong></h3><ol><li><strong>高额补贴</strong>:杭州市对千亿级通用大模型的训练补助高达5000万元，为全国<span class=\"spamTxt\">最高</span>。</li><li><strong>区域差异</strong>:一线城市（如北京、上海、深圳）补贴力度更大，侧重研发和算力支持;中西部地区通过高额补贴吸引企业落户。</li><li><strong>灵活奖励</strong>:广东省部分地区按算法或模型数量奖励，鼓励企业多领域突破。</li></ol><h3><strong>四、企业如何申请?</strong></h3><ol><li><strong>完成备案</strong>:通过国家网信办备案系统提交技术细节和应用场景说明。</li><li><strong>属地申报</strong>:向当地工信或科技部门提交补贴申请，附备案证明、研发投入凭证等材料。</li><li><strong>动态关注</strong>:部分政策需满足营收或应用案例条件，建议企业提前规划。</li></ol><h3><strong>五、专家解读</strong></h3><p>“备案政策并非限制，而是为AI行业划定合规跑道。”中国人工智能学会副秘书长表示，“企业应抓住政策红利，加速技术落地，同时注重数据安全和算法透明。”</p><p><strong>【结语】</strong></p><p>全国大模型算法备案奖励补贴政策为企业提供了强有力的支持，也为人工智能技术的规范化发展奠定了坚实基础。各企业可根据自身需求，选择最适合的政策申请补贴，抢占技术制高点。</p><p><strong>（数据截至2025年3月，具体政策以各地<span class=\"spamTxt\">最新</span>文件为准）</strong></p><p><strong>新闻来源</strong>:国家网信办、各省市工信局公开信息</p>",
          "contentSnippet": "【导语】\n随着人工智能技术的迅猛发展，大模型与算法已成为推动各行业创新的核心力量。为规范技术应用并鼓励企业合规发展，全国各省市纷纷出台大模型算法备案奖励补贴政策，最高补贴金额达5000万元。以下是2025年全国各省市政策汇总详情。\n一、政策背景与意义\n大模型备案和算法备案是国家为规范生成式人工智能技术和算法推荐服务而推出的重要制度。通过备案，企业需披露技术细节，确保数据安全和算法透明，从而维护网络空间秩序、保障用户权益并促进行业健康发展。截至2025年3月，全国算法备案数量已达3234个，大模型备案数量为407个，覆盖金融、医疗、教育等多个领域。\n全国大模型备案和算法备案区域分布：\n\n算法备案：北京（27.64%）、广东（21.03%）、上海（14.29%）。\n大模型备案：北京（ 117 款）、上海（ 123 款）、广东（ 40 款）。\n\n二、全国各省市奖励补贴政策一览表\n\n\n\n省市地区政策内容\n\n广东省广州海珠区1. 企业首次完成国家级生成式人工智能上线备案（大语言模型备案），最高获100万元奖励2. 首次完成国家级境内互联网信息服务算法备案或深度合成服务算法备案，最高拿20万元奖励3. 在办公房租、模型优化、人才、营收增量、示范发展等方面有补贴，单个企业每年最高奖励1000万元\n广东省广州天河区1. 新设立且纳入天河区规模以上统计的公司，获10万元一次性奖励2. 年度营业收入首次达1亿元及以上，再拿100万元奖励3. 新落户特定区域企业，根据经济发展贡献获不同比例奖励<br>4. 对获得风险投资、研发投入增长的企业有相应奖励\n广东省深圳龙岗区1. 算力补贴最高不超过1000万元2. 大模型调用扶持最高200万元3. 通过大模型备案的企业中，前十名最高补贴200万元<br>4. 在智能穿戴、人工智能软件应用、具身智能、公共服务平台、重大活动、房租等方面有补贴\n广东省深圳前海1. 房租补贴最高300万元<br>2. 企业所得税减按15%征收，符合条件的个人所得税超过15%的部分予以补贴<br>3. 研发投入最高补贴500万元<br>4. 算力补贴最高2000万元<br>5. 大模型应用领域超过10个的，最高奖励100万元\n北京市石景山区在算力建设、算力应用、数据流通、房租、场景示范应用、产业运营等方面给予补贴，最高补贴额度分别可达1000万元、1000万元、300万元、500万元、500万元、200万元\n上海市徐汇区1. 从算力、数据要素供给、创新能力、大模型团队落户、企业营收晋级、大模型备案等维度支持<br>2. 有应用场景、大型活动、投贷等补贴以及人才配套服务<br>3. 通过大模型备案手续的企业，最高可补贴研发费用投入的30%，最高200万元\n四川省成都市1. 对“首版次”软件产品、国家重点研发计划成果转化、大模型备案前十等给予补贴<br>2. 算法采购、新获批实验室等可获支持<br>3. 对企业营收突破、专精特新企业、风险投资、人才等方面有奖励政策<br>4. 对性能先进且成功通过国家大模型备案登记的前十名企业，给予100万元一次性奖励\n浙江省杭州市本级每年设立5000万元的“算力券”支持中小企业购买算力服务；对参数量超过千亿的通用大模型，给予最高5000万元的训练成本补助\n浙江省金华市对服务平台建设、企业研发、大模型建设等给予补助，对参数量不低于十亿个的AI大模型，给予算力成本50%的补助，最高不超过2000万元\n浙江省宁波市对通过国家大模型备案登记的企业，给予100万元的奖励\n福建省厦门市1. 有算力补贴、对国家级和省级项目补助、创新平台奖励、公共服务平台运营补贴、企业研发投入奖励等政策2. 企业购买或租用符合条件的智能算力服务，年度实际支出费用5万元（含）以上的，最高补贴100万元\n江苏省嘉兴市1. 对使用智算、超算算力的企业给予算力补贴<br>2. 新获得中央网信办生成式人工智能模型备案的企业，年度算力补贴金额最高可达500万元3. 通过大模型备案的企业可一次性获得100万元奖励4. 新入选国家、浙江省人工智能应用场景的企业有相应奖励\n贵州省贵阳市1. 对通过国家网信办境内深度合成服务算法备案的大模型，按建设成本的30%给予一次性补助，最高不超过500万元2. 大模型应用场景和公告平台建设给予补助，鼓励企业购买数据用于训练\n安徽省/1. 通过“揭榜挂帅”等方式支持大模型研究2. 评选优秀场景应用案例给予补助3. 对落户企业匹配要素资源，对引进项目给予市奖补，单个项目最高资助5000万元\n湖北省武汉市有关键技术突破、算力补贴，垂直行业模型研发和算力使用补助，公共服务平台奖励等政策\n湖北省汉阳区在房租、营收、人才、研发、自研大模型应用等方面给予补贴，年营收超2000万元且年研发超300万元的企业，最高一次性补助不超100万元\n\n三、政策亮点分析\n\n高额补贴:杭州市对千亿级通用大模型的训练补助高达5000万元，为全国最高。\n区域差异:一线城市（如北京、上海、深圳）补贴力度更大，侧重研发和算力支持;中西部地区通过高额补贴吸引企业落户。\n灵活奖励:广东省部分地区按算法或模型数量奖励，鼓励企业多领域突破。\n\n四、企业如何申请?\n\n完成备案:通过国家网信办备案系统提交技术细节和应用场景说明。\n属地申报:向当地工信或科技部门提交补贴申请，附备案证明、研发投入凭证等材料。\n动态关注:部分政策需满足营收或应用案例条件，建议企业提前规划。\n\n五、专家解读\n“备案政策并非限制，而是为AI行业划定合规跑道。”中国人工智能学会副秘书长表示，“企业应抓住政策红利，加速技术落地，同时注重数据安全和算法透明。”\n【结语】\n全国大模型算法备案奖励补贴政策为企业提供了强有力的支持，也为人工智能技术的规范化发展奠定了坚实基础。各企业可根据自身需求，选择最适合的政策申请补贴，抢占技术制高点。\n（数据截至2025年3月，具体政策以各地最新文件为准）\n新闻来源:国家网信办、各省市工信局公开信息",
          "guid": "https://www.aibase.com/zh/news/16932",
          "isoDate": "2025-04-08T08:31:02.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "全新视频生成框架SkyReels-A2发布：可控视频生成技术再创新高度",
          "link": "https://www.aibase.com/zh/news/16931",
          "pubDate": "Tue, 08 Apr 2025 08:14:55 GMT",
          "author": "AI Base",
          "content": "<p>最近，Skywork AI 的研究团队推出了一种名为 SkyReels-A2的全新视频生成框架，标志着可控视频生成技术的新高度。这个名为 “元素到视频（E2V）” 的框架可以根据文本提示，将各种视觉元素(如角色、物体、背景)合成自然的视频，并且能够与参考图像保持高度一致。</p><p style=\"text-align:center\"><img src=\"https://upload.chinaz.com/2025/0408/6387972562893764384481234.png\" title=\"111.png\" alt=\"111.png\" referrerpolicy=\"no-referrer\"></p><p>SkyReels-A2的核心在于其复杂的数据处理流程。研究团队设计了一条全面的数据构建管道，以生成包含提示、参考图像和视频的三元组，从而为模型训练提供数据支持。其生成过程通过两个分支进行:空间特征分支和语义特征分支。空间特征分支利用细粒度的变分自编码器（VAE）来处理每个组成元素，而语义特征分支则利用 CLIP 视觉编码器提取更深层次的语义信息。这种双管齐下的策略确保了生成视频既符合文本提示，又能够保持各个元素之间的自然衔接。</p><p>除了保证视频内容的多样性与高质量，SkyReels-A2还优化了推理过程，以提高生成速度和输出稳定性。这使得用户可以更快地创建出专业水准的视频内容。SkyReels-A2不仅是一款开放源代码的商业级模型，它的出现也为影视制作和虚拟电商等领域提供了巨大的创作潜力。</p><p>最后，研究团队还推出了一套系统的评估基准 A2Bench，旨在全面评估生成视频的质量。这一基准不仅考虑了自动评测指标，还包括用户的主观评价，从多个角度真实反映了 E2V 任务的效果。</p><p>SkyReels-A2无疑是一个改变游戏规则的工具，期待它在创意应用领域的广泛应用，助力内容创作者突破现有的技术瓶颈，实现更富想象力的创作。</p><p>项目地址：https://top.aibase.com/tool/skyreels-a2</p>",
          "contentSnippet": "最近，Skywork AI 的研究团队推出了一种名为 SkyReels-A2的全新视频生成框架，标志着可控视频生成技术的新高度。这个名为 “元素到视频（E2V）” 的框架可以根据文本提示，将各种视觉元素(如角色、物体、背景)合成自然的视频，并且能够与参考图像保持高度一致。\n\nSkyReels-A2的核心在于其复杂的数据处理流程。研究团队设计了一条全面的数据构建管道，以生成包含提示、参考图像和视频的三元组，从而为模型训练提供数据支持。其生成过程通过两个分支进行:空间特征分支和语义特征分支。空间特征分支利用细粒度的变分自编码器（VAE）来处理每个组成元素，而语义特征分支则利用 CLIP 视觉编码器提取更深层次的语义信息。这种双管齐下的策略确保了生成视频既符合文本提示，又能够保持各个元素之间的自然衔接。\n除了保证视频内容的多样性与高质量，SkyReels-A2还优化了推理过程，以提高生成速度和输出稳定性。这使得用户可以更快地创建出专业水准的视频内容。SkyReels-A2不仅是一款开放源代码的商业级模型，它的出现也为影视制作和虚拟电商等领域提供了巨大的创作潜力。\n最后，研究团队还推出了一套系统的评估基准 A2Bench，旨在全面评估生成视频的质量。这一基准不仅考虑了自动评测指标，还包括用户的主观评价，从多个角度真实反映了 E2V 任务的效果。\nSkyReels-A2无疑是一个改变游戏规则的工具，期待它在创意应用领域的广泛应用，助力内容创作者突破现有的技术瓶颈，实现更富想象力的创作。\n项目地址：https://top.aibase.com/tool/skyreels-a2",
          "guid": "https://www.aibase.com/zh/news/16931",
          "isoDate": "2025-04-08T08:14:55.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "Vision-R1：强化学习助力视觉定位，图文模型性能提升 50%",
          "link": "https://www.aibase.com/zh/news/16929",
          "pubDate": "Tue, 08 Apr 2025 06:49:37 GMT",
          "author": "AI Base",
          "content": "<p>近日，中国科学院自动化研究所与中科紫东太初团队联手推出了一种新方法 ——Vision-R1，利用类 R1强化学习技术，显著提升了视觉定位的能力。这个方法不仅在目标检测和视觉定位等复杂任务上实现了50% 的性能提升，甚至超过了参数规模超过10倍的现有<span class=\"spamTxt\">最优</span>模型（SOTA）。</p><p>当前，图文大模型通常依赖 “预训练 + 监督微调” 的方法来提高对用户指令的响应能力，但这种方法在资源消耗和训练效率上都存在较大挑战。Vision-R1通过结合高质量的指令对齐数据和强化学习，创新性地改变了这一局面。该方法通过设计一种视觉任务评估驱动的奖励机制，为模型的目标定位能力提供了强有力的支持。</p><p style=\"text-align:center\"><img src=\"https://upload.chinaz.com/2025/0408/6387972053723732505188099.png\" title=\"image.png\" alt=\"image.png\" referrerpolicy=\"no-referrer\"></p><p>具体而言，Vision-R1的奖励机制包括四个核心部分:首先，它采用了多目标预测的方式，以确保在密集场景中有效评估预测质量;其次，设计了双重格式奖励，以解决长序列预测中的格式错误问题;再者，召回奖励鼓励模型尽可能多地识别目标;最后，精度奖励则确保模型生成的目标框质量更高。这些设计相互作用，形成了 “1+1&gt;2” 的优化效果，使模型在复杂视觉任务中表现更为出色。</p><p>为了解决预测高质量目标框的挑战，研究团队还提出了一种渐进式规则调整策略，通过动态调整奖励计算规则，促使模型持续改进其性能。训练过程分为初学阶段和进阶阶段，逐步提高奖励标准，以实现从基础到高精度的转变。</p><p>在一系列测试中，Vision-R1在经典目标检测数据集 COCO 和多样场景的 ODINW-13上显示出卓越的性能，无论是基础性能如何，经过 Vision-R1训练后，模型的表现都大幅提升，进一步接近专业定位模型。这一方法不仅有效提升了图文大模型的视觉定位能力，同时也为未来的多模态 AI 应用提供了新的方向。</p><p>项目地址:https://github.com/jefferyZhan/Griffon/tree/master/Vision-R1</p>",
          "contentSnippet": "近日，中国科学院自动化研究所与中科紫东太初团队联手推出了一种新方法 ——Vision-R1，利用类 R1强化学习技术，显著提升了视觉定位的能力。这个方法不仅在目标检测和视觉定位等复杂任务上实现了50% 的性能提升，甚至超过了参数规模超过10倍的现有最优模型（SOTA）。\n当前，图文大模型通常依赖 “预训练 + 监督微调” 的方法来提高对用户指令的响应能力，但这种方法在资源消耗和训练效率上都存在较大挑战。Vision-R1通过结合高质量的指令对齐数据和强化学习，创新性地改变了这一局面。该方法通过设计一种视觉任务评估驱动的奖励机制，为模型的目标定位能力提供了强有力的支持。\n\n具体而言，Vision-R1的奖励机制包括四个核心部分:首先，它采用了多目标预测的方式，以确保在密集场景中有效评估预测质量;其次，设计了双重格式奖励，以解决长序列预测中的格式错误问题;再者，召回奖励鼓励模型尽可能多地识别目标;最后，精度奖励则确保模型生成的目标框质量更高。这些设计相互作用，形成了 “1+1>2” 的优化效果，使模型在复杂视觉任务中表现更为出色。\n为了解决预测高质量目标框的挑战，研究团队还提出了一种渐进式规则调整策略，通过动态调整奖励计算规则，促使模型持续改进其性能。训练过程分为初学阶段和进阶阶段，逐步提高奖励标准，以实现从基础到高精度的转变。\n在一系列测试中，Vision-R1在经典目标检测数据集 COCO 和多样场景的 ODINW-13上显示出卓越的性能，无论是基础性能如何，经过 Vision-R1训练后，模型的表现都大幅提升，进一步接近专业定位模型。这一方法不仅有效提升了图文大模型的视觉定位能力，同时也为未来的多模态 AI 应用提供了新的方向。\n项目地址:https://github.com/jefferyZhan/Griffon/tree/master/Vision-R1",
          "guid": "https://www.aibase.com/zh/news/16929",
          "isoDate": "2025-04-08T06:49:37.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "Sync Labs 发布 Lipsync-2：全球首个零-shot的嘴型同步模型",
          "link": "https://www.aibase.com/zh/news/16928",
          "pubDate": "Tue, 08 Apr 2025 06:17:01 GMT",
          "author": "AI Base",
          "content": "<p>人工智能技术公司 Sync Labs 近日通过 Twitter 宣布推出其<span class=\"spamTxt\">最新</span>产品 Lipsync-2，这款模型被誉为“全球首个零-shot嘴型同步模型”，无需额外训练或微调即可保留演讲者的独特风格。这一突破性技术在真实感、表现力、控制力、质量和速度方面均实现了显著提升，适用于真人视频、动画以及AI生成的内容。</p><p style=\"text-align:center\"><img src=\"https://upload.chinaz.com/2025/0408/6387971857890025523320844.png\" title=\"QQ_1744092971287.png\" alt=\"QQ_1744092971287.png\" referrerpolicy=\"no-referrer\"></p><p>Lipsync-2的创新特性</p><p>根据 Sync Labs 在4月1日发布的 Twitter 消息，Lipsync-2的核心亮点在于其“零-shot”能力，即无需针对特定演讲者进行预训练，模型便可即时学习并生成符合其独特说话风格的嘴型同步效果。这一特性颠覆了传统嘴型同步技术对大量训练数据的需求，使得内容创作者能够更高效地应用该技术。</p><p><video id=\"tmpVedio0\" class=\"edui-upload-video video-js vjs-default-skin video-js\" controls=\"\" preload=\"meta\" width=\"750\" height=\"450\" src=\"https://upload.chinaz.com/video/2025/0408/6387971860904982912558069.mp4\" data-setup=\"{}\"><source src=\"https://upload.chinaz.com/video/2025/0408/6387971860904982912558069.mp4\" type=\"video/mp4\"></video></p><p>此外，Sync Labs 还透露，Lipsync-2在多个维度上实现了技术飞跃。无论是真人视频、动画角色，还是AI生成的人物，Lipsync-2都能提供更高的真实感和表现力。</p><p>新增控制功能:温度参数</p><p>除了零-shot能力，Lipsync-2引入了一项名为“温度”（temperature）的控制功能。这一参数允许用户调节嘴型同步的表现程度，从简洁自然的同步效果到更具夸张表现力的生成效果，满足不同场景的需求。目前，这一功能处于私人测试阶段，仅逐步向付费用户开放。</p><p>应用前景:多语言教育与内容创作</p><p>Sync Labs 在4月3日的 Twitter 帖子中进一步展示了 Lipsync-2的潜在应用场景，称其“在准确性、风格和表现力上表现出色”，并提出“让每场讲座都能以每种语言呈现”的愿景。这一技术不仅可用于视频翻译和字级编辑，还能助力角色重新动画化，甚至支持逼真的AI用户生成内容（UGC），为教育、娱乐和营销领域带来革命性变化。</p><p>行业反响与未来期待</p><p>Lipsync-2的发布迅速引发了行业关注。Sync Labs 表示，该模型已在 fal 平台上开放体验，用户可通过访问 fal 的模型库一探究竟。自4月1日宣布以来，Twitter 上关于 Lipsync-2的讨论持续升温，许多用户对其跨领域应用的潜力表示期待。</p><p>作为人工智能视频技术的先锋企业，Sync Labs 通过 Lipsync-2再次证明了其在创新领域的领导地位。随着该技术的逐步推广，内容创作的门槛或将进一步降低，而观众也将享受到更加自然、沉浸式的视听体验。</p>",
          "contentSnippet": "人工智能技术公司 Sync Labs 近日通过 Twitter 宣布推出其最新产品 Lipsync-2，这款模型被誉为“全球首个零-shot嘴型同步模型”，无需额外训练或微调即可保留演讲者的独特风格。这一突破性技术在真实感、表现力、控制力、质量和速度方面均实现了显著提升，适用于真人视频、动画以及AI生成的内容。\n\nLipsync-2的创新特性\n根据 Sync Labs 在4月1日发布的 Twitter 消息，Lipsync-2的核心亮点在于其“零-shot”能力，即无需针对特定演讲者进行预训练，模型便可即时学习并生成符合其独特说话风格的嘴型同步效果。这一特性颠覆了传统嘴型同步技术对大量训练数据的需求，使得内容创作者能够更高效地应用该技术。\n\n此外，Sync Labs 还透露，Lipsync-2在多个维度上实现了技术飞跃。无论是真人视频、动画角色，还是AI生成的人物，Lipsync-2都能提供更高的真实感和表现力。\n新增控制功能:温度参数\n除了零-shot能力，Lipsync-2引入了一项名为“温度”（temperature）的控制功能。这一参数允许用户调节嘴型同步的表现程度，从简洁自然的同步效果到更具夸张表现力的生成效果，满足不同场景的需求。目前，这一功能处于私人测试阶段，仅逐步向付费用户开放。\n应用前景:多语言教育与内容创作\nSync Labs 在4月3日的 Twitter 帖子中进一步展示了 Lipsync-2的潜在应用场景，称其“在准确性、风格和表现力上表现出色”，并提出“让每场讲座都能以每种语言呈现”的愿景。这一技术不仅可用于视频翻译和字级编辑，还能助力角色重新动画化，甚至支持逼真的AI用户生成内容（UGC），为教育、娱乐和营销领域带来革命性变化。\n行业反响与未来期待\nLipsync-2的发布迅速引发了行业关注。Sync Labs 表示，该模型已在 fal 平台上开放体验，用户可通过访问 fal 的模型库一探究竟。自4月1日宣布以来，Twitter 上关于 Lipsync-2的讨论持续升温，许多用户对其跨领域应用的潜力表示期待。\n作为人工智能视频技术的先锋企业，Sync Labs 通过 Lipsync-2再次证明了其在创新领域的领导地位。随着该技术的逐步推广，内容创作的门槛或将进一步降低，而观众也将享受到更加自然、沉浸式的视听体验。",
          "guid": "https://www.aibase.com/zh/news/16928",
          "isoDate": "2025-04-08T06:17:01.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "IBM发布z17大型机：每日可处理4500亿次AI推理，性能提升50%",
          "link": "https://www.aibase.com/zh/news/16927",
          "pubDate": "Tue, 08 Apr 2025 06:12:50 GMT",
          "author": "AI Base",
          "content": "<p>IBM周一发布了其大型计算机硬件的<span class=\"spamTxt\">最新</span>产品——IBM z17。这款完全加密的大型机由IBM Telum II处理器驱动，专为250多种AI用例而设计，包括AI代理和生成式AI应用场景。</p><p>虽然大型机可能被一些人视为过时技术，但据消息人士透露，当今71%的《财富》500强企业仍在使用它们。根据咨询公司Market Research Future的数据，到2024年，大型机市场价值估计将达到53亿美元。</p><p>z17每天能处理4500亿次推理运算，比2022年发布的前代产品IBM z16提升了50%。新系统设计理念是能够与其他硬件、软件和开源工具完全集成，提供灵活的企业计算解决方案。</p><p style=\"text-align: center\"><img src=\"https://pic.chinaz.com/picmap/202308171345267110_2.jpg\" title=\"互联网 大数据2 (图片来源：AI合成)\" alt=\"互联网 大数据2\" referrerpolicy=\"no-referrer\"></p><p style=\"text-align: center;\">图源备注：图片由AI生成，图片授权服务商Midjourney</p><p>IBM Z产品管理和设计副总裁蒂娜·塔奎尼奥（Tina Tarquinio）在接受TechCrunch采访时表示，这次大型机升级已经筹备了五年，远早于2022年11月OpenAI发布ChatGPT引发的当前AI热潮。IBM在打造z17时花费了2，000多个小时的研究时间，从100多个客户那里收集反馈。塔奎尼奥认为有趣的是，五年前开始的研发方向与市场最终的走向高度一致。</p><p>塔奎尼奥说:\"当我们得知要推出AI加速器时，尤其是在2022年下半年，行业中关于AI的所有变化都令人兴奋不已。我认为<span class=\"spamTxt\">最大</span>的问题是，我们不知道接下来会发生什么。因此，就AI能帮助我们做什么而言，可能性真的是无限的。\"</p><p>z17的设计考虑了AI市场的快速发展趋势。这款大型机在发布时将支持48个IBM Spyre AI加速器芯片，并计划在12个月内将这一数字提高到96个。\"我们有意留有余地，提高人工智能的敏捷性，\"塔奎尼奥解释道，\"随着新模型的推出，我们确保为更大的模型留有空间——这些模型可能需要更多的本地内存来相互通信。我们之所以这样做，是因为我们知道这确实是会变化的领域。新模型会不断出现和发展。\"</p><p>塔奎尼奥强调，z17的一大亮点是节能性能。\"在片上，我们将AI加速提高了7.5倍，但所需的能耗比在业内其他类型的加速器或平台上进行多模型处理所需能耗少5.5倍。\"</p><p>IBM z17大型机将于6月8日全面上市。</p>",
          "contentSnippet": "IBM周一发布了其大型计算机硬件的最新产品——IBM z17。这款完全加密的大型机由IBM Telum II处理器驱动，专为250多种AI用例而设计，包括AI代理和生成式AI应用场景。\n虽然大型机可能被一些人视为过时技术，但据消息人士透露，当今71%的《财富》500强企业仍在使用它们。根据咨询公司Market Research Future的数据，到2024年，大型机市场价值估计将达到53亿美元。\nz17每天能处理4500亿次推理运算，比2022年发布的前代产品IBM z16提升了50%。新系统设计理念是能够与其他硬件、软件和开源工具完全集成，提供灵活的企业计算解决方案。\n\n图源备注：图片由AI生成，图片授权服务商Midjourney\nIBM Z产品管理和设计副总裁蒂娜·塔奎尼奥（Tina Tarquinio）在接受TechCrunch采访时表示，这次大型机升级已经筹备了五年，远早于2022年11月OpenAI发布ChatGPT引发的当前AI热潮。IBM在打造z17时花费了2，000多个小时的研究时间，从100多个客户那里收集反馈。塔奎尼奥认为有趣的是，五年前开始的研发方向与市场最终的走向高度一致。\n塔奎尼奥说:\"当我们得知要推出AI加速器时，尤其是在2022年下半年，行业中关于AI的所有变化都令人兴奋不已。我认为最大的问题是，我们不知道接下来会发生什么。因此，就AI能帮助我们做什么而言，可能性真的是无限的。\"\nz17的设计考虑了AI市场的快速发展趋势。这款大型机在发布时将支持48个IBM Spyre AI加速器芯片，并计划在12个月内将这一数字提高到96个。\"我们有意留有余地，提高人工智能的敏捷性，\"塔奎尼奥解释道，\"随着新模型的推出，我们确保为更大的模型留有空间——这些模型可能需要更多的本地内存来相互通信。我们之所以这样做，是因为我们知道这确实是会变化的领域。新模型会不断出现和发展。\"\n塔奎尼奥强调，z17的一大亮点是节能性能。\"在片上，我们将AI加速提高了7.5倍，但所需的能耗比在业内其他类型的加速器或平台上进行多模型处理所需能耗少5.5倍。\"\nIBM z17大型机将于6月8日全面上市。",
          "guid": "https://www.aibase.com/zh/news/16927",
          "isoDate": "2025-04-08T06:12:50.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "酷狗音乐与DeepSeek达成深度合作 推全新“AI 听歌报告”",
          "link": "https://www.aibase.com/zh/news/16926",
          "pubDate": "Tue, 08 Apr 2025 06:00:37 GMT",
          "author": "AI Base",
          "content": "<p><span style=\"text-indent: 2em;\">在当今人工智能技术不断深入文娱行业的背景下，酷狗音乐与国内领先的人工智能公司深度求索（DeepSeek）达成了战略合作。</span></p><p><span style=\"text-indent: 2em;\">双方的合作通过大模型技术的系统性应用，推动了音乐平台的进化，从单纯的 “工具型应用” 转变为 “智慧化娱乐中枢”。这一转型的核心在于推出的四大 AI 功能模块，它们正在全面重塑音乐消费的全链路体验，为行业设立了 AI 与音乐融合发展的新标杆。</span></p><p style=\"text-align:center\"><img src=\"https://upload.chinaz.com/2025/0408/6387971761308086438440490.png\" title=\"QQ_1744092001442.png\" alt=\"QQ_1744092001442.png\" referrerpolicy=\"no-referrer\"></p><p>酷狗音乐通过 DeepSeek 的多模态理解能力，推出了全新的 “AI 听歌报告”。这一报告不仅打破了传统的数据罗列方式，还能够精准识别用户的音乐偏好和情绪标签，并结合时间和场景构建出三维听歌画像。通过这种有趣的听歌报告，用户不仅能够分享自己的音乐喜好，还能实现个体数据分析与社交连接的跨越式升级。</p><p>酷狗音乐还推出了场景推荐系统，利用 DeepSeek 搭建的自动生成能力，对用户的搜索内容进行深入解析。<span style=\"text-indent: 2em;\">酷狗音乐与 DeepSeek 合作推出的智能歌单管家，运用了 AI 语义理解技术来自动解析歌单内歌曲的共性特征，并基于深度学习生成风格化的命名建议。</span></p><p>在用户生成内容（UGC）迅速爆炸的音乐社区中，DeepSeek 的语义理解技术也带来了全新的改变。该系统可以实时扫描大量歌曲评论，自动生成观点热评总结，帮助用户快速捕捉大众共鸣点。同时，“AI 评论官” 功能也为互动评论提供了角色设定，开创了人机协同的新内容生产模式。</p><blockquote><p>划重点:</p><p>🎵 酷狗音乐与 DeepSeek 合作推出四大 AI 功能模块，重塑音乐消费体验。&nbsp;&nbsp;</p><p>📊 新版 “AI 听歌报告” 提供个性化音乐分析与社交分享功能。&nbsp;&nbsp;</p><p>🎨 智能歌单管家通过 AI 提升用户创作效率和美学体验。&nbsp;&nbsp;</p></blockquote>",
          "contentSnippet": "在当今人工智能技术不断深入文娱行业的背景下，酷狗音乐与国内领先的人工智能公司深度求索（DeepSeek）达成了战略合作。\n双方的合作通过大模型技术的系统性应用，推动了音乐平台的进化，从单纯的 “工具型应用” 转变为 “智慧化娱乐中枢”。这一转型的核心在于推出的四大 AI 功能模块，它们正在全面重塑音乐消费的全链路体验，为行业设立了 AI 与音乐融合发展的新标杆。\n\n酷狗音乐通过 DeepSeek 的多模态理解能力，推出了全新的 “AI 听歌报告”。这一报告不仅打破了传统的数据罗列方式，还能够精准识别用户的音乐偏好和情绪标签，并结合时间和场景构建出三维听歌画像。通过这种有趣的听歌报告，用户不仅能够分享自己的音乐喜好，还能实现个体数据分析与社交连接的跨越式升级。\n酷狗音乐还推出了场景推荐系统，利用 DeepSeek 搭建的自动生成能力，对用户的搜索内容进行深入解析。酷狗音乐与 DeepSeek 合作推出的智能歌单管家，运用了 AI 语义理解技术来自动解析歌单内歌曲的共性特征，并基于深度学习生成风格化的命名建议。\n在用户生成内容（UGC）迅速爆炸的音乐社区中，DeepSeek 的语义理解技术也带来了全新的改变。该系统可以实时扫描大量歌曲评论，自动生成观点热评总结，帮助用户快速捕捉大众共鸣点。同时，“AI 评论官” 功能也为互动评论提供了角色设定，开创了人机协同的新内容生产模式。\n\n划重点:\n🎵 酷狗音乐与 DeepSeek 合作推出四大 AI 功能模块，重塑音乐消费体验。  \n📊 新版 “AI 听歌报告” 提供个性化音乐分析与社交分享功能。  \n🎨 智能歌单管家通过 AI 提升用户创作效率和美学体验。",
          "guid": "https://www.aibase.com/zh/news/16926",
          "isoDate": "2025-04-08T06:00:37.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "英伟达完成收购 Lepton AI，阿里前副总裁贾扬清携团队加盟",
          "link": "https://www.aibase.com/zh/news/16924",
          "pubDate": "Tue, 08 Apr 2025 03:22:17 GMT",
          "author": "AI Base",
          "content": "<p><span style=\"text-indent: 2em;\">据 The Information*援引知情人士消息，英伟达已完成对 Lepton AI 的收购，这家由 AI 领域知名专家、阿里巴巴前副总裁贾扬清创办的初创企业交易价值高达数亿美元。</span></p><p><span style=\"text-indent: 2em;\">据悉，Lepton AI 成立于2023年，定位为 AI 基础设施公司，专注于为初创企业提供高效的云端解决方案。其核心业务包括出租英伟达 GPU 服务器，并开发配套软件，帮助客户在云中构建、管理和优化 AI 应用。目前，Lepton AI 团队规模较小，仅约20名员工，但其技术实力和市场潜力已受到业界关注。</span></p><p style=\"text-align: center\"><img src=\"https://pic.chinaz.com/picmap/202306131355473164_2.jpg\" title=\"人机合作 (图片来源：AI合成)\" alt=\"人机合作\" referrerpolicy=\"no-referrer\"></p><p style=\"text-align: center;\">图源备注：图片由AI生成，图片授权服务商Midjourney</p><p>知情人士透露，Lepton AI 的联合创始人贾扬清和白俊杰均已加入英伟达。贾扬清在 AI 领域声名显赫，曾在谷歌参与 TensorFlow 框架开发，后加入阿里巴巴担任副总裁，负责大数据和 AI 技术研发。2023年离职后，他与白俊杰共同创立 Lepton AI，目标是通过简化 AI 基础设施的部署，降低初创企业进入 AI 市场的门槛。成立仅数月，Lepton AI 便于2023年5月完成1100万美元（约合人民币7900万元）的天使轮融资，显示出投资者对其商业模式的高度认可。</p><p>此次收购被视为英伟达在 AI 生态布局中的重要一步。作为全球 GPU 市场的<span class=\"spamTxt\">领导者</span>，英伟达近年来持续加大对 AI 基础设施和云服务的投入。Lepton AI 的加入不仅为其带来了贾扬清团队在 GPU 服务器租赁和 AI 软件开发领域的丰富经验，还进一步巩固了英伟达在云端 AI 计算市场的竞争力。业内人士分析，Lepton AI 的技术可能被整合进英伟达的 DGX Cloud 或其他云服务产品线，为客户提供更灵活、高效的 AI 开发工具。</p><p>对于 Lepton AI 而言，此次收购为其提供了更广阔的发展平台。依托英伟达的资源和技术支持，贾扬清团队有望加速推动 AI 基础设施的创新，助力更多企业实现 AI 驱动的业务转型。这笔交易也反映了当前 AI 行业并购热潮，巨头通过收购初创公司快速吸纳人才和技术，以抢占市场先机。</p>",
          "contentSnippet": "据 The Information*援引知情人士消息，英伟达已完成对 Lepton AI 的收购，这家由 AI 领域知名专家、阿里巴巴前副总裁贾扬清创办的初创企业交易价值高达数亿美元。\n据悉，Lepton AI 成立于2023年，定位为 AI 基础设施公司，专注于为初创企业提供高效的云端解决方案。其核心业务包括出租英伟达 GPU 服务器，并开发配套软件，帮助客户在云中构建、管理和优化 AI 应用。目前，Lepton AI 团队规模较小，仅约20名员工，但其技术实力和市场潜力已受到业界关注。\n\n图源备注：图片由AI生成，图片授权服务商Midjourney\n知情人士透露，Lepton AI 的联合创始人贾扬清和白俊杰均已加入英伟达。贾扬清在 AI 领域声名显赫，曾在谷歌参与 TensorFlow 框架开发，后加入阿里巴巴担任副总裁，负责大数据和 AI 技术研发。2023年离职后，他与白俊杰共同创立 Lepton AI，目标是通过简化 AI 基础设施的部署，降低初创企业进入 AI 市场的门槛。成立仅数月，Lepton AI 便于2023年5月完成1100万美元（约合人民币7900万元）的天使轮融资，显示出投资者对其商业模式的高度认可。\n此次收购被视为英伟达在 AI 生态布局中的重要一步。作为全球 GPU 市场的领导者，英伟达近年来持续加大对 AI 基础设施和云服务的投入。Lepton AI 的加入不仅为其带来了贾扬清团队在 GPU 服务器租赁和 AI 软件开发领域的丰富经验，还进一步巩固了英伟达在云端 AI 计算市场的竞争力。业内人士分析，Lepton AI 的技术可能被整合进英伟达的 DGX Cloud 或其他云服务产品线，为客户提供更灵活、高效的 AI 开发工具。\n对于 Lepton AI 而言，此次收购为其提供了更广阔的发展平台。依托英伟达的资源和技术支持，贾扬清团队有望加速推动 AI 基础设施的创新，助力更多企业实现 AI 驱动的业务转型。这笔交易也反映了当前 AI 行业并购热潮，巨头通过收购初创公司快速吸纳人才和技术，以抢占市场先机。",
          "guid": "https://www.aibase.com/zh/news/16924",
          "isoDate": "2025-04-08T03:22:17.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "​谷歌推全新AI安全模型Sec-Gemini v1，秒级洞悉网络攻击根源",
          "link": "https://www.aibase.com/zh/news/16923",
          "pubDate": "Tue, 08 Apr 2025 03:18:56 GMT",
          "author": "AI Base",
          "content": "<p><span style=\"text-indent: 2em;\">谷歌在其官方安全博客上宣布推出一项令人瞩目的创新——</span><strong style=\"text-indent: 2em;\">Sec-Gemini v1</strong><span style=\"text-indent: 2em;\">，这是一款全新的实验性人工智能模型，专注于推动网络安全AI领域的发展。此举标志着谷歌在利用AI技术应对日益严峻的网络威胁方面迈出了重要一步。</span></p><p style=\"text-align:center\"><img src=\"https://upload.chinaz.com/2025/0408/6387970787121268313399939.png\" title=\"QQ_1744082262499.png\" alt=\"QQ_1744082262499.png\" referrerpolicy=\"no-referrer\"></p><p><strong>应对攻防不对称:AI助力防御者扭转局面</strong></p><p>谷歌指出，当前网络安全领域面临着一个根本性的挑战，即攻防之间的不对称。防御者需要应对所有潜在的网络威胁，而攻击者只需成功找到并利用一个漏洞即可。这种不对称性使得保护系统变得异常困难、耗时且容易出错。谷歌认为，借助AI驱动的网络安全工作流程，有望<strong>显著提升网络安全专业人员的能力，从而帮助防御者扭转不利局面</strong>。</p><p><strong>Gemini赋能，实时知识驱动</strong></p><p>为了有效增强安全运营（SecOps）流程的能力，Sec-Gemini v1结合了<strong>Gemini的先进推理能力以及近乎实时的网络安全知识和工具</strong>。这种强大的组合使得Sec-Gemini v1在关键的网络安全工作流程中表现出色，包括<strong>事件根本原因分析、威胁分析和漏洞影响理解</strong>。</p><p>Sec-Gemini v1之所以能在关键网络安全基准测试中超越其他模型，得益于其对<strong>Google Threat Intelligence （GTI）、OSV(开源漏洞数据库)和其他关键数据源的深度整合</strong>。具体而言，Sec-Gemini v1在领先的威胁情报基准测试CTI-MCQ上<strong>至少领先其他模型11%</strong>。此外，在评估大型语言模型（LLM）理解漏洞描述的细微差别、识别根本原因中的漏洞并根据CWE分类法准确分类能力的CTI-Root Cause Mapping基准测试中，Sec-Gemini v1也<strong>至少领先其他模型10.5%</strong>。</p><p style=\"text-align:center\"><img src=\"https://upload.chinaz.com/2025/0408/6387970789045195449567926.png\" title=\"QQ_1744082279239.png\" alt=\"QQ_1744082279239.png\" referrerpolicy=\"no-referrer\"></p><p style=\"text-align:center\"><img src=\"https://upload.chinaz.com/2025/0408/6387970789878823978350462.png\" title=\"QQ_1744082292456.png\" alt=\"QQ_1744082292456.png\" referrerpolicy=\"no-referrer\"></p><p><strong>实例解析:Salt Typhoon威胁分析能力</strong></p><p>为了展示Sec-Gemini v1的全面性，谷歌提供了一个关键网络安全问题的响应示例。当被问及Salt Typhoon时，<strong>Sec-Gemini v1能够准确判断其为一个威胁行动者</strong>（并非所有模型都能做到），并借助其与Mandiant威胁情报数据的深度集成，提供了对该威胁行动者的全面描述。</p><p style=\"text-align:center\"><img src=\"https://upload.chinaz.com/2025/0408/6387970790845985563376531.png\" title=\"QQ_1744082300968.png\" alt=\"QQ_1744082300968.png\" referrerpolicy=\"no-referrer\"></p><p>进一步地，当被问及Salt Typhoon描述中的漏洞时，<strong>Sec-Gemini v1不仅输出了漏洞的详细信息</strong>（这得益于其与谷歌运营的开源漏洞数据库OSV的集成），<strong>还将这些漏洞与威胁行动者关联起来</strong>（利用Mandiant的数据）。通过Sec-Gemini v1，分析师可以<strong>更快地了解与特定漏洞相关的风险和威胁概况</strong>。</p><p style=\"text-align:center\"><img src=\"https://upload.chinaz.com/2025/0408/6387970791850673162918477.png\" title=\"QQ_1744082310966.png\" alt=\"QQ_1744082310966.png\" referrerpolicy=\"no-referrer\"></p><p><strong>开放合作，共探AI网络安全前沿</strong></p><p>谷歌坚信，成功推动AI网络安全发展，最终将天平向防御者倾斜，需要整个网络安全社区的紧密合作。因此，<strong>Sec-Gemini v1目前以免费形式提供给选定的组织、机构、专业人士和非政府组织用于研究目的</strong>。谷歌鼓励有兴趣在AI网络安全领域开展合作的机构通过指定表格申请早期访问Sec-Gemini v1。</p><p>Sec-Gemini v1的发布预示着AI在网络安全领域应用的巨大潜力，通过提升威胁情报分析、漏洞理解和事件响应效率，有望从根本上改善网络安全防御态势。</p><p>官方博客：https://security.googleblog.com/2025/04/google-launches-sec-gemini-v1-new.html</p>",
          "contentSnippet": "谷歌在其官方安全博客上宣布推出一项令人瞩目的创新——Sec-Gemini v1，这是一款全新的实验性人工智能模型，专注于推动网络安全AI领域的发展。此举标志着谷歌在利用AI技术应对日益严峻的网络威胁方面迈出了重要一步。\n\n应对攻防不对称:AI助力防御者扭转局面\n谷歌指出，当前网络安全领域面临着一个根本性的挑战，即攻防之间的不对称。防御者需要应对所有潜在的网络威胁，而攻击者只需成功找到并利用一个漏洞即可。这种不对称性使得保护系统变得异常困难、耗时且容易出错。谷歌认为，借助AI驱动的网络安全工作流程，有望显著提升网络安全专业人员的能力，从而帮助防御者扭转不利局面。\nGemini赋能，实时知识驱动\n为了有效增强安全运营（SecOps）流程的能力，Sec-Gemini v1结合了Gemini的先进推理能力以及近乎实时的网络安全知识和工具。这种强大的组合使得Sec-Gemini v1在关键的网络安全工作流程中表现出色，包括事件根本原因分析、威胁分析和漏洞影响理解。\nSec-Gemini v1之所以能在关键网络安全基准测试中超越其他模型，得益于其对Google Threat Intelligence （GTI）、OSV(开源漏洞数据库)和其他关键数据源的深度整合。具体而言，Sec-Gemini v1在领先的威胁情报基准测试CTI-MCQ上至少领先其他模型11%。此外，在评估大型语言模型（LLM）理解漏洞描述的细微差别、识别根本原因中的漏洞并根据CWE分类法准确分类能力的CTI-Root Cause Mapping基准测试中，Sec-Gemini v1也至少领先其他模型10.5%。\n\n\n实例解析:Salt Typhoon威胁分析能力\n为了展示Sec-Gemini v1的全面性，谷歌提供了一个关键网络安全问题的响应示例。当被问及Salt Typhoon时，Sec-Gemini v1能够准确判断其为一个威胁行动者（并非所有模型都能做到），并借助其与Mandiant威胁情报数据的深度集成，提供了对该威胁行动者的全面描述。\n\n进一步地，当被问及Salt Typhoon描述中的漏洞时，Sec-Gemini v1不仅输出了漏洞的详细信息（这得益于其与谷歌运营的开源漏洞数据库OSV的集成），还将这些漏洞与威胁行动者关联起来（利用Mandiant的数据）。通过Sec-Gemini v1，分析师可以更快地了解与特定漏洞相关的风险和威胁概况。\n\n开放合作，共探AI网络安全前沿\n谷歌坚信，成功推动AI网络安全发展，最终将天平向防御者倾斜，需要整个网络安全社区的紧密合作。因此，Sec-Gemini v1目前以免费形式提供给选定的组织、机构、专业人士和非政府组织用于研究目的。谷歌鼓励有兴趣在AI网络安全领域开展合作的机构通过指定表格申请早期访问Sec-Gemini v1。\nSec-Gemini v1的发布预示着AI在网络安全领域应用的巨大潜力，通过提升威胁情报分析、漏洞理解和事件响应效率，有望从根本上改善网络安全防御态势。\n官方博客：https://security.googleblog.com/2025/04/google-launches-sec-gemini-v1-new.html",
          "guid": "https://www.aibase.com/zh/news/16923",
          "isoDate": "2025-04-08T03:18:56.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "国产AI崛起！17亿参数开源图像模型HiDream-I1横空出世",
          "link": "https://www.aibase.com/zh/news/16922",
          "pubDate": "Tue, 08 Apr 2025 03:12:57 GMT",
          "author": "AI Base",
          "content": "<p>当代码的力量遇上艺术的灵感，新一代人工智能正在悄然改变创意世界的边界。近日，国产开源图像生成模型HiDream-I1震撼发布，凭借17亿参数的技术底蕴，这款由HiDream-ai团队倾力打造的AI\"画匠\"正迅速成为科技圈新宠。</p><p>这款基于扩散模型技术的开源图像生成工具，能够将文本描述转化为高质量图像，在细节渲染和图像一致性方面展现出令人瞩目的实力。初步测试显示，HiDream-I1在色彩还原、边缘处理和构图完整性上表现不俗，特别是面对复杂场景和多样化风格时，依然能够生成清晰且富有艺术感的画面，与Stable Diffusion等国际知名模型相比毫不逊色。</p><p style=\"text-align:center\"><img src=\"https://upload.chinaz.com/2025/0408/6387970755123893668568347.png\" title=\"image.png\" alt=\"image.png\" referrerpolicy=\"no-referrer\"></p><p>技术专家分析认为，HiDream-I1的成功很可能源于其开发团队对扩散模型前沿技术的精准把握，以及大规模预训练策略的巧妙应用。这种组合使其在生成速度与质量之间找到了<span class=\"spamTxt\">绝佳</span>平衡点。为满足不同用户需求，开发团队贴心地提供了完整版和精简版两种模型，后者专为计算资源有限的用户设计。更值得一提的是，该模型配备了一键式操作的推理脚本，极大降低了使用门槛，彰显了开源技术的普惠精神。</p><p>目前，HiDream-I1已在GitHub平台上完全开源，并采用MIT许可证授权，允许开发者自由使用和改进。团队还提供了详尽的使用指南，并推荐搭配Flash Attention等优化工具以进一步提升性能。这种开放透明的态度不仅吸引了大量独立开发者和研究人员的关注，也为模型的持续优化和社区协作创造了有利条件。业内专家普遍认为，HiDream-I1很可能成为国产开源AI领域的一匹黑马，有潜力在国际舞台上与<span class=\"spamTxt\">顶尖</span>技术同台竞技。</p><p>尽管前景光明，HiDream-I1作为新生力量仍面临着一系列挑战。虽然17亿参数在开源模型中已属可观规模，但与DALL·E3等动辄数十亿甚至百亿参数的商业巨头相比，其在图像多样性和创造性方面的表现还需更多实际验证。同时，在高分辨率图像生成或极端复杂场景处理方面的能力也有待更多数据支持。未来，HiDream-I1能否借助开源社区的力量实现突破性进展，将成为决定其长期影响力的关键因素。</p><p>正值全球AI图像生成技术迅猛发展之际，HiDream-I1的横空出世为艺术创作、商业设计、教育科研等多个领域带来了免费且高效的工具选择。随着社区参与度的提升和技术的不断迭代，这款国产AI模型不仅有望成为中国人工智能技术的新名片，更可能在全球开源生态中占据重要位置，为更广泛的用户群体打开AI创意世界的大门，让人工智能的魅力触手可及。</p><p>项目地址：<a href=\"https://top.aibase.com/tool/hidream-i1\" _src=\"https://top.aibase.com/tool/hidream-i1\">https://top.aibase.com/tool/hidream-i1</a></p>",
          "contentSnippet": "当代码的力量遇上艺术的灵感，新一代人工智能正在悄然改变创意世界的边界。近日，国产开源图像生成模型HiDream-I1震撼发布，凭借17亿参数的技术底蕴，这款由HiDream-ai团队倾力打造的AI\"画匠\"正迅速成为科技圈新宠。\n这款基于扩散模型技术的开源图像生成工具，能够将文本描述转化为高质量图像，在细节渲染和图像一致性方面展现出令人瞩目的实力。初步测试显示，HiDream-I1在色彩还原、边缘处理和构图完整性上表现不俗，特别是面对复杂场景和多样化风格时，依然能够生成清晰且富有艺术感的画面，与Stable Diffusion等国际知名模型相比毫不逊色。\n\n技术专家分析认为，HiDream-I1的成功很可能源于其开发团队对扩散模型前沿技术的精准把握，以及大规模预训练策略的巧妙应用。这种组合使其在生成速度与质量之间找到了绝佳平衡点。为满足不同用户需求，开发团队贴心地提供了完整版和精简版两种模型，后者专为计算资源有限的用户设计。更值得一提的是，该模型配备了一键式操作的推理脚本，极大降低了使用门槛，彰显了开源技术的普惠精神。\n目前，HiDream-I1已在GitHub平台上完全开源，并采用MIT许可证授权，允许开发者自由使用和改进。团队还提供了详尽的使用指南，并推荐搭配Flash Attention等优化工具以进一步提升性能。这种开放透明的态度不仅吸引了大量独立开发者和研究人员的关注，也为模型的持续优化和社区协作创造了有利条件。业内专家普遍认为，HiDream-I1很可能成为国产开源AI领域的一匹黑马，有潜力在国际舞台上与顶尖技术同台竞技。\n尽管前景光明，HiDream-I1作为新生力量仍面临着一系列挑战。虽然17亿参数在开源模型中已属可观规模，但与DALL·E3等动辄数十亿甚至百亿参数的商业巨头相比，其在图像多样性和创造性方面的表现还需更多实际验证。同时，在高分辨率图像生成或极端复杂场景处理方面的能力也有待更多数据支持。未来，HiDream-I1能否借助开源社区的力量实现突破性进展，将成为决定其长期影响力的关键因素。\n正值全球AI图像生成技术迅猛发展之际，HiDream-I1的横空出世为艺术创作、商业设计、教育科研等多个领域带来了免费且高效的工具选择。随着社区参与度的提升和技术的不断迭代，这款国产AI模型不仅有望成为中国人工智能技术的新名片，更可能在全球开源生态中占据重要位置，为更广泛的用户群体打开AI创意世界的大门，让人工智能的魅力触手可及。\n项目地址：https://top.aibase.com/tool/hidream-i1",
          "guid": "https://www.aibase.com/zh/news/16922",
          "isoDate": "2025-04-08T03:12:57.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "Qwen3即将来袭：阿里云新模型相关支持已正式合并至vLLM代码库",
          "link": "https://www.aibase.com/zh/news/16921",
          "pubDate": "Tue, 08 Apr 2025 02:59:56 GMT",
          "author": "AI Base",
          "content": "<p>近日，阿里云旗下人工智能大模型系列Qwen迎来重要进展，其下一代模型Qwen3的相关支持已正式合并至vLLM（高效大语言模型推理框架）的代码库中。这一消息迅速引发了科技圈的热烈讨论，标志着Qwen3的发布已进入倒计时阶段。据悉，Qwen3将包含至少两个版本:Qwen3-8B和Qwen3-MoE-15B-A2B，分别代表不同规模和架构的创新尝试，为开发者与企业用户带来了更多期待。</p><p>Qwen3-8B作为系列中的基础模型，预计将延续Qwen家族在语言理解与生成任务上的优异表现。业界推测，这一版本可能在多模态能力上有所突破，能够同时处理文本、图像甚至其他数据类型，从而满足更广泛的应用场景需求。与此同时，Qwen3-MoE-15B-A2B则采用了混合专家（Mixture-of-Experts， MoE）架构，拥有15亿参数，其中约2亿为活跃参数。这种设计旨在通过高效的专家路由机制，在保持较低计算成本的同时实现接近更大模型的性能表现。分析人士指出，若Qwen3-MoE-15B-A2B能在性能上媲美此前的Qwen2.5-Max(一款以高智能著称的模型)，其在实际应用中的潜力将不可小觑。</p><p style=\"text-align:center\"><img src=\"https://upload.chinaz.com/2025/0408/6387970677379963648046733.png\" title=\"image.png\" alt=\"image.png\" referrerpolicy=\"no-referrer\"></p><p>此次vLLM对Qwen3的支持合并，意味着开发者将能够利用这一高性能推理框架，轻松部署Qwen3模型以实现快速、稳定的推理任务。vLLM以其高效的内存管理和并行处理能力闻名，能够显著提升大模型在生产环境中的运行效率。这一进展不仅为Qwen3的落地应用铺平了道路，也进一步巩固了阿里云在开源AI生态中的影响力。</p><p>尽管Qwen3的具体功能和性能细节尚未完全公开，业界对其寄予厚望。Qwen2.5系列此前已在编码、数学推理和多语言任务中展现出超越同行的实力，而Qwen3被期待在这些领域进一步突破，尤其是在资源受限环境下的表现。MoE架构的引入也引发了讨论:相比传统密集模型，Qwen3-MoE-15B-A2B可能在能效比上更具优势，适合部署在边缘设备或中小型服务器上。然而，也有声音认为，15亿参数的规模相对较小，是否能完全满足复杂任务的需求仍需实测验证。</p><p>阿里云近年来在AI领域的持续投入已使其成为全球开源模型开发的重要力量。从Qwen1.5到Qwen2.5，每一代模型的迭代都伴随着技术与生态的双重进步。Qwen3的到来，不仅是阿里云技术升级的体现，也是在全球AI竞赛中抢占先机的重要一步。可以预见，随着更多细节的披露和模型的正式发布，Qwen3将在开发社区和企业应用中掀起新的热潮，为从智能助手到自动化流程的多种场景注入新的活力。</p>",
          "contentSnippet": "近日，阿里云旗下人工智能大模型系列Qwen迎来重要进展，其下一代模型Qwen3的相关支持已正式合并至vLLM（高效大语言模型推理框架）的代码库中。这一消息迅速引发了科技圈的热烈讨论，标志着Qwen3的发布已进入倒计时阶段。据悉，Qwen3将包含至少两个版本:Qwen3-8B和Qwen3-MoE-15B-A2B，分别代表不同规模和架构的创新尝试，为开发者与企业用户带来了更多期待。\nQwen3-8B作为系列中的基础模型，预计将延续Qwen家族在语言理解与生成任务上的优异表现。业界推测，这一版本可能在多模态能力上有所突破，能够同时处理文本、图像甚至其他数据类型，从而满足更广泛的应用场景需求。与此同时，Qwen3-MoE-15B-A2B则采用了混合专家（Mixture-of-Experts， MoE）架构，拥有15亿参数，其中约2亿为活跃参数。这种设计旨在通过高效的专家路由机制，在保持较低计算成本的同时实现接近更大模型的性能表现。分析人士指出，若Qwen3-MoE-15B-A2B能在性能上媲美此前的Qwen2.5-Max(一款以高智能著称的模型)，其在实际应用中的潜力将不可小觑。\n\n此次vLLM对Qwen3的支持合并，意味着开发者将能够利用这一高性能推理框架，轻松部署Qwen3模型以实现快速、稳定的推理任务。vLLM以其高效的内存管理和并行处理能力闻名，能够显著提升大模型在生产环境中的运行效率。这一进展不仅为Qwen3的落地应用铺平了道路，也进一步巩固了阿里云在开源AI生态中的影响力。\n尽管Qwen3的具体功能和性能细节尚未完全公开，业界对其寄予厚望。Qwen2.5系列此前已在编码、数学推理和多语言任务中展现出超越同行的实力，而Qwen3被期待在这些领域进一步突破，尤其是在资源受限环境下的表现。MoE架构的引入也引发了讨论:相比传统密集模型，Qwen3-MoE-15B-A2B可能在能效比上更具优势，适合部署在边缘设备或中小型服务器上。然而，也有声音认为，15亿参数的规模相对较小，是否能完全满足复杂任务的需求仍需实测验证。\n阿里云近年来在AI领域的持续投入已使其成为全球开源模型开发的重要力量。从Qwen1.5到Qwen2.5，每一代模型的迭代都伴随着技术与生态的双重进步。Qwen3的到来，不仅是阿里云技术升级的体现，也是在全球AI竞赛中抢占先机的重要一步。可以预见，随着更多细节的披露和模型的正式发布，Qwen3将在开发社区和企业应用中掀起新的热潮，为从智能助手到自动化流程的多种场景注入新的活力。",
          "guid": "https://www.aibase.com/zh/news/16921",
          "isoDate": "2025-04-08T02:59:56.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "ElevenLabs推出MCP服务器:AI语音能力无缝整合到智能助手",
          "link": "https://www.aibase.com/zh/news/16920",
          "pubDate": "Tue, 08 Apr 2025 02:53:22 GMT",
          "author": "AI Base",
          "content": "<p>ElevenLabs<span class=\"spamTxt\">最新</span>推出的MCP（Multi-modal Communication Protocol）服务器为AI生态系统带来重大升级。这项服务允许用户通过简单的文本提示，让AI助手(如Claude、Cursor、Windsurf等)直接访问ElevenLabs的完整AI音频平台能力。</p><p><video id=\"tmpVedio0\" class=\"edui-upload-video video-js vjs-default-skin video-js\" controls=\"\" preload=\"meta\" width=\"750\" height=\"450\" src=\"https://upload.chinaz.com/video/2025/0408/6387970638364838894663417.mp4\" data-setup=\"{}\"><source src=\"https://upload.chinaz.com/video/2025/0408/6387970638364838894663417.mp4\" type=\"video/mp4\"></video></p><p>MCP服务器本质上充当了一座桥梁，将ElevenLabs先进的文字转语音、语音克隆等技术连接到用户日常使用的AI工具中，使这些工具能够\"开口说话\"或处理各种声音内容。它提供了统一且可扩展的语音服务接口，大幅简化了API调用流程。</p><p>该服务支持文字转语音、语音转文字、声音克隆、多说话人识别与再合成、语音设计以及会话式AI等核心功能。特别值得注意的是，MCP服务器甚至支持启动语音代理来执行外拨电话任务，例如代表用户订购披萨。</p><p>在技术实现上，MCP服务器处理多种数据流，包括将简单文本转换为高质量语音文件、基于样本克隆特定声音、将音频转录为文本（支持说话人识别），以及生成自然环境音效等。这些功能通过简化的接口提供，让开发者和AI助手能够轻松整合这些先进的音频处理能力。</p>",
          "contentSnippet": "ElevenLabs最新推出的MCP（Multi-modal Communication Protocol）服务器为AI生态系统带来重大升级。这项服务允许用户通过简单的文本提示，让AI助手(如Claude、Cursor、Windsurf等)直接访问ElevenLabs的完整AI音频平台能力。\n\nMCP服务器本质上充当了一座桥梁，将ElevenLabs先进的文字转语音、语音克隆等技术连接到用户日常使用的AI工具中，使这些工具能够\"开口说话\"或处理各种声音内容。它提供了统一且可扩展的语音服务接口，大幅简化了API调用流程。\n该服务支持文字转语音、语音转文字、声音克隆、多说话人识别与再合成、语音设计以及会话式AI等核心功能。特别值得注意的是，MCP服务器甚至支持启动语音代理来执行外拨电话任务，例如代表用户订购披萨。\n在技术实现上，MCP服务器处理多种数据流，包括将简单文本转换为高质量语音文件、基于样本克隆特定声音、将音频转录为文本（支持说话人识别），以及生成自然环境音效等。这些功能通过简化的接口提供，让开发者和AI助手能够轻松整合这些先进的音频处理能力。",
          "guid": "https://www.aibase.com/zh/news/16920",
          "isoDate": "2025-04-08T02:53:22.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "PokemonGym：AI玩宝可梦Red，Claude仅用450步征服",
          "link": "https://www.aibase.com/zh/news/16919",
          "pubDate": "Tue, 08 Apr 2025 02:50:27 GMT",
          "author": "AI Base",
          "content": "<p>在人工智能领域不断突破的今天，一个名为 <strong>PokemonGym</strong> 的创新项目正悄然兴起，引起了游戏爱好者和AI研究者的广泛关注。<strong>PokemonGym 是一套专门为评估人工智能（AI）代理在经典游戏《宝可梦Red》中表现的服务平台</strong>。通过构建一套完善的服务器-客户端架构，PokemonGym 使得开发者可以训练和测试各种AI算法在虚拟的游戏世界中自主行动。</p><p><video id=\"tmpVedio0\" class=\"edui-upload-video video-js vjs-default-skin video-js\" controls=\"\" preload=\"meta\" width=\"750\" height=\"450\" src=\"https://upload.chinaz.com/video/2025/0408/6387970617257622541731797.mp4\" data-setup=\"{}\"><source src=\"https://upload.chinaz.com/video/2025/0408/6387970617257622541731797.mp4\" type=\"video/mp4\"></video></p><h3>PokemonGym的核心功能:让AI自主探索宝可梦世界</h3><p>PokemonGym 的核心在于其精心设计的系统:</p><p style=\"text-align: center;\"><img src=\"https://upload.chinaz.com/2025/0408/6387970618992106595439646.png\" title=\"QQ_1744080582447.png\" alt=\"QQ_1744080582447.png\" referrerpolicy=\"no-referrer\"></p><ul><li><strong>服务器 （Server）</strong>:这是一个基于 FastAPI 框架构建的后端服务，它负责运行《宝可梦Red》的模拟器，并通过应用程序接口（API）向外部暴露游戏状态。这意味着AI代理可以通过与服务器通信来获取游戏画面、角色状态等信息。</li><li><strong>人类代理 （Human Agent）</strong>:这是一个用户界面，允许人类玩家通过键盘控制在服务器上运行的《宝可梦Red》游戏。这为开发者提供了一个基准，可以对比人类玩家和AI代理的游戏行为和效率。</li><li><strong>演示代理 （Demo Agent）</strong>:这是一个由 <strong>Claude</strong> 大语言模型驱动的AI代理，它能够完全自主地玩《宝可梦Red》。该演示代理展示了当前先进的AI技术在复杂游戏环境中的潜力。</li><li><strong>评估系统 （Evaluation System）</strong>:PokemonGym 内置了一套评分机制，通过奖励玩家在游戏中的各种进展来评估AI代理的表现。这些进展包括捕捉新的宝可梦、获得道馆徽章、探索新的地点以及完成关键的游戏事件和里程碑。</li><li><strong>状态管理 （State Management）</strong>:系统具备强大的游戏状态保存和加载功能，允许跨会话继续游戏。这对于长时间的AI训练和评估至关重要。</li></ul><p>令人瞩目的是，PokemonGym 的开发者透露，由 Anthropic 的 <strong>Claude 大语言模型驱动的演示代理在约450步操作后成功获得了它的<span class=\"spamTxt\">第一</span>只宝可梦</strong>。作为一个对比，人类玩家通常需要大约400步的操作才能达到相同的成就。尽管在初期探索阶段，AI 的效率与人类相近，但这无疑证明了当前大型语言模型在理解游戏环境和制定行动策略方面已经具备了相当的能力。</p><h3>PokemonGym的未来潜力</h3><p>PokemonGym 的出现，不仅为AI研究人员提供了一个评估和比较不同AI算法在复杂游戏环境中表现的平台，也为游戏AI的未来发展带来了新的可能性。我们可以期待，未来将有更多更强大的AI代理在 PokemonGym 上诞生，甚至在更复杂的电子游戏中展现出超越人类玩家的潜力。</p><p>入口：https://top.aibase.com/tool/pokemongym</p>",
          "contentSnippet": "在人工智能领域不断突破的今天，一个名为 PokemonGym 的创新项目正悄然兴起，引起了游戏爱好者和AI研究者的广泛关注。PokemonGym 是一套专门为评估人工智能（AI）代理在经典游戏《宝可梦Red》中表现的服务平台。通过构建一套完善的服务器-客户端架构，PokemonGym 使得开发者可以训练和测试各种AI算法在虚拟的游戏世界中自主行动。\n\nPokemonGym的核心功能:让AI自主探索宝可梦世界\nPokemonGym 的核心在于其精心设计的系统:\n\n\n服务器 （Server）:这是一个基于 FastAPI 框架构建的后端服务，它负责运行《宝可梦Red》的模拟器，并通过应用程序接口（API）向外部暴露游戏状态。这意味着AI代理可以通过与服务器通信来获取游戏画面、角色状态等信息。\n人类代理 （Human Agent）:这是一个用户界面，允许人类玩家通过键盘控制在服务器上运行的《宝可梦Red》游戏。这为开发者提供了一个基准，可以对比人类玩家和AI代理的游戏行为和效率。\n演示代理 （Demo Agent）:这是一个由 Claude 大语言模型驱动的AI代理，它能够完全自主地玩《宝可梦Red》。该演示代理展示了当前先进的AI技术在复杂游戏环境中的潜力。\n评估系统 （Evaluation System）:PokemonGym 内置了一套评分机制，通过奖励玩家在游戏中的各种进展来评估AI代理的表现。这些进展包括捕捉新的宝可梦、获得道馆徽章、探索新的地点以及完成关键的游戏事件和里程碑。\n状态管理 （State Management）:系统具备强大的游戏状态保存和加载功能，允许跨会话继续游戏。这对于长时间的AI训练和评估至关重要。\n\n令人瞩目的是，PokemonGym 的开发者透露，由 Anthropic 的 Claude 大语言模型驱动的演示代理在约450步操作后成功获得了它的第一只宝可梦。作为一个对比，人类玩家通常需要大约400步的操作才能达到相同的成就。尽管在初期探索阶段，AI 的效率与人类相近，但这无疑证明了当前大型语言模型在理解游戏环境和制定行动策略方面已经具备了相当的能力。\nPokemonGym的未来潜力\nPokemonGym 的出现，不仅为AI研究人员提供了一个评估和比较不同AI算法在复杂游戏环境中表现的平台，也为游戏AI的未来发展带来了新的可能性。我们可以期待，未来将有更多更强大的AI代理在 PokemonGym 上诞生，甚至在更复杂的电子游戏中展现出超越人类玩家的潜力。\n入口：https://top.aibase.com/tool/pokemongym",
          "guid": "https://www.aibase.com/zh/news/16919",
          "isoDate": "2025-04-08T02:50:27.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "​Geekplus 连续四年入选全球顶级机器人公司，助力仓储效率革命",
          "link": "https://www.aibase.com/zh/news/16918",
          "pubDate": "Tue, 08 Apr 2025 02:20:33 GMT",
          "author": "AI Base",
          "content": "<p><span style=\"text-indent: 2em;\">全球储机器人领域的</span><span class=\"spamTxt\" style=\"text-indent: 2em;\"><span class=\"spamTxt\">领导者</span></span><span style=\"text-indent: 2em;\"> Geekplus 自豪地宣布，再次获得《机器人商业评论》(RBR) 颁发的 2025 年 RBR50 创新奖，这也是该公司连续第四次获得此殊荣。Geekplus 与全球科技巨头如 ABB 和 Nvidia 一同，被誉为机器人行业的 “奥斯卡”，以其在技术进步、商业影响和行业领导力方面的突出表现而备受认可。</span></p><p>Geekplus 的 SkyCube 托盘到人解决方案以其创新的集成托盘存储和拣选操作设计，重新定义了仓储自动化。这一技术实现了 5 到 8 倍的存储密度提升，并使拣选效率提高了 300%。目前，全球知名企业如吉利汽车和 Ship8 等都已采纳了 SkyCube 解决方案，证明其在大规模仓储运营中的转型能力。</p><p>Geekplus 在大型多机器人协调技术方面也突破了传统界限。其自主研发的机器人管理系统（RMS）能够在一个设施内管理超过 5000 台机器人，每秒处理 10，000 个任务，树立了高容量物流操作的新标杆。这一创新不仅确保了 SkyCube 的无缝运行，还与 Geekplus 的核心解决方案完美整合。</p><p>这项技术有效解决了全渠道仓储中的一大挑战，即在处理复杂的 B2B 和 B2C 订单履行时，管理多样化的库存类型。对于一家全球快消品巨头而言，SkyCube 成功将拣选效率提升了一倍，并降低了 65% 的人工成本，带来了显著的价值，为智能仓储树立了新的标杆。</p><p>作为仓储机器人领域的一站式合作伙伴，Geekplus 提供全面的机器人解决方案，从拣选、分拣到物料搬运和智能叉车，满足不同的仓储自动化需求。所有机器人型号均整合为一个系统，实现了无缝协调，使企业能够高效地扩展运营。</p><blockquote><p>划重点：&nbsp;&nbsp;</p><p>🌟 Geekplus 连续四年获得 2025 年 RBR50 创新奖，与 ABB 和 Nvidia 并肩。&nbsp;&nbsp;</p><p>🚀 SkyCube 解决方案实现 5-8 倍的存储密度和 300% 的拣选效率提升。&nbsp;&nbsp;</p><p>🤖 其机器人管理系统可管理超过 5000 台机器人，每秒处理 10，000 个任务，推动智能仓储变革。</p></blockquote><p><br></p>",
          "contentSnippet": "全球储机器人领域的领导者 Geekplus 自豪地宣布，再次获得《机器人商业评论》(RBR) 颁发的 2025 年 RBR50 创新奖，这也是该公司连续第四次获得此殊荣。Geekplus 与全球科技巨头如 ABB 和 Nvidia 一同，被誉为机器人行业的 “奥斯卡”，以其在技术进步、商业影响和行业领导力方面的突出表现而备受认可。\nGeekplus 的 SkyCube 托盘到人解决方案以其创新的集成托盘存储和拣选操作设计，重新定义了仓储自动化。这一技术实现了 5 到 8 倍的存储密度提升，并使拣选效率提高了 300%。目前，全球知名企业如吉利汽车和 Ship8 等都已采纳了 SkyCube 解决方案，证明其在大规模仓储运营中的转型能力。\nGeekplus 在大型多机器人协调技术方面也突破了传统界限。其自主研发的机器人管理系统（RMS）能够在一个设施内管理超过 5000 台机器人，每秒处理 10，000 个任务，树立了高容量物流操作的新标杆。这一创新不仅确保了 SkyCube 的无缝运行，还与 Geekplus 的核心解决方案完美整合。\n这项技术有效解决了全渠道仓储中的一大挑战，即在处理复杂的 B2B 和 B2C 订单履行时，管理多样化的库存类型。对于一家全球快消品巨头而言，SkyCube 成功将拣选效率提升了一倍，并降低了 65% 的人工成本，带来了显著的价值，为智能仓储树立了新的标杆。\n作为仓储机器人领域的一站式合作伙伴，Geekplus 提供全面的机器人解决方案，从拣选、分拣到物料搬运和智能叉车，满足不同的仓储自动化需求。所有机器人型号均整合为一个系统，实现了无缝协调，使企业能够高效地扩展运营。\n\n划重点：  \n🌟 Geekplus 连续四年获得 2025 年 RBR50 创新奖，与 ABB 和 Nvidia 并肩。  \n🚀 SkyCube 解决方案实现 5-8 倍的存储密度和 300% 的拣选效率提升。  \n🤖 其机器人管理系统可管理超过 5000 台机器人，每秒处理 10，000 个任务，推动智能仓储变革。",
          "guid": "https://www.aibase.com/zh/news/16918",
          "isoDate": "2025-04-08T02:20:33.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "Cloudflare 发布 Node.js 生态 Agents 开发包，助力 AI 代理开发",
          "link": "https://www.aibase.com/zh/news/16916",
          "pubDate": "Tue, 08 Apr 2025 02:11:56 GMT",
          "author": "AI Base",
          "content": "<p><span style=\"text-indent: 2em;\">近日，Cloudflare 推出了一款面向 Node.js 生态的 Agents 开发包，为开发者提供了一套完整的 AI 代理开发基础设施。</span></p><p><span style=\"text-indent: 2em;\">这一开发包集成了多项核心功能，包括工作流引擎、工具集成框架、多代理协作平台（MCP）以及状态持久化支持，旨在简化 AI 代理的构建与部署流程。</span></p><p style=\"text-align:center\"><span style=\"text-indent: 2em;\"><img src=\"https://upload.chinaz.com/2025/0408/6387970390754521867106112.png\" title=\"QQ20250408-101137.png\" alt=\"QQ20250408-101137.png\" referrerpolicy=\"no-referrer\"></span></p><p>据介绍，该开发包能够帮助开发者轻松实现自动化任务执行、多工具协同以及动态适应上下文的能力。Cloudflare 官网还特别提供了一段动画演示，生动展示了生成式 AI 与 Agentic 模式之间的区别，吸引了不少关注。动画直观地呈现了传统生成式 AI 的线性输出与 Agentic 代理的非线性、自主决策特性，凸显了后者在复杂任务处理中的优势。</p><p>此举标志着 Cloudflare 在 AI 代理领域的进一步深耕。通过整合 Node.js 生态与边缘计算能力，Agents 开发包不仅提升了开发效率，还为构建智能、自适应的代理系统提供了强大支持。开发者可通过官网了解详情并体验这一全新工具。</p><p>官网: https://agents.cloudflare.com/</p>",
          "contentSnippet": "近日，Cloudflare 推出了一款面向 Node.js 生态的 Agents 开发包，为开发者提供了一套完整的 AI 代理开发基础设施。\n这一开发包集成了多项核心功能，包括工作流引擎、工具集成框架、多代理协作平台（MCP）以及状态持久化支持，旨在简化 AI 代理的构建与部署流程。\n\n据介绍，该开发包能够帮助开发者轻松实现自动化任务执行、多工具协同以及动态适应上下文的能力。Cloudflare 官网还特别提供了一段动画演示，生动展示了生成式 AI 与 Agentic 模式之间的区别，吸引了不少关注。动画直观地呈现了传统生成式 AI 的线性输出与 Agentic 代理的非线性、自主决策特性，凸显了后者在复杂任务处理中的优势。\n此举标志着 Cloudflare 在 AI 代理领域的进一步深耕。通过整合 Node.js 生态与边缘计算能力，Agents 开发包不仅提升了开发效率，还为构建智能、自适应的代理系统提供了强大支持。开发者可通过官网了解详情并体验这一全新工具。\n官网: https://agents.cloudflare.com/",
          "guid": "https://www.aibase.com/zh/news/16916",
          "isoDate": "2025-04-08T02:11:56.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "GitHub 官方开源 MCP 服务器，支持无缝集成 GitHub API",
          "link": "https://www.aibase.com/zh/news/16915",
          "pubDate": "Tue, 08 Apr 2025 02:02:12 GMT",
          "author": "AI Base",
          "content": "<p><span style=\"text-indent: 2em;\">近日，GitHub 正式开源了一款全新的 MCP（Model Context Protocol）服务器，与 GitHub API 无缝集成，为开发者带来更高效的工作流体验。据悉，该服务器由 GitHub 联合 Anthropic 开发，采用 Go 语言重写，相较旧版功能更强大且易用。它保留了旧版服务器的所有功能，并新增了对自动化 GitHub 工作流的支持，能够从 GitHub 仓库中提取问题、获取信息等。</span></p><p style=\"text-align: center\"><img src=\"https://pic.chinaz.com/picmap/202304041450450257_6.jpg\" title=\"芯片 AI绘图 (2) (图片来源：AI合成)\" alt=\"芯片 AI绘图 (2)\" referrerpolicy=\"no-referrer\"></p><p style=\"text-align: center;\">图源备注：图片由AI生成，图片授权服务商Midjourney</p><p>这款 MCP 服务器可在多种环境中运行，包括 VS Code 的 Agent Mode、Claude Desktop，以及任何支持 MCP 协议的平台。随着 MCP 生态的日益完善，其灵活性和扩展性受到广泛关注。一名用户在推文中表示:“MCP 生态越来越完善了，等有空我也要试试开发个微信机器人的 MCP!”这反映了开发者对 MCP 潜力的期待与热情。</p><p>GitHub MCP 服务器的开源标志着 AI 与开发工具整合的进一步深化。无论是优化代码管理还是实现自动化任务，它都为开发者提供了强大支持。未来，随着更多开发者加入 MCP 生态，其应用场景有望进一步扩展。</p><p>GitHub MCP 服务器: https://github.com/github/github-mcp-serverVS Code Agent Mode&nbsp;</p><p>官方文档: https://code.visualstudio.com/docs/copilot/chat/chat-agent-mode</p>",
          "contentSnippet": "近日，GitHub 正式开源了一款全新的 MCP（Model Context Protocol）服务器，与 GitHub API 无缝集成，为开发者带来更高效的工作流体验。据悉，该服务器由 GitHub 联合 Anthropic 开发，采用 Go 语言重写，相较旧版功能更强大且易用。它保留了旧版服务器的所有功能，并新增了对自动化 GitHub 工作流的支持，能够从 GitHub 仓库中提取问题、获取信息等。\n\n图源备注：图片由AI生成，图片授权服务商Midjourney\n这款 MCP 服务器可在多种环境中运行，包括 VS Code 的 Agent Mode、Claude Desktop，以及任何支持 MCP 协议的平台。随着 MCP 生态的日益完善，其灵活性和扩展性受到广泛关注。一名用户在推文中表示:“MCP 生态越来越完善了，等有空我也要试试开发个微信机器人的 MCP!”这反映了开发者对 MCP 潜力的期待与热情。\nGitHub MCP 服务器的开源标志着 AI 与开发工具整合的进一步深化。无论是优化代码管理还是实现自动化任务，它都为开发者提供了强大支持。未来，随着更多开发者加入 MCP 生态，其应用场景有望进一步扩展。\nGitHub MCP 服务器: https://github.com/github/github-mcp-serverVS Code Agent Mode \n官方文档: https://code.visualstudio.com/docs/copilot/chat/chat-agent-mode",
          "guid": "https://www.aibase.com/zh/news/16915",
          "isoDate": "2025-04-08T02:02:12.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "五菱发布 “灵语座舱”：让沟通不再有障碍的智能驾驶舱",
          "link": "https://www.aibase.com/zh/news/16914",
          "pubDate": "Tue, 08 Apr 2025 02:01:22 GMT",
          "author": "AI Base",
          "content": "<p>五菱汽车正式推出了全新的 “灵语座舱”，该产品融合了先进的灵语 AI 中枢大模型，旨在突破语言沟通的障碍。这一座舱系统的核心优势在于其强大的方言识别能力，承诺能够让不同地方的用户无障碍地交流。</p><p>灵语 AI 中枢大模型的设计理念是通过感知、理解、表达和交互的全面升级，为用户提供更加智能和便捷的驾驶体验。该系统不仅支持智能调度，还内置了多项技术，比如语义拼接技术、知识蒸馏技术以及多音区对话分离技术，使得在复杂的语音环境中，系统依然能够保持高效的沟通能力。</p><p style=\"text-align:center\"><img src=\"https://upload.chinaz.com/2025/0408/6387970325856801992804467.png\" title=\"image.png\" alt=\"image.png\" referrerpolicy=\"no-referrer\"></p><p>五菱表示，灵语座舱特别适应中国市场，能够识别多达8种方言和12种重口音，识别率更是超过95%。这意味着，无论是来自南方的用户，还是北方的用户，都能轻松与座舱进行互动，真正实现 “让语言不再成为交流的障碍” 的目标。</p><p>此外，灵语座舱还提供了丰富的功能，如百科助手、灵感创作、旅游助手、音乐助手，以及景点和建筑查询等。这些功能不仅提升了用户的驾驶体验，还能在旅途中为用户提供有用的信息和灵感。</p><p>五菱的这一创新产品无疑将进一步推动智能汽车领域的发展，随着技术的不断进步，未来的汽车将不再是单纯的交通工具，而是充满智慧的交流伙伴。</p>",
          "contentSnippet": "五菱汽车正式推出了全新的 “灵语座舱”，该产品融合了先进的灵语 AI 中枢大模型，旨在突破语言沟通的障碍。这一座舱系统的核心优势在于其强大的方言识别能力，承诺能够让不同地方的用户无障碍地交流。\n灵语 AI 中枢大模型的设计理念是通过感知、理解、表达和交互的全面升级，为用户提供更加智能和便捷的驾驶体验。该系统不仅支持智能调度，还内置了多项技术，比如语义拼接技术、知识蒸馏技术以及多音区对话分离技术，使得在复杂的语音环境中，系统依然能够保持高效的沟通能力。\n\n五菱表示，灵语座舱特别适应中国市场，能够识别多达8种方言和12种重口音，识别率更是超过95%。这意味着，无论是来自南方的用户，还是北方的用户，都能轻松与座舱进行互动，真正实现 “让语言不再成为交流的障碍” 的目标。\n此外，灵语座舱还提供了丰富的功能，如百科助手、灵感创作、旅游助手、音乐助手，以及景点和建筑查询等。这些功能不仅提升了用户的驾驶体验，还能在旅途中为用户提供有用的信息和灵感。\n五菱的这一创新产品无疑将进一步推动智能汽车领域的发展，随着技术的不断进步，未来的汽车将不再是单纯的交通工具，而是充满智慧的交流伙伴。",
          "guid": "https://www.aibase.com/zh/news/16914",
          "isoDate": "2025-04-08T02:01:22.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "Mozilla发布LocalScore：简化本地AI模型基准测试的新工具",
          "link": "https://www.aibase.com/zh/news/16913",
          "pubDate": "Tue, 08 Apr 2025 01:58:19 GMT",
          "author": "AI Base",
          "content": "<p>Mozilla 最近通过其 Mozilla Builders 计划推出了一款名为 LocalScore 的工具，旨在为本地大型语言模型（LLM）提供便捷的基准测试。该工具兼容 Windows 和 Linux 系统，具有极大的潜力，成为了易于分发的 LLM 框架的重要组成部分。尽管 LocalScore 仍处于早期开发阶段，但其表现已相当不错。</p><p style=\"text-align:center\"><img src=\"https://upload.chinaz.com/2025/0408/6387970307245364546519798.png\" title=\"image.png\" alt=\"image.png\" referrerpolicy=\"no-referrer\"></p><p>LocalScore 是基于上周发布的 Llamafile0.9.2版本开发的，这一更新使得 LocalScore 成为一款实用的基准测试工具，能够在 CPU 和 GPU 上进行大型语言模型的性能评估。通过这一工具，用户可以轻松测量 LLM 系统的性能，获取快速且可靠的结果。</p><p style=\"text-align:center\"><img src=\"https://upload.chinaz.com/2025/0408/6387970308584557117535805.png\" title=\"image.png\" alt=\"image.png\" referrerpolicy=\"no-referrer\"></p><p>用户可以选择直接从 Llamafile 包中调用 LocalScore，或者使用适用于 Windows 和 Linux 的独立 LocalScore 二进制文件，方便进行 AI 基准测试。值得一提的是，LocalScore.ai 作为一个可选的存储库，专门用于存储 CPU 和 GPU 基准测试的结果，这些结果基于 Meta Llama3.1模型的官方模型进行计算。用户通过 LocalScore.ai 能够轻松运行基准测试，过程简单明了。</p><p>LocalScore 的推出不仅提升了 Mozilla 在 AI 和 LLM 领域的影响力，也为开发者和研究人员提供了一个开源的、便捷的基准测试工具。Mozilla Builders 计划期待更多易用、快速部署的跨平台开源 AI 基准测试工具的出现，以促进 AI 技术的进一步发展。</p>",
          "contentSnippet": "Mozilla 最近通过其 Mozilla Builders 计划推出了一款名为 LocalScore 的工具，旨在为本地大型语言模型（LLM）提供便捷的基准测试。该工具兼容 Windows 和 Linux 系统，具有极大的潜力，成为了易于分发的 LLM 框架的重要组成部分。尽管 LocalScore 仍处于早期开发阶段，但其表现已相当不错。\n\nLocalScore 是基于上周发布的 Llamafile0.9.2版本开发的，这一更新使得 LocalScore 成为一款实用的基准测试工具，能够在 CPU 和 GPU 上进行大型语言模型的性能评估。通过这一工具，用户可以轻松测量 LLM 系统的性能，获取快速且可靠的结果。\n\n用户可以选择直接从 Llamafile 包中调用 LocalScore，或者使用适用于 Windows 和 Linux 的独立 LocalScore 二进制文件，方便进行 AI 基准测试。值得一提的是，LocalScore.ai 作为一个可选的存储库，专门用于存储 CPU 和 GPU 基准测试的结果，这些结果基于 Meta Llama3.1模型的官方模型进行计算。用户通过 LocalScore.ai 能够轻松运行基准测试，过程简单明了。\nLocalScore 的推出不仅提升了 Mozilla 在 AI 和 LLM 领域的影响力，也为开发者和研究人员提供了一个开源的、便捷的基准测试工具。Mozilla Builders 计划期待更多易用、快速部署的跨平台开源 AI 基准测试工具的出现，以促进 AI 技术的进一步发展。",
          "guid": "https://www.aibase.com/zh/news/16913",
          "isoDate": "2025-04-08T01:58:19.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "夸克AI加持！阿里智能AI眼镜或于2025年底发布",
          "link": "https://www.aibase.com/zh/news/16912",
          "pubDate": "Tue, 08 Apr 2025 01:42:32 GMT",
          "author": "AI Base",
          "content": "<p><span style=\"text-indent: 2em;\">根维深信息Wellsenn XR消息，阿里巴巴已正式敲定AI智能眼镜项目方案，并正加速招聘和扩充团队。该项目由智能信息事业群天猫精灵团队主导，旨在推出硬件规格超越Ray-Ban Meta的智能眼镜产品。</span></p><p><span style=\"text-indent: 2em;\">据悉，阿里AI智能眼镜采用高通AR1芯片与恒玄BES2800的双芯片双系统架构，优化功耗与续航表现。摄像头沿用Ray-Ban Meta的索尼IMX681CMOS（1200万像素），由立景提供模组，整机代工则交由立讯精密负责。</span></p><p style=\"text-align: center\"><img src=\"https://pic.chinaz.com/picmap/202504031049202004_0.jpg\" title=\"眼镜，智能眼镜 (图片来源：AI合成)\" alt=\"眼镜，智能眼镜\" referrerpolicy=\"no-referrer\"></p><p style=\"text-align: center;\">图源备注：图片由AI生成，图片授权服务商Midjourney</p><p>阿里计划推出两款版本:不带显示的AI智能眼镜和带显示的AI+AR智能眼镜，其中AI+AR版本优先级更高。AR版本将采用表面浮雕光栅衍射光波导技术，搭载单绿色Micro LED光机模组，提升显示效果。AI功能方面，眼镜将深度整合阿里AI旗舰应用“夸克”，基于通义大模型技术，升级传统搜索为集AI对话、深度研究与任务执行于一体的“AI<span class=\"spamTxt\">超级</span>框”体验。</p><p>此举标志着阿里在AI与AR领域的进一步布局，或将挑战Meta在智能眼镜市场的地位。</p>",
          "contentSnippet": "根维深信息Wellsenn XR消息，阿里巴巴已正式敲定AI智能眼镜项目方案，并正加速招聘和扩充团队。该项目由智能信息事业群天猫精灵团队主导，旨在推出硬件规格超越Ray-Ban Meta的智能眼镜产品。\n据悉，阿里AI智能眼镜采用高通AR1芯片与恒玄BES2800的双芯片双系统架构，优化功耗与续航表现。摄像头沿用Ray-Ban Meta的索尼IMX681CMOS（1200万像素），由立景提供模组，整机代工则交由立讯精密负责。\n\n图源备注：图片由AI生成，图片授权服务商Midjourney\n阿里计划推出两款版本:不带显示的AI智能眼镜和带显示的AI+AR智能眼镜，其中AI+AR版本优先级更高。AR版本将采用表面浮雕光栅衍射光波导技术，搭载单绿色Micro LED光机模组，提升显示效果。AI功能方面，眼镜将深度整合阿里AI旗舰应用“夸克”，基于通义大模型技术，升级传统搜索为集AI对话、深度研究与任务执行于一体的“AI超级框”体验。\n此举标志着阿里在AI与AR领域的进一步布局，或将挑战Meta在智能眼镜市场的地位。",
          "guid": "https://www.aibase.com/zh/news/16912",
          "isoDate": "2025-04-08T01:42:32.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "​美国多家媒体呼吁政府要求OpenAI等科技公司为AI使用的内容付费",
          "link": "https://www.aibase.com/zh/news/16911",
          "pubDate": "Tue, 08 Apr 2025 01:41:24 GMT",
          "author": "AI Base",
          "content": "<p>近日，多家知名出版商组成的新闻 / 媒体联盟向美国政府发出呼吁，要求大型科技公司为其人工智能产品所使用的内容支付费用。该联盟包括《纽约时报》、《卫报》等国际知名媒体，发起了一项名为 “支持负责任的人工智能” 的活动，指责这些公司在创建人工智能产品时，未经授权窃取创作者的创意和内容，而不向创作者提供任何报酬。</p><p style=\"text-align: center\"><img src=\"https://pic.chinaz.com/picmap/201904150932285225_4.jpg\" title=\"版权 (1)(1) (图片版权所属：站长之家)\" alt=\"版权 (1)(1)\" referrerpolicy=\"no-referrer\"></p><p>该活动的官方网站强调，这种行为是 “非美国式的、错误的”。这些大型科技公司正在利用各种创作者的劳动成果，推动人工智能的发展，侵犯了创意产业的合法权益。该活动通过醒目的红白横幅吸引公众关注，上面标语包括 “保护工作免受人工智能盗窃”、“人工智能也会窃取你的工作”、“警惕人工智能” 等口号。这些横幅将在美国各地的数百家新闻出版物和数字媒体上展示。</p><p>此次活动向美国政府提出了三项主要要求:首先，要求大型科技和人工智能公司公平地补偿内容创作者;其次，要求对人工智能生成的内容提供透明的来源和归属信息;最后，呼吁防止大型企业采取垄断行为和反竞争行为。新闻 / 媒体联盟的总裁兼首席执行官丹尼尔・科菲表示，媒体行业并不反对人工智能的发展，但希望看到一个平衡的生态系统，让人工智能能够以负责任的方式运作，同时为优质内容的创造者提供回报，以促进产业的发展。</p><p>此外，OpenAI 与新闻 / 媒体联盟的成员之间曾发生过冲突。去年12月，《纽约时报》对 OpenAI 和微软提起诉讼，指控这两家公司未经授权使用其文章进行人工智能训练。就在上个月，一名联邦法官裁定此案可以继续进行，驳回了 OpenAI 提出的撤诉请求。</p><blockquote><p>划重点:</p><p>📄 媒体联盟呼吁美国政府要求大型科技公司支付使用内容的费用。</p><p>⚖️ 该活动提出三项主要要求:公平补偿、内容透明和防止垄断行为。</p><p>🎨 OpenAI 新工具引发关注，同时也让部分艺术家感到不安。</p></blockquote>",
          "contentSnippet": "近日，多家知名出版商组成的新闻 / 媒体联盟向美国政府发出呼吁，要求大型科技公司为其人工智能产品所使用的内容支付费用。该联盟包括《纽约时报》、《卫报》等国际知名媒体，发起了一项名为 “支持负责任的人工智能” 的活动，指责这些公司在创建人工智能产品时，未经授权窃取创作者的创意和内容，而不向创作者提供任何报酬。\n\n该活动的官方网站强调，这种行为是 “非美国式的、错误的”。这些大型科技公司正在利用各种创作者的劳动成果，推动人工智能的发展，侵犯了创意产业的合法权益。该活动通过醒目的红白横幅吸引公众关注，上面标语包括 “保护工作免受人工智能盗窃”、“人工智能也会窃取你的工作”、“警惕人工智能” 等口号。这些横幅将在美国各地的数百家新闻出版物和数字媒体上展示。\n此次活动向美国政府提出了三项主要要求:首先，要求大型科技和人工智能公司公平地补偿内容创作者;其次，要求对人工智能生成的内容提供透明的来源和归属信息;最后，呼吁防止大型企业采取垄断行为和反竞争行为。新闻 / 媒体联盟的总裁兼首席执行官丹尼尔・科菲表示，媒体行业并不反对人工智能的发展，但希望看到一个平衡的生态系统，让人工智能能够以负责任的方式运作，同时为优质内容的创造者提供回报，以促进产业的发展。\n此外，OpenAI 与新闻 / 媒体联盟的成员之间曾发生过冲突。去年12月，《纽约时报》对 OpenAI 和微软提起诉讼，指控这两家公司未经授权使用其文章进行人工智能训练。就在上个月，一名联邦法官裁定此案可以继续进行，驳回了 OpenAI 提出的撤诉请求。\n\n划重点:\n📄 媒体联盟呼吁美国政府要求大型科技公司支付使用内容的费用。\n⚖️ 该活动提出三项主要要求:公平补偿、内容透明和防止垄断行为。\n🎨 OpenAI 新工具引发关注，同时也让部分艺术家感到不安。",
          "guid": "https://www.aibase.com/zh/news/16911",
          "isoDate": "2025-04-08T01:41:24.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "前苹果设计总监最新最开发项目或为一款无屏 AI 手机",
          "link": "https://www.aibase.com/zh/news/16910",
          "pubDate": "Tue, 08 Apr 2025 01:36:24 GMT",
          "author": "AI Base",
          "content": "<p>据The Information报道，OpenAI 正在考虑收购一家公司，这家公司由前苹果设计总监 Jony Ive 和 OpenAI 首席执行官 Sam Altman 共同创立，名为 “io Products”。该公司专注于开发新型人工智能设备，包括一款可能没有屏幕的 “手机”，以及其他适用于家庭的智能产品。尽管项目接近的人士表示，这款产品并不完全是传统意义上的手机。</p><p>Ive 与 Altman 的合作始于一年多前，双方的主要目标是打造一款语音人工智能助手。目前，该项目仍处于初期设计阶段，最终产品的概念尚未确定。这家公司得到了 Laurene Powell Jobs 的 Emerson Collective 的资金支持。io Products 团队规模较小，核心成员包括前苹果设计师唐坦和埃文斯・汉基，他们曾与 Ive 一同设计过 iPhone，团队的设计能力备受期待。</p><p>除了收购的可能性，OpenAI 与 io Products 还在探讨其他合作方式。据知情人士透露，如果 OpenAI 完成收购，他们不仅能获取相关技术，还能整合开发该设备的工程团队。交易的结构预计将涉及 io Products 雇佣工程师来开发硬件，而 OpenAI 则负责提供人工智能功能，Ive 的 LoveFrom 工作室则会提供设计方面的专业知识。</p><p>Jony Ive 于2019年离开苹果，曾担任苹果的首席设计官，之后成立了自己的设计公司 LoveFrom。尽管如此，他仍然为苹果担任顾问，直到2022年才结束合作关系。</p><blockquote><p>划重点:</p><p>📱 OpenAI 考虑收购 Jony Ive 和 Sam Altman 创立的 AI 硬件初创公司 “io Products”，专注于无屏幕智能设备的开发。</p><p>💻 io Products 团队由前苹果设计师组成，目前仍处于初期设计阶段，尚未确定最终产品概念。</p><p>🤖 OpenAI 与 io Products 的合作可能会加剧其与苹果在人工智能语音助手市场的竞争。</p></blockquote>",
          "contentSnippet": "据The Information报道，OpenAI 正在考虑收购一家公司，这家公司由前苹果设计总监 Jony Ive 和 OpenAI 首席执行官 Sam Altman 共同创立，名为 “io Products”。该公司专注于开发新型人工智能设备，包括一款可能没有屏幕的 “手机”，以及其他适用于家庭的智能产品。尽管项目接近的人士表示，这款产品并不完全是传统意义上的手机。\nIve 与 Altman 的合作始于一年多前，双方的主要目标是打造一款语音人工智能助手。目前，该项目仍处于初期设计阶段，最终产品的概念尚未确定。这家公司得到了 Laurene Powell Jobs 的 Emerson Collective 的资金支持。io Products 团队规模较小，核心成员包括前苹果设计师唐坦和埃文斯・汉基，他们曾与 Ive 一同设计过 iPhone，团队的设计能力备受期待。\n除了收购的可能性，OpenAI 与 io Products 还在探讨其他合作方式。据知情人士透露，如果 OpenAI 完成收购，他们不仅能获取相关技术，还能整合开发该设备的工程团队。交易的结构预计将涉及 io Products 雇佣工程师来开发硬件，而 OpenAI 则负责提供人工智能功能，Ive 的 LoveFrom 工作室则会提供设计方面的专业知识。\nJony Ive 于2019年离开苹果，曾担任苹果的首席设计官，之后成立了自己的设计公司 LoveFrom。尽管如此，他仍然为苹果担任顾问，直到2022年才结束合作关系。\n\n划重点:\n📱 OpenAI 考虑收购 Jony Ive 和 Sam Altman 创立的 AI 硬件初创公司 “io Products”，专注于无屏幕智能设备的开发。\n💻 io Products 团队由前苹果设计师组成，目前仍处于初期设计阶段，尚未确定最终产品概念。\n🤖 OpenAI 与 io Products 的合作可能会加剧其与苹果在人工智能语音助手市场的竞争。",
          "guid": "https://www.aibase.com/zh/news/16910",
          "isoDate": "2025-04-08T01:36:24.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "Meta高管回应Llama 4训练作弊传言：坚决否认不实指控",
          "link": "https://www.aibase.com/zh/news/16909",
          "pubDate": "Tue, 08 Apr 2025 01:31:25 GMT",
          "author": "AI Base",
          "content": "<p>在近日的社交媒体上，Meta 公司的高层对关于其新 AI 模型 Llama4的 “不当训练” 指控进行了澄清，称这些说法完全不属实。指控声称 Meta 在其新推出的 Llama4Maverick 和 Llama4Scout 模型上，通过在特定基准测试的 “测试集” 上进行训练，以此来人为提高模型的性能表现。</p><p>Meta 的生成式人工智能副总裁艾哈迈德・阿尔・达赫勒（Ahmad Al-Dahle）在社交平台 X 上作出回应，明确表示这类说法毫无根据。他指出，测试集是用于评估模型性能的数据集，若在此数据集上进行训练，确实会导致模型的表现看起来远优于实际能力，这种行为在业界被视为不正当竞争。</p><p style=\"text-align: center\"><img src=\"https://pic.chinaz.com/picmap/202310270933175014_5.jpg\" title=\"LLM 羊驼 数学大模型 (图片来源：AI合成)\" alt=\"LLM 羊驼 数学大模型\" referrerpolicy=\"no-referrer\"></p><p style=\"text-align: center;\">图源备注：图片由AI生成，图片授权服务商Midjourney</p><p>不过，值得注意的是，Llama4Maverick 和 Llama4Scout 在某些任务上的确表现不如预期，Meta 也承认其选择在基准测试平台 LM Arena 上使用未发布的实验版本 Maverick 来获得更高的成绩，这无疑为上述谣言提供了部分 “证据”。研究人员已经发现，公众可下载的 Maverick 与在 LM Arena 上托管的版本在行为上存在显著差异。</p><p>阿尔・达赫勒还表示，一些用户在使用不同云服务商提供的 Llama4模型时，确实遇到了质量参差不齐的情况。他解释说:“由于我们在模型准备好后就迅速发布，因此预计需要几天的时间来调整所有公开的版本。我们将继续进行错误修复，并与合作伙伴保持沟通。”</p><p>Meta 此次澄清表明，该公司在 AI 领域的伦理标准仍然值得信赖，同时也提醒大家，任何 AI 模型的表现都可能因版本差异而有所不同。</p>",
          "contentSnippet": "在近日的社交媒体上，Meta 公司的高层对关于其新 AI 模型 Llama4的 “不当训练” 指控进行了澄清，称这些说法完全不属实。指控声称 Meta 在其新推出的 Llama4Maverick 和 Llama4Scout 模型上，通过在特定基准测试的 “测试集” 上进行训练，以此来人为提高模型的性能表现。\nMeta 的生成式人工智能副总裁艾哈迈德・阿尔・达赫勒（Ahmad Al-Dahle）在社交平台 X 上作出回应，明确表示这类说法毫无根据。他指出，测试集是用于评估模型性能的数据集，若在此数据集上进行训练，确实会导致模型的表现看起来远优于实际能力，这种行为在业界被视为不正当竞争。\n\n图源备注：图片由AI生成，图片授权服务商Midjourney\n不过，值得注意的是，Llama4Maverick 和 Llama4Scout 在某些任务上的确表现不如预期，Meta 也承认其选择在基准测试平台 LM Arena 上使用未发布的实验版本 Maverick 来获得更高的成绩，这无疑为上述谣言提供了部分 “证据”。研究人员已经发现，公众可下载的 Maverick 与在 LM Arena 上托管的版本在行为上存在显著差异。\n阿尔・达赫勒还表示，一些用户在使用不同云服务商提供的 Llama4模型时，确实遇到了质量参差不齐的情况。他解释说:“由于我们在模型准备好后就迅速发布，因此预计需要几天的时间来调整所有公开的版本。我们将继续进行错误修复，并与合作伙伴保持沟通。”\nMeta 此次澄清表明，该公司在 AI 领域的伦理标准仍然值得信赖，同时也提醒大家，任何 AI 模型的表现都可能因版本差异而有所不同。",
          "guid": "https://www.aibase.com/zh/news/16909",
          "isoDate": "2025-04-08T01:31:25.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "​谷歌将多模态搜索功能引入AI模式，用户可询问图像内容",
          "link": "https://www.aibase.com/zh/news/16908",
          "pubDate": "Tue, 08 Apr 2025 01:31:09 GMT",
          "author": "AI Base",
          "content": "<p>谷歌近日在其博客中宣布，将多模态搜索功能引入 AI 模式，这一新功能允许用户通过复杂的问题深入了解图像内容。此功能为有权使用 AI 模式的用户提供，用户现在可以直接对他们上传或用相机拍摄的照片进行提问。</p><p>AI 模式中的新图像分析功能是基于Google Lens 的多模式技术。谷歌表示，该模式能够理解图像中的整个场景，包括物体之间的关系、材质、颜色、形状及排列等。通过一种称为 “查询扇出” 的技术，用户可以对图像及其所显示的对象提出多个问题，获得比传统搜索更详细的信息。</p><p style=\"text-align:center\"><img src=\"https://upload.chinaz.com/2025/0408/6387970139152135743027357.png\" title=\"QQ_1744075778663.png\" alt=\"QQ_1744075778663.png\" referrerpolicy=\"no-referrer\"></p><p style=\"text-align:center\"><img src=\"https://upload.chinaz.com/2025/0408/6387970140293823351949793.png\" title=\"QQ_1744075795700.png\" alt=\"QQ_1744075795700.png\" referrerpolicy=\"no-referrer\"></p><p>例如，用户可以拍摄一张书架的照片，然后询问:“如果我喜欢这些书，还有哪些类似的、评价很高的书?”AI 模式将识别照片中的每本书，并生成一份推荐书籍列表，附带了解更多信息和购买链接。更为人性化的是，用户还可以继续提问，以进一步缩小搜索范围，比如 “我在寻找快速阅读材料，这些推荐中哪一个最短?” 这样的互动方式让搜索变得更加智能和个性化。</p><p>谷歌表示，AI 模式的新功能将在未来几周内向数百万加入实验室的用户推广，此前该模式仅限于 Google One AI Premium 订阅用户使用。此次推出的 AI 模式旨在与市面上流行的服务，如 Perplexity 和 OpenAI 的 ChatGPT Search 等进行竞争。</p><p>谷歌还表示，未来将持续改进用户体验，并扩展这一新功能，力求为用户带来更优质的服务体验。</p><blockquote><p>划重点:</p><p>🌟 新功能:谷歌 AI 模式允许用户通过多模态搜索深入提问图像内容。&nbsp;&nbsp;</p><p>📚 智能推荐:用户可上传照片并获得相关书籍推荐及链接。&nbsp;&nbsp;</p><p>🚀 扩展计划:新功能将在数百万用户中推广，未来将持续改进。&nbsp;&nbsp;</p></blockquote>",
          "contentSnippet": "谷歌近日在其博客中宣布，将多模态搜索功能引入 AI 模式，这一新功能允许用户通过复杂的问题深入了解图像内容。此功能为有权使用 AI 模式的用户提供，用户现在可以直接对他们上传或用相机拍摄的照片进行提问。\nAI 模式中的新图像分析功能是基于Google Lens 的多模式技术。谷歌表示，该模式能够理解图像中的整个场景，包括物体之间的关系、材质、颜色、形状及排列等。通过一种称为 “查询扇出” 的技术，用户可以对图像及其所显示的对象提出多个问题，获得比传统搜索更详细的信息。\n\n\n例如，用户可以拍摄一张书架的照片，然后询问:“如果我喜欢这些书，还有哪些类似的、评价很高的书?”AI 模式将识别照片中的每本书，并生成一份推荐书籍列表，附带了解更多信息和购买链接。更为人性化的是，用户还可以继续提问，以进一步缩小搜索范围，比如 “我在寻找快速阅读材料，这些推荐中哪一个最短?” 这样的互动方式让搜索变得更加智能和个性化。\n谷歌表示，AI 模式的新功能将在未来几周内向数百万加入实验室的用户推广，此前该模式仅限于 Google One AI Premium 订阅用户使用。此次推出的 AI 模式旨在与市面上流行的服务，如 Perplexity 和 OpenAI 的 ChatGPT Search 等进行竞争。\n谷歌还表示，未来将持续改进用户体验，并扩展这一新功能，力求为用户带来更优质的服务体验。\n\n划重点:\n🌟 新功能:谷歌 AI 模式允许用户通过多模态搜索深入提问图像内容。  \n📚 智能推荐:用户可上传照片并获得相关书籍推荐及链接。  \n🚀 扩展计划:新功能将在数百万用户中推广，未来将持续改进。",
          "guid": "https://www.aibase.com/zh/news/16908",
          "isoDate": "2025-04-08T01:31:09.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "​亚马逊 AI 视频模型 Nova Reel 升级：可生成长达两分钟的视频片段",
          "link": "https://www.aibase.com/zh/news/16907",
          "pubDate": "Tue, 08 Apr 2025 01:27:10 GMT",
          "author": "AI Base",
          "content": "<p>亚马逊近日对其 AI 视频生成模型 Nova Reel 进行了升级，推出了 Nova Reel1.1版本。这个新版本不仅能够生成长达两分钟的视频片段，还可以制作多镜头视频，使得各个镜头之间的风格保持一致。Nova Reel 于2024年12月<span class=\"spamTxt\">首次</span>发布，是亚马逊在生成视频领域的重要尝试。</p><p style=\"text-align: center;\"><img src=\"https://upload.chinaz.com/2025/0408/6387970120849887713205466.png\" title=\"QQ_1744075593323.png\" alt=\"QQ_1744075593323.png\" referrerpolicy=\"no-referrer\"></p><p>据 AWS 开发倡导者 Elizabeth Fuentes 在一篇博文中透露，用户可以通过提供最长4，000个字符的提示，生成由六秒镜头组成的长视频。新版的 Nova Reel 还引入了一种名为 “Multishot Manual” 的新模式。在这种模式下，用户可以提供图像和文本提示，帮助模型更好地控制视频镜头的构图。Fuentes 指出，给定1280×720分辨率的图像和最多512个字符的提示，Multishot Manual 模式可以生成最多包含20个镜头的视频。</p><p style=\"text-align: center;\"><img src=\"https://upload.chinaz.com/2025/0408/6387970112607309868778120.png\" title=\"QQ_1744075514217.png\" alt=\"QQ_1744075514217.png\" referrerpolicy=\"no-referrer\"></p><p>Nova Reel 目前仅通过亚马逊 AWS 平台和相关服务（如 AI 开发套件 Bedrock）提供，客户需申请特别访问权限。随着越来越多的公司进入生成视频领域，Nova Reel 与 OpenAI、Google 等公司的产品展开了激烈的竞争。</p><p>然而，关于该视频生成模型的开发方法，外界依然存在质疑。生成式 AI 模型通常需要通过大量视频样本进行训练，以 “学习” 生成新的视频片段。然而，部分公司在未获得所有者或创作者许可的情况下，使用受版权保护的视频进行训练，这可能导致用户面临知识产权诉讼。尽管亚马逊尚未披露 Reel 的训练数据来源，也没有明确说明创作者如何选择退出其数据集，但该公司表示，将根据其赔偿政策保护任何被指控侵犯其模型生成的媒体版权的 AWS 客户。</p><p>官方博客:https://aws.amazon.com/cn/blogs/aws/amazon-nova-reel-1-1-featuring-up-to-2-minutes-multi-shot-videos/</p><blockquote><p>划重点:&nbsp;&nbsp;</p><p>🎥 Nova Reel1.1版可以生成长达两分钟的视频，并支持多镜头制作。&nbsp;&nbsp;</p><p>📊 用户可提供长达4，000字符的提示，生成6秒镜头视频，最多20个镜头。&nbsp;&nbsp;</p><p>⚖️ 亚马逊对训练数据来源的保密引发了关于版权和知识产权的讨论。</p></blockquote>",
          "contentSnippet": "亚马逊近日对其 AI 视频生成模型 Nova Reel 进行了升级，推出了 Nova Reel1.1版本。这个新版本不仅能够生成长达两分钟的视频片段，还可以制作多镜头视频，使得各个镜头之间的风格保持一致。Nova Reel 于2024年12月首次发布，是亚马逊在生成视频领域的重要尝试。\n\n据 AWS 开发倡导者 Elizabeth Fuentes 在一篇博文中透露，用户可以通过提供最长4，000个字符的提示，生成由六秒镜头组成的长视频。新版的 Nova Reel 还引入了一种名为 “Multishot Manual” 的新模式。在这种模式下，用户可以提供图像和文本提示，帮助模型更好地控制视频镜头的构图。Fuentes 指出，给定1280×720分辨率的图像和最多512个字符的提示，Multishot Manual 模式可以生成最多包含20个镜头的视频。\n\nNova Reel 目前仅通过亚马逊 AWS 平台和相关服务（如 AI 开发套件 Bedrock）提供，客户需申请特别访问权限。随着越来越多的公司进入生成视频领域，Nova Reel 与 OpenAI、Google 等公司的产品展开了激烈的竞争。\n然而，关于该视频生成模型的开发方法，外界依然存在质疑。生成式 AI 模型通常需要通过大量视频样本进行训练，以 “学习” 生成新的视频片段。然而，部分公司在未获得所有者或创作者许可的情况下，使用受版权保护的视频进行训练，这可能导致用户面临知识产权诉讼。尽管亚马逊尚未披露 Reel 的训练数据来源，也没有明确说明创作者如何选择退出其数据集，但该公司表示，将根据其赔偿政策保护任何被指控侵犯其模型生成的媒体版权的 AWS 客户。\n官方博客:https://aws.amazon.com/cn/blogs/aws/amazon-nova-reel-1-1-featuring-up-to-2-minutes-multi-shot-videos/\n\n划重点:  \n🎥 Nova Reel1.1版可以生成长达两分钟的视频，并支持多镜头制作。  \n📊 用户可提供长达4，000字符的提示，生成6秒镜头视频，最多20个镜头。  \n⚖️ 亚马逊对训练数据来源的保密引发了关于版权和知识产权的讨论。",
          "guid": "https://www.aibase.com/zh/news/16907",
          "isoDate": "2025-04-08T01:27:10.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "Meta Llama4强势登场，却在长上下文任务中翻车",
          "link": "https://www.aibase.com/zh/news/16906",
          "pubDate": "Tue, 08 Apr 2025 01:25:14 GMT",
          "author": "AI Base",
          "content": "<p><span style=\"text-indent: 2em;\">一项新的独立评估显示，Meta <span class=\"spamTxt\">最新</span>推出的 Llama4模型——Maverick 和 Scout 在标准测试中表现出色，但在复杂长上下文任务中表现欠佳。根据人工智能分析的“智能指数”，Maverick 得分49分，领先 Claude3.7Sonnet（得分未具体列出），但落后于 Deepseek V30324(53分);Scout 得分36分，与 GPT-4o-mini 相当，优于 Claude3.5Sonnet 和 Mistral Small3.1。两款模型在推理、编码和数学任务中表现稳定，未显示明显短板。</span></p><p style=\"text-align:center\"><span style=\"text-indent: 2em;\"><img src=\"https://upload.chinaz.com/2025/0408/6387970107932040458617550.png\" title=\"QQ20250408-092416.png\" alt=\"QQ20250408-092416.png\" referrerpolicy=\"no-referrer\"></span></p><p>Maverick 的架构效率令人瞩目，其活动参数仅为 Deepseek V3的170亿（对比370亿），总参数占60%(4020亿对比6710亿)，且能处理图像而非仅限于文本。价格方面，Maverick 每百万输入/输出代币均价为0.24美元/0.77美元，Scout 为0.15美元/0.4美元，低于 Deepseek V3，甚至比 GPT-4o 便宜10倍，成为最实惠的 AI 模型之一。</p><p>然而，Llama4的发布引发争议。LMArena 基准测试显示，Maverick 在 Meta 推荐的“实验性聊天版本”下排名第二，但启用“风格控制”后跌至第五，凸显其依赖格式优化而非纯粹内容质量。测试人员质疑 Meta 的基准可靠性，指出其与其他平台表现差异明显。Meta 承认优化了人类评估体验，但否认训练数据作弊。</p><p style=\"text-align:center\"><img src=\"https://upload.chinaz.com/2025/0408/6387970108928466265636479.png\" title=\"QQ20250408-092427.png\" alt=\"QQ20250408-092427.png\" referrerpolicy=\"no-referrer\"></p><p>长上下文任务是 Llama4的明显弱点。Fiction.live 测试表明，Maverick 在128，000个令牌下准确率仅为28.1%，Scout 更低至15.6%，远逊于 Gemini2.5Pro 的90.6%。尽管 Meta 宣称 Maverick 支持100万令牌、Scout 支持1000万令牌上下文窗口，但实际性能远未达标。研究显示，超大上下文窗口收益有限，128K 以下更实用。</p><p>Meta 生成 AI 负责人 Ahmad Al-Dahle 回应称，早期不一致源于实施问题，而非模型缺陷。他否认测试作弊指控，并表示部署优化正在进行，预计数日内稳定。</p>",
          "contentSnippet": "一项新的独立评估显示，Meta 最新推出的 Llama4模型——Maverick 和 Scout 在标准测试中表现出色，但在复杂长上下文任务中表现欠佳。根据人工智能分析的“智能指数”，Maverick 得分49分，领先 Claude3.7Sonnet（得分未具体列出），但落后于 Deepseek V30324(53分);Scout 得分36分，与 GPT-4o-mini 相当，优于 Claude3.5Sonnet 和 Mistral Small3.1。两款模型在推理、编码和数学任务中表现稳定，未显示明显短板。\n\nMaverick 的架构效率令人瞩目，其活动参数仅为 Deepseek V3的170亿（对比370亿），总参数占60%(4020亿对比6710亿)，且能处理图像而非仅限于文本。价格方面，Maverick 每百万输入/输出代币均价为0.24美元/0.77美元，Scout 为0.15美元/0.4美元，低于 Deepseek V3，甚至比 GPT-4o 便宜10倍，成为最实惠的 AI 模型之一。\n然而，Llama4的发布引发争议。LMArena 基准测试显示，Maverick 在 Meta 推荐的“实验性聊天版本”下排名第二，但启用“风格控制”后跌至第五，凸显其依赖格式优化而非纯粹内容质量。测试人员质疑 Meta 的基准可靠性，指出其与其他平台表现差异明显。Meta 承认优化了人类评估体验，但否认训练数据作弊。\n\n长上下文任务是 Llama4的明显弱点。Fiction.live 测试表明，Maverick 在128，000个令牌下准确率仅为28.1%，Scout 更低至15.6%，远逊于 Gemini2.5Pro 的90.6%。尽管 Meta 宣称 Maverick 支持100万令牌、Scout 支持1000万令牌上下文窗口，但实际性能远未达标。研究显示，超大上下文窗口收益有限，128K 以下更实用。\nMeta 生成 AI 负责人 Ahmad Al-Dahle 回应称，早期不一致源于实施问题，而非模型缺陷。他否认测试作弊指控，并表示部署优化正在进行，预计数日内稳定。",
          "guid": "https://www.aibase.com/zh/news/16906",
          "isoDate": "2025-04-08T01:25:14.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "谷歌DeepMind被曝启用“激进”竞业禁止协议 ，离职一年内不得为竞争对手工作",
          "link": "https://www.aibase.com/zh/news/16905",
          "pubDate": "Tue, 08 Apr 2025 01:19:58 GMT",
          "author": "AI Base",
          "content": "<p>在竞争激烈的人工智能行业中，谷歌的 AI 部门 DeepMind 采取了极端措施，以留住<span class=\"spamTxt\">顶尖</span>人才。据《商业内幕》报道，该公司在英国的部分 AI 员工签署了 “激进” 的竞业协议，这意味着这些员工在离职后的一年内不得为竞争对手工作。这种协议不仅限制了员工的职业选择，还让他们在这一年中无法参与行业内快速发展的技术进步。</p><p style=\"text-align: center\"><img src=\"https://pic.chinaz.com/picmap/201811151621147122_90.jpg\" title=\"谷歌，google (图片来源图虫：已授站长之家使用)\" alt=\"谷歌，google\" referrerpolicy=\"no-referrer\"></p><p>有报道称，这些员工在协议期间仍会领取工资，实际上相当于一段长达一年的带薪休假。然而，这种做法让一些研究人员感到被隔离，与行业的发展脱节。尽管美国联邦贸易委员会（FTC）去年已禁止大部分竞业协议，但这一禁令不适用于 DeepMind 位于伦敦的总部，因此员工们依旧面临这些限制。</p><p>最近，微软 AI 部门的副总裁在社交媒体平台 X 上发文，表示有 DeepMind 的员工向他求助，表达对解除非竞争协议的绝望感。这一情况引发了广泛关注，显示出 AI 行业内人才流动的复杂性及其对个人职业发展的影响。</p><p style=\"text-align: center;\"><img src=\"https://upload.chinaz.com/2025/0408/6387970089882739103651362.png\" title=\"QQ_1744075286701.png\" alt=\"QQ_1744075286701.png\" referrerpolicy=\"no-referrer\"></p><p>谷歌在给《商业内幕》的回复中表示，他们会 “有选择地” 使用竞业协议。这一表态并未消除外界对公司人力资源管理方式的质疑，尤其是在如此快速变化的行业中。</p><p>随着人工智能技术的快速发展，各大科技公司之间的竞争愈发激烈。谷歌通过这种方式试图保护自身的技术优势，但这种措施是否会影响员工的工作满意度及行业内的创新，仍有待观察。</p><blockquote><p>划重点:</p><p>🔒 谷歌的 DeepMind 在英国实施竞业协议，限制部分 AI 员工在离职后的一年内加入竞争对手。</p><p>💰 在协议期间，这些员工会获得薪水，相当于长达一年的带薪休假。</p><p>😟 微软 AI 副总裁透露，DeepMind 的员工因非竞争协议感到绝望，寻求解脱。</p></blockquote>",
          "contentSnippet": "在竞争激烈的人工智能行业中，谷歌的 AI 部门 DeepMind 采取了极端措施，以留住顶尖人才。据《商业内幕》报道，该公司在英国的部分 AI 员工签署了 “激进” 的竞业协议，这意味着这些员工在离职后的一年内不得为竞争对手工作。这种协议不仅限制了员工的职业选择，还让他们在这一年中无法参与行业内快速发展的技术进步。\n\n有报道称，这些员工在协议期间仍会领取工资，实际上相当于一段长达一年的带薪休假。然而，这种做法让一些研究人员感到被隔离，与行业的发展脱节。尽管美国联邦贸易委员会（FTC）去年已禁止大部分竞业协议，但这一禁令不适用于 DeepMind 位于伦敦的总部，因此员工们依旧面临这些限制。\n最近，微软 AI 部门的副总裁在社交媒体平台 X 上发文，表示有 DeepMind 的员工向他求助，表达对解除非竞争协议的绝望感。这一情况引发了广泛关注，显示出 AI 行业内人才流动的复杂性及其对个人职业发展的影响。\n\n谷歌在给《商业内幕》的回复中表示，他们会 “有选择地” 使用竞业协议。这一表态并未消除外界对公司人力资源管理方式的质疑，尤其是在如此快速变化的行业中。\n随着人工智能技术的快速发展，各大科技公司之间的竞争愈发激烈。谷歌通过这种方式试图保护自身的技术优势，但这种措施是否会影响员工的工作满意度及行业内的创新，仍有待观察。\n\n划重点:\n🔒 谷歌的 DeepMind 在英国实施竞业协议，限制部分 AI 员工在离职后的一年内加入竞争对手。\n💰 在协议期间，这些员工会获得薪水，相当于长达一年的带薪休假。\n😟 微软 AI 副总裁透露，DeepMind 的员工因非竞争协议感到绝望，寻求解脱。",
          "guid": "https://www.aibase.com/zh/news/16905",
          "isoDate": "2025-04-08T01:19:58.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "​谷歌 Gemini Live 屏幕共享功能开始支持 Pixel 9 和 Galaxy S25 手机",
          "link": "https://www.aibase.com/zh/news/16904",
          "pubDate": "Tue, 08 Apr 2025 01:13:34 GMT",
          "author": "AI Base",
          "content": "<p>近日，谷歌宣布其<span class=\"spamTxt\">最新</span>的 Gemini Live 摄像头和屏幕共享功能正在向 Pixel9系列手机和三星 Galaxy S25设备推送。这一更新将使用户能够通过对话式 AI 聊天机器人实时获得与周围环境相关的信息，极大提升了手机的互动性和实用性。虽然目前这一功能仅限于新款设备，但谷歌表示，未来将向更多安卓设备推出，但使用该功能的用户需要成为 Gemini Advanced 的付费订阅用户。</p><p style=\"text-align:center\"><img src=\"https://upload.chinaz.com/2025/0408/6387970039947434984386454.png\" title=\"QQ_1744074787970.png\" alt=\"QQ_1744074787970.png\" referrerpolicy=\"no-referrer\"></p><p>Gemini Live 功能的使用相当简单。用户只需按下按钮即可激活实时视频功能，并向 Gemini Live 提问有关摄像头所捕捉到的内容。例如，当用户将摄像头对准水族箱时，可以询问 Gemini Live 关于特定鱼类的信息。此外，用户还可以使用新的屏幕共享按钮，将购物网站展示给 Gemini Live，进一步请求 AI 助手对比产品或提供搭配建议。</p><p>这一新功能最早在谷歌今年4月的 Pixel Drop 视频中展示，而在5月份的 Google I/O 开发者大会上也做了详细的演示，称其为 “Project Astra”。谷歌发言人亚历克斯・约瑟夫在上个月确认，该功能已经开始向客户推送。一些用户在 Reddit 社区中反馈，他们在小米等品牌的手机上也收到了这一更新。</p><p>值得一提的是，Gemini Live 目前支持45种语言，面向18岁以上的用户开放（不包括教育和企业账户），这使得不同国家的用户都能够体验到这一创新的技术。</p><p>随着技术的不断进步，Gemini Live 将为用户的日常生活带来更为便利的体验，帮助他们轻松获取信息和进行互动，彰显了智能手机在生活中越来越重要的角色。</p><blockquote><p>划重点:</p><p>🌟 新功能:谷歌 Gemini Live 摄像头和屏幕共享功能已上线 Pixel9和 Galaxy S25设备。</p><p>🛒 使用便捷:用户可实时提问，获取摄像头捕捉内容的信息和购物建议。</p><p>🌍 语言支持:Gemini Live 支持45种语言，适合18岁以上用户。</p></blockquote>",
          "contentSnippet": "近日，谷歌宣布其最新的 Gemini Live 摄像头和屏幕共享功能正在向 Pixel9系列手机和三星 Galaxy S25设备推送。这一更新将使用户能够通过对话式 AI 聊天机器人实时获得与周围环境相关的信息，极大提升了手机的互动性和实用性。虽然目前这一功能仅限于新款设备，但谷歌表示，未来将向更多安卓设备推出，但使用该功能的用户需要成为 Gemini Advanced 的付费订阅用户。\n\nGemini Live 功能的使用相当简单。用户只需按下按钮即可激活实时视频功能，并向 Gemini Live 提问有关摄像头所捕捉到的内容。例如，当用户将摄像头对准水族箱时，可以询问 Gemini Live 关于特定鱼类的信息。此外，用户还可以使用新的屏幕共享按钮，将购物网站展示给 Gemini Live，进一步请求 AI 助手对比产品或提供搭配建议。\n这一新功能最早在谷歌今年4月的 Pixel Drop 视频中展示，而在5月份的 Google I/O 开发者大会上也做了详细的演示，称其为 “Project Astra”。谷歌发言人亚历克斯・约瑟夫在上个月确认，该功能已经开始向客户推送。一些用户在 Reddit 社区中反馈，他们在小米等品牌的手机上也收到了这一更新。\n值得一提的是，Gemini Live 目前支持45种语言，面向18岁以上的用户开放（不包括教育和企业账户），这使得不同国家的用户都能够体验到这一创新的技术。\n随着技术的不断进步，Gemini Live 将为用户的日常生活带来更为便利的体验，帮助他们轻松获取信息和进行互动，彰显了智能手机在生活中越来越重要的角色。\n\n划重点:\n🌟 新功能:谷歌 Gemini Live 摄像头和屏幕共享功能已上线 Pixel9和 Galaxy S25设备。\n🛒 使用便捷:用户可实时提问，获取摄像头捕捉内容的信息和购物建议。\n🌍 语言支持:Gemini Live 支持45种语言，适合18岁以上用户。",
          "guid": "https://www.aibase.com/zh/news/16904",
          "isoDate": "2025-04-08T01:13:34.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "​Shopify CEO要求团队要招聘新成员前，需先证明AI无法完成工作",
          "link": "https://www.aibase.com/zh/news/16903",
          "pubDate": "Tue, 08 Apr 2025 01:11:06 GMT",
          "author": "AI Base",
          "content": "<p>近日，Shopify 首席执行官托比・吕特克（Tobi Lütke）向员工发出了一份备忘录，强调在寻求增加人手或资源之前，团队必须证明为什么他们 “无法通过人工智能(AI)完成所需工作”。吕特克在备忘录中提到，这个要求旨在促进团队思考如何将 AI 融入工作流程，并激发创新。</p><p style=\"text-align: center\"><img src=\"https://pic.chinaz.com/picmap/202305291455510902_2.jpg\" title=\"AI机器人面试，谈判 (图片来源：AI合成)\" alt=\"AI机器人面试，谈判\" referrerpolicy=\"no-referrer\"></p><p style=\"text-align: center;\">图源备注：图片由AI生成，图片授权服务商Midjourney</p><p>吕特克在备忘录中提出了一个重要问题:“如果自动化 AI 代理已经是团队的一部分，那么这一领域会是什么样子?” 这一问题能够引发富有创意的讨论与项目，从而帮助团队更好地利用现有资源。他认为，AI 的使用已成为公司工作方式的根本转变，这是他职业生涯中所见过的最快速变化之一。</p><p>在这份备忘录中，吕特克指出，能够有效使用 AI 已经成为 Shopify 员工的基本要求。他强调，熟练掌握 AI 的使用是一项需要不断学习的技能，员工应该积极尝试并练习这一技能。此外，AI 使用相关的问题将被纳入公司的绩效和同事评审问卷中，进一步推动员工在日常工作中考虑如何与 AI 协作。</p><p>吕特克强调，成功的关键在于整个团队在应用自己专业技能的基础上，结合 AI 的力量，为商家提供更好的服务。他的这番话不仅反映了对 AI 技术的重视，也展示了 Shopify 希望通过技术进步提升整体工作效率的愿景。</p><blockquote><p>划重点:</p><p>🌟 在增加人手或资源前，团队需证明 AI 无法完成的任务。</p><p>🤖 使用 AI 已成为 Shopify 员工的基本工作要求。</p><p>🚀 整体成功依赖于专业技能与 AI 的结合，旨在更好地服务商家。</p></blockquote>",
          "contentSnippet": "近日，Shopify 首席执行官托比・吕特克（Tobi Lütke）向员工发出了一份备忘录，强调在寻求增加人手或资源之前，团队必须证明为什么他们 “无法通过人工智能(AI)完成所需工作”。吕特克在备忘录中提到，这个要求旨在促进团队思考如何将 AI 融入工作流程，并激发创新。\n\n图源备注：图片由AI生成，图片授权服务商Midjourney\n吕特克在备忘录中提出了一个重要问题:“如果自动化 AI 代理已经是团队的一部分，那么这一领域会是什么样子?” 这一问题能够引发富有创意的讨论与项目，从而帮助团队更好地利用现有资源。他认为，AI 的使用已成为公司工作方式的根本转变，这是他职业生涯中所见过的最快速变化之一。\n在这份备忘录中，吕特克指出，能够有效使用 AI 已经成为 Shopify 员工的基本要求。他强调，熟练掌握 AI 的使用是一项需要不断学习的技能，员工应该积极尝试并练习这一技能。此外，AI 使用相关的问题将被纳入公司的绩效和同事评审问卷中，进一步推动员工在日常工作中考虑如何与 AI 协作。\n吕特克强调，成功的关键在于整个团队在应用自己专业技能的基础上，结合 AI 的力量，为商家提供更好的服务。他的这番话不仅反映了对 AI 技术的重视，也展示了 Shopify 希望通过技术进步提升整体工作效率的愿景。\n\n划重点:\n🌟 在增加人手或资源前，团队需证明 AI 无法完成的任务。\n🤖 使用 AI 已成为 Shopify 员工的基本工作要求。\n🚀 整体成功依赖于专业技能与 AI 的结合，旨在更好地服务商家。",
          "guid": "https://www.aibase.com/zh/news/16903",
          "isoDate": "2025-04-08T01:11:06.000Z"
        }
      },
      {
        "json": {
          "creator": "AI Base",
          "title": "​商汤科技 SenseCore 2.0 升级在即，算力将实现指数级增长",
          "link": "https://www.aibase.com/zh/news/16902",
          "pubDate": "Mon, 07 Apr 2025 09:46:30 GMT",
          "author": "AI Base",
          "content": "<p><span style=\"text-indent: 2em;\">商汤科技发布消息，2025商汤技术交流日将于4月10日14时举行。商汤大装置SenseCore也将迎来全面升级，相关技术能力将迎来指数级增长。</span></p><p><span style=\"text-indent: 2em;\">这次升级将为其技术能力带来显著提升，尤其是在 AI 基础设施、具身智能研发及行业大模型的应用等方面，预计将实现指数级的增长。</span></p><p style=\"text-align:center\"><img src=\"https://upload.chinaz.com/2025/0407/6387964477859898803557998.png\" title=\"QQ_1744019170508.png\" alt=\"QQ_1744019170508.png\" referrerpolicy=\"no-referrer\"></p><p>自2021年推出以来，商汤大装置 SenseCore 作为新型 AI 基础设施，成功整合了全国范围内的算力资源。该系统实现了算力的统一调度，并在上海、深圳、广州、福州、济南、重庆等多个城市建立了新的计算节点。截止到2024年7月，SenseCore 的总算力规模已经达到20000petaFLOPS，搭载超过5.4万块 GPU，这不仅支持了商汤自身的大模型研发，还为外部客户提供了训练大模型和应用部署的服务。</p>",
          "contentSnippet": "商汤科技发布消息，2025商汤技术交流日将于4月10日14时举行。商汤大装置SenseCore也将迎来全面升级，相关技术能力将迎来指数级增长。\n这次升级将为其技术能力带来显著提升，尤其是在 AI 基础设施、具身智能研发及行业大模型的应用等方面，预计将实现指数级的增长。\n\n自2021年推出以来，商汤大装置 SenseCore 作为新型 AI 基础设施，成功整合了全国范围内的算力资源。该系统实现了算力的统一调度，并在上海、深圳、广州、福州、济南、重庆等多个城市建立了新的计算节点。截止到2024年7月，SenseCore 的总算力规模已经达到20000petaFLOPS，搭载超过5.4万块 GPU，这不仅支持了商汤自身的大模型研发，还为外部客户提供了训练大模型和应用部署的服务。",
          "guid": "https://www.aibase.com/zh/news/16902",
          "isoDate": "2025-04-07T09:46:30.000Z"
        }
      }
    ]
  },
  "connections": {
    "When clicking ‘Test workflow’": {
      "main": [
        [
          {
            "node": "RSS1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields": {
      "main": [
        [
          {
            "node": "Edit Fields1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "RSS1": {
      "main": [
        [
          {
            "node": "Edit Fields",
            "type": "main",
            "index": 0
          },
          {
            "node": "Filter",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields1": {
      "main": [
        [
          {
            "node": "Edit Fields2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Filter": {
      "main": [
        []
      ]
    },
    "Edit Fields2": {
      "main": [
        [
          {
            "node": "Edit Fields3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields3": {
      "main": [
        [
          {
            "node": "Edit Fields4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1",
    "timezone": "Asia/Shanghai",
    "callerPolicy": "workflowsFromSameOwner"
  },
  "versionId": "32857633-2557-476a-a3ca-b06437ed9f97",
  "meta": {
    "instanceId": "667f8e49cea6f05a4f2d4764a2ef083b44c681d7bcf3709cc71f85be90eeca2e"
  },
  "id": "O7XoSj1EG2Ers2s6",
  "tags": []
}