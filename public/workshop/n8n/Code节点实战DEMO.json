{
  "name": "Code节点实战DEMO",
  "nodes": [
    {
      "parameters": {
        "pollTimes": {
          "item": [
            {
              "mode": "everyHour"
            }
          ]
        },
        "feedUrl": "http://www.jintiankansha.me/rss/G42TC7DGG44WKMLEHFRGIMZSMMZDSMZXMI3DCYZZGYZWEMRRGQ4TMNLEMU2TGYTBMYZGGMQ="
      },
      "type": "n8n-nodes-base.rssFeedReadTrigger",
      "typeVersion": 1,
      "position": [
        -600,
        600
      ],
      "id": "7b9b6771-fff2-4b5b-9f66-c992ad180f04",
      "name": "RSS Feed Trigger"
    },
    {
      "parameters": {
        "jsCode": "function processImageUrl(url) {\n  if (url.includes('src=')) {\n    url = url.split('src=')[1];\n  }\n  if (url.includes('wx_fmt=png')) {\n    url = url.replace(/\\?wx_fmt=png.*$/, '.png');\n  }\n  return url;\n}\n\nfunction createBlocks(inputData) {\n  const blocks = [];\n  \n  const lines = inputData.split('\\n').filter(line => line.trim());\n  \n  for (let i = 0; i < lines.length; i++) {\n    const line = lines[i].trim();\n    \n    // 跳过空行\n    if (!line) continue;\n    \n    // 处理图片链接\n    if (line.startsWith('[http') && line.endsWith(']')) {\n      const rawImageUrl = line.slice(1, -1);\n      const processedImageUrl = processImageUrl(rawImageUrl);\n      blocks.push({\n        type: \"image\",\n        block: {\n          url: processedImageUrl\n        }\n      });\n      continue;\n    }\n    \n    // 处理项目符号列表\n    if (line.startsWith('*')) {\n      blocks.push({\n        type: \"bulleted_list_item\",\n        block: {\n          text: line.slice(2).trim()\n        }\n      });\n      continue;\n    }\n    \n    // 处理标题\n    if (line === \"三大核心技术\") {\n      blocks.push({\n        type: \"heading_1\",\n        block: {\n          text: line\n        }\n      });\n      continue;\n    }\n    \n    if (line === \"攻克动态环境中的智能决策困境\") {\n      blocks.push({\n        type: \"heading_2\",\n        block: {\n          text: line\n        }\n      });\n      continue;\n    }\n    \n    // 处理普通段落\n    blocks.push({\n      type: \"paragraph\",\n      block: {\n        text: line\n      }\n    });\n  }\n  \n  return blocks;\n}\n\n// 处理输入数据\nconst inputData = $('HTML').first().json.data;\nconst notionBlocks = createBlocks(inputData);\n\nreturn notionBlocks.map(block => block);\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        540,
        600
      ],
      "id": "a4fcd748-a175-4e74-9297-3861755970b0",
      "name": "Code"
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "leftValue": "={{ $json.type }}",
                    "rightValue": "heading_1",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "id": "b68d3564-52e4-4dac-9c22-122fb0983aba"
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "heading_1"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "650b2f78-2fc2-4108-af6a-001e391c6579",
                    "leftValue": "={{ $json.type }}",
                    "rightValue": "heading_2",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "heading_2"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "801c27ac-89b5-4c4b-bdd6-8fe0262e78c9",
                    "leftValue": "={{ $json.type }}",
                    "rightValue": "heading_3",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "heading_3"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "8ed1eb89-0d91-476b-a105-aa58b91801ad",
                    "leftValue": "={{ $json.type }}",
                    "rightValue": "bulleted_list_item",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "bulleted_list_item"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "500e4286-58a6-4eda-84b1-9c1ca4a2a053",
                    "leftValue": "={{ $json.type }}",
                    "rightValue": "paragraph",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "paragraph"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "9d218758-8891-4063-b442-a1f5ac9409ab",
                    "leftValue": "={{ $json.type }}",
                    "rightValue": "quote",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "quote"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "fb754c01-4680-4fe4-b3c7-e4b4a23e5ab7",
                    "leftValue": "={{ $json.type }}",
                    "rightValue": "numbered_list_item",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "numbered_list_item"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "b18a248d-0791-4a0c-a88d-8620aad6d085",
                    "leftValue": "={{ $json.type }}",
                    "rightValue": "image",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "image"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3.2,
      "position": [
        1180,
        540
      ],
      "id": "7607de7e-9ead-4a21-aa72-da81fb217acd",
      "name": "Switch"
    },
    {
      "parameters": {
        "resource": "block",
        "blockId": {
          "__rl": true,
          "value": "={{ $('创建博客').first().json.url }}",
          "mode": "url"
        },
        "blockUi": {
          "blockValues": [
            {
              "textContent": "={{ $json.block.text }}"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.notion",
      "typeVersion": 2.2,
      "position": [
        1820,
        1340
      ],
      "id": "bc786d42-8a7d-4bc9-92c6-71f3f3ba6c79",
      "name": "Notion1",
      "credentials": {
        "notionApi": {
          "id": "tHqNwAxXQ88MGWlm",
          "name": "Notion account"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "resource": "block",
        "blockId": {
          "__rl": true,
          "value": "={{ $('创建博客').first().json.url }}",
          "mode": "url"
        },
        "blockUi": {
          "blockValues": [
            {
              "type": "heading_1",
              "textContent": "={{ $json.block.text }}"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.notion",
      "typeVersion": 2.2,
      "position": [
        1820,
        520
      ],
      "id": "edb43c1b-d500-46e6-ba47-598f73127ce8",
      "name": "Notion2",
      "credentials": {
        "notionApi": {
          "id": "tHqNwAxXQ88MGWlm",
          "name": "Notion account"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "resource": "block",
        "blockId": {
          "__rl": true,
          "value": "={{ $('创建博客').first().json.url }}",
          "mode": "url"
        },
        "blockUi": {
          "blockValues": [
            {
              "type": "heading_2",
              "textContent": "={{ $json.block.text }}"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.notion",
      "typeVersion": 2.2,
      "position": [
        1820,
        740
      ],
      "id": "11a898b4-e064-4c55-b4f9-71ca2402c0bd",
      "name": "Notion3",
      "credentials": {
        "notionApi": {
          "id": "tHqNwAxXQ88MGWlm",
          "name": "Notion account"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "resource": "block",
        "blockId": {
          "__rl": true,
          "value": "={{ $('创建博客').first().json.url }}",
          "mode": "url"
        },
        "blockUi": {
          "blockValues": [
            {
              "type": "heading_3",
              "textContent": "={{ $json.block.text }}"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.notion",
      "typeVersion": 2.2,
      "position": [
        1820,
        940
      ],
      "id": "cd53c01f-9a09-42cb-868c-b16a291ed0fc",
      "name": "Notion4",
      "credentials": {
        "notionApi": {
          "id": "tHqNwAxXQ88MGWlm",
          "name": "Notion account"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "resource": "block",
        "blockId": {
          "__rl": true,
          "value": "={{ $('创建博客').first().json.url }}",
          "mode": "url"
        },
        "blockUi": {
          "blockValues": [
            {
              "type": "bulleted_list_item",
              "textContent": "={{ $json.block.text }}"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.notion",
      "typeVersion": 2.2,
      "position": [
        1820,
        1140
      ],
      "id": "b5ee7b1a-f095-4602-971c-7c81fa6e0aa1",
      "name": "Notion5",
      "credentials": {
        "notionApi": {
          "id": "tHqNwAxXQ88MGWlm",
          "name": "Notion account"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "resource": "block",
        "blockId": {
          "__rl": true,
          "value": "={{ $('创建博客').first().json.url }}",
          "mode": "url"
        },
        "blockUi": {
          "blockValues": [
            {
              "textContent": "={{ $json.block.text }}"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.notion",
      "typeVersion": 2.2,
      "position": [
        1820,
        1540
      ],
      "id": "25ed8ba8-e258-4ce9-ab00-f8093ba38b6f",
      "name": "Notion6",
      "credentials": {
        "notionApi": {
          "id": "tHqNwAxXQ88MGWlm",
          "name": "Notion account"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "resource": "block",
        "blockId": {
          "__rl": true,
          "value": "={{ $('创建博客').first().json.url }}",
          "mode": "url"
        },
        "blockUi": {
          "blockValues": [
            {
              "type": "numbered_list_item",
              "textContent": "={{ $json.block.text }}"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.notion",
      "typeVersion": 2.2,
      "position": [
        1820,
        1740
      ],
      "id": "3f35bf2c-2da7-4ebb-8a71-b9fdd8c6c8ad",
      "name": "Notion7",
      "credentials": {
        "notionApi": {
          "id": "tHqNwAxXQ88MGWlm",
          "name": "Notion account"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [
        900,
        600
      ],
      "id": "08e9832c-00c3-4ee4-a5f1-cc9b6f0333f1",
      "name": "Loop Over Items"
    },
    {
      "parameters": {
        "resource": "databasePage",
        "databaseId": {
          "__rl": true,
          "value": "1a8629a6-152d-8038-9fa8-ca68e6c5503a",
          "mode": "list",
          "cachedResultName": "N8N-每日热点",
          "cachedResultUrl": "https://www.notion.so/1a8629a6152d80389fa8ca68e6c5503a"
        },
        "title": "={{ $('RSS Feed Trigger').item.json.title }}",
        "propertiesUi": {
          "propertyValues": [
            {
              "key": "发布日期|date",
              "date": "={{ $('RSS Feed Trigger').item.json.pubDate }}"
            },
            {
              "key": "网址|url",
              "urlValue": "={{ $('RSS Feed Trigger').item.json.link }}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.notion",
      "typeVersion": 2.2,
      "position": [
        140,
        600
      ],
      "id": "dbbf5d69-18c6-494f-b36c-7174ba190f0b",
      "name": "创建博客",
      "executeOnce": true,
      "retryOnFail": true,
      "notesInFlow": false,
      "credentials": {
        "notionApi": {
          "id": "tHqNwAxXQ88MGWlm",
          "name": "Notion account"
        }
      }
    },
    {
      "parameters": {
        "operation": "extractHtmlContent",
        "dataPropertyName": "content",
        "extractionValues": {
          "values": [
            {
              "key": "=data",
              "cssSelector": ".rich_media_content"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.html",
      "typeVersion": 1.2,
      "position": [
        -360,
        600
      ],
      "id": "e99460e0-522b-4789-bd31-70a754529bf8",
      "name": "HTML"
    },
    {
      "parameters": {
        "resource": "block",
        "blockId": {
          "__rl": true,
          "value": "={{ $('创建博客').first().json.url }}",
          "mode": "url"
        },
        "blockUi": {
          "blockValues": [
            {
              "type": "image",
              "url": "={{ $json.block.url }}"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.notion",
      "typeVersion": 2.2,
      "position": [
        1820,
        1960
      ],
      "id": "bc01d839-fc87-4aa3-a7d4-fbac1cae50db",
      "name": "Notion",
      "credentials": {
        "notionApi": {
          "id": "tHqNwAxXQ88MGWlm",
          "name": "Notion account"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "8ea27625-6373-4b24-b57a-959c2117b85d",
              "name": "json",
              "value": "={{$input.all()}}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        140,
        920
      ],
      "id": "bdd861a5-c943-4a7c-a895-e4d194dbde44",
      "name": "Edit Fields"
    }
  ],
  "pinData": {
    "RSS Feed Trigger": [
      {
        "json": {
          "title": "合成数据也能通吃真实世界？首个融合重建-预测-规划的生成式世界模型AETHER开源",
          "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650965919&idx=3&sn=58e92572d93fe65b91fd374fa818c226&chksm=85ae42c5ea158951815190de2e4842f5c2337a18ab683b5657fdf5823825dc57dc7c8d6e516b&scene=0#rd",
          "pubDate": "Sun, 20 Apr 2025 12:03:00 +0800",
          "enclosure": {
            "url": "http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9uOJxRmgWI1T1QsyxU6C3PyllxzkY7pzXjNnZ94iafVTYgmPFDaAPnVIeV5prSeOO1mBsYrsrR52g/0?wx_fmt=jpeg",
            "length": "0",
            "type": "image/jpeg"
          },
          "content": "\n\n    \n\n    \n\n    \n         <div class=\"rich_media_content\" id=\"js_content\"><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5703125\" data-s=\"300,640\" data-type=\"png\" data-w=\"1280\" type=\"block\" data-imgfileid=\"503474618\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">近日，上海人工智能实验室（上海 AI 实验室）</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">开源了生成式世界模型 AETHER</span><span textstyle=\"\" style=\"font-size: 15px;\">。该模型全部由合成数据训练而成，不仅在传统重建与生成任务中表现领先，更首次赋予大模型在真实世界中的 3D 空间决策与规划能力，可助力机器人完成目标导向的视觉规划、4D 动态重建、动作条件的视频预测等复杂任务。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">研究团队将几何重建与生成式建模深度融合，首创</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">「重建 — 预测 — 规划</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">」 一体化框架，通过 AETHER 使大模型能够感知周围环境，理解物体之间的位置、运动和因果关系，从而做出更智能的行动决策。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">实验表明，传统世界模型通常聚焦于 RGB 图像的预测而忽略了背后隐含的几何信息，引入空间建模后，各项指标均显著提升，其中视频一致性指标提升约 4%。更重要的是，即使只使用合成数据进行训练，模型在真实环境中依然展现出强大的零样本泛化能力。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">论文与模型已经同步开源。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.0419501133786848\" data-s=\"300,640\" data-type=\"png\" data-w=\"882\" type=\"block\" data-imgfileid=\"503481835\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9uOJxRmgWI1T1QsyxU6C3PlQHkGEjCE2GhmAYiaVcPefIcr6RDdEiayrWiaTicvQqKExniciaOuAYNXicAQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li style=\"color: rgb(123, 12, 0);\"><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);\">论文标题：</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);\">AETHER: Geometric-Aware Unified World Modeling</span></span></p></li><li style=\"color: rgb(123, 12, 0);\"><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);\">论文链接：https://arxiv.org/abs/2503.18945</span></span></p></li><li style=\"color: rgb(123, 12, 0);\"><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);\">项目主页：https://aether-world.github.io</span></span></p></li></ul><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section nodeleaf=\"\" style=\"margin-left: 8px;margin-right: 8px;\"><iframe class=\"video_iframe rich_pages\" data-src=\"https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;action=mpvideo&amp;auto=0&amp;vid=wxv_3947365329373822979\" data-mpvid=\"wxv_3947365329373822979\" data-vidtype=\"2\" data-cover=\"http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gW9uOJxRmgWI1T1QsyxU6C3P2I541MiajQBWT3BtLs6OJibOJ2L7rVsyuJiareU6ogPBJzIjiao9lfW0tg%2F0%3Fwx_fmt%3Djpeg\" data-ratio=\"1.7777777777777777\" data-w=\"1920\"></iframe></section><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">三大核心技术</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">攻克动态环境中的智能决策困境</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">传统世界模型主要应用于自动驾驶与游戏开发等领域，通过其丰富的动作标签来预测接下来的视觉画面。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">但由于缺乏对真实三维空间的建模能力，这容易导致模型预测结果出现不符合物理规律的现象。同时，由于依赖且缺乏真实数据，面对更复杂多变的场景时，其泛化能力也明显不足。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">针对以上问题，研究团队提出了生成式世界模型 AETHER，基于三维时空建模，通过引入并构建几何空间，大幅提升了模型空间推理的准确性与一致性。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">具体而言，</span><span textstyle=\"\" style=\"font-size: 15px;font-weight: normal;\">研究团队利用海量仿真 RGBD 数据，开发了一套完整的数据清洗与动态重建流程，并标注了丰富的动作序列</span><span textstyle=\"\" style=\"font-size: 15px;\">。同时，他们提出一种多模态数据的动态融合机制，首次将动态重建、视频预测和动作规划这三项任务融合在一个统一的框架中进行优化，从而实现了真正的一体化多任务协同，大幅提高了模型的稳定性与鲁棒性。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">面对复杂多变的现实世界，如何让具身智能系统实现可靠、高效的决策是人工智能领域的一项重大挑战。研究团队在 </span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">AETHER 框架</span><span textstyle=\"\" style=\"font-size: 15px;\">中通过三项关键技术突破，显著提升了具身系统在动态环境中的感知、建模与决策能力。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">目标导向视觉规划</span><span textstyle=\"\" style=\"font-size: 15px;\">：可根据起始与目标场景，自动生成一条实现视觉目标的合理路径，并以视频形式呈现全过程。通过联合优化重建与预测目标，AETHER 内嵌空间几何先验知识，使生成结果兼具物理合理性。这使得具身智能系统能像人类一样</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">「看路规划</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">」—— 通过摄像头观察环境后，自动生成既安全又符合物理规律的行动路线。</span></span></p></li><li><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">4D 动态重建</span><span textstyle=\"\" style=\"font-size: 15px;\">：通过自动标注流水线，构建合成 4D 数据集，无需真实世界数据即可实现零样本迁移，精准捕捉并重建时空环境的动态变化。例如，输入一段街景视频，系统即可重建包含时间维度的三维场景模型，精确呈现行人行走、车辆运动等动态过程，建模精度可达毫米级。</span></span></p></li></ul><p style=\"margin:0px 8px;line-height:1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.49166666666666664\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503481846\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9uOJxRmgWI1T1QsyxU6C3PfkzHPwbLiaU10LhRG9ZRTcWrPrVUEJDzdiaflwoibERXjSZeoVEfEibHvA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;color: rgb(136, 136, 136);font-style: italic;\">自动相机标注 pipeline。</span></span></p><p style=\"margin:0px 8px;line-height:1.75em;\"><span leaf=\"\"><br></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">动作条件视频预测</span><span textstyle=\"\" style=\"font-size: 15px;\">：创新性地采用相机轨迹作为全局动作表征，可直接基于初始视觉观察和潜在动作，预测未来场景的变化趋势。相当于给具身智能系统装上了预测未来的</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">「镜头</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">」。</span></span></p></li></ul><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">可零样本泛化至真实场景</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">不同于传统仅预测图像变化的世界模型，AETHER 不仅能同时完成四维时空的重建与预测，还支持由动作控制驱动的场景推演与路径规划。值得强调的是，该方法完全在虚拟数据上训练，即可实现对真实世界的零样本泛化，展现出强大的跨域迁移能力。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">具体流程如下图所示，图中黄色、蓝色和红色分别表示图像、动作与深度的潜在变量，灰色表示噪声项，白色框为零填充区域。模型通过组合不同的条件输入（如观察帧、目标帧和动作轨迹），结合扩散过程，实现对多种任务的统一建模与生成。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">就像在拼一副完整的动态拼图，观察帧提供了</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">「现在的样子</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">」，目标帧给出了</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">「未来的样子</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">」，动作轨迹则是</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">「怎么从这里走到那里</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">」，而扩散过程则像是拼图的拼接逻辑，把这些零散信息有序组合起来，最终还原出一个连续、合理且可预测的时空过程。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.36203703703703705\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503481868\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9uOJxRmgWI1T1QsyxU6C3PhG266R4R6FjwvWM4WvGpyXOficexPtTZz293NicA3icHxJ3hFLL8xgiblA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">为了支持同时完成重建、预测和规划这三类不同任务，AETHER 设计了一种统一的多任务框架，首次实现在同一个系统中整合动态重建、视频预测和动作规划。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">其核心在于：能够融合图像、动作、深度等多模态信息，建立一个跨模态共享的时空一致性建模空间，实现不同任务在同一认知基础上的协同优化。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">实验结果</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">在多个实验任务中，AETHER 在动态场景重建方面已达到甚至超过现有 SOTA 水平。同时发现在多任务框架下，各个任务有很好的促进，尤其在动作跟随的准确度上面有较大的提升。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.6555555555555556\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503481869\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9uOJxRmgWI1T1QsyxU6C3PM5DQQL6Dedud5vX137aCd3QZX8YRRqlbictPrSzCyqemM2Et0q8huHg/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" data-style=\"margin-top: 5px; outline: 0px; max-width: 100%; color: rgb(34, 34, 34); font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif letter-spacing: white-space: normal caret-color: rgb background-color: text-align: center line-height: margin-bottom: box-sizing: border-box overflow-wrap: break-word class=\"js_darkmode__6\" style=\"text-indent: 0px;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\"><span leaf=\"\" data-pm-slice=\"1 1 [\" para style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;\">该方法有望为具身智能大模型在数据增强、路径规划以及基于模型的强化学习等方向研究提供技术支撑。</span></span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" data-style=\"margin-top: 5px; outline: 0px; max-width: 100%; color: rgb(34, 34, 34); font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif letter-spacing: white-space: normal caret-color: rgb background-color: text-align: center line-height: margin-bottom: box-sizing: border-box overflow-wrap: break-word class=\"js_darkmode__6\" style=\"-webkit-tap-highlight-color: transparent;margin-top: 5px;margin-bottom: 0px;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);letter-spacing: 0.544px;text-wrap: wrap;font-family: -apple-system, BlinkMacSystemFont, \"><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif><span leaf=\"\">© THE END </span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" data-style=\"margin-top: 5px; outline: 0px; max-width: 100%; color: rgb(34, 34, 34); font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif letter-spacing: white-space: normal caret-color: rgb background-color: text-align: center line-height: margin-bottom: box-sizing: border-box overflow-wrap: break-word class=\"js_darkmode__7\" style=\"-webkit-tap-highlight-color: transparent;margin-top: 5px;margin-bottom: 0px;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);letter-spacing: 0.544px;text-wrap: wrap;font-family: -apple-system, BlinkMacSystemFont, \"><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;\"><span leaf=\"\">转载请联系本公众号获得授权</span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" data-style=\"margin-top: 5px; outline: 0px; max-width: 100%; color: rgb(34, 34, 34); font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif letter-spacing: white-space: normal caret-color: rgb background-color: text-align: center line-height: margin-bottom: box-sizing: border-box overflow-wrap: break-word class=\"js_darkmode__8\" style=\"-webkit-tap-highlight-color: transparent;margin-top: 5px;margin-bottom: 0px;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);letter-spacing: 0.544px;text-wrap: wrap;font-family: -apple-system, BlinkMacSystemFont, \"><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;\"><span leaf=\"\">投稿或寻求报道：liyazhou@jiqizhixin.com</span></span></p><p style=\"display: none;\"><mp-style-type data-value=\"3\"></mp-style-type></p></div> \n                <video id=\"video\" src=\"http://mpvideo.qpic.cn/0bc3uyaayaaazuakjoaae5ufbjwdbstaadaa.f10002.mp4?dis_k=2ffff5faa86e2f5b1fafa9fcb1bbc023&amp;dis_t=1745121893&amp;play_scene=10120&amp;auth_info=eNWJ/vkDPnES/LyztCUNRDEWYmJhSDFmTWtVVSNmDwdDJThkVjsEekcCYGBhQk59PgI0&amp;auth_key=07e8c93fc2ea0b8377532c98c543a77d\" width=\"100%\" controls>\n                    <div class=\"fallback\"><p></p></div>\n                </video>\n                \n    \n\n    \n    <br>\n\n    \n        <a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650965919&amp;idx=3&amp;sn=58e92572d93fe65b91fd374fa818c226&amp;chksm=85ae42c5ea158951815190de2e4842f5c2337a18ab683b5657fdf5823825dc57dc7c8d6e516b&amp;scene=0#rd\" style=\"color: blue\" class=\"media_tool_meta meta_primary\">文章原文</a>\n        <br>\n    \n\n    \n\n    <img alt=\"\" width=\"1px\" height=\"1px\" class=\"\" style=\"width:1px;height:1px;display:none\" src=\"http://www.jintiankansha.me/rss_static/83680/vCVE3G4HMu\">\n\n",
          "contentSnippet": "近日，上海人工智能实验室（上海 AI 实验室）开源了生成式世界模型 AETHER。该模型全部由合成数据训练而成，不仅在传统重建与生成任务中表现领先，更首次赋予大模型在真实世界中的 3D 空间决策与规划能力，可助力机器人完成目标导向的视觉规划、4D 动态重建、动作条件的视频预测等复杂任务。\n\n\n研究团队将几何重建与生成式建模深度融合，首创「重建 — 预测 — 规划」 一体化框架，通过 AETHER 使大模型能够感知周围环境，理解物体之间的位置、运动和因果关系，从而做出更智能的行动决策。\n\n\n实验表明，传统世界模型通常聚焦于 RGB 图像的预测而忽略了背后隐含的几何信息，引入空间建模后，各项指标均显著提升，其中视频一致性指标提升约 4%。更重要的是，即使只使用合成数据进行训练，模型在真实环境中依然展现出强大的零样本泛化能力。\n\n\n论文与模型已经同步开源。\n\n\n\n\n论文标题：AETHER: Geometric-Aware Unified World Modeling\n\n论文链接：https://arxiv.org/abs/2503.18945\n\n项目主页：https://aether-world.github.io\n\n\n\n\n三大核心技术\n攻克动态环境中的智能决策困境\n\n\n传统世界模型主要应用于自动驾驶与游戏开发等领域，通过其丰富的动作标签来预测接下来的视觉画面。\n\n\n但由于缺乏对真实三维空间的建模能力，这容易导致模型预测结果出现不符合物理规律的现象。同时，由于依赖且缺乏真实数据，面对更复杂多变的场景时，其泛化能力也明显不足。\n\n\n针对以上问题，研究团队提出了生成式世界模型 AETHER，基于三维时空建模，通过引入并构建几何空间，大幅提升了模型空间推理的准确性与一致性。\n\n\n具体而言，研究团队利用海量仿真 RGBD 数据，开发了一套完整的数据清洗与动态重建流程，并标注了丰富的动作序列。同时，他们提出一种多模态数据的动态融合机制，首次将动态重建、视频预测和动作规划这三项任务融合在一个统一的框架中进行优化，从而实现了真正的一体化多任务协同，大幅提高了模型的稳定性与鲁棒性。\n\n\n面对复杂多变的现实世界，如何让具身智能系统实现可靠、高效的决策是人工智能领域的一项重大挑战。研究团队在 AETHER 框架中通过三项关键技术突破，显著提升了具身系统在动态环境中的感知、建模与决策能力。\n\n\n\n目标导向视觉规划：可根据起始与目标场景，自动生成一条实现视觉目标的合理路径，并以视频形式呈现全过程。通过联合优化重建与预测目标，AETHER 内嵌空间几何先验知识，使生成结果兼具物理合理性。这使得具身智能系统能像人类一样「看路规划」—— 通过摄像头观察环境后，自动生成既安全又符合物理规律的行动路线。\n\n4D 动态重建：通过自动标注流水线，构建合成 4D 数据集，无需真实世界数据即可实现零样本迁移，精准捕捉并重建时空环境的动态变化。例如，输入一段街景视频，系统即可重建包含时间维度的三维场景模型，精确呈现行人行走、车辆运动等动态过程，建模精度可达毫米级。\n\n\n\n\n自动相机标注 pipeline。\n\n\n\n动作条件视频预测：创新性地采用相机轨迹作为全局动作表征，可直接基于初始视觉观察和潜在动作，预测未来场景的变化趋势。相当于给具身智能系统装上了预测未来的「镜头」。\n\n\n\n可零样本泛化至真实场景\n\n\n不同于传统仅预测图像变化的世界模型，AETHER 不仅能同时完成四维时空的重建与预测，还支持由动作控制驱动的场景推演与路径规划。值得强调的是，该方法完全在虚拟数据上训练，即可实现对真实世界的零样本泛化，展现出强大的跨域迁移能力。\n\n\n具体流程如下图所示，图中黄色、蓝色和红色分别表示图像、动作与深度的潜在变量，灰色表示噪声项，白色框为零填充区域。模型通过组合不同的条件输入（如观察帧、目标帧和动作轨迹），结合扩散过程，实现对多种任务的统一建模与生成。\n\n\n就像在拼一副完整的动态拼图，观察帧提供了「现在的样子」，目标帧给出了「未来的样子」，动作轨迹则是「怎么从这里走到那里」，而扩散过程则像是拼图的拼接逻辑，把这些零散信息有序组合起来，最终还原出一个连续、合理且可预测的时空过程。\n\n\n\n为了支持同时完成重建、预测和规划这三类不同任务，AETHER 设计了一种统一的多任务框架，首次实现在同一个系统中整合动态重建、视频预测和动作规划。\n\n\n其核心在于：能够融合图像、动作、深度等多模态信息，建立一个跨模态共享的时空一致性建模空间，实现不同任务在同一认知基础上的协同优化。\n\n\n实验结果\n\n\n在多个实验任务中，AETHER 在动态场景重建方面已达到甚至超过现有 SOTA 水平。同时发现在多任务框架下，各个任务有很好的促进，尤其在动作跟随的准确度上面有较大的提升。\n\n\n\n该方法有望为具身智能大模型在数据增强、路径规划以及基于模型的强化学习等方向研究提供技术支撑。\n© THE END \n转载请联系本公众号获得授权\n投稿或寻求报道：liyazhou@jiqizhixin.com\n\n \n                \n                    \n\n\n                \n                \n    \n\n    \n    \n文章原文",
          "guid": "http://www.jintiankansha.me/t/vCVE3G4HMu",
          "categories": [
            "无"
          ],
          "isoDate": "2025-04-20T04:03:00.000Z"
        }
      }
    ]
  },
  "connections": {
    "RSS Feed Trigger": {
      "main": [
        [
          {
            "node": "HTML",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Switch": {
      "main": [
        [
          {
            "node": "Notion2",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Notion3",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Notion4",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Notion5",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Notion1",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Notion6",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Notion7",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Notion",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Notion2": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Loop Over Items": {
      "main": [
        [],
        [
          {
            "node": "Switch",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Notion3": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Notion4": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Notion5": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Notion1": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Notion6": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Notion7": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "创建博客": {
      "main": [
        [
          {
            "node": "Code",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTML": {
      "main": [
        [
          {
            "node": "创建博客",
            "type": "main",
            "index": 0
          },
          {
            "node": "Edit Fields",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Notion": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "e417afd2-6c0c-4fc9-a51f-0e627392ebdf",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "667f8e49cea6f05a4f2d4764a2ef083b44c681d7bcf3709cc71f85be90eeca2e"
  },
  "id": "um7mcdfkdnF4Nv8U",
  "tags": []
}