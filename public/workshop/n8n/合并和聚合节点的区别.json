{
  "name": "合并和聚合节点的区别",
  "nodes": [
    {
      "parameters": {
        "method": "PATCH",
        "url": "=https://api.notion.com/v1/blocks/{{ $('Notion').item.json.id }}/children",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "notionApi",
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "children",
              "value": "={{ $json.blocks }}"
            }
          ]
        },
        "options": {
          "batching": {
            "batch": {
              "batchSize": 1,
              "batchInterval": 5000
            }
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -80,
        2040
      ],
      "id": "67f8b547-f151-4e5d-86c1-21f7a19315e4",
      "name": "HTTP Request",
      "credentials": {
        "notionApi": {
          "id": "tHqNwAxXQ88MGWlm",
          "name": "Notion account"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [
        140,
        2040
      ],
      "id": "1f4d6ffc-5a32-44ab-9073-bbd94bafd211",
      "name": "Loop Over Items"
    },
    {
      "parameters": {
        "jsCode": "/**\n * 将Markdown文本转换为纯文本\n * @param {string} markdown - 输入的Markdown格式文本\n * @returns {string} - 转换后的纯文本字符串\n */\nfunction markdownToText(markdown) {\n    if (!markdown) return '';\n\n    let text = markdown;\n\n    // 移除代码块\n    text = text.replace(/```[\\s\\S]*?```/g, '');\n    text = text.replace(/`([^`]+)`/g, '$1');\n\n    // 移除标题符号\n    text = text.replace(/^#{1,6}\\s+/gm, '');\n\n    // 移除粗体和斜体\n    text = text.replace(/[*_]{2}([^*_]+)[*_]{2}/g, '$1'); // 粗体\n    text = text.replace(/[*_]([^*_]+)[*_]/g, '$1'); // 斜体\n\n    // 处理链接\n    text = text.replace(/\\[([^\\]]+)\\]\\([^)]+\\)/g, '$1'); // [文本](链接)\n    text = text.replace(/\\[([^\\]]+)\\]\\[[^\\]]*\\]/g, '$1'); // [文本][引用]\n\n    // 移除图片标记\n    text = text.replace(/!\\[([^\\]]*?)\\]\\([^)]+\\)/g, '$1');\n\n    // 处理列表\n    text = text.replace(/^[\\s]*[\\-*+]\\s+/gm, ''); // 无序列表\n    text = text.replace(/^[\\s]*\\d+\\.\\s+/gm, ''); // 有序列表\n\n    // 处理引用\n    text = text.replace(/^\\s*>\\s+/gm, '');\n\n    // 处理水平分割线\n    text = text.replace(/^\\s*[-*_]{3,}\\s*$/gm, '\\n');\n\n    // 移除HTML标签\n    text = text.replace(/<[^>]+>/g, '');\n\n    // 处理转义字符\n    text = text.replace(/\\\\([\\\\`*_{}\\[\\]()#+\\-.!])/g, '$1');\n\n    // 清理多余的空行\n    text = text.replace(/\\n\\s*\\n/g, '\\n\\n');\n    text = text.replace(/^\\s+|\\s+$/g, '');\n\n    return text;\n}\n\n/**\n * 将文本按指定长度分段\n * @param {string} text - 输入文本\n * @param {number} segmentLength - 每段文本的最大长度\n * @returns {string[]} - 分段后的文本数组\n */\nfunction splitTextIntoSegments(text, segmentLength = 1800) {\n    const segments = [];\n    let remainingText = text;\n\n    while (remainingText.length > 0) {\n        if (remainingText.length <= segmentLength) {\n            segments.push(remainingText);\n            break;\n        }\n\n        let endIndex = segmentLength;\n        // 尝试在句子或段落边界处分段\n        const nextParagraph = remainingText.indexOf('\\n\\n', endIndex - 100);\n        const nextSentence = remainingText.indexOf('. ', endIndex - 100);\n\n        if (nextParagraph !== -1 && nextParagraph < endIndex + 100) {\n            endIndex = nextParagraph;\n        } else if (nextSentence !== -1 && nextSentence < endIndex + 100) {\n            endIndex = nextSentence + 1;\n        }\n\n        segments.push(remainingText.substring(0, endIndex).trim());\n        remainingText = remainingText.substring(endIndex).trim();\n    }\n\n    return segments;\n}\n\n// 示例输入\nconst markdownInput = $('Loop Over Items').first().json.data;\nconst plainText = markdownToText(markdownInput);\nconst textSegments = splitTextIntoSegments(plainText);\n\n// 将文本段落转换为规范的block对象格式\nconst blocks = textSegments.map(segment => ({\n    object: 'block',\n    type: 'paragraph',\n    paragraph: {\n        rich_text: [\n            {\n                type: 'text',\n                annotations: {\n                    bold: false,\n                    strikethrough: false,\n                    underline: false,\n                    italic: false,\n                    code: false,\n                    color: 'default'\n                },\n                text: {\n                    content: segment\n                }\n            }\n        ]\n    }\n}));\n\nreturn {\n    blocks: blocks\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -300,
        2115
      ],
      "id": "3e14e352-6534-4fe7-87a5-69d384268c04",
      "name": "Code"
    },
    {
      "parameters": {
        "resource": "databasePage",
        "databaseId": {
          "__rl": true,
          "value": "198629a6-152d-8016-b4ce-ce205e5e422c",
          "mode": "list",
          "cachedResultName": "AI Agents文章收集",
          "cachedResultUrl": "https://www.notion.so/198629a6152d8016b4cece205e5e422c"
        },
        "title": "={{ $('Loop Over Items').item.json.title }}",
        "simple": false,
        "propertiesUi": {
          "propertyValues": [
            {
              "key": "url|url",
              "urlValue": "={{ $('Loop Over Items').item.json.link }}"
            },
            {
              "key": "发布时间|rich_text",
              "textContent": "={{ $('Loop Over Items').item.json.pubDate.replace(/.*?(\\d{2} \\w{3} \\d{4} \\d{2}:\\d{2}:\\d{2}).*/, '$1') }}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.notion",
      "typeVersion": 2.2,
      "position": [
        360,
        2115
      ],
      "id": "4a31105f-901b-4ea9-b0de-24c481d6b31d",
      "name": "Notion",
      "credentials": {
        "notionApi": {
          "id": "tHqNwAxXQ88MGWlm",
          "name": "Notion account"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "html": "={{ $json.content }}",
        "options": {}
      },
      "type": "n8n-nodes-base.markdown",
      "typeVersion": 1,
      "position": [
        140,
        520
      ],
      "id": "97f08a2f-6ce7-48eb-9255-a0e657d95103",
      "name": "Markdown2"
    },
    {
      "parameters": {
        "html": "={{ $json.content }}",
        "options": {}
      },
      "type": "n8n-nodes-base.markdown",
      "typeVersion": 1,
      "position": [
        140,
        320
      ],
      "id": "469ce0d4-670c-4efa-a915-782df434c973",
      "name": "Markdown1"
    },
    {
      "parameters": {
        "html": "={{ $json.content }}",
        "options": {}
      },
      "type": "n8n-nodes-base.markdown",
      "typeVersion": 1,
      "position": [
        140,
        120
      ],
      "id": "7747cd1d-ed04-40d6-8267-d46acc2bf4b5",
      "name": "Markdown"
    },
    {
      "parameters": {
        "rule": {
          "interval": [
            {
              "field": "hours"
            }
          ]
        }
      },
      "id": "d7f36271-ec67-46e7-a7b2-f077cedd2e31",
      "name": "Schedule Trigger",
      "type": "n8n-nodes-base.scheduleTrigger",
      "position": [
        -300,
        320
      ],
      "typeVersion": 1.2
    },
    {
      "parameters": {
        "url": "http://www.jintiankansha.me/rss/G42TC7DGG44WKMLEHFRGIMZSMMZDSMZXMI3DCYZZGYZWEMRRGQ4TMNLEMU2TGYTBMYZGGMQ=",
        "options": {
          "ignoreSSL": true
        }
      },
      "id": "353f44d9-023d-4a5f-8dab-c09452d7f273",
      "name": "机器之心",
      "type": "n8n-nodes-base.rssFeedRead",
      "position": [
        -80,
        120
      ],
      "typeVersion": 1.1,
      "notesInFlow": false,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "url": "http://www.jintiankansha.me/rss/GEYDONJSPQ4DIMRTGA3DAMTCMQ2TAMZYMY2GEZJQMZQWIMZVGFSGINZTGI4GCNJWG4YWKMBWHE======",
        "options": {
          "ignoreSSL": true
        }
      },
      "id": "3be6447d-da21-467f-8c25-cd52e48b5e32",
      "name": "新智元",
      "type": "n8n-nodes-base.rssFeedRead",
      "position": [
        -80,
        320
      ],
      "typeVersion": 1.1,
      "alwaysOutputData": false,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "url": "http://www.jintiankansha.me/rss/GEYDQOJYPRRWKM3DHE4WEOLEMVTGKMZQGQYDSMTDGJTDSNLBGM4WCMJRMM4GCNZRMIYGCNDBHA======",
        "options": {}
      },
      "type": "n8n-nodes-base.rssFeedRead",
      "typeVersion": 1.1,
      "position": [
        -80,
        520
      ],
      "id": "548de78c-2ad1-4a54-b581-146ae1e0f7e1",
      "name": "量子位",
      "executeOnce": false,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "numberInputs": 3
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3,
      "position": [
        360,
        320
      ],
      "id": "83071f04-c9f4-4240-8446-99422934527f",
      "name": "合并数据"
    },
    {
      "parameters": {
        "aggregate": "aggregateAllItemData",
        "options": {}
      },
      "type": "n8n-nodes-base.aggregate",
      "typeVersion": 1,
      "position": [
        360,
        1580
      ],
      "id": "35ad4626-1db8-4f4c-95f2-afc9229e586f",
      "name": "Aggregate"
    },
    {
      "parameters": {
        "url": "http://www.jintiankansha.me/rss/G42TC7DGG44WKMLEHFRGIMZSMMZDSMZXMI3DCYZZGYZWEMRRGQ4TMNLEMU2TGYTBMYZGGMQ=",
        "options": {
          "ignoreSSL": true
        }
      },
      "id": "ae646fb4-c9f1-463a-a5ba-0268c7ee5516",
      "name": "机器之心1",
      "type": "n8n-nodes-base.rssFeedRead",
      "position": [
        -80,
        1380
      ],
      "typeVersion": 1.1,
      "notesInFlow": false,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "url": "http://www.jintiankansha.me/rss/GEYDONJSPQ4DIMRTGA3DAMTCMQ2TAMZYMY2GEZJQMZQWIMZVGFSGINZTGI4GCNJWG4YWKMBWHE======",
        "options": {
          "ignoreSSL": true
        }
      },
      "id": "8f2461de-dd05-43af-a1d2-2ec4e25e00ed",
      "name": "新智元1",
      "type": "n8n-nodes-base.rssFeedRead",
      "position": [
        -80,
        1580
      ],
      "typeVersion": 1.1,
      "alwaysOutputData": false,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "url": "http://www.jintiankansha.me/rss/GEYDQOJYPRRWKM3DHE4WEOLEMVTGKMZQGQYDSMTDGJTDSNLBGM4WCMJRMM4GCNZRMIYGCNDBHA======",
        "options": {}
      },
      "type": "n8n-nodes-base.rssFeedRead",
      "typeVersion": 1.1,
      "position": [
        -80,
        1780
      ],
      "id": "dac1d4ce-accd-432e-af17-74e415296c88",
      "name": "量子位1",
      "executeOnce": false,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "html": "={{ $json.content }}",
        "options": {}
      },
      "type": "n8n-nodes-base.markdown",
      "typeVersion": 1,
      "position": [
        140,
        1780
      ],
      "id": "d078577b-2cee-4455-bbfd-5cf720c4a1d6",
      "name": "Markdown3"
    },
    {
      "parameters": {
        "html": "={{ $json.content }}",
        "options": {}
      },
      "type": "n8n-nodes-base.markdown",
      "typeVersion": 1,
      "position": [
        140,
        1580
      ],
      "id": "23d6504a-d062-4b0c-946d-e24c1f2407d6",
      "name": "Markdown4"
    },
    {
      "parameters": {
        "html": "={{ $json.content }}",
        "options": {}
      },
      "type": "n8n-nodes-base.markdown",
      "typeVersion": 1,
      "position": [
        140,
        1380
      ],
      "id": "fc9fe360-dbcc-49d5-a078-0b35ee13326c",
      "name": "Markdown5"
    },
    {
      "parameters": {
        "rule": {
          "interval": [
            {
              "field": "hours"
            }
          ]
        }
      },
      "id": "3801d7af-88b2-48c9-8425-eda183557192",
      "name": "Schedule Trigger1",
      "type": "n8n-nodes-base.scheduleTrigger",
      "position": [
        -300,
        1580
      ],
      "typeVersion": 1.2
    },
    {
      "parameters": {
        "html": "={{ $json.content }}",
        "options": {}
      },
      "type": "n8n-nodes-base.markdown",
      "typeVersion": 1,
      "position": [
        140,
        1120
      ],
      "id": "b04459ad-ef93-4c0f-802a-471f38af7bc5",
      "name": "Markdown6"
    },
    {
      "parameters": {
        "html": "={{ $json.content }}",
        "options": {}
      },
      "type": "n8n-nodes-base.markdown",
      "typeVersion": 1,
      "position": [
        140,
        920
      ],
      "id": "e701ed83-adf1-4ead-83be-506ab9428023",
      "name": "Markdown7"
    },
    {
      "parameters": {
        "html": "={{ $json.content }}",
        "options": {}
      },
      "type": "n8n-nodes-base.markdown",
      "typeVersion": 1,
      "position": [
        140,
        720
      ],
      "id": "311983c8-b86e-4172-8ab1-85eae5ab2755",
      "name": "Markdown8"
    },
    {
      "parameters": {
        "url": "http://www.jintiankansha.me/rss/G42TC7DGG44WKMLEHFRGIMZSMMZDSMZXMI3DCYZZGYZWEMRRGQ4TMNLEMU2TGYTBMYZGGMQ=",
        "options": {
          "ignoreSSL": true
        }
      },
      "id": "3b8633c2-4ac3-4dca-89e1-86c734a9bdc7",
      "name": "机器之心2",
      "type": "n8n-nodes-base.rssFeedRead",
      "position": [
        -80,
        720
      ],
      "typeVersion": 1.1,
      "notesInFlow": false,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "url": "http://www.jintiankansha.me/rss/GEYDONJSPQ4DIMRTGA3DAMTCMQ2TAMZYMY2GEZJQMZQWIMZVGFSGINZTGI4GCNJWG4YWKMBWHE======",
        "options": {
          "ignoreSSL": true
        }
      },
      "id": "416bed0d-e28b-4ebc-8fe1-db5b276fc12c",
      "name": "新智元2",
      "type": "n8n-nodes-base.rssFeedRead",
      "position": [
        -80,
        920
      ],
      "typeVersion": 1.1,
      "alwaysOutputData": false,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "url": "http://www.jintiankansha.me/rss/GEYDQOJYPRRWKM3DHE4WEOLEMVTGKMZQGQYDSMTDGJTDSNLBGM4WCMJRMM4GCNZRMIYGCNDBHA======",
        "options": {}
      },
      "type": "n8n-nodes-base.rssFeedRead",
      "typeVersion": 1.1,
      "position": [
        -80,
        1120
      ],
      "id": "b75a4b8f-ae71-4808-8fac-0a50413ae68e",
      "name": "量子位2",
      "executeOnce": false,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "numberInputs": 3
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3,
      "position": [
        360,
        920
      ],
      "id": "b0e2eea4-9752-48d1-9f1e-308784a6a8b1",
      "name": "合并数据1"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.1,
      "position": [
        580,
        620
      ],
      "id": "53510893-0ba3-4153-8947-150415f69b2c",
      "name": "Merge"
    }
  ],
  "pinData": {
    "机器之心": [
      {
        "json": {
          "title": "颠覆传统信息搜索，效果是之前SOTA的三倍？UIUC韩家炜、孙冀萌团队开源DeepRetrieval，让模型端到端地学会搜索！",
          "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650963731&idx=4&sn=28f1d2a68c5b9f23f435f7aa66335473&chksm=8593ba76d088c1c15fa73b18bb65dd1a3248edc9f61f7ff321f751bebb6b8a4ad40e1d126749&scene=0#rd",
          "pubDate": "Tue, 08 Apr 2025 12:48:00 +0800",
          "enclosure": {
            "url": "http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXNUMFw5WKdZ2wK23QFWTia30IKE9E7p9aj8Za1nX2493SObukR3YsrYQ/0?wx_fmt=jpeg",
            "length": "0",
            "type": "image/jpeg"
          },
          "content": "\n\n    \n\n    \n\n    \n         <div class=\"rich_media_content\" id=\"js_content\"><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><img alt=\"图片\" class=\"rich_pages wxw-img\" data-ratio=\"0.5703703703703704\" data-w=\"1080\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4qxCCBDwsURwYQxQzqtnNcfgBE6kDVeb9ib93vNCvo6N7OCH5mhZ91Qq3LFH2n8ku4sfbWdBA6iag/640?wx_fmt=png&amp;from=appmsg&amp;tp=wxpic&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1\" style=\"max-width: 600px\"></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">在信息检索系统中，搜索引擎的能力只是影响结果的一个方面，</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">真正的瓶颈往往在于：用户的原始 query 本身不够好</span><span textstyle=\"\" style=\"font-size: 15px;\">。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">尤其在专业搜索场景（如文献、数据库查询）中，用户往往无法用精确、完整的表达描述他们的需求。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">那么问题来了：</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">能不能教大模型优化原始 query 的表达方式，从而让已有检索系统的能力被最大化激发？</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">来自 UIUC 的 Jiawei Han 和 Jimeng Sun 团队的一项最新工作 </span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">DeepRetrieval </span><span textstyle=\"\" style=\"font-size: 15px;\">就是针对这个问题提出了系统性解法，只需 </span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">3B 的 LLM </span><span textstyle=\"\" style=\"font-size: 15px;\">即可实现 50 个点以上的提升。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.29259259259259257\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503479539\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXBspLlhjWN6Dhlboydic2Vy2BQSKmyse7OVXbKibFzKRXkwkW240PSmNQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li style=\"color: rgb(123, 12, 0);font-size: 15px;\"><section style=\"text-align: left;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: normal;\">论文标题：</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: normal;\">DeepRetrieval: Hacking Real Search Engines and Retrievers with Large Language Models via Reinforcement Learning</span></span></section></li><li style=\"color: rgb(123, 12, 0);\"><section style=\"text-align: left;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);font-weight: normal;\">论文地址：https://arxiv.org/pdf/2503.00223</span></span></section></li><li style=\"color: rgb(123, 12, 0);\"><section style=\"text-align: left;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);font-weight: normal;\">开源代码：https://github.com/pat-jj/DeepRetrieval</span></span></section></li><li style=\"color: rgb(123, 12, 0);\"><p style=\"padding: 0pt;text-align: left;line-height: 1.75em;\"><span style=\"font-family: Arial;color: rgb(255, 0, 0);font-size: 11pt;\"><font face=\"微软雅黑\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);font-weight: normal;text-decoration: none;\">开源模型：</span></span></font></span><span style=\"font-family: Arial;color: rgb(255, 0, 0);\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);font-weight: normal;text-decoration: none;\">https://huggingface.co/DeepRetrieval</span></span></span><span style=\"font-family: Arial;color: rgb(255, 0, 0);font-size: 11pt;\"><p></p></span></p><section style=\"text-align: left;line-height: 1.75em;\"><span leaf=\"\"><br></span></section></li></ul><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">一句话概括</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">：</span><span textstyle=\"\" style=\"font-size: 15px;\">DeepRetrieval 是一个基于强化学习（RL）的 query 优化系统，训练 LLM 在不同检索任务中优化原始查询，以最大化真实系统的检索效果。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">它不是训练一个新的 retriever，也不是让模型直接回答问题，而是：</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">在不改变现有搜索系统的前提下，通过优化原始 query，让「提问方式」变得更聪明，从而获取更好的结果。</span></span><span leaf=\"\"><br></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">更多有意义的讨论请读原文正文和附录的 Discussion 部分。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.537962962962963\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503479540\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXCBLibudFoia00WzQat7q3SFAH1NtZ9GcqgLEdoh8BbdXWZibJia7sJljoA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">方法细节</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5046296296296297\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503479541\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXecAuVNUgm8icOtOV9rBMuPl3tFhicw3Lp3MBUK6copqcL4GkUhicsw2Kg/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">方法要点</span></span></section><section><span leaf=\"\"><br></span></section><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li style=\"font-size: 15px;\"><section style=\"text-align: justify;line-height: 1.75em;\"><span leaf=\"\" style=\"text-align: justify;\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">输入</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">：原始查询 q</span></span></section></li><li style=\"font-size: 15px;\"><section style=\"text-align: justify;line-height: 1.75em;\"><span leaf=\"\" style=\"text-align: justify;\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">输出</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">：改写后的查询 q′（自然语言、布尔表达式或 SQL）</span></span></section></li><li style=\"font-size: 15px;\"><section style=\"text-align: justify;line-height: 1.75em;\"><span leaf=\"\" style=\"text-align: justify;\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">环境反馈</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">：使用 q′ 去检索系统中查询 → 返回结果 → 与 groundtruth 对比，计算 reward，reward 为 task-specific 检索表现（如 Recall@K、NDCG@K、SQL accuracy）使用 PPO 进行训练，并加入格式奖励（format correctness）与 KL-regularization 保证训练稳定，优化目标如下：</span></span></section></li></ul><section><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.14432989690721648\" data-s=\"300,640\" data-type=\"png\" data-w=\"485\" type=\"block\" data-imgfileid=\"503479542\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJX28KVkdOuDZOunZOQ1wa1D05tsO6ATdTJcGTk3n28GWV9xkq4fgNTEA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">其中，π_ref 是参考策略（reference policy），通常指的是</span></span><span leaf=\"\" style=\"text-align: justify;\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">在强化学习开始之前的初始模型</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">。β 是一个合适的 KL 惩罚系数，用于</span></span><span leaf=\"\" style=\"text-align: justify;\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">控制正则化的强度</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">。KL 散度项的作用是</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">惩罚当前策略与参考策略之间的过大偏离</span><span textstyle=\"\" style=\"font-size: 15px;\">，从而在强化学习训练过程中</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">保证策略更新的稳定性</span><span textstyle=\"\" style=\"font-size: 15px;\">。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">实验结果</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">真实搜索引擎的文献搜索</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.7175925925925926\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503479544\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXxd9EbD2Iu4qmHbBLmJLx4jseH059z3bDMM79CzEwZe5bk7YNtJCr1Q/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span data-pm-slice=\"0 0 []\"><span leaf=\"\" style=\"text-align: justify;\"><span textstyle=\"\" style=\"font-size: 15px;\">首先在真实的搜索引擎上进行实验，文中用到了专业搜索引擎 PubMed 和 ClinicalTrials.gov。无需改动搜索引擎或其它任何检索器，仅通过端到端地优化 query 表达，DeepRetrieval 就可以让结果获得 10 倍提升，远超各个商业大模型和之前的 SO</span></span><span leaf=\"\" style=\"text-align: justify;\"><span textstyle=\"\" style=\"font-size: 15px;\">TA 方法 LEADS（蒸馏 + SFT 方法）。</span></span></span><span style=\"font-family: Arial;color: rgb(0, 0, 0);font-size: 11pt;\"><p></p></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">Evidence-Seeking 检索：通用搜索引擎的革新潜力</span></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></section><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">DeepRetrieval 在 Evidence-Seeking 检索任务上的优异表现令人瞩目。如表 1 所示，结合简单 BM25，这个仅有 3B 参数的模型在 SQuAD、TriviaQA 和 NQ 数据集上超越了 GPT-4o 和 Claude-3.5 等大型商业模型。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">Evidence-Seeking 任务的核心是找到支持特定事实性问题答案的确切文档证据，在通用搜索引擎环境中，这一能力尤为关键。作者团队指出，将 DeepRetrieval 应用到 Google、Bing 等通用搜索引擎的 Evidence-Seeking 场景将带来显著优势：</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li><p style=\"text-align: justify;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">精准定位事实文档：</span><span textstyle=\"\" style=\"font-size: 15px;\">通用搜索引擎包含海量信息，用户难以构建能精确定位证据段落的查询。DeepRetrieval 可将简单问题转化为包含关键术语、同义词和限定符的复杂查询，显著提高找到权威证据的概率。</span></span></p></li></ul><p style=\"text-align:justify;margin-left:8px;margin-right:8px;line-height:1.75em;\"><span leaf=\"\"><br></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li><p style=\"text-align: justify;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">克服知识时效性限制：</span><span textstyle=\"\" style=\"font-size: 15px;\">模型能够将「2024 年奥运会金牌榜前三名」等超出 LLM 知识截止日期的问题转化为精确搜索表达，使检索系统能够找到最新事实证据。</span></span></p></li></ul><p style=\"text-align:justify;margin-left:8px;margin-right:8px;line-height:1.75em;\"><span leaf=\"\"><br></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li><p style=\"text-align: justify;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">多源验证能力：</span><span textstyle=\"\" style=\"font-size: 15px;\">通过优化查询帮助搜索引擎找到多个独立来源的事实证据，从而交叉验证信息准确性，这是纯 LLM 问答无法实现的关键优势。</span></span></p></li></ul><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">作者团队表示会将这部分的延伸作为 DeepRetrieval </span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">未来主要的探索方向之一</span><span textstyle=\"\" style=\"font-size: 15px;\">。</span></span></p><p><span leaf=\"\"><br></span></p><section style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">Classic IR（Sparse / Dense）</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5462962962962963\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503479545\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXia8iaXYBqCS7H8cdxteJM8wX7INncMibWO9UnrDh6ebPFOmlkpHVBxtwA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">在 BM25 和 dense retriever 下，DeepRetrieval 提供了平均 5~10 点 NDCG 提升，并且：</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">BM25 + DeepRetrieval 和多数 dense baseline 水平相当</span><span textstyle=\"\" style=\"font-size: 15px;\">。</span></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">结合极快的检索速度（BM25 vs dense：352s vs 12,232s），展示了一个现实可部署、性能不俗的高效方案。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">SQL 检索任务</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">在 SQL 检索任务中，DeepRetrieval 摆脱了对 groundtruth SQL 的依赖，直接利用生成 SQL 的执行成功率优化模型，通过生成更精准的 SQL 语句，使得模型在 Spider、BIRD 等数据集上的执行正确率均超过对比模型（包括 GPT-4o 和基于 SFT 的大模型）。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"2.0232558139534884\" data-s=\"300,640\" data-type=\"png\" data-w=\"688\" type=\"block\" data-imgfileid=\"503479546\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJX7dIvL7e2KGSebJUG4XtkuHafTsYt3R2B47Ricj40RgEcD20blfQribew/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><p style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">探索胜于模仿：RL 为何超越 SFT</span></span></p><p style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">DeepRetrieval 的实验揭示了强化学习（RL）在搜索优化上相比监督微调（SFT）的独特优势。实验数据令人信服：在文献搜索上，RL 方法的 DeepRetrieval（65.07%）超过 SFT 方法 LEADS（24.68%）近三倍；在 SQL 任务上，从零开始的 RL 训练（无需任何 gold SQL 语句的监督）也优于使用 GPT-4o 蒸馏数据的 SFT 模型。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">这种显著差异源于两种方法的本质区别：SFT 是「模仿学习」，试图复制参考查询，而 RL 是「直接优化」，通过环境反馈学习最优查询策略。SFT 方法的局限在于参考查询本身可能不是最优的，即使是人类专家或大模型也难以直观设计出最适合特定搜索引擎的查询表达。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">论文中的案例分析进一步证实了这一点。例如，在 PubMed 搜索中，DeepRetrieval 生成的查询如「((DDAVP) AND (Perioperative Procedures OR Blood Transfusion OR Desmopressin OR Anticoagulant)) AND (Randomized Controlled Trial)」融合了医学领域的专业术语和 PubMed 搜索引擎偏好的布尔结构，这种组合很难通过简单模仿预定义的查询模板获得。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">相反，RL 允许模型通过尝试与错误来探索查询空间，发现人类甚至未考虑的有效模式，并直接针对最终目标（如 Recall 或执行准确率）进行优化。这使 DeepRetrieval 能够生成高度适合特定搜索引擎特性的查询，适应不同检索环境的独特需求。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">这一发现具有重要启示：在追求最佳检索性能时，让模型通过反馈学习如何与检索系统「对话」，比简单模仿既定模式更为有效，这也解释了为何参数量较小的 DeepRetrieval 能在多项任务上超越拥有更多参数的商业模型。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">模型 Think&amp;Query 长度分析</span></span></p><p style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-imgfileid=\"503479991\" data-ratio=\"2.541471048513302\" data-s=\"300,640\" data-type=\"png\" data-w=\"639\" type=\"block\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8apWjQibSDGflicVKV7CAsLLjiaQhPuem4SZ9FNO1fwz7OncZH9pEmcbfnS5LqYLuAyx5PdAVjJZjibA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">通过分析 DeepRetrieval 在训练过程中模型思考链和查询长度的变化，可以发现以下</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">关键洞见</span><span textstyle=\"\" style=\"font-size: 15px;\">：</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">思考链长度演变</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">与「aha moment」相反</span><span textstyle=\"\" style=\"font-size: 15px;\">，DeepRetrieval 的思考链长度随训练呈</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">下降趋势</span><span textstyle=\"\" style=\"font-size: 15px;\">，而非增长。这与 DeepSeek-R1 报告的「aha moment」现象形成鲜明对比，后者的思考链会随训练进展变得更长。图 4(a) 清晰地展示了 Qwen 模型思考链从初始约 150 tokens 逐渐降至稳定的 50 tokens 左右，而 Llama 模型的思考链更短，甚至降至接近 25 tokens。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">查询长度特征</span></span></p><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">实验揭示了思考过程对查询长度的显著影响。</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">无思考过程的模型容易陷入次优解</span><span textstyle=\"\" style=\"font-size: 15px;\">，如图 4(b) 所示，Qwen 无思考版本生成极长查询（500-600 tokens），表现出过度扩展的倾向。相比之下，有思考过程的模型保持更为适中的查询长度，Qwen 约 150 tokens，Llama 约 100 tokens。有趣的是，不同模型采用不同长度策略，但能达到相似性能，表明查询生成存在多样有效路径。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">性能与思考过程关系</span></span></p><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">思考过程对检索性能有决定性影响。图 4(c) 表明，</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">具备思考能力的模型性能显著提升</span><span textstyle=\"\" style=\"font-size: 15px;\">，有思考的模型 Recall@3K 能达到 65%，而无思考模型仅 50% 左右。此外，</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">训练效率也明显提高</span><span textstyle=\"\" style=\"font-size: 15px;\">，有思考的模型更快达到高性能并保持稳定。论文附录 D.1 的分析表明，思考过程帮助模型避免简单地通过增加查询长度和重复术语来提升性能，而是引导模型学习更有效的语义组织策略。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">关键结论</span></span></p><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">DeepRetrieval 展示了思考过程在信息检索中扮演「探索促进器」</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">的关键角色。与数学或编程问题不同，检索任务不需要像「aha moment」那样的突然顿悟现象。相反，检索优化遵循</span><span textstyle=\"\" style=\"font-size: 15px;\">「先详细思考，后逐渐精简」</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">的模式，模型在内化有效策略后，不再需要冗长思考。这表明</span><span textstyle=\"\" style=\"font-size: 15px;\">检索任务中思考链的主要功能是探索，一旦策略稳定便可简化。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">这种分析表明，适当的思考过程设计对于构建高效的检索优化系统至关重要，能够在不增加模型参数的情况下显著提升性能，为未来的 LLM 应用于搜索任务提供了重要设计思路。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">结论</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">DeepRetrieval 的贡献在于揭示了一个常被忽视但至关重要的事实：</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">检索效果的上限不仅在于检索器本身，更在于如何「提问」</span><span textstyle=\"\" style=\"font-size: 15px;\">。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">通过强化学习教 LLM 改写原始查询，DeepRetrieval 不仅摆脱了对人工标注数据和大模型蒸馏的依赖，还在多个任务上证明了改写 query 的巨大潜力。这项工作为搜索与信息检索领域带来了新的思考：未来的检索优化，不仅是提升引擎算法，更是如何让用户「问得更好」，从而激发出检索系统的全部潜力。</span></span></section><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" style=\"margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb auto center><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif><span leaf=\"\"><br></span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" style=\"margin: 5px 8px 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb auto center><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;\">© THE END </span></span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" style=\"margin: 5px 8px 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb auto center><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"outline: 0px;font-size: 12px;color: rgb(136, 136, 136);\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;\">转载请联系本公众号获得授权</span></span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" style=\"margin: 5px 8px 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb auto center><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"outline: 0px;font-size: 12px;color: rgb(136, 136, 136);\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;\">投稿或寻求报道：liyazhou@jiqizhixin.com</span></span></span></p><p style=\"display: none;\"><mp-style-type data-value=\"10000\"></mp-style-type></p></div>\n    \n\n    \n    <br>\n\n    \n        <a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963731&amp;idx=4&amp;sn=28f1d2a68c5b9f23f435f7aa66335473&amp;chksm=8593ba76d088c1c15fa73b18bb65dd1a3248edc9f61f7ff321f751bebb6b8a4ad40e1d126749&amp;scene=0#rd\" style=\"color: blue\" class=\"media_tool_meta meta_primary\">文章原文</a>\n        <br>\n    \n\n    \n\n    <img alt=\"\" width=\"1px\" height=\"1px\" class=\"\" style=\"width:1px;height:1px;display:none\" src=\"http://www.jintiankansha.me/rss_static/4365/mh3IOHrP5I\">\n\n",
          "contentSnippet": "在信息检索系统中，搜索引擎的能力只是影响结果的一个方面，真正的瓶颈往往在于：用户的原始 query 本身不够好。\n\n\n尤其在专业搜索场景（如文献、数据库查询）中，用户往往无法用精确、完整的表达描述他们的需求。\n\n\n那么问题来了：能不能教大模型优化原始 query 的表达方式，从而让已有检索系统的能力被最大化激发？\n\n\n来自 UIUC 的 Jiawei Han 和 Jimeng Sun 团队的一项最新工作 DeepRetrieval 就是针对这个问题提出了系统性解法，只需 3B 的 LLM 即可实现 50 个点以上的提升。\n\n\n\n\n\n\n论文标题：DeepRetrieval: Hacking Real Search Engines and Retrievers with Large Language Models via Reinforcement Learning\n\n论文地址：https://arxiv.org/pdf/2503.00223\n\n开源代码：https://github.com/pat-jj/DeepRetrieval\n\n开源模型：https://huggingface.co/DeepRetrieval\n\n\n\n\n一句话概括：DeepRetrieval 是一个基于强化学习（RL）的 query 优化系统，训练 LLM 在不同检索任务中优化原始查询，以最大化真实系统的检索效果。\n\n\n它不是训练一个新的 retriever，也不是让模型直接回答问题，而是：\n\n\n在不改变现有搜索系统的前提下，通过优化原始 query，让「提问方式」变得更聪明，从而获取更好的结果。\n\n\n\n更多有意义的讨论请读原文正文和附录的 Discussion 部分。\n\n\n\n\n\n方法细节\n\n\n\n\n\n方法要点\n\n\n\n输入：原始查询 q\n\n输出：改写后的查询 q′（自然语言、布尔表达式或 SQL）\n\n环境反馈：使用 q′ 去检索系统中查询 → 返回结果 → 与 groundtruth 对比，计算 reward，reward 为 task-specific 检索表现（如 Recall@K、NDCG@K、SQL accuracy）使用 PPO 进行训练，并加入格式奖励（format correctness）与 KL-regularization 保证训练稳定，优化目标如下：\n\n\n\n\n\n\n其中，π_ref 是参考策略（reference policy），通常指的是在强化学习开始之前的初始模型。β 是一个合适的 KL 惩罚系数，用于控制正则化的强度。KL 散度项的作用是惩罚当前策略与参考策略之间的过大偏离，从而在强化学习训练过程中保证策略更新的稳定性。\n\n\n实验结果\n\n\n真实搜索引擎的文献搜索\n\n\n\n\n\n首先在真实的搜索引擎上进行实验，文中用到了专业搜索引擎 PubMed 和 ClinicalTrials.gov。无需改动搜索引擎或其它任何检索器，仅通过端到端地优化 query 表达，DeepRetrieval 就可以让结果获得 10 倍提升，远超各个商业大模型和之前的 SOTA 方法 LEADS（蒸馏 + SFT 方法）。\n\n\n\nEvidence-Seeking 检索：通用搜索引擎的革新潜力\n\n\nDeepRetrieval 在 Evidence-Seeking 检索任务上的优异表现令人瞩目。如表 1 所示，结合简单 BM25，这个仅有 3B 参数的模型在 SQuAD、TriviaQA 和 NQ 数据集上超越了 GPT-4o 和 Claude-3.5 等大型商业模型。\n\n\nEvidence-Seeking 任务的核心是找到支持特定事实性问题答案的确切文档证据，在通用搜索引擎环境中，这一能力尤为关键。作者团队指出，将 DeepRetrieval 应用到 Google、Bing 等通用搜索引擎的 Evidence-Seeking 场景将带来显著优势：\n\n\n\n精准定位事实文档：通用搜索引擎包含海量信息，用户难以构建能精确定位证据段落的查询。DeepRetrieval 可将简单问题转化为包含关键术语、同义词和限定符的复杂查询，显著提高找到权威证据的概率。\n\n\n\n\n克服知识时效性限制：模型能够将「2024 年奥运会金牌榜前三名」等超出 LLM 知识截止日期的问题转化为精确搜索表达，使检索系统能够找到最新事实证据。\n\n\n\n\n多源验证能力：通过优化查询帮助搜索引擎找到多个独立来源的事实证据，从而交叉验证信息准确性，这是纯 LLM 问答无法实现的关键优势。\n\n\n\n作者团队表示会将这部分的延伸作为 DeepRetrieval 未来主要的探索方向之一。\n\n\nClassic IR（Sparse / Dense）\n\n\n\n\n\n在 BM25 和 dense retriever 下，DeepRetrieval 提供了平均 5~10 点 NDCG 提升，并且：BM25 + DeepRetrieval 和多数 dense baseline 水平相当。\n\n\n结合极快的检索速度（BM25 vs dense：352s vs 12,232s），展示了一个现实可部署、性能不俗的高效方案。\n\n\nSQL 检索任务\n\n\n在 SQL 检索任务中，DeepRetrieval 摆脱了对 groundtruth SQL 的依赖，直接利用生成 SQL 的执行成功率优化模型，通过生成更精准的 SQL 语句，使得模型在 Spider、BIRD 等数据集上的执行正确率均超过对比模型（包括 GPT-4o 和基于 SFT 的大模型）。\n\n\n\n\n\n探索胜于模仿：RL 为何超越 SFT\n\n\nDeepRetrieval 的实验揭示了强化学习（RL）在搜索优化上相比监督微调（SFT）的独特优势。实验数据令人信服：在文献搜索上，RL 方法的 DeepRetrieval（65.07%）超过 SFT 方法 LEADS（24.68%）近三倍；在 SQL 任务上，从零开始的 RL 训练（无需任何 gold SQL 语句的监督）也优于使用 GPT-4o 蒸馏数据的 SFT 模型。\n\n\n这种显著差异源于两种方法的本质区别：SFT 是「模仿学习」，试图复制参考查询，而 RL 是「直接优化」，通过环境反馈学习最优查询策略。SFT 方法的局限在于参考查询本身可能不是最优的，即使是人类专家或大模型也难以直观设计出最适合特定搜索引擎的查询表达。\n\n\n论文中的案例分析进一步证实了这一点。例如，在 PubMed 搜索中，DeepRetrieval 生成的查询如「((DDAVP) AND (Perioperative Procedures OR Blood Transfusion OR Desmopressin OR Anticoagulant)) AND (Randomized Controlled Trial)」融合了医学领域的专业术语和 PubMed 搜索引擎偏好的布尔结构，这种组合很难通过简单模仿预定义的查询模板获得。\n\n\n相反，RL 允许模型通过尝试与错误来探索查询空间，发现人类甚至未考虑的有效模式，并直接针对最终目标（如 Recall 或执行准确率）进行优化。这使 DeepRetrieval 能够生成高度适合特定搜索引擎特性的查询，适应不同检索环境的独特需求。\n\n\n这一发现具有重要启示：在追求最佳检索性能时，让模型通过反馈学习如何与检索系统「对话」，比简单模仿既定模式更为有效，这也解释了为何参数量较小的 DeepRetrieval 能在多项任务上超越拥有更多参数的商业模型。\n\n\n模型 Think&Query 长度分析\n\n\n\n\n\n通过分析 DeepRetrieval 在训练过程中模型思考链和查询长度的变化，可以发现以下关键洞见：\n\n\n思考链长度演变\n\n\n与「aha moment」相反，DeepRetrieval 的思考链长度随训练呈下降趋势，而非增长。这与 DeepSeek-R1 报告的「aha moment」现象形成鲜明对比，后者的思考链会随训练进展变得更长。图 4(a) 清晰地展示了 Qwen 模型思考链从初始约 150 tokens 逐渐降至稳定的 50 tokens 左右，而 Llama 模型的思考链更短，甚至降至接近 25 tokens。\n\n\n查询长度特征\n\n\n实验揭示了思考过程对查询长度的显著影响。无思考过程的模型容易陷入次优解，如图 4(b) 所示，Qwen 无思考版本生成极长查询（500-600 tokens），表现出过度扩展的倾向。相比之下，有思考过程的模型保持更为适中的查询长度，Qwen 约 150 tokens，Llama 约 100 tokens。有趣的是，不同模型采用不同长度策略，但能达到相似性能，表明查询生成存在多样有效路径。\n\n\n性能与思考过程关系\n\n\n思考过程对检索性能有决定性影响。图 4(c) 表明，具备思考能力的模型性能显著提升，有思考的模型 Recall@3K 能达到 65%，而无思考模型仅 50% 左右。此外，训练效率也明显提高，有思考的模型更快达到高性能并保持稳定。论文附录 D.1 的分析表明，思考过程帮助模型避免简单地通过增加查询长度和重复术语来提升性能，而是引导模型学习更有效的语义组织策略。\n\n\n关键结论\n\n\nDeepRetrieval 展示了思考过程在信息检索中扮演「探索促进器」的关键角色。与数学或编程问题不同，检索任务不需要像「aha moment」那样的突然顿悟现象。相反，检索优化遵循「先详细思考，后逐渐精简」的模式，模型在内化有效策略后，不再需要冗长思考。这表明检索任务中思考链的主要功能是探索，一旦策略稳定便可简化。\n\n\n这种分析表明，适当的思考过程设计对于构建高效的检索优化系统至关重要，能够在不增加模型参数的情况下显著提升性能，为未来的 LLM 应用于搜索任务提供了重要设计思路。\n\n\n结论\n\n\nDeepRetrieval 的贡献在于揭示了一个常被忽视但至关重要的事实：检索效果的上限不仅在于检索器本身，更在于如何「提问」。\n\n\n通过强化学习教 LLM 改写原始查询，DeepRetrieval 不仅摆脱了对人工标注数据和大模型蒸馏的依赖，还在多个任务上证明了改写 query 的巨大潜力。这项工作为搜索与信息检索领域带来了新的思考：未来的检索优化，不仅是提升引擎算法，更是如何让用户「问得更好」，从而激发出检索系统的全部潜力。\n\n\n© THE END \n转载请联系本公众号获得授权\n投稿或寻求报道：liyazhou@jiqizhixin.com\n\n\n    \n\n    \n    \n文章原文",
          "guid": "http://www.jintiankansha.me/t/mh3IOHrP5I",
          "categories": [
            "无"
          ],
          "isoDate": "2025-04-08T04:48:00.000Z"
        }
      },
      {
        "json": {
          "title": "类R1强化学习迁移到视觉定位！全开源Vision-R1将图文大模型性能提升50％",
          "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650963731&idx=3&sn=7c62398a729785a7d02da7b9d47fab3a&chksm=8525221905860a7ee31228d160e4f9c43b94d60c8acde57393a69b9a129332cc7c29446bba77&scene=0#rd",
          "pubDate": "Tue, 08 Apr 2025 12:48:00 +0800",
          "enclosure": {
            "url": "http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vX2GR4SOzMayrnjia6a0Op2Ec4BvGASYZanMpyJQL3OzdhLn6wjibgCyg/0?wx_fmt=jpeg",
            "length": "0",
            "type": "image/jpeg"
          },
          "content": "\n\n    \n\n    \n\n    \n         <div class=\"rich_media_content\" id=\"js_content\"><section style=\"text-align: center;margin: 0px 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5703125\" data-s=\"300,640\" data-type=\"png\" data-w=\"1280\" type=\"block\" data-imgfileid=\"503474618\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">图文大模型通常采用</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">「预训练 + 监督微调</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">」的两阶段范式进行训练，以强化其指令跟随能力。受语言领域的启发，多模态偏好优化技术凭借其在数据效率和性能增益方面的优势，被广泛用于对齐人类偏好。目前，该技术主要依赖高质量的偏好数据标注和精准的奖励模型训练来提升模型表现。然而，这一方法不仅资源消耗巨大，训练过程仍然极具挑战。</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">受到基于规则的强化学习（Rule-Based Reinforcement Learning）在 R1 上成功应用的启发，</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">中科院自动化研究所与中科紫东太初团队探索了如何结合高质量指令对齐数据与类 R1 的强化学习方法，进一步增强图文大模型的视觉定位能力</span><span textstyle=\"\" style=\"font-size: 15px;\">。该方法首次在 Object Detection、Visual Grounding 等复杂视觉任务上，使 Qwen2.5-VL 模型实现了最高 50% 的性能提升，超越了参数规模超过 10 倍的 SOTA 模型。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">目前，相关工作论文、模型及数据集代码均已开源。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.3055555555555556\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480005\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v2e77kvXDNLSZUg2LNXaRBlus0430lDHwnlVYWfYb5TJO4PQjEAQaHQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p><span leaf=\"\"><br></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li style=\"color: rgb(123, 12, 0);\"><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);\">论文标题：Vision-R1: Evolving Human-Free Alignment in Large Vision-Language Models via Vision-Guided Reinforcement Learning</span></span></p></li><li style=\"color: rgb(123, 12, 0);\"><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);\">论文地址：https://arxiv.org/pdf/2503.18013</span></span></p></li><li style=\"color: rgb(123, 12, 0);\"><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);\">Github 仓库：https://github.com/jefferyZhan/Griffon/tree/master/Vision-R1</span></span></p></li><li style=\"color: rgb(123, 12, 0);\"><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);\">Huggingface 仓库：https://huggingface.co/collections/JefferyZhan/vision-r1-67e166f8b6a9ec3f6a664262</span></span></p></li></ul><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">引言</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">目标定位任务要求模型能够精准识别用户输入的任意感兴趣目标，并给出精确的目标框，对图文大模型的细粒度感知和空间理解能力提出了严峻挑战。当前，图文大模型通常将目标定位建模为文本序列预测任务，并通过大规模预训练和指令数据的监督微调，以 Next Token Prediction 实现对不同粒度目标描述的精准定位。尽管在指代表达理解等任务上已超越传统视觉专家模型，但在更复杂、目标密集的场景中，其视觉定位与目标检测能力仍与专家模型存在显著差距。</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">R1 的成功应用推动了对基于规则的任务级别奖励监督的探索，使模型摆脱了对人工偏好数据标注和奖励模型训练的依赖。值得注意的是，视觉定位指令数据本身具有精准的空间位置标注，并与与人类对精准目标定位偏好高度一致。基于这些优势，Vision-R1 通过设计类 R1 的强化学习后训练框架，在任务级别监督中引入基于视觉任务评价指标的反馈奖励信号，为增强图文大模型的细粒度视觉定位能力提供了创新突破方向。</span></span></p><p><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5472222222222223\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480006\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vJDCID3GgZyWTM8ChASD740oNgKot2lsgVYfxXvI8XjOJicpddVXJqCQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin-left: 8px;margin-right: 8px;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;color: rgb(136, 136, 136);font-style: italic;\">Vision-R1 关键设计示意图</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">Vision Criteria-Driven Reward Function</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">聚焦图文大模型目标定位问题</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">在文本序列的统一建模和大规模数据的自回归训练下，图文大模型在目标定位任务上取得了显著的性能提升。然而，其进一步发展仍受到三大关键问题的限制：（1）密集场景中的长序列预测易出现格式错误，（2）有效预测目标的召回率较低，（3）目标定位精度不足。 </span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">这些问题制约了模型在更复杂视觉任务上的表现。在自回归 Token 级别的监督机制下，模型无法获得实例级别的反馈，而直接在单目标场景下应用 GRPO 训练方法又忽视了视觉定位任务的特性及 Completion 级别监督的优势。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">为此，研究团队结合图文大模型在视觉定位任务中面临的挑战，提出了一种基于视觉任务评价准则驱动的奖励函数，其设计包括以下四个核心部分：</span></span></p><p><span leaf=\"\"><br></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">框优先的预测匹配</span><span textstyle=\"\" style=\"font-size: 15px;\">：与仅针对单个目标进行设计的方法不同，Vision-R1 采用多目标预测的统一建模方式。为了计算包含多个目标预测的奖励，Vision-R1 首先对文本序列化的预测结果进行反序列化，提取出每个目标的预测框及其标签，并将预测结果与真实标注进行匹配，以确保奖励机制能够全面衡量多目标场景下的定位质量。</span></span></p></li><li><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">双重格式奖励</span><span textstyle=\"\" style=\"font-size: 15px;\">：该奖励项旨在解决密集场景下长序列预测的格式错误问题。对于每个预测文本序列，模型需满足指定的模板格式（如 Qwen2.5-VL 采用的 JSON 格式），并确保目标坐标的数值正确性。仅当预测结果同时满足格式和内容要求时，模型才能获得奖励 1，从而引导其生成符合标准的预测输出。</span></span></p></li><li><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">召回奖励</span><span textstyle=\"\" style=\"font-size: 15px;\">：该奖励项针对有效预测目标召回率低的问题，鼓励模型尽可能多地识别目标。具体而言，针对每个预测目标及其匹配的真实目标（GT），当两者的 IoU 超过预设阈值 ζ 时，视为该预测有效。对于一个预测序列，其召回奖励定义为有效预测目标数量与实际需要预测目标数量的比例，以此激励模型提高目标的覆盖率。</span></span></p></li></ul><p style=\"margin:0px 8px;line-height:1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.1675925925925926\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480007\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vCwasgjnKomk6Y4icCY3w8iadAvX1bLIllQo7VO1hJyVN6icYiciaQyn3ekw/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin:0px 8px;line-height:1.75em;\"><span leaf=\"\"><br></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">精度奖励</span><span textstyle=\"\" style=\"font-size: 15px;\">：精度奖励与召回奖励协同作用，形成</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">「1+1&gt;2</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">」的优化效果。其中，召回奖励提升模型对目标的全面识别能力，而精度奖励则确保预测的准确性。精度奖励从单实例角度衡量预测质量，其核心目标是鼓励模型生成高质量的边界框。具体地，精度奖励被定义为所有有效预测的平均 IoU 值，以直接激励模型优化目标框的精确度：</span></span></p></li></ul><p><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.17407407407407408\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480008\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v6WEzXicJpQdhhGQHXTM1kOfVZCpKVQx7qkiaqy9LriabGk2eHUkB664PQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5666666666666667\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480009\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vPov0VPHWruJWz9nH1JJicIRs3IaK8D2EnE7ZVUia1SXzsQ9NnI9mbAdA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin-left: 8px;margin-right: 8px;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;color: rgb(136, 136, 136);font-style: italic;\">Vision-R1 整体框架</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">Progressive Rule Refinement Strategy</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">实现持续性能提升</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">在目标定位任务中，预测高质量（高 IoU）的目标框始终是一个挑战，尤其是在密集场景和小目标情况下。这种困难可能导致模型在同组预测中奖励差异较小，从而影响优化效果。针对这一问题，研究团队提出了渐进式规则调整策略，该策略通过在训练过程中动态调整奖励计算规则，旨在实现模型的持续性能提升。该策略主要包括两个核心部分：</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">差异化策略</span><span textstyle=\"\" style=\"font-size: 15px;\">：该策略的目标是扩大预测结果与实际奖励之间的映射差异。具体而言，通过惩罚低召回率（Recall）和低平均 IoU 的预测，并对高召回率和高 IoU 的预测给予较高奖励，从而鼓励模型生成更高质量的预测，尤其是在当前能够达到的最佳预测上获得最大奖励。这一策略引导模型在训练过程中逐渐提高预测精度，同时避免低质量预测的奖励过高，促进其优化。具体实现如下：</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.3675925925925926\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480010\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v2y8Y6piclrWYXp5VsAicG2IfNdIpG2K4u9W6JrJWsQY4WsIoSXyPkUibQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">阶段渐近策略</span><span textstyle=\"\" style=\"font-size: 15px;\">：类似于许多有效的学习方法，给初学者设定容易实现的目标并逐步提升奖励难度是一个常见且行之有效的策略。在 Vision-R1 中，训练过程被划分为初学阶段和进阶阶段，并通过逐步调整阈值 ζ 来实现奖励规则的逐渐变化。具体来说：</span></span></p><p><span leaf=\"\"><br></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">初学阶段（Beginner Phase）</span><span textstyle=\"\" style=\"font-size: 15px;\">： 在这一阶段，设置较低的 ζ 阈值（0.5/0.75），给予模型相对宽松的奖励标准，帮助其快速入门并学习基础的定位能力。</span></span></p></li><li><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">进阶阶段（Advanced Phase）</span><span textstyle=\"\" style=\"font-size: 15px;\">： 随着训练的深入，逐步提高 ζ 阈值，增加标准要求，以促使模型达到更高的准确度，避免模型依赖简单策略，从而持续推动模型性能的提升。</span></span></p></li></ul><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">不同模型的域内外目标检测评测</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">为全面评估 Vision-R1 的效果，研究团队选择了近期定位能力大幅提升的 Qwen2.5-VL-7B 模型和定位能力突出的 Griffon-G-7B 模型，在更有挑战的经典目标检测数据集 COCO 和多样场景的 ODINW-13 上进行测试，以展现方法对不同定位水平模型的适用性。</span></span></p><p><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5305555555555556\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480011\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v0pVFPvKaKDYzhkqIpUicqvMuM8ibRYX4azDj5uVtOlhq1LqKVjoN0Fkw/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin-left: 8px;margin-right: 8px;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;color: rgb(136, 136, 136);font-style: italic;\">经典 COCO/ODINW 数据集上 Vision-R1 方法相较于基线模型性能的提升</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">实验结果表明，无论基础性能如何，与基线模型相比这些模型在 Vision-R1 训练后性能大幅提升，甚至超过同系列 SOTA 模型，进一步接近了定位专家模型。</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">研究团队还在模型没有训练的域外定位数据集上进行测试，Vision-R1 在不同模型的四个数据集上取得了平均 6% 的性能提升，充分论证了方法的泛化性。</span></span></p><p><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.27685185185185185\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480012\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v9Aicd4jfK3HdpRQjKTZia8Zvdiaiab0lzfx7G4xN7MsPgZ7k96efNrcIHg/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;color: rgb(136, 136, 136);font-style: italic;\">域外数据集上 Vision-R1 方法相较于基线模型性能的提升</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">模型通用问答能力评测</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">研究团队进一步评估了模型在非定位等通用任务上的性能，以验证方法是否能在少量影响模型通用能力的情况下，大幅度提升模型的视觉定位能力。研究团队发现，Vision-R1 近乎不损失模型的通用能力，在通用问答、图表问答等评测集上模型实现了与基准模型基本一致的性能。</span></span></p><p><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.2962962962962963\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480013\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vCvIaG3SPdER8CvEw5ibjvnpxGwf9pABOLzdRLnp64SeTUKgxYd1u00A/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;color: rgb(136, 136, 136);font-style: italic;\">通用问答数据集上 Vision-R1 方法与基线模型性能的比较</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">可视化分析</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">研究团队提供了在 Qwen2.5-VL-7B 模型上使用 Vision-R1 后在多个场景下的目标检测可视化结果。如结果所示，Vision-R1 训练后，模型能够更好召回所感兴趣的物体，并进一步提升定位的精度。</span></span></p><p><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-croporisrc=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vJ9DVoz1hlMAibMiatOBUWAbUo8PRIpFWgP3akTIiaRhNhHvAM54IguSqA/0?wx_fmt=png&amp;from=appmsg\" data-cropselx2=\"562\" data-cropsely2=\"208\" data-imgfileid=\"503480053\" data-ratio=\"0.3690828402366864\" data-s=\"300,640\" data-type=\"png\" data-w=\"2704\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vJ9DVoz1hlMAibMiatOBUWAbUo8PRIpFWgP3akTIiaRhNhHvAM54IguSqA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin-left: 8px;margin-right: 8px;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;color: rgb(136, 136, 136);font-style: italic;\">Vision-R1 训练模型与基准模型检测结果可视化</span></span></p><section><span leaf=\"\"><br></span></section><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" data-style=\"margin-top: 5px; outline: 0px; max-width: 100%; color: rgb(34, 34, 34); font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif letter-spacing: white-space: normal caret-color: rgb background-color: text-align: center line-height: margin-bottom: box-sizing: border-box overflow-wrap: break-word class=\"js_darkmode__6\" style=\"-webkit-tap-highlight-color: transparent;margin-top: 5px;margin-bottom: 0px;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);letter-spacing: 0.544px;text-wrap: wrap;font-family: -apple-system, BlinkMacSystemFont, \"><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif><span leaf=\"\">© THE END </span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" data-style=\"margin-top: 5px; outline: 0px; max-width: 100%; color: rgb(34, 34, 34); font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif letter-spacing: white-space: normal caret-color: rgb background-color: text-align: center line-height: margin-bottom: box-sizing: border-box overflow-wrap: break-word class=\"js_darkmode__7\" style=\"-webkit-tap-highlight-color: transparent;margin-top: 5px;margin-bottom: 0px;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);letter-spacing: 0.544px;text-wrap: wrap;font-family: -apple-system, BlinkMacSystemFont, \"><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;\"><span leaf=\"\">转载请联系本公众号获得授权</span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" data-style=\"margin-top: 5px; outline: 0px; max-width: 100%; color: rgb(34, 34, 34); font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif letter-spacing: white-space: normal caret-color: rgb background-color: text-align: center line-height: margin-bottom: box-sizing: border-box overflow-wrap: break-word class=\"js_darkmode__8\" style=\"-webkit-tap-highlight-color: transparent;margin-top: 5px;margin-bottom: 0px;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);letter-spacing: 0.544px;text-wrap: wrap;font-family: -apple-system, BlinkMacSystemFont, \"><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;\"><span leaf=\"\">投稿或寻求报道：liyazhou@jiqizhixin.com</span></span></p><p style=\"display: none;\"><mp-style-type data-value=\"10000\"></mp-style-type></p></div>\n    \n\n    \n    <br>\n\n    \n        <a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963731&amp;idx=3&amp;sn=7c62398a729785a7d02da7b9d47fab3a&amp;chksm=8525221905860a7ee31228d160e4f9c43b94d60c8acde57393a69b9a129332cc7c29446bba77&amp;scene=0#rd\" style=\"color: blue\" class=\"media_tool_meta meta_primary\">文章原文</a>\n        <br>\n    \n\n    \n\n    <img alt=\"\" width=\"1px\" height=\"1px\" class=\"\" style=\"width:1px;height:1px;display:none\" src=\"http://www.jintiankansha.me/rss_static/4365/n89LPmpAv7\">\n\n",
          "contentSnippet": "图文大模型通常采用「预训练 + 监督微调」的两阶段范式进行训练，以强化其指令跟随能力。受语言领域的启发，多模态偏好优化技术凭借其在数据效率和性能增益方面的优势，被广泛用于对齐人类偏好。目前，该技术主要依赖高质量的偏好数据标注和精准的奖励模型训练来提升模型表现。然而，这一方法不仅资源消耗巨大，训练过程仍然极具挑战。\n\n\n受到基于规则的强化学习（Rule-Based Reinforcement Learning）在 R1 上成功应用的启发，中科院自动化研究所与中科紫东太初团队探索了如何结合高质量指令对齐数据与类 R1 的强化学习方法，进一步增强图文大模型的视觉定位能力。该方法首次在 Object Detection、Visual Grounding 等复杂视觉任务上，使 Qwen2.5-VL 模型实现了最高 50% 的性能提升，超越了参数规模超过 10 倍的 SOTA 模型。\n\n\n目前，相关工作论文、模型及数据集代码均已开源。\n\n\n\n\n\n\n论文标题：Vision-R1: Evolving Human-Free Alignment in Large Vision-Language Models via Vision-Guided Reinforcement Learning\n\n论文地址：https://arxiv.org/pdf/2503.18013\n\nGithub 仓库：https://github.com/jefferyZhan/Griffon/tree/master/Vision-R1\n\nHuggingface 仓库：https://huggingface.co/collections/JefferyZhan/vision-r1-67e166f8b6a9ec3f6a664262\n\n\n\n引言\n\n\n目标定位任务要求模型能够精准识别用户输入的任意感兴趣目标，并给出精确的目标框，对图文大模型的细粒度感知和空间理解能力提出了严峻挑战。当前，图文大模型通常将目标定位建模为文本序列预测任务，并通过大规模预训练和指令数据的监督微调，以 Next Token Prediction 实现对不同粒度目标描述的精准定位。尽管在指代表达理解等任务上已超越传统视觉专家模型，但在更复杂、目标密集的场景中，其视觉定位与目标检测能力仍与专家模型存在显著差距。\n\n\nR1 的成功应用推动了对基于规则的任务级别奖励监督的探索，使模型摆脱了对人工偏好数据标注和奖励模型训练的依赖。值得注意的是，视觉定位指令数据本身具有精准的空间位置标注，并与与人类对精准目标定位偏好高度一致。基于这些优势，Vision-R1 通过设计类 R1 的强化学习后训练框架，在任务级别监督中引入基于视觉任务评价指标的反馈奖励信号，为增强图文大模型的细粒度视觉定位能力提供了创新突破方向。\n\n\n\nVision-R1 关键设计示意图\n\n\nVision Criteria-Driven Reward Function\n聚焦图文大模型目标定位问题\n\n\n在文本序列的统一建模和大规模数据的自回归训练下，图文大模型在目标定位任务上取得了显著的性能提升。然而，其进一步发展仍受到三大关键问题的限制：（1）密集场景中的长序列预测易出现格式错误，（2）有效预测目标的召回率较低，（3）目标定位精度不足。 \n\n\n这些问题制约了模型在更复杂视觉任务上的表现。在自回归 Token 级别的监督机制下，模型无法获得实例级别的反馈，而直接在单目标场景下应用 GRPO 训练方法又忽视了视觉定位任务的特性及 Completion 级别监督的优势。\n\n\n为此，研究团队结合图文大模型在视觉定位任务中面临的挑战，提出了一种基于视觉任务评价准则驱动的奖励函数，其设计包括以下四个核心部分：\n\n\n\n框优先的预测匹配：与仅针对单个目标进行设计的方法不同，Vision-R1 采用多目标预测的统一建模方式。为了计算包含多个目标预测的奖励，Vision-R1 首先对文本序列化的预测结果进行反序列化，提取出每个目标的预测框及其标签，并将预测结果与真实标注进行匹配，以确保奖励机制能够全面衡量多目标场景下的定位质量。\n\n双重格式奖励：该奖励项旨在解决密集场景下长序列预测的格式错误问题。对于每个预测文本序列，模型需满足指定的模板格式（如 Qwen2.5-VL 采用的 JSON 格式），并确保目标坐标的数值正确性。仅当预测结果同时满足格式和内容要求时，模型才能获得奖励 1，从而引导其生成符合标准的预测输出。\n\n召回奖励：该奖励项针对有效预测目标召回率低的问题，鼓励模型尽可能多地识别目标。具体而言，针对每个预测目标及其匹配的真实目标（GT），当两者的 IoU 超过预设阈值 ζ 时，视为该预测有效。对于一个预测序列，其召回奖励定义为有效预测目标数量与实际需要预测目标数量的比例，以此激励模型提高目标的覆盖率。\n\n\n\n\n\n\n\n精度奖励：精度奖励与召回奖励协同作用，形成「1+1>2」的优化效果。其中，召回奖励提升模型对目标的全面识别能力，而精度奖励则确保预测的准确性。精度奖励从单实例角度衡量预测质量，其核心目标是鼓励模型生成高质量的边界框。具体地，精度奖励被定义为所有有效预测的平均 IoU 值，以直接激励模型优化目标框的精确度：\n\n\n\n\n\n\n\nVision-R1 整体框架\n\n\nProgressive Rule Refinement Strategy\n实现持续性能提升\n\n\n在目标定位任务中，预测高质量（高 IoU）的目标框始终是一个挑战，尤其是在密集场景和小目标情况下。这种困难可能导致模型在同组预测中奖励差异较小，从而影响优化效果。针对这一问题，研究团队提出了渐进式规则调整策略，该策略通过在训练过程中动态调整奖励计算规则，旨在实现模型的持续性能提升。该策略主要包括两个核心部分：\n\n\n差异化策略：该策略的目标是扩大预测结果与实际奖励之间的映射差异。具体而言，通过惩罚低召回率（Recall）和低平均 IoU 的预测，并对高召回率和高 IoU 的预测给予较高奖励，从而鼓励模型生成更高质量的预测，尤其是在当前能够达到的最佳预测上获得最大奖励。这一策略引导模型在训练过程中逐渐提高预测精度，同时避免低质量预测的奖励过高，促进其优化。具体实现如下：\n\n\n\n\n\n阶段渐近策略：类似于许多有效的学习方法，给初学者设定容易实现的目标并逐步提升奖励难度是一个常见且行之有效的策略。在 Vision-R1 中，训练过程被划分为初学阶段和进阶阶段，并通过逐步调整阈值 ζ 来实现奖励规则的逐渐变化。具体来说：\n\n\n\n初学阶段（Beginner Phase）： 在这一阶段，设置较低的 ζ 阈值（0.5/0.75），给予模型相对宽松的奖励标准，帮助其快速入门并学习基础的定位能力。\n\n进阶阶段（Advanced Phase）： 随着训练的深入，逐步提高 ζ 阈值，增加标准要求，以促使模型达到更高的准确度，避免模型依赖简单策略，从而持续推动模型性能的提升。\n\n\n\n不同模型的域内外目标检测评测\n\n\n为全面评估 Vision-R1 的效果，研究团队选择了近期定位能力大幅提升的 Qwen2.5-VL-7B 模型和定位能力突出的 Griffon-G-7B 模型，在更有挑战的经典目标检测数据集 COCO 和多样场景的 ODINW-13 上进行测试，以展现方法对不同定位水平模型的适用性。\n\n\n\n经典 COCO/ODINW 数据集上 Vision-R1 方法相较于基线模型性能的提升\n\n\n实验结果表明，无论基础性能如何，与基线模型相比这些模型在 Vision-R1 训练后性能大幅提升，甚至超过同系列 SOTA 模型，进一步接近了定位专家模型。\n\n\n研究团队还在模型没有训练的域外定位数据集上进行测试，Vision-R1 在不同模型的四个数据集上取得了平均 6% 的性能提升，充分论证了方法的泛化性。\n\n\n\n域外数据集上 Vision-R1 方法相较于基线模型性能的提升\n\n\n模型通用问答能力评测\n\n\n研究团队进一步评估了模型在非定位等通用任务上的性能，以验证方法是否能在少量影响模型通用能力的情况下，大幅度提升模型的视觉定位能力。研究团队发现，Vision-R1 近乎不损失模型的通用能力，在通用问答、图表问答等评测集上模型实现了与基准模型基本一致的性能。\n\n\n\n通用问答数据集上 Vision-R1 方法与基线模型性能的比较\n\n\n可视化分析\n\n\n研究团队提供了在 Qwen2.5-VL-7B 模型上使用 Vision-R1 后在多个场景下的目标检测可视化结果。如结果所示，Vision-R1 训练后，模型能够更好召回所感兴趣的物体，并进一步提升定位的精度。\n\n\n\nVision-R1 训练模型与基准模型检测结果可视化\n\n\n© THE END \n转载请联系本公众号获得授权\n投稿或寻求报道：liyazhou@jiqizhixin.com\n\n\n    \n\n    \n    \n文章原文",
          "guid": "http://www.jintiankansha.me/t/n89LPmpAv7",
          "categories": [
            "无"
          ],
          "isoDate": "2025-04-08T04:48:00.000Z"
        }
      },
      {
        "json": {
          "title": "斯坦福2025 AI Index报告来了：DeepSeek在全文中被提到45次",
          "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650963731&idx=2&sn=9843c5010e27941cd6a9cc09bb2ef96f&chksm=8559d5f21da721c9e2ddbeb61eb74999a52b0f50db55cf6ccca09e7df353af7a2e2dcd33e091&scene=0#rd",
          "pubDate": "Tue, 08 Apr 2025 12:48:00 +0800",
          "enclosure": {
            "url": "http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vMXg96e3psNcAzExF8TVafXN4cOS4TpvecJaNLvYB1kzSpJ4daq507w/0?wx_fmt=jpeg",
            "length": "0",
            "type": "image/jpeg"
          },
          "content": "\n\n    \n\n    \n\n    \n         <div class=\"rich_media_content\" id=\"js_content\"><section data-mpa-powered-by=\"yiban.io\" data-style=\"white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: \" helvetica neue sans gb yahei arial sans-serif box-sizing: border-box overflow-wrap: break-word mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" data-pm-slice=\"0 0 []\" class=\"js_darkmode__0\" style=\"-webkit-tap-highlight-color: transparent;margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;color: rgba(0, 0, 0, 0.9);font-size: 17px;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: 0.544px;orphans: 2;text-align: justify;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;white-space: normal;text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px;background-color: rgb(255, 255, 255);text-size-adjust: inherit;caret-color: rgb(34, 34, 34);font-family: \" visible><section mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" class=\"js_darkmode__1\" style=\"-webkit-tap-highlight-color: transparent;margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px;visibility: visible;line-height: 27.2px;\"><section mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" class=\"js_darkmode__2\" style=\"-webkit-tap-highlight-color: transparent;margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px;visibility: visible;line-height: 27.2px;\"><section data-id=\"85660\" data-custom=\"rgb(117, 117, 118)\" data-color=\"rgb(117, 117, 118)\" mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" class=\"js_darkmode__3\" style=\"-webkit-tap-highlight-color: transparent;margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 27.2px;\"><section data-style=\"margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;\" mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" class=\"js_darkmode__4\" style=\"-webkit-tap-highlight-color: transparent;margin: 2em 0px 0px;padding: 0.5em 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px;border-top: 1px solid rgb(204, 204, 204);border-bottom: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;line-height: 27.2px;\"><p mp-original-font-size=\"17\" mp-original-line-height=\"29.75\" class=\"js_darkmode__5\" style=\"-webkit-tap-highlight-color: transparent;margin: -1.2em 8px 0px;padding: 0px;outline: 0px;max-width: 100%;clear: both;min-height: 1em;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 29.75px;box-sizing: border-box !important;overflow-wrap: break-word !important;color: rgb(163, 163, 163) !important;\"><span mp-original-font-size=\"15\" mp-original-line-height=\"29.75\" style=\"-webkit-tap-highlight-color: transparent;margin-top: 0px;margin-bottom: 0px;padding: 0px;outline: 0px;max-width: 100%;color: rgb(255, 255, 255);font-family: inherit;font-size: 15px;letter-spacing: 0.544px;background-color: rgb(117, 117, 118);text-decoration: inherit;visibility: visible;line-height: 29.75px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span leaf=\"\" style=\"-webkit-tap-highlight-color: transparent;margin-top: 0px;margin-bottom: 0px;padding: 0px;outline: 0px;max-width: 100%;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\">机器之心报道</span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"29.75\" style=\"-webkit-tap-highlight-color: transparent;margin: 0px 8px;padding: 0px;outline: 0px;max-width: 100%;clear: both;min-height: 1em;text-align: center;visibility: visible;line-height: 29.75px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span leaf=\"\" style=\"-webkit-tap-highlight-color: transparent;margin-top: 0px;margin-bottom: 0px;padding: 0px;outline: 0px;max-width: 100%;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span textstyle=\"\" style=\"font-size: 12px;color: rgb(136, 136, 136);font-weight: bold;\">编辑：蛋酱、+0</span></span></p></section></section></section></section></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">刚刚，斯坦福大学正式发布了《2025 AI Index》报告。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">在过去的一段时间里，人工智能领域经历了一场蓬勃的发展，但与此同时，也有人说「人工智能是一个泡沫」。其他的讨论话题包括但不限于：人工智能的现有技术和架构将不断取得突破；人工智能走在一条不可持续的道路上；人工智能将取代你的工作；人工智能最擅长的就是把你的家庭照片变成吉卜力工作室风格的动画图像……</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">每一年的斯坦福 AI Index 报告都会对领域的发展进行系统的梳理，今年也是如此。《2025 AI Index》报告总共 400 多页，涵盖了研发、技术性能、负责任的人工智能、经济影响、科学和医学、政策、教育和公众舆论等主题的图表和数据。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"1.3009259259259258\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480032\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vO3HwySDfK9xNJna7fkjBs86J1sghxibGMtrTrmRnsgR5ib6AcWib0M8yQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: left;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);\">报告地址：https://hai.stanford.edu/ai-index/2025-ai-index-report</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">目录如下：</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"1.2055555555555555\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480033\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v652VgoueXibyrzianukib2r3PBA3XtCr7RY0EhjqCKaVd8AXVuU8owGGw/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">除了谷歌、OpenAI 之外，中国公司 DeepSeek 也成为报告关注的焦点，在 PDF 全文中被提到了 45 次。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">关于今年 AI Index 报告的核心内容，我们通过 12 张图片来了解：</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">美国公司的遥遥领先</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.9355555555555556\" data-s=\"300,640\" data-type=\"png\" data-w=\"900\" type=\"block\" data-imgfileid=\"503480034\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0voOjZickZWdKMv7wYmKQwgibeqmicRkpFmic0XiaXCniazj0zvPJgyBAOhBMw/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">虽然衡量国家在人工智能竞赛中「领先」的方式多种多样（如期刊文章发表或引用数量、专利授权等），但一个直观的评估指标是观察哪些国家发布了具有影响力的模型。研究机构 Epoch AI 拥有一个从 1950 年至今的重要人工智能模型数据库，AI Index 从中提取了相关数据进行分析。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">数据显示，去年美国发布了 40 个知名模型，中国发布了 15 个，欧洲仅有 3 个（均来自法国）。另有数据表明，2024 年发布的这些模型几乎全部来自产业界，而非学术界或政府部门。关于 2023 年至 2024 年知名模型发布数量减少的现象，AI Index 认为可能是由于技术复杂度提高和训练成本持续攀升所致。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">说到训练成本……</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5842592592592593\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480035\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vyleg1v6XYmAFBtQfsoibahkAhcISOwkE2ogM2VeMBCR88Tia5ZXw2r1g/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">在这方面，AI Index 缺乏精确数据，因为许多领先的人工智能公司已停止公开其训练过程信息。斯坦福研究人员与 Epoch AI 合作，基于训练时长、硬件类型和数量等详细信息，估算了部分模型的成本。在可评估的模型中，最昂贵的是谷歌的 Gemini 1.0 Ultra，训练成本约达 1.92 亿美元。训练成本的全面上涨与报告中的其他发现相符：模型在参数数量、训练时间和训练数据量等方面持续规模化扩张。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">值得注意的是，DeepSeek 并未包含在这一分析中。这家公司在 2025 年 1 月声称仅用 600 万美元训练出了 DeepSeek-R1，引发金融市场震动，虽然部分行业专家对此说法持怀疑态度。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">AI Index 指导委员会联合主任 Yolanda Gil 在接受 IEEE Spectrum 采访时表示，她认为 DeepSeek「非常令人印象深刻」，并指出计算机科学历史上充满了早期低效技术被更优雅解决方案取代的案例。她补充道：「我不是唯一一个相信某个时点会出现更高效版本大语言模型的人。我们只是不知道谁会构建它以及如何构建。」</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">使用人工智能的成本正在下降</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5601851851851852\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480036\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vugYOHSCYguR6ZfYwPcQqqibZmoOIMcUkTrIB2DJ3Tg1prTyRkoAw91Q/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">尽管大多数 AI 模型的训练成本持续攀升，但报告中强调了几个积极趋势：硬件成本降低、硬件性能提升及能源效率提高。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">这使得推理成本（即查询已训练模型的费用）正在急剧下降。这张使用对数比例的图表展示了 AI 性能每美元的发展趋势。报告指出，蓝线表明每百万 tokens 的成本从 20 美元降至 0.07 美元；粉线则显示在不到一年时间内，成本从 15 美元降至 0.12 美元。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">人工智能的显著碳足迹</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5703703703703704\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480037\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vGOfD2FjJ9mFVCLUgdGfSN55eYVibNgBuAcaHk6dqpgweFic0gdvYSJEg/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">虽然能源效率提高是一个积极的趋势，但存在一个不容忽视的问题：尽管效率有所提升，整体能耗仍在增长，这意味着处于人工智能热潮中心的数据中心留下了巨大的碳足迹。AI Index 基于训练硬件、云服务提供商和地理位置等因素，估算了特定 AI 模型的碳排放，发现前沿人工智能模型的训练碳排放量呈稳步增长趋势 —— 其中 DeepSeek 模型是个例外。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">数据显示，最大的排放源是 Meta 的 Llama 3.1 模型，估计产生了 8930 吨二氧化碳排放，相当于约 496 个美国人一年的生活碳排放量。这一显著的环境影响解释了为何人工智能公司正积极采用核能作为可靠的零碳能源来源。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">人工智能模型性能差距持续缩小</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.575925925925926\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480038\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vMDib7Esrhia5vTPusl8xpVOcqK1BTR0cLbic0el334ycHicYtiaeutRQjAA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">美国在已发布的知名模型数量上仍然保持领先地位，但中国模型在质量方面正在迅速赶上。数据显示，在聊天机器人基准测试上的性能差距正在不断缩小。2024 年 1 月，顶尖美国模型的表现比最优中国模型高出 9.26%；到 2025 年 2 月，这一差距已缩小至仅 1.70%。报告在推理、数学和编程等其他基准测试中也发现了类似趋势。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">人类最后的考试</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5324074074074074\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480039\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vd5PZFOlexXtUqYqONHAJuOmMS1QnmBmjAJwGTSrlyNta154maHkESQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">今年的报告指出了一个不可忽视的事实：用于评估人工智能系统能力的众多基准测试已经「饱和」—— 人工智能系统在这些测试上获得的分数如此之高，以至于它们不再具有区分价值。这种现象已在多个领域出现：通用知识、图像推理、数学、编程等。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">Gil 表示，她惊讶地目睹一个又一个基准测试逐渐失去参考意义。她指出：「我一直认为性能会趋于平稳，会达到一个需要新技术或根本不同架构才能继续取得进展的临界点。但事实并非如此。」</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">面对这种局面，执着的研究人员不断设计新的基准测试，以期挑战人工智能系统。其中一项是「人类的最后考试」，它由来自全球 500 个机构的专业领域专家贡献的极具挑战性问题组成。到目前为止，即使对最顶尖的人工智能系统而言，这项测试仍然难以攻克：OpenAI 的推理模型 o1 目前以 8.8% 的正确答案率位居榜首。业界正密切关注这种局面能持续多久。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">公共数据面临的威胁</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5777777777777777\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480040\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v16BV9P3cbkGkWh2Nc9HkzFWIiaUatrhWLiaaFe7Mm132LPBv8vyOF7yA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">当今生成式 AI 系统通过训练海量从互联网抓取的数据获得智能，这导致了一个经常被提及的观点：「数据是 AI 经济的新石油」。随着人工智能公司不断挑战可输入模型的数据量极限，业界开始担忧「数据峰值」问题，以及何时会耗尽这种关键资源。一个问题是，越来越多的网站正在限制机器人爬取并抓取其数据（可能是因为担忧人工智能公司从其数据中获利，同时破坏其商业模式）。网站通过机器可读的 robots.txt 文件声明这些限制。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">数据显示，顶级网络域名中 48% 的数据现已被完全限制访问。然而，Gil 指出，人工智能领域可能会出现新方法，终结对庞大数据集的依赖。她认为：「预计在某些时候，数据量将不再如此关键。」</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">企业资金持续涌入人工智能领域</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5425925925925926\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480041\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vbPWSFtEFAybYRkAhRly9wrXLmAhst8rIhKxxXzPibtv4TkLOFBWibs5Q/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">过去五年，企业界已为人工智能投资敞开了资金闸门。虽然 2024 年的全球总体投资未能达到 2021 年的疯狂高峰，但值得注意的是，私人投资规模达到了前所未有的水平。在 2024 年 1500 亿美元的私人投资中，相关指数的另一项数据表明，约 330 亿美元流向了生成式 AI 领域。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">企业等待人工智能投资的巨大回报</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5416666666666666\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480042\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vDSe1ZI3znuCmibibCC3kuUnasMRLG9onc4aIwls7k1ibiaXNSmrDlAwesg/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">理论上，企业投资人工智能是因为期望获得可观的投资回报。在这个话题上，人们常以激昂语气讨论人工智能的变革性本质和前所未有的生产力提升。然而，企业尚未见到能带来显著成本节省或实质性新收益的转变。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">麦肯锡调查数据显示，在报告成本降低的企业中，大多数节省幅度不足 10%；在因人工智能获得收入增长的企业中，大多数报告的增长幅度不到 5%。巨大的回报可能仍在路上，从投资数据来看，众多企业正在押注于此，但目前尚未实现。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">AI 医生或将很快接诊</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-imgfileid=\"503480043\" data-ratio=\"1.0322222222222222\" data-s=\"300,640\" data-type=\"png\" data-w=\"900\" type=\"block\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vENogKWLf0u7UW75OKDvK1CLLyNRPUO7lrcHeAF7yKhRGYgoMibYibLFg/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">科学与医疗领域的人工智能应用是人工智能浪潮中的一个重要分支。报告列举了多个新发布的基础模型，这些模型旨在协助材料科学、天气预报和量子计算等领域的研究人员。众多公司正尝试将人工智能的预测和生成能力转化为盈利性药物研发。OpenAI 的 o1 推理模型最近在医学执照考试问题集 MedQA 的基准测试中取得了 96% 的得分。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">然而，这似乎仍是一个潜力巨大但尚未转化为显著实际影响的领域 —— 部分原因可能是人类尚未完全掌握如何有效使用这项技术。2024 年的一项研究测试了医生在使用 GPT-4 作为常规资源补充时是否能做出更准确的诊断。结果表明，这既未提高诊断准确性，也未加快诊断速度。值得注意的是，单独使用的 GPT-4 表现却优于人机团队和单独的人类医生。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">美国的人工智能政策行动转向州级层面</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-imgfileid=\"503480044\" data-ratio=\"0.5425925925925926\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vbRJkKD3BJL1W2OtKVNmEiaFfibSTeJP0OGhWGp3ryyicesPJslCv91vLQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">这张图表显示，美国国会虽有大量关于人工智能的讨论，但实际行动寥寥无几。报告指出，美国的政策制定已转移至州级层面，2024 年共有 131 项法案在各州获得通过。其中 56 项与深度伪造（deepfake）相关，禁止在选举中使用深度伪造技术或借此传播未经同意的私密图像。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">美国之外，欧洲已通过《人工智能法案》（AI Act），该法案要求开发被认定为高风险的人工智能系统的公司承担新的责任义务。然而，全球主要趋势是各国联合发表关于人工智能应在世界上扮演何种角色的全面但无约束力的声明。因此，实质性监管行动相对有限，而讨论却十分广泛。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">人类是乐观主义者</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5277777777777778\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480045\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vmdTB8Tlfa8bGJWaOeibG1ugAXORH1zyj5o4e1iaZIOlPgpT8T7EELt5w/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">无论你是股票摄影师、营销经理还是卡车司机，关于人工智能是否以及何时会取代你的工作，社会上已有广泛讨论。然而，最近一项关于人工智能态度的全球调查显示，大多数人并不感到受到人工智能的威胁。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">来自 32 个国家的 60% 受访者认为人工智能将改变他们的工作方式，但仅有 36% 的人预期会被替代。「这些调查结果确实让我感到惊讶，」Gil 表示，「人们认为『人工智能将改变我的工作，但我仍将创造价值』，这种观点非常令人鼓舞。」让我们拭目以待，看看我们能否都通过管理人工智能团队来持续创造价值。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">更多细节，可参考报告原文。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: center;margin-bottom: 0px;margin-left: 8px;margin-right: 8px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.8518518518518519\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" data-imgfileid=\"503478358\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibD4lCB7aJY0WoFGLCNz0tCh7FbEdJhtvUB5Y0TKawRI38FibjTdXdibM3bsf05HHvbN99GwB8GhOEQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></span></p><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;margin: 5px 8px 0px;outline: 0px;letter-spacing: 0.544px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb inherit center><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif><span leaf=\"\">© THE END </span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;margin: 5px 8px 0px;outline: 0px;letter-spacing: 0.544px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb inherit center><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;\"><span leaf=\"\">转载请联系本公众号获得授权</span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;margin: 5px 8px 0px;outline: 0px;letter-spacing: 0.544px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb inherit center><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;\"><span leaf=\"\">投稿或寻求报道：liyazhou@jiqizhixin.com</span></span></p><p style=\"display: none;\"><mp-style-type data-value=\"3\"></mp-style-type></p></div>\n    \n\n    \n    <br>\n\n    \n        <a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963731&amp;idx=2&amp;sn=9843c5010e27941cd6a9cc09bb2ef96f&amp;chksm=8559d5f21da721c9e2ddbeb61eb74999a52b0f50db55cf6ccca09e7df353af7a2e2dcd33e091&amp;scene=0#rd\" style=\"color: blue\" class=\"media_tool_meta meta_primary\">文章原文</a>\n        <br>\n    \n\n    \n\n    <img alt=\"\" width=\"1px\" height=\"1px\" class=\"\" style=\"width:1px;height:1px;display:none\" src=\"http://www.jintiankansha.me/rss_static/4365/GaNPqOtUez\">\n\n",
          "contentSnippet": "机器之心报道\n编辑：蛋酱、+0\n\n\n\n\n\n刚刚，斯坦福大学正式发布了《2025 AI Index》报告。\n\n\n在过去的一段时间里，人工智能领域经历了一场蓬勃的发展，但与此同时，也有人说「人工智能是一个泡沫」。其他的讨论话题包括但不限于：人工智能的现有技术和架构将不断取得突破；人工智能走在一条不可持续的道路上；人工智能将取代你的工作；人工智能最擅长的就是把你的家庭照片变成吉卜力工作室风格的动画图像……\n\n\n每一年的斯坦福 AI Index 报告都会对领域的发展进行系统的梳理，今年也是如此。《2025 AI Index》报告总共 400 多页，涵盖了研发、技术性能、负责任的人工智能、经济影响、科学和医学、政策、教育和公众舆论等主题的图表和数据。\n\n\n\n报告地址：https://hai.stanford.edu/ai-index/2025-ai-index-report\n\n\n目录如下：\n\n\n\n除了谷歌、OpenAI 之外，中国公司 DeepSeek 也成为报告关注的焦点，在 PDF 全文中被提到了 45 次。\n\n\n关于今年 AI Index 报告的核心内容，我们通过 12 张图片来了解：\n\n\n美国公司的遥遥领先\n\n\n\n虽然衡量国家在人工智能竞赛中「领先」的方式多种多样（如期刊文章发表或引用数量、专利授权等），但一个直观的评估指标是观察哪些国家发布了具有影响力的模型。研究机构 Epoch AI 拥有一个从 1950 年至今的重要人工智能模型数据库，AI Index 从中提取了相关数据进行分析。\n\n\n数据显示，去年美国发布了 40 个知名模型，中国发布了 15 个，欧洲仅有 3 个（均来自法国）。另有数据表明，2024 年发布的这些模型几乎全部来自产业界，而非学术界或政府部门。关于 2023 年至 2024 年知名模型发布数量减少的现象，AI Index 认为可能是由于技术复杂度提高和训练成本持续攀升所致。\n\n\n说到训练成本……\n\n\n\n在这方面，AI Index 缺乏精确数据，因为许多领先的人工智能公司已停止公开其训练过程信息。斯坦福研究人员与 Epoch AI 合作，基于训练时长、硬件类型和数量等详细信息，估算了部分模型的成本。在可评估的模型中，最昂贵的是谷歌的 Gemini 1.0 Ultra，训练成本约达 1.92 亿美元。训练成本的全面上涨与报告中的其他发现相符：模型在参数数量、训练时间和训练数据量等方面持续规模化扩张。\n\n\n值得注意的是，DeepSeek 并未包含在这一分析中。这家公司在 2025 年 1 月声称仅用 600 万美元训练出了 DeepSeek-R1，引发金融市场震动，虽然部分行业专家对此说法持怀疑态度。\n\n\nAI Index 指导委员会联合主任 Yolanda Gil 在接受 IEEE Spectrum 采访时表示，她认为 DeepSeek「非常令人印象深刻」，并指出计算机科学历史上充满了早期低效技术被更优雅解决方案取代的案例。她补充道：「我不是唯一一个相信某个时点会出现更高效版本大语言模型的人。我们只是不知道谁会构建它以及如何构建。」\n\n\n使用人工智能的成本正在下降\n\n\n\n尽管大多数 AI 模型的训练成本持续攀升，但报告中强调了几个积极趋势：硬件成本降低、硬件性能提升及能源效率提高。\n\n\n这使得推理成本（即查询已训练模型的费用）正在急剧下降。这张使用对数比例的图表展示了 AI 性能每美元的发展趋势。报告指出，蓝线表明每百万 tokens 的成本从 20 美元降至 0.07 美元；粉线则显示在不到一年时间内，成本从 15 美元降至 0.12 美元。\n\n\n人工智能的显著碳足迹\n\n\n\n虽然能源效率提高是一个积极的趋势，但存在一个不容忽视的问题：尽管效率有所提升，整体能耗仍在增长，这意味着处于人工智能热潮中心的数据中心留下了巨大的碳足迹。AI Index 基于训练硬件、云服务提供商和地理位置等因素，估算了特定 AI 模型的碳排放，发现前沿人工智能模型的训练碳排放量呈稳步增长趋势 —— 其中 DeepSeek 模型是个例外。\n\n\n数据显示，最大的排放源是 Meta 的 Llama 3.1 模型，估计产生了 8930 吨二氧化碳排放，相当于约 496 个美国人一年的生活碳排放量。这一显著的环境影响解释了为何人工智能公司正积极采用核能作为可靠的零碳能源来源。\n\n\n人工智能模型性能差距持续缩小\n\n\n\n美国在已发布的知名模型数量上仍然保持领先地位，但中国模型在质量方面正在迅速赶上。数据显示，在聊天机器人基准测试上的性能差距正在不断缩小。2024 年 1 月，顶尖美国模型的表现比最优中国模型高出 9.26%；到 2025 年 2 月，这一差距已缩小至仅 1.70%。报告在推理、数学和编程等其他基准测试中也发现了类似趋势。\n\n\n人类最后的考试\n\n\n\n今年的报告指出了一个不可忽视的事实：用于评估人工智能系统能力的众多基准测试已经「饱和」—— 人工智能系统在这些测试上获得的分数如此之高，以至于它们不再具有区分价值。这种现象已在多个领域出现：通用知识、图像推理、数学、编程等。\n\n\nGil 表示，她惊讶地目睹一个又一个基准测试逐渐失去参考意义。她指出：「我一直认为性能会趋于平稳，会达到一个需要新技术或根本不同架构才能继续取得进展的临界点。但事实并非如此。」\n\n\n面对这种局面，执着的研究人员不断设计新的基准测试，以期挑战人工智能系统。其中一项是「人类的最后考试」，它由来自全球 500 个机构的专业领域专家贡献的极具挑战性问题组成。到目前为止，即使对最顶尖的人工智能系统而言，这项测试仍然难以攻克：OpenAI 的推理模型 o1 目前以 8.8% 的正确答案率位居榜首。业界正密切关注这种局面能持续多久。\n\n\n公共数据面临的威胁\n\n\n\n当今生成式 AI 系统通过训练海量从互联网抓取的数据获得智能，这导致了一个经常被提及的观点：「数据是 AI 经济的新石油」。随着人工智能公司不断挑战可输入模型的数据量极限，业界开始担忧「数据峰值」问题，以及何时会耗尽这种关键资源。一个问题是，越来越多的网站正在限制机器人爬取并抓取其数据（可能是因为担忧人工智能公司从其数据中获利，同时破坏其商业模式）。网站通过机器可读的 robots.txt 文件声明这些限制。\n\n\n数据显示，顶级网络域名中 48% 的数据现已被完全限制访问。然而，Gil 指出，人工智能领域可能会出现新方法，终结对庞大数据集的依赖。她认为：「预计在某些时候，数据量将不再如此关键。」\n\n\n企业资金持续涌入人工智能领域\n\n\n\n过去五年，企业界已为人工智能投资敞开了资金闸门。虽然 2024 年的全球总体投资未能达到 2021 年的疯狂高峰，但值得注意的是，私人投资规模达到了前所未有的水平。在 2024 年 1500 亿美元的私人投资中，相关指数的另一项数据表明，约 330 亿美元流向了生成式 AI 领域。\n\n\n企业等待人工智能投资的巨大回报\n\n\n\n理论上，企业投资人工智能是因为期望获得可观的投资回报。在这个话题上，人们常以激昂语气讨论人工智能的变革性本质和前所未有的生产力提升。然而，企业尚未见到能带来显著成本节省或实质性新收益的转变。\n\n\n麦肯锡调查数据显示，在报告成本降低的企业中，大多数节省幅度不足 10%；在因人工智能获得收入增长的企业中，大多数报告的增长幅度不到 5%。巨大的回报可能仍在路上，从投资数据来看，众多企业正在押注于此，但目前尚未实现。\n\n\nAI 医生或将很快接诊\n\n\n\n科学与医疗领域的人工智能应用是人工智能浪潮中的一个重要分支。报告列举了多个新发布的基础模型，这些模型旨在协助材料科学、天气预报和量子计算等领域的研究人员。众多公司正尝试将人工智能的预测和生成能力转化为盈利性药物研发。OpenAI 的 o1 推理模型最近在医学执照考试问题集 MedQA 的基准测试中取得了 96% 的得分。\n\n\n然而，这似乎仍是一个潜力巨大但尚未转化为显著实际影响的领域 —— 部分原因可能是人类尚未完全掌握如何有效使用这项技术。2024 年的一项研究测试了医生在使用 GPT-4 作为常规资源补充时是否能做出更准确的诊断。结果表明，这既未提高诊断准确性，也未加快诊断速度。值得注意的是，单独使用的 GPT-4 表现却优于人机团队和单独的人类医生。\n\n\n美国的人工智能政策行动转向州级层面\n\n\n\n这张图表显示，美国国会虽有大量关于人工智能的讨论，但实际行动寥寥无几。报告指出，美国的政策制定已转移至州级层面，2024 年共有 131 项法案在各州获得通过。其中 56 项与深度伪造（deepfake）相关，禁止在选举中使用深度伪造技术或借此传播未经同意的私密图像。\n\n\n美国之外，欧洲已通过《人工智能法案》（AI Act），该法案要求开发被认定为高风险的人工智能系统的公司承担新的责任义务。然而，全球主要趋势是各国联合发表关于人工智能应在世界上扮演何种角色的全面但无约束力的声明。因此，实质性监管行动相对有限，而讨论却十分广泛。\n\n\n人类是乐观主义者\n\n\n\n无论你是股票摄影师、营销经理还是卡车司机，关于人工智能是否以及何时会取代你的工作，社会上已有广泛讨论。然而，最近一项关于人工智能态度的全球调查显示，大多数人并不感到受到人工智能的威胁。\n\n\n来自 32 个国家的 60% 受访者认为人工智能将改变他们的工作方式，但仅有 36% 的人预期会被替代。「这些调查结果确实让我感到惊讶，」Gil 表示，「人们认为『人工智能将改变我的工作，但我仍将创造价值』，这种观点非常令人鼓舞。」让我们拭目以待，看看我们能否都通过管理人工智能团队来持续创造价值。\n\n\n更多细节，可参考报告原文。\n\n\n\n\n\n© THE END \n转载请联系本公众号获得授权\n投稿或寻求报道：liyazhou@jiqizhixin.com\n\n\n    \n\n    \n    \n文章原文",
          "guid": "http://www.jintiankansha.me/t/GaNPqOtUez",
          "categories": [
            "无"
          ],
          "isoDate": "2025-04-08T04:48:00.000Z"
        }
      }
    ],
    "量子位1": [
      {
        "json": {
          "title": "量子位招聘 | DeepSeek帮我们改的招聘启事",
          "link": "http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247786774&idx=5&sn=36f077cc98d61090998d72b0ea1bdda8&chksm=e9da3dc0ebbcfc12f4e2799833aa00422c695bb2ba0e6ad04f88798eaab9e736f25776507707&scene=0#rd",
          "pubDate": "Tue, 08 Apr 2025 12:46:00 +0800",
          "enclosure": {
            "url": "http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDL6GWnDiaqKPbMY8bbt5yl4y2Y9BGicxicJgjpzdzibBRrWuYPPpGySiaNMucsQWBtSzLqCIgfagRniaoQ/0?wx_fmt=jpeg",
            "length": "0",
            "type": "image/jpeg"
          },
          "content": "\n\n    \n\n    \n\n    \n         <div class=\"rich_media_content\" id=\"js_content\"><h5 style=\"font-family: ExtraLight-0;background-color: rgb(248, 248, 248);border-radius: 3px;margin-top: 10px;margin-bottom: 30px;padding: 10px;color: rgb(51, 51, 51);font-size: 14px;text-align: left;line-height: 2;word-break: break-all !important;letter-spacing: 1px !important;word-spacing: 1px !important;\"><span leaf=\"\">DeepSeek 发自 凹非寺</span><span leaf=\"\"><br></span><span leaf=\"\">量子位 | 公众号 QbitAI</span></h5><p style=\"font-size: 16px;white-space: normal;color: rgb(34, 34, 34);font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">未来同事，你好~</span></p><p style=\"font-size: 16px;white-space: normal;color: rgb(34, 34, 34);font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">这是一则</span><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">招聘帖</span></strong><span leaf=\"\">。</span></p><p style=\"font-size: 16px;white-space: normal;color: rgb(34, 34, 34);font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">量子位</span></strong><span leaf=\"\">是一个关注AI及前沿科技的新媒体平台，我们着迷于全新技术和趋势带来的改变，并正致力于帮助更多人第一时间看懂新趋势、新机遇。</span></p><p style=\"font-size: 16px;white-space: normal;color: rgb(34, 34, 34);font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">如果你与我们志同道合，对</span><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">AI大模型、具身智能、终端硬件、AI新媒体编辑</span></strong><span leaf=\"\">感兴趣，我们正在招聘这些领域的原创作者。</span></p><p style=\"font-size: 16px;white-space: normal;color: rgb(34, 34, 34);font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">以下岗位均为全职，工作地点：北京中关村。</span></strong></p><p style=\"font-size: 16px;white-space: normal;color: rgb(34, 34, 34);font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">岗位面向：社招、应届毕业生，所有岗位均可实习——表现出色均可转正</span></strong></p><p style=\"font-size: 16px;white-space: normal;color: rgb(34, 34, 34);font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">加分项：</span></strong></p><ul style=\"font-size: 16px;text-align: start;white-space: normal;color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;padding-left: 30px;list-style-type: square;letter-spacing: 1px !important;word-spacing: 1px !important;min-height: 1em !important;\" class=\"list-paddingleft-1\"><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">乐于探索AI新工具，善用AI新工具；</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">拥有解读论文的能力，能深入浅出讲解原理；</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">有写代码能力；</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">量子位长期读者。</span></p></li></ul><p style=\"font-size: 16px;white-space: normal;color: rgb(34, 34, 34);font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">加入我们，你可以获得：</span></strong></p><ul style=\"font-size: 16px;text-align: start;white-space: normal;color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;padding-left: 30px;list-style-type: square;letter-spacing: 1px !important;word-spacing: 1px !important;min-height: 1em !important;\" class=\"list-paddingleft-1\"><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">站在AI浪潮之巅</span></strong><span leaf=\"\">：第一时间接触和了解AI领域最新技术和产品，构建完整的AI认知体系。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">玩转AI新工具</span></strong><span leaf=\"\">：将各种AI新技术、新工具应用于工作，提升工作效率和创造力。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">打造个人影响力</span></strong><span leaf=\"\">：通过撰写独家原创内容，建立个人知名度，成为AI领域的意见领袖。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">拓展行业人脉</span></strong><span leaf=\"\">：与AI领域大咖零距离接触，参与重要科技活动和发布会，拓展行业视野。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">获得专业指导</span></strong><span leaf=\"\">：会由主编级编辑出任mentor，提供一对一指导，帮你更快进步获得成长。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">加入活力团队</span></strong><span leaf=\"\">：与一群志同道合的年轻人一起工作，享受扁平、简单、开放、充满活力的团队氛围。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">获得丰厚回报</span></strong><span leaf=\"\">：具有竞争力的薪资待遇（8K-20K），五险一金、餐补、项目绩效、商务绩效、加班补助等福利一应俱全。</span></p></li></ul><p style=\"font-size: 16px;white-space: normal;color: rgb(34, 34, 34);font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">在招岗位包括：</span></strong></p><ul style=\"font-size: 16px;text-align: start;white-space: normal;color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;padding-left: 30px;list-style-type: square;letter-spacing: 1px !important;word-spacing: 1px !important;min-height: 1em !important;\" class=\"list-paddingleft-1\"><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">AI大模型方向编辑作者</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">具身智能机器人方向编辑作者</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">终端硬件方向编辑作者</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">AI新媒体编辑（微博/小红书方向）</span></p></li></ul><h2 style=\"white-space: normal;color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;text-align: left;margin-top: 40px;margin-bottom: 40px;line-height: 1.5;font-weight: bold;padding-left: 15px;word-break: break-all !important;border-left-width: 6px !important;border-left-style: solid !important;border-left-color: rgb(0, 153, 127) !important;font-size: 20px !important;letter-spacing: 1px !important;word-spacing: 1px !important;\"><span leaf=\"\">AI大模型方向编辑作者</span></h2><p style=\"font-size: 16px;white-space: normal;color: rgb(34, 34, 34);font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">你需要做什么？</span></strong></p><ul style=\"font-size: 16px;text-align: start;white-space: normal;color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;padding-left: 30px;list-style-type: square;letter-spacing: 1px !important;word-spacing: 1px !important;min-height: 1em !important;\" class=\"list-paddingleft-1\"><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">紧跟AI浪潮</span></strong><span leaf=\"\">：密切关注AI、大模型领域的最新动态和进展，保持对行业趋势的敏锐洞察。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">挖掘优质选题</span></strong><span leaf=\"\">：深入挖掘AI大模型领域的优质选题，策划并撰写深度文章、行业分析等内容。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">十级冲浪选手</span></strong><span leaf=\"\">：活跃于各大网络平台，收集整理行业资讯，捕捉热点话题。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">参与内容运营</span></strong><span leaf=\"\">：学习并参与量子位内容的全平台运营，提升内容传播力和影响力。</span></p></li></ul><p style=\"font-size: 16px;white-space: normal;color: rgb(34, 34, 34);font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">我们希望你是：</span></strong></p><ul style=\"font-size: 16px;text-align: start;white-space: normal;color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;padding-left: 30px;list-style-type: square;letter-spacing: 1px !important;word-spacing: 1px !important;min-height: 1em !important;\" class=\"list-paddingleft-1\"><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">AI狂热爱好者</span></strong><span leaf=\"\">：对AI大模型、前沿科技充满热情，痴迷于探索科技新进展。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">文字表达高手</span></strong><span leaf=\"\">：具备扎实的文字功底，能够用流畅、清晰的语言表达复杂的概念。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">信息搜集达人</span></strong><span leaf=\"\">：能够熟练阅读和翻译外文资料，喜欢挖掘论文在内的源头信息，获取第一手行业资讯。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">学历背景不限</span></strong><span leaf=\"\">：全日制本科以上学历，专业不限，欢迎所有对AI充满热情的伙伴加入。</span></p></li></ul><h2 style=\"white-space: normal;color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;text-align: left;margin-top: 40px;margin-bottom: 40px;line-height: 1.5;font-weight: bold;padding-left: 15px;word-break: break-all !important;border-left-width: 6px !important;border-left-style: solid !important;border-left-color: rgb(0, 153, 127) !important;font-size: 20px !important;letter-spacing: 1px !important;word-spacing: 1px !important;\"><span leaf=\"\">具身智能机器人方向编辑作者</span></h2><p style=\"font-size: 16px;white-space: normal;color: rgb(34, 34, 34);font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">你需要做什么？</span></strong></p><ul style=\"font-size: 16px;text-align: start;white-space: normal;color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;padding-left: 30px;list-style-type: square;letter-spacing: 1px !important;word-spacing: 1px !important;min-height: 1em !important;\" class=\"list-paddingleft-1\"><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">追踪行业前沿</span></strong><span leaf=\"\">：密切关注具身智能领域的最新动态、技术突破和行业趋势，保持对前沿科技的敏锐嗅觉。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">打造独家内容</span></strong><span leaf=\"\">：深入挖掘具身智能领域的独家选题，撰写原创深度文章、行业分析报告等内容。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">建立行业人脉</span></strong><span leaf=\"\">：与具身智能领域的专家学者、企业领袖建立良好联系，获取第一手行业资讯。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">构建行业认知</span></strong><span leaf=\"\">：深入研究具身智能领域，形成体系化的行业认知和洞察，输出有价值的观点。</span></p></li></ul><p style=\"font-size: 16px;white-space: normal;color: rgb(34, 34, 34);font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">我们希望你是：</span></strong></p><ul style=\"font-size: 16px;text-align: start;white-space: normal;color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;padding-left: 30px;list-style-type: square;letter-spacing: 1px !important;word-spacing: 1px !important;min-height: 1em !important;\" class=\"list-paddingleft-1\"><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">具身智能狂热粉</span></strong><span leaf=\"\">：对具身智能、机器人技术、前沿科技充满热情，痴迷于探索科技新进展。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">逻辑思维强者</span></strong><span leaf=\"\">：学习能力强，善于分析和解决问题，做事追求逻辑和条理。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">文笔流畅的写手</span></strong><span leaf=\"\">：具备自然流畅的文笔表达能力，能够将复杂的技术概念通俗易懂地呈现给读者。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">社交达人（加分项）</span></strong><span leaf=\"\">：性格偏E，喜欢与人交流，善于建立和维护人际关系。</span></p></li></ul><h2 style=\"white-space: normal;color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;text-align: left;margin-top: 40px;margin-bottom: 40px;line-height: 1.5;font-weight: bold;padding-left: 15px;word-break: break-all !important;border-left-width: 6px !important;border-left-style: solid !important;border-left-color: rgb(0, 153, 127) !important;font-size: 20px !important;letter-spacing: 1px !important;word-spacing: 1px !important;\"><span leaf=\"\">终端硬件方向编辑作者</span></h2><p style=\"font-size: 16px;white-space: normal;color: rgb(34, 34, 34);font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">你需要做什么？</span></strong></p><ul style=\"font-size: 16px;text-align: start;white-space: normal;color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;padding-left: 30px;list-style-type: square;letter-spacing: 1px !important;word-spacing: 1px !important;min-height: 1em !important;\" class=\"list-paddingleft-1\"><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">追踪硬件前沿</span></strong><span leaf=\"\">：密切关注AI终端硬件领域的最新进展，包括手机、PC、智能眼镜等产品的技术突破和产业变革。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">深度产品分析</span></strong><span leaf=\"\">：从技术原理到用户体验，深入分析终端硬件产品，撰写深度评测、产品对比等内容。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">参与内容运营</span></strong><span leaf=\"\">：学习并参与量子位内容的全平台运营，提升内容传播力和影响力。</span></p></li></ul><p style=\"font-size: 16px;white-space: normal;color: rgb(34, 34, 34);font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">我们希望你是：</span></strong></p><ul style=\"font-size: 16px;text-align: start;white-space: normal;color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;padding-left: 30px;list-style-type: square;letter-spacing: 1px !important;word-spacing: 1px !important;min-height: 1em !important;\" class=\"list-paddingleft-1\"><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">硬件发烧友</span></strong><span leaf=\"\">：热爱科技产品，对终端硬件充满热情，是“搞机”爱好者。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">技术洞察者</span></strong><span leaf=\"\">：能够从技术原理到产品体验，构建对终端硬件的认知体系，并输出有价值的观点。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">文笔流畅的写手</span></strong><span leaf=\"\">：具备自然流畅的文笔表达能力，能够将复杂的技术概念通俗易懂地呈现给读者。</span></p></li></ul><h2 style=\"white-space: normal;color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;text-align: left;margin-top: 40px;margin-bottom: 40px;line-height: 1.5;font-weight: bold;padding-left: 15px;word-break: break-all !important;border-left-width: 6px !important;border-left-style: solid !important;border-left-color: rgb(0, 153, 127) !important;font-size: 20px !important;letter-spacing: 1px !important;word-spacing: 1px !important;\"><span leaf=\"\">AI新媒体编辑（微博/小红书方向）</span></h2><p style=\"font-size: 16px;white-space: normal;color: rgb(34, 34, 34);font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">你需要做什么？</span></strong></p><ul style=\"font-size: 16px;text-align: start;white-space: normal;color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;padding-left: 30px;list-style-type: square;letter-spacing: 1px !important;word-spacing: 1px !important;min-height: 1em !important;\" class=\"list-paddingleft-1\"><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">负责微博、小红书平台的内容策划、撰写和发布，追踪全球AI新动态，用符合平台调性的语言风格进行表达。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">关注用户反馈，与读者互动交流，提升账号粘性和影响力。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">不断优化内容质量和传播效果，探索提升内容影响力的方法。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">关注AI领域热点，敏锐捕捉新技术、新进展，并策划相关内容，助力打造爆款。</span></p></li></ul><p style=\"font-size: 16px;white-space: normal;color: rgb(34, 34, 34);font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">我们希望你是：</span></strong></p><ul style=\"font-size: 16px;text-align: start;white-space: normal;color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;padding-left: 30px;list-style-type: square;letter-spacing: 1px !important;word-spacing: 1px !important;min-height: 1em !important;\" class=\"list-paddingleft-1\"><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">网感超棒的年轻人</span></strong><span leaf=\"\">：热爱社交平台，是微博、小红书的深度用户，熟悉平台玩法和用户喜好。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">文笔流畅的段子手</span></strong><span leaf=\"\">：能用通俗易懂、生动有趣的语言表达观点，拉近与读者的距离。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">嗅觉敏锐的新闻人</span></strong><span leaf=\"\">：对AI领域充满热情，能够快速捕捉行业热点，并具备一定的新闻敏感度。</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p style=\"font-family: Arial;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">目标明确的行动派</span></strong><span leaf=\"\">：以创造热搜为目标，具备较强的执行力和学习能力，能够不断优化工作方法。</span></p></li></ul><h1 class=\"js_darkmode__22\" style=\"-webkit-tap-highlight-color: transparent;margin-top: 40px;margin-bottom: 40px;padding-left: 15px;outline: 0px;font-weight: bold;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;text-align: left;line-height: 1.5;font-size: 20px !important;word-break: break-all !important;border-left: 6px solid rgb(0, 153, 127) !important;letter-spacing: 1px !important;word-spacing: 1px !important;\"><span leaf=\"\">应聘方式</span></h1><ol style=\"color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;text-align: start;background-color: rgb(255, 255, 255);padding-left: 30px;font-size: 16px;letter-spacing: 1px !important;word-spacing: 1px !important;min-height: 1em !important;\" class=\"list-paddingleft-1\"><li style=\"line-height: 28px;margin: 8px 16px;\"><p><span leaf=\"\">请将个人简历发送至zhaopin@qbitai.com，邮件主题请注明“</span><span style=\"color: rgb(0, 153, 127);\"><strong><span leaf=\"\">量子位XX方向应聘 - [你的姓名]</span></strong></span><span leaf=\"\">”；</span></p></li><li style=\"line-height: 28px;margin: 8px 16px;\"><p><span leaf=\"\">随简历附上你的科技行业代表作品，或者能展现个人写作水平和风格的作品。</span></p></li></ol><p style=\"-webkit-tap-highlight-color: transparent;margin-top: 40px;margin-bottom: 40px;padding-left: 15px;outline: 0px;font-weight: bold;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;text-align: left;line-height: 1.5;font-size: 20px !important;word-break: break-all !important;border-left: 6px solid rgb(0, 153, 127) !important;letter-spacing: 1px !important;word-spacing: 1px !important;\"><span leaf=\"\">关于量子位</span></p><p class=\"js_darkmode__6\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);font-size: 16px;font-family: Arial;text-align: left;margin: 20px 16px !important;min-height: 1.5em !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;\"><span leaf=\"\">截至2025年，通过及时追踪AI及前沿科技进展，量子位在微信公众号已经有超230万订阅用户，全网用户超700万，日均阅读量200万+。</span></p><p class=\"js_darkmode__7\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);font-size: 16px;font-family: Arial;text-align: left;margin: 20px 16px !important;min-height: 1.5em !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;\"><span class=\"js_darkmode__8\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;text-wrap-style: initial;\"><span leaf=\"\">在新榜和清博等第三方数据平台，量子位已是AI以及前沿科技行业TOP1</span><span class=\"js_darkmode__9\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;text-wrap-style: initial;\"><span leaf=\"\">新媒体。</span></span></span></p><section style=\"-webkit-tap-highlight-color: transparent;margin-right: 16px;margin-left: 16px;outline: 0px;color: rgba(255, 255, 255, 0.6);font-family: \" pingfang sc system-ui neue sans gb yahei ui arial sans-serif rgb center nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-imgfileid=\"100292065\" data-ratio=\"0.8977556109725686\" data-s=\"300,640\" data-type=\"png\" data-w=\"802\" style=\"-webkit-tap-highlight-color: transparent; outline: 0px; visibility: visible !important; width: 645px !important; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAuicfYC90wicp2aEgTicviaZgwAKZiaI5psEfM5ZibXIofiaWsu3Dc0J4ewANSzYiaGk3Z2WdicMuhQkfPt0w/640?wx_fmt=other&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1\"></section><p class=\"js_darkmode__10\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);font-size: 16px;font-family: Arial;text-align: left;margin: 20px 16px !important;min-height: 1.5em !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;\"><span leaf=\"\">每年各大主流媒体平台评选时，量子位都被认为是最具影响力的科技账号之一，包括但不限于：微信公众号12周年代表性帐号、腾讯科技年度影响力创作者、澎湃新闻最澎湃创作者、新浪财经年度科技账号、今日头条年度媒体创作者…</span></p><p class=\"js_darkmode__11\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);font-size: 16px;font-family: Arial;text-align: left;margin: 20px 16px !important;min-height: 1.5em !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;\"><span leaf=\"\">量子位也是行业顶级会议的战略合作者：中国计算机学会CNCC年度战略合作伙伴、WAIC世界人工智能大会战略合作伙伴、中国人工智能产业发展联盟媒体组成员……</span></p><p class=\"js_darkmode__12\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);font-size: 16px;font-family: Arial;text-align: left;margin: 20px 16px !important;min-height: 1.5em !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;\"><span leaf=\"\">我们还拥有5万+微信社群用户，他们都是信仰技术、追求新知，渴望每天最先获悉全球科技新进展的人。</span></p><p class=\"js_darkmode__14\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);font-size: 16px;font-family: Arial;text-align: left;margin: 20px 16px !important;min-height: 1.5em !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;\"><span leaf=\"\">在量子位，我们奉行好奇心驱动，敢想敢上，多劳多得的文化，并且以信息和媒体的方式，不断实现自我价值的提升。这不只限于精神认知，也在于物质回报。</span></p><p class=\"js_darkmode__15\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);font-size: 16px;font-family: Arial;text-align: left;margin: 20px 16px !important;min-height: 1.5em !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;\"><span leaf=\"\">英雄不问出处，我们也不在意你的专业出身，文科 or 理科，计算机 or 生化环材 or 新传中文，都不是评估标准。</span></p><p class=\"js_darkmode__16\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);font-size: 16px;font-family: Arial;text-align: left;margin: 20px 16px !important;min-height: 1.5em !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;\"><span leaf=\"\">我们秉持的始终是第一性原理，关注的是你是否有足够的好奇心，以及用行动消灭好奇的能力——</span></p><p class=\"js_darkmode__17\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);font-size: 16px;font-family: Arial;text-align: left;margin: 20px 16px !important;min-height: 1.5em !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;\"><span leaf=\"\">线上追踪挖掘线索也好，线下找到最具发言权来回答问题的人也罢，最后可以深入浅出把信息分享给每个人，让所有人无差别获知世界的新进展。</span></p><p class=\"js_darkmode__18\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);font-size: 16px;font-family: Arial;text-align: left;margin: 20px 16px !important;min-height: 1.5em !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;\"><span leaf=\"\">量子位，持续在找这样的人，持续在构建这样的人组成的团队，持续在创造让每个人更上一层楼的文化。</span></p><section class=\"js_darkmode__19\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);font-size: 16px;font-family: Arial;text-align: center;margin: 20px 16px !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-imgfileid=\"100292064\" data-ratio=\"0.9731481481481481\" data-w=\"1080\" style=\"-webkit-tap-highlight-color: transparent; outline: 0px; visibility: visible !important; width: 645px !important; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtAU7pXrelY8sPkDicZDiaLL3Ocq9fdeqnjMl9ibHOibcgFcTXWxFDib4HGHhicQ82HCC8BbYrWNplqemAjA/640?wx_fmt=other&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1&amp;tp=webp\"></section><p class=\"js_darkmode__20\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);font-size: 16px;font-family: Arial;text-align: left;margin: 20px 16px !important;min-height: 1.5em !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;\"><span leaf=\"\">在这个团队中，我们日常氛围轻松，追求人人平等，隔三差五聚餐。</span></p><p class=\"js_darkmode__20\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);font-size: 16px;font-family: Arial;text-align: left;margin: 20px 16px !important;min-height: 1.5em !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;\"><span leaf=\"\">嗯，基本无人可以侥幸一直瘦着<img class=\"rich_pages wxw-img\" data-ratio=\"1\" data-w=\"128\" style=\"display:inline-block; width:20px; vertical-align:middle; background-size:cover; max-width: 600px\" src=\"https://res.wx.qq.com/t/wx_fed/we-emoji/res/v1.3.10/assets/newemoji/Yellowdog.png\">。</span></p><section style=\"margin-bottom: 0px;\"><section><section><p><span leaf=\"\"><br></span></p><section style=\"margin-top: 10px;margin-bottom: 10px;color: rgb(62, 62, 62);font-size: 16px;letter-spacing: 0.578px;text-align: right;justify-content: flex-end;display: flex;flex-flow: row;\"><section style=\"padding-right: 10px;display: inline-block;width: auto;vertical-align: middle;align-self: center;flex: 0 0 auto;min-width: 5%;height: auto;\"><section style=\"text-align: justify;font-size: 12px;\"><p style=\"text-align: right;\"><strong><span leaf=\"\">一键三连</span></strong><span style=\"color: rgb(0, 153, 127);\"><strong><span leaf=\"\">「点赞」「转发」「小心心」</span></strong></span></p><p style=\"text-align: right;\"><strong><span leaf=\"\">欢迎在评论区留下你的想法！</span></strong></p></section><section style=\"transform: perspective(0px);transform-style: flat;\"><section style=\"margin-top: 5px;margin-bottom: 10px;transform: rotateY(180deg);\"><section style=\"width: 201.828px;height: 5px;background-image: linear-gradient(90deg, rgba(0, 153, 127, 0.5) 13%, rgba(235, 25, 24, 0) 100%);\"><svg viewbox=\"0 0 1 1\" style=\"float:left;line-height:0;width:0;vertical-align:top;\"></svg></section></section></section></section></section><section style=\"margin-top: 15px;margin-bottom: 25px;color: rgb(62, 62, 62);font-size: 16px;letter-spacing: 0.578px;opacity: 0.8;\"><section style=\"text-align: center;\"><p><span style=\"font-size: 17px;\"><span leaf=\"\">— </span><strong><span leaf=\"\">完</span></strong><span leaf=\"\"> —</span></span></p></section></section></section></section><section style=\"font-size: 14px;line-height: 2;\"><p><span style=\"color: rgb(0, 153, 127);\"><strong><span leaf=\"\">速抢席位！</span></strong></span><span style=\"color: rgb(0, 153, 127);\"><strong><span leaf=\"\">中国AIGC产业峰会</span></strong></span><strong><span leaf=\"\">观众报名通道已开启</span></strong><span leaf=\"\"> 🙋‍♀️</span></p><p style=\"\"><span leaf=\"\"><a style=\"\" href=\"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&amp;mid=2247786481&amp;idx=3&amp;sn=f9cc1b9e27536ab95d29dd98acd2485a&amp;scene=21#wechat_redirect\" textvalue=\"最新嘉宾曝光啦\" data-itemshowtype=\"0\" target=\"_blank\" linktype=\"text\" data-linktype=\"2\">最新嘉宾曝光啦</a></span><span style=\"font-size: 14px;letter-spacing: 0.578px;\"><span leaf=\"\"> 🔥 </span></span><span leaf=\"\">百度、</span><span style=\"font-family: \" pingfang sc system-ui neue sans gb yahei ui arial sans-serif rgb><span leaf=\"\">华为、AWS、</span></span><span leaf=\"\">无问芯穹、数势科技、面壁智能、生数科技等十数位AI领域创变者将齐聚峰会，让更多人用上AI、用好AI，与AI一同加速成长～</span></p><p style=\"\"><strong><span style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">4月16日</span></span></strong><span leaf=\"\">，就在</span><strong><span style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">北京</span></span></strong><span leaf=\"\">，</span><span style=\"font-size: 14px;letter-spacing: 0.578px;\"><span leaf=\"\">一起来深度求索AI怎么用</span></span><span style=\"font-size: 14px;letter-spacing: 0.578px;color: rgb(0, 153, 127);\"><strong><span leaf=\"\"> 🙌 <a class=\"weapp_text_link js_weapp_entry\" data-miniprogram-type=\"text\" style=\"font-size: 14px;\" data-miniprogram-appid=\"wxe8a015203d67e81c\" data-miniprogram-path=\"pages/event-detail/event-detail?id=9798007926900\" data-miniprogram-nickname=\"活动行\" data-miniprogram-servicetype=\"\" data-miniprogram-applink=\"\">点击报名参会</a></span></strong></span></p><section style=\"text-align: center;margin-top: 16px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-imgfileid=\"100302528\" data-ratio=\"0.75\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBBQkaaRqaRr3m2FXlKJ4AU4iaZ706lfGbPBJhwgGMqJQ1af2aAXh9ibWa7KW2H5Xq6F6XBrTcHjmMw/640?wx_fmt=jpeg&amp;from=appmsg\" style=\"max-width: 600px\"></span></section></section><section style=\"text-align: center;margin-top: 10px;margin-bottom: 10px;line-height: 0;\"><section style=\"vertical-align: middle;display: inline-block;line-height: 0;\"><span leaf=\"\"><br></span></section></section><p style=\"\"><span leaf=\"\"><br></span></p><section style=\"font-size: 14px;color: rgb(0, 153, 127);\"><p style=\"text-align: center;\"><strong><span leaf=\"\">🌟 一键星标 🌟</span></strong></p><p style=\"text-align: center;\"><strong><span leaf=\"\">科技前沿进展每日见</span></strong></p></section><p style=\"\"><span leaf=\"\"><br></span></p><section class=\"mp_profile_iframe_wrp\"><span leaf=\"\"><mp-common-profile class=\"js_uneditable custom_select_card mp_profile_iframe\" data-pluginname=\"mpprofile\" data-nickname=\"量子位\" data-alias=\"QbitAI\" data-from=\"0\" data-headimg=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCEFSVW5ubo08Zfv1qB5iapricibTBdETkBNtolJxnSUib6UXhjWWz3aib8vETY00P2lKR1uG3qLHicSoWg/0?wx_fmt=png\" data-signature=\"追踪人工智能新趋势，关注科技行业新突破\" data-id=\"MzIzNjc1NzUzMw==\" data-is_biz_ban=\"0\" data-service_type=\"1\"></mp-common-profile></span></section><section><section><section><p><span leaf=\"\"><br></span></p></section></section></section></section><p style=\"display: none;\"><mp-style-type data-value=\"10000\"></mp-style-type></p></div>\n    \n\n    \n    <br>\n\n    \n        <a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&amp;mid=2247786774&amp;idx=5&amp;sn=36f077cc98d61090998d72b0ea1bdda8&amp;chksm=e9da3dc0ebbcfc12f4e2799833aa00422c695bb2ba0e6ad04f88798eaab9e736f25776507707&amp;scene=0#rd\" style=\"color: blue\" class=\"media_tool_meta meta_primary\">文章原文</a>\n        <br>\n    \n\n    \n\n    <img alt=\"\" width=\"1px\" height=\"1px\" class=\"\" style=\"width:1px;height:1px;display:none\" src=\"http://www.jintiankansha.me/rss_static/97720/qKr97qDbkj\">\n\n",
          "contentSnippet": "DeepSeek 发自 凹非寺\n量子位 | 公众号 QbitAI\n未来同事，你好~\n这是一则招聘帖。\n量子位是一个关注AI及前沿科技的新媒体平台，我们着迷于全新技术和趋势带来的改变，并正致力于帮助更多人第一时间看懂新趋势、新机遇。\n如果你与我们志同道合，对AI大模型、具身智能、终端硬件、AI新媒体编辑感兴趣，我们正在招聘这些领域的原创作者。\n以下岗位均为全职，工作地点：北京中关村。\n岗位面向：社招、应届毕业生，所有岗位均可实习——表现出色均可转正\n加分项：\n\n乐于探索AI新工具，善用AI新工具；\n\n拥有解读论文的能力，能深入浅出讲解原理；\n\n有写代码能力；\n\n量子位长期读者。\n\n加入我们，你可以获得：\n\n站在AI浪潮之巅：第一时间接触和了解AI领域最新技术和产品，构建完整的AI认知体系。\n\n玩转AI新工具：将各种AI新技术、新工具应用于工作，提升工作效率和创造力。\n\n打造个人影响力：通过撰写独家原创内容，建立个人知名度，成为AI领域的意见领袖。\n\n拓展行业人脉：与AI领域大咖零距离接触，参与重要科技活动和发布会，拓展行业视野。\n\n获得专业指导：会由主编级编辑出任mentor，提供一对一指导，帮你更快进步获得成长。\n\n加入活力团队：与一群志同道合的年轻人一起工作，享受扁平、简单、开放、充满活力的团队氛围。\n\n获得丰厚回报：具有竞争力的薪资待遇（8K-20K），五险一金、餐补、项目绩效、商务绩效、加班补助等福利一应俱全。\n\n在招岗位包括：\n\nAI大模型方向编辑作者\n\n具身智能机器人方向编辑作者\n\n终端硬件方向编辑作者\n\nAI新媒体编辑（微博/小红书方向）\n\nAI大模型方向编辑作者\n你需要做什么？\n\n紧跟AI浪潮：密切关注AI、大模型领域的最新动态和进展，保持对行业趋势的敏锐洞察。\n\n挖掘优质选题：深入挖掘AI大模型领域的优质选题，策划并撰写深度文章、行业分析等内容。\n\n十级冲浪选手：活跃于各大网络平台，收集整理行业资讯，捕捉热点话题。\n\n参与内容运营：学习并参与量子位内容的全平台运营，提升内容传播力和影响力。\n\n我们希望你是：\n\nAI狂热爱好者：对AI大模型、前沿科技充满热情，痴迷于探索科技新进展。\n\n文字表达高手：具备扎实的文字功底，能够用流畅、清晰的语言表达复杂的概念。\n\n信息搜集达人：能够熟练阅读和翻译外文资料，喜欢挖掘论文在内的源头信息，获取第一手行业资讯。\n\n学历背景不限：全日制本科以上学历，专业不限，欢迎所有对AI充满热情的伙伴加入。\n\n具身智能机器人方向编辑作者\n你需要做什么？\n\n追踪行业前沿：密切关注具身智能领域的最新动态、技术突破和行业趋势，保持对前沿科技的敏锐嗅觉。\n\n打造独家内容：深入挖掘具身智能领域的独家选题，撰写原创深度文章、行业分析报告等内容。\n\n建立行业人脉：与具身智能领域的专家学者、企业领袖建立良好联系，获取第一手行业资讯。\n\n构建行业认知：深入研究具身智能领域，形成体系化的行业认知和洞察，输出有价值的观点。\n\n我们希望你是：\n\n具身智能狂热粉：对具身智能、机器人技术、前沿科技充满热情，痴迷于探索科技新进展。\n\n逻辑思维强者：学习能力强，善于分析和解决问题，做事追求逻辑和条理。\n\n文笔流畅的写手：具备自然流畅的文笔表达能力，能够将复杂的技术概念通俗易懂地呈现给读者。\n\n社交达人（加分项）：性格偏E，喜欢与人交流，善于建立和维护人际关系。\n\n终端硬件方向编辑作者\n你需要做什么？\n\n追踪硬件前沿：密切关注AI终端硬件领域的最新进展，包括手机、PC、智能眼镜等产品的技术突破和产业变革。\n\n深度产品分析：从技术原理到用户体验，深入分析终端硬件产品，撰写深度评测、产品对比等内容。\n\n参与内容运营：学习并参与量子位内容的全平台运营，提升内容传播力和影响力。\n\n我们希望你是：\n\n硬件发烧友：热爱科技产品，对终端硬件充满热情，是“搞机”爱好者。\n\n技术洞察者：能够从技术原理到产品体验，构建对终端硬件的认知体系，并输出有价值的观点。\n\n文笔流畅的写手：具备自然流畅的文笔表达能力，能够将复杂的技术概念通俗易懂地呈现给读者。\n\nAI新媒体编辑（微博/小红书方向）\n你需要做什么？\n\n负责微博、小红书平台的内容策划、撰写和发布，追踪全球AI新动态，用符合平台调性的语言风格进行表达。\n\n关注用户反馈，与读者互动交流，提升账号粘性和影响力。\n\n不断优化内容质量和传播效果，探索提升内容影响力的方法。\n\n关注AI领域热点，敏锐捕捉新技术、新进展，并策划相关内容，助力打造爆款。\n\n我们希望你是：\n\n网感超棒的年轻人：热爱社交平台，是微博、小红书的深度用户，熟悉平台玩法和用户喜好。\n\n文笔流畅的段子手：能用通俗易懂、生动有趣的语言表达观点，拉近与读者的距离。\n\n嗅觉敏锐的新闻人：对AI领域充满热情，能够快速捕捉行业热点，并具备一定的新闻敏感度。\n\n目标明确的行动派：以创造热搜为目标，具备较强的执行力和学习能力，能够不断优化工作方法。\n\n应聘方式\n\n请将个人简历发送至zhaopin@qbitai.com，邮件主题请注明“量子位XX方向应聘 - [你的姓名]”；\n\n随简历附上你的科技行业代表作品，或者能展现个人写作水平和风格的作品。\n\n关于量子位\n截至2025年，通过及时追踪AI及前沿科技进展，量子位在微信公众号已经有超230万订阅用户，全网用户超700万，日均阅读量200万+。\n在新榜和清博等第三方数据平台，量子位已是AI以及前沿科技行业TOP1新媒体。\n\n每年各大主流媒体平台评选时，量子位都被认为是最具影响力的科技账号之一，包括但不限于：微信公众号12周年代表性帐号、腾讯科技年度影响力创作者、澎湃新闻最澎湃创作者、新浪财经年度科技账号、今日头条年度媒体创作者…\n量子位也是行业顶级会议的战略合作者：中国计算机学会CNCC年度战略合作伙伴、WAIC世界人工智能大会战略合作伙伴、中国人工智能产业发展联盟媒体组成员……\n我们还拥有5万+微信社群用户，他们都是信仰技术、追求新知，渴望每天最先获悉全球科技新进展的人。\n在量子位，我们奉行好奇心驱动，敢想敢上，多劳多得的文化，并且以信息和媒体的方式，不断实现自我价值的提升。这不只限于精神认知，也在于物质回报。\n英雄不问出处，我们也不在意你的专业出身，文科 or 理科，计算机 or 生化环材 or 新传中文，都不是评估标准。\n我们秉持的始终是第一性原理，关注的是你是否有足够的好奇心，以及用行动消灭好奇的能力——\n线上追踪挖掘线索也好，线下找到最具发言权来回答问题的人也罢，最后可以深入浅出把信息分享给每个人，让所有人无差别获知世界的新进展。\n量子位，持续在找这样的人，持续在构建这样的人组成的团队，持续在创造让每个人更上一层楼的文化。\n\n在这个团队中，我们日常氛围轻松，追求人人平等，隔三差五聚餐。\n嗯，基本无人可以侥幸一直瘦着。\n\n\n\n\n\n\n一键三连「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n\n\n\n\n\n\n— 完 —\n\n\n\n速抢席位！中国AIGC产业峰会观众报名通道已开启 🙋‍♀️\n最新嘉宾曝光啦 🔥 百度、华为、AWS、无问芯穹、数势科技、面壁智能、生数科技等十数位AI领域创变者将齐聚峰会，让更多人用上AI、用好AI，与AI一同加速成长～\n4月16日，就在北京，一起来深度求索AI怎么用 🙌 点击报名参会\n\n\n\n\n\n\n\n\n🌟 一键星标 🌟\n科技前沿进展每日见\n\n\n\n\n\n\n\n\n\n\n\n\n    \n\n    \n    \n文章原文",
          "guid": "http://www.jintiankansha.me/t/qKr97qDbkj",
          "categories": [
            "无"
          ],
          "isoDate": "2025-04-08T04:46:00.000Z"
        }
      },
      {
        "json": {
          "title": "AI危险检测再进化！三层级解析长视频异常，各种时序粒度均有明显优势 | CVPR HighLight",
          "link": "http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247786774&idx=4&sn=3d2d3c76e08f136240c6305cb502c31e&chksm=e9c1e2170bd17ff24aba5cd0711abb39e7d9e612bdf0070fcdd5edf0f173fa53df6558b2c4e3&scene=0#rd",
          "pubDate": "Tue, 08 Apr 2025 12:46:00 +0800",
          "enclosure": {
            "url": "http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCj15cgGmoLoKIO9prnjwuicIibjWFcGLTxYqkKcVqPCVjBHAtV4ChAo0YQlvXQ3eeNbSDwlhJ1qZlg/0?wx_fmt=jpeg",
            "length": "0",
            "type": "image/jpeg"
          },
          "content": "\n\n    \n\n    \n\n    \n         <div class=\"rich_media_content\" id=\"js_content\"><h5 style=\"font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: ExtraLight-0;background-color: rgb(248, 248, 248);border-radius: 3px;overflow-wrap: break-word;margin: 10px 0px 30px;padding: 10px;color: rgb(51, 51, 51);font-size: 14px;text-align: left;line-height: 2;font-weight: 300;word-break: break-all !important;letter-spacing: 1px !important;word-spacing: 1px !important;\" data-pm-slice=\"0 0 []\"><span leaf=\"\">HolmesVAU团队 投稿</span><span leaf=\"\"><br></span><span leaf=\"\">量子位 | 公众号 QbitAI</span></h5><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\"><span textstyle=\"\" style=\"color: rgb(0, 153, 127);font-weight: bold;\">多模态视频异常理解任务</span>，又有新突破！</span></p><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">“异常理解”是指在视频监控、自动驾驶等场景中，利用模型发现视频中的异常内容，从而预判危险，以便及时做出决策。</span></p><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">来自华中科大等机构的研究人员，提出了新的视频异常理解模型<span textstyle=\"\" style=\"color: rgb(0, 153, 127);font-weight: bold;\">Holmes-VAU</span>，以及相关数据集。</span></p><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">与通用多模态大模型对比，Holmes-VAU<span textstyle=\"\" style=\"color: rgb(0, 153, 127);font-weight: bold;\">在各种时序粒度的视频异常理解上都展现出显著优势</span>。</span></p><section style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;padding: 0px;font-size: 16px;font-family: Arial;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-imgfileid=\"100303027\" data-ratio=\"0.7716763005780347\" data-type=\"png\" data-w=\"1038\" style=\"margin: 0px auto; padding: 0px; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCj15cgGmoLoKIO9prnjwuickfYRF1KEaf6k9kLbaal8UGweB7SJwfxKDJqBjKhmjFkCwduqVxicdTg/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">为了实现开放世界的多模态视频异常理解（VAU），已有的VAU benchmark只有短视频的caption标注或长视频的instruction标注，忽略了视频异常事件的时序复杂性。</span></p><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">为同时促进模型对短视频的感知能力和对长视频的推理能力，作者提出了一种高效半自动数据引擎并构建了<span textstyle=\"\" style=\"color: rgb(0, 153, 127);font-weight: bold;\">HIVAU-70k数据集</span>，包含超7万视频异常理解任务的多时序尺度指令数据。</span></p><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">同时作者提出了一种基于异常分数的时序采样器，从长视频中动态稀疏采样关键帧到后续多模态大模型中，显著提升了异常分析的准确性和推理效率。</span></p><h2 style=\"color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;text-align: left;margin: 40px 0px;line-height: 1.5;font-weight: bold;padding-left: 15px;word-break: break-all !important;border-left: 6px solid rgb(0, 153, 127) !important;font-size: 20px !important;letter-spacing: 1px !important;word-spacing: 1px !important;\"><span leaf=\"\">多层级视频异常理解指令数据集</span></h2><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">针对视频异常理解任务(Video Anomaly Understanding)，以往的一些异常视频指令数据集主要有两方面问题：</span></p><ul style=\"color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-align: start;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;padding-left: 30px;font-size: 16px;list-style-type: square;letter-spacing: 1px !important;word-spacing: 1px !important;min-height: 1em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;\" class=\"list-paddingleft-1\"><li style=\"line-height: 28px;margin: 8px 16px;\"><section><span leaf=\"\">数据集中的视频时长较短，导致模型缺乏对长视频的异常理解能力；</span></section></li><li style=\"line-height: 28px;margin: 8px 16px;\"><section><span leaf=\"\">即便包含长视频，也缺乏对长视频的细粒度和结构化的标注，导致模型的异常理解空间难以对齐。</span></section></li></ul><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">为此，作者提出了一个大型多模态指令数据集HIVAU-70k，其中包含多种时间粒度的视频异常标注，由粗到细分别为：</span></p><ul style=\"color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-align: start;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;padding-left: 30px;font-size: 16px;list-style-type: square;letter-spacing: 1px !important;word-spacing: 1px !important;min-height: 1em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;\" class=\"list-paddingleft-1\"><li style=\"line-height: 28px;margin: 8px 16px;\"><section><span leaf=\"\"><span textstyle=\"\" style=\"color: rgb(0, 153, 127);font-weight: bold;\">video-level</span>：未裁剪长视频，包括视频中所有异常事件的文本描述分析；</span></section></li><li style=\"line-height: 28px;margin: 8px 16px;\"><section><span leaf=\"\"><span textstyle=\"\" style=\"color: rgb(0, 153, 127);font-weight: bold;\">event-level</span>：从长视频中裁剪出的异常事件片段，包括单个异常事件的文本描述分析；</span></section></li><li style=\"line-height: 28px;margin: 8px 16px;\"><section><span leaf=\"\"><span textstyle=\"\" style=\"color: rgb(0, 153, 127);font-weight: bold;\">clip-level</span>：从event中进一步裁剪出的视频片段，包括视频片段的文本描述。</span></section></li></ul><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">HIVAU-70k中的指令数据包括视频描述、异常判断、异常描述和异常分析等任务，为视频异常理解多模态大模型提供了丰富多样的数据来源。</span></p><section style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;padding: 0px;font-size: 16px;font-family: Arial;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.37407407407407406\" data-type=\"png\" data-w=\"1080\" style=\"margin: 0px auto; padding: 0px; max-width: 600px\" data-imgfileid=\"100303026\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCj15cgGmoLoKIO9prnjwuic7NrsRNeBBb8fibibrcrqMu5IrX0b5nyTKoq0cM76zYfVBDnyKIRW2EzA/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">这样的多层级指令数据集是怎么构造的呢？从一个未裁剪的长视频开始，需要依次经过以下三个步骤：</span></p><ul style=\"color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-align: start;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;padding-left: 30px;font-size: 16px;list-style-type: square;letter-spacing: 1px !important;word-spacing: 1px !important;min-height: 1em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;\" class=\"list-paddingleft-1\"><li style=\"line-height: 28px;margin: 8px 16px;\"><section><span leaf=\"\"><span textstyle=\"\" style=\"color: rgb(0, 153, 127);font-weight: bold;\">分层视频解耦</span>（Hierarchical Video Decoupling）：将video-level视频中的异常事件标注并裁剪出来，得到event-level视频, 再对event-level视频进一步平均切分得到clip-level视频；</span></section></li><li style=\"line-height: 28px;margin: 8px 16px;\"><section><span leaf=\"\"><span textstyle=\"\" style=\"color: rgb(0, 153, 127);font-weight: bold;\">分层自由文本注释</span>（Hierarchical Free-text Annotation）：对于clip-level视频，使用人工或caption model得到clip caption；对于event-level视频，结合所包含的clip-level caption和异常类别，提示LLM得到事件总结；对于video-level视频，结合所包含的事件总结和异常类别，提示LLM得到视频总结；</span></section></li><li style=\"line-height: 28px;margin: 8px 16px;\"><section><span leaf=\"\"><span textstyle=\"\" style=\"color: rgb(0, 153, 127);font-weight: bold;\">层次化指令数据构建</span>（Hierarchical Instruction Data Construction）：针对不同层级的视频及其文本标注，设计不同的任务，构造任务相关的问题并与文本注释组合，得到最终的指令数据。</span></section></li></ul><section style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;padding: 0px;font-size: 16px;font-family: Arial;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.7764060356652949\" data-type=\"png\" data-w=\"729\" style=\"margin: 0px auto; padding: 0px; max-width: 600px\" data-imgfileid=\"100303025\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCj15cgGmoLoKIO9prnjwuic4H2SicNicHoBMicXxmY7WLMK8FXyVm4FTuL5sf8fwVSMltgIfmcwiaUcxA/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">与其他相关的数据集相比，HIVAU-70k不仅有数量上的优势，还提供了多粒度的文本标注以及时序上的异常边界标注。</span></p><section style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;padding: 0px;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.27367055771725035\" data-type=\"png\" data-w=\"771\" style=\"text-align: center; margin: 0px auto; padding: 0px; max-width: 600px\" data-imgfileid=\"100303024\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCj15cgGmoLoKIO9prnjwuicdZBJlnMdjVer9dSglh9xiaicibictaSCdjZ459RryZNc00NELLooFprasQ/640?wx_fmt=png&amp;from=appmsg\"></section><h2 style=\"color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;text-align: left;margin: 40px 0px;line-height: 1.5;font-weight: bold;padding-left: 15px;word-break: break-all !important;border-left: 6px solid rgb(0, 153, 127) !important;font-size: 20px !important;letter-spacing: 1px !important;word-spacing: 1px !important;\"><span leaf=\"\">动态稀疏采样的视频异常理解模型</span></h2><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">长视频异常理解在使用大型语言模型（LLMs）或视觉语言模型（VLMs）时，常因帧冗余问题而受到限制，导致异常检测的准确性变得复杂。</span></p><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">以往的VAU（视频异常理解）方法难以聚焦异常。</span></p><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">例如，密集窗口采样方法会增加大量冗余帧的计算量，而均匀帧采样方法常常错过关键异常帧，使其应用范围局限于短视频。</span></p><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">为此，作者提出了Anomaly-focused Temporal Sampler (ATS)，并将其集成到VLM中，通过在HIVAU-70k上的指令微调，构建了Holmes-VAU模型。</span></p><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">异常帧通常比正常帧包含更多信息，并表现出更大的变化，基于这一观察，作者设计了一种采样策略，在异常分数较高的区域采样更多帧，同时在分数较低的区域减少采样。</span></p><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">为实现非均匀采样，作者提出了一种“密度感知采样器”（density-aware sampler），用于从总共T个输入帧中选择N个帧。</span></p><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">具体来说，作者将异常分数S视为概率质量函数，并首先沿时间维度累积它们，得到累积分布函数（CDF），记为 S_cumsum：</span></p><section style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;padding: 0px;font-size: 16px;font-family: Arial;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.2928870292887029\" data-type=\"png\" data-w=\"239\" style=\"margin: 0px auto; padding: 0px; max-width: 600px\" data-imgfileid=\"100303023\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCj15cgGmoLoKIO9prnjwuicqPZJm8smm4oN8tDZVysic4PNj0vusBWbmL7sJ9sAoo8cr3fXCOEibPrQ/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">接着，在累积轴上均匀采样N个点，并将这些点映射到累积分布S_cumsum上。相应的时间轴上的N个时间戳会被映射到最接近的帧索引，最终形成采样的帧索引集合G。</span></p><h6 style=\"font-family: Arial, Helvetica, sans-serif;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;color: rgb(143, 143, 143);text-align: center;margin: 0px 16px 0px 0px;line-height: 1.3;font-weight: 300;word-break: break-all !important;font-size: 13px !important;letter-spacing: 1px !important;word-spacing: 1px !important;\"><strong style=\"font-weight: bold;color: rgb(0, 153, 127);\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.9243466299862448\" data-type=\"png\" data-w=\"727\" style=\"margin: 0px auto; padding: 0px; max-width: 600px\" data-imgfileid=\"100303031\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCj15cgGmoLoKIO9prnjwuic7aNP006Xb8G4VPlykOuhZtLxdnNHHpFO4TIjhkNdiaWyGLERZiazTGTw/640?wx_fmt=png&amp;from=appmsg\"></span></strong></h6><h6 style=\"font-family: Arial, Helvetica, sans-serif;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;color: rgb(143, 143, 143);text-align: right;margin: 0px 16px 0px 0px;line-height: 1.3;font-weight: 300;word-break: break-all !important;font-size: 13px !important;letter-spacing: 1px !important;word-spacing: 1px !important;\"><strong style=\"font-weight: bold;color: rgb(0, 153, 127);\"><span leaf=\"\">△</span></strong><span leaf=\"\">Holmes-VAU模型框架图</span></h6><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">下入展示了测试集上的异常分数和采样帧的可视化结果。这些结果表明了ATS的准确异常检测能力，最终输入到多模态大模型的采样帧也集中于异常区域。</span></p><h6 style=\"font-family: Arial, Helvetica, sans-serif;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;color: rgb(143, 143, 143);text-align: center;margin: 0px 16px 0px 0px;line-height: 1.3;font-weight: 300;word-break: break-all !important;font-size: 13px !important;letter-spacing: 1px !important;word-spacing: 1px !important;\"><strong style=\"font-weight: bold;color: rgb(0, 153, 127);\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.3226452905811623\" data-type=\"png\" data-w=\"1497\" style=\"margin: 0px auto; padding: 0px; max-width: 600px\" data-imgfileid=\"100303030\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCj15cgGmoLoKIO9prnjwuiccv1JGqnwN17Pp4S9gX1JntzKMDvhrXp5wN780xFlkDCibOicq3kibPPdg/640?wx_fmt=png&amp;from=appmsg\"></span></strong></h6><h6 style=\"font-family: Arial, Helvetica, sans-serif;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;color: rgb(143, 143, 143);text-align: right;margin: 0px 16px 0px 0px;line-height: 1.3;font-weight: 300;word-break: break-all !important;font-size: 13px !important;letter-spacing: 1px !important;word-spacing: 1px !important;\"><strong style=\"font-weight: bold;color: rgb(0, 153, 127);\"><span leaf=\"\">△</span></strong><span leaf=\"\">Anomly-focused Temporal Sampler (ATS) 异常分数及采样帧示意图</span></h6><h2 style=\"color: rgb(34, 34, 34);font-family: Arial, Helvetica, sans-serif;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;text-align: left;margin: 40px 0px;line-height: 1.5;font-weight: bold;padding-left: 15px;word-break: break-all !important;border-left: 6px solid rgb(0, 153, 127) !important;font-size: 20px !important;letter-spacing: 1px !important;word-spacing: 1px !important;\"><span leaf=\"\">实验结果</span></h2><h4 style=\"font-family: Arial, Helvetica, sans-serif;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;color: rgb(62, 62, 62);font-weight: bold;text-align: center;margin: 10px 60px;padding-top: 0px;padding-bottom: 6px;border-bottom: 3px solid rgb(0, 153, 127);word-break: break-all !important;font-size: 16px !important;letter-spacing: 1px !important;word-spacing: 1px !important;\"><span leaf=\"\">异常推理性能评估</span></h4><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">作者在HIVAU-70k的测试集上，将模型输出的推理文本与注释的真实文本进行比较，计算了包括BLEU、CIDEr、METEOR和ROUGE等指标来衡量模型输出的异常理解文本质量。</span></p><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">与通用多模态大模型对比，Holmes-VAU在各种时序粒度的视频异常理解上都展现出显著优势。</span></p><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;padding: 0px;font-size: 16px;font-family: Arial;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.2667525773195876\" data-type=\"png\" data-w=\"776\" style=\"margin: 0px auto; padding: 0px; max-width: 600px\" data-imgfileid=\"100303028\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCj15cgGmoLoKIO9prnjwuicxCDmEv4dj5uthMOibfFXusKbk4MEefCMdoVzHP1o1KhTHxfN4GdmKXA/640?wx_fmt=png&amp;from=appmsg\"></span></p><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;padding: 0px;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">在多层级标注中，对不同层级指令数据集的组合，可以观察发现，单一层级的标注只能提升单一层级任务的性能。</span></p><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">不同层级的标注组合可以相互补充，实现从clip-level的基础视觉感知, 到event-level单一异常事件的分析，再到video-level的长时序异常总结和推理等方面的全面提升，达到更细粒度和完整的多模态异常空间对齐。</span></p><section style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;padding: 0px;font-size: 16px;font-family: Arial;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5394190871369294\" data-type=\"png\" data-w=\"482\" style=\"margin: 0px auto; padding: 0px; max-width: 600px\" data-imgfileid=\"100303029\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCj15cgGmoLoKIO9prnjwuic8icaQezFv7eehTYm5z59wPLFAp7cL28xIStYy8LDNQcIb8kpTkuNUmQ/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">对于非均匀采样器的作用，作者也对比了不同帧采样方式，包括本文提出的ATS、之前方法用的Top-K采样和Uniform采样。</span></p><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">结果表明在相同的采样帧数下，ATS展现出更优越的长视频异常理解能力，这是由于Top-K采样过于集中在异常帧，忽略了视频上下文的参考，Uniform采样则容易忽略关键的异常帧。</span></p><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">而作者提出的ATS则有效结合了这两者的优势，关注异常帧的同时，能够保留部分上下文帧的采样。</span></p><section style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;padding: 0px;font-size: 16px;font-family: Arial;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.7034632034632035\" data-type=\"png\" data-w=\"462\" style=\"margin: 0px auto; padding: 0px; max-width: 600px\" data-imgfileid=\"100303032\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCj15cgGmoLoKIO9prnjwuicbdb7dfR9s3H6zicvice1aIOKUGdjQibiavDM5ibicyLpwM3KlkYUlKiby1y1g/640?wx_fmt=png&amp;from=appmsg\"></section><h4 style=\"font-family: Arial, Helvetica, sans-serif;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;color: rgb(62, 62, 62);font-weight: bold;text-align: center;margin: 10px 60px;padding-top: 0px;padding-bottom: 6px;border-bottom: 3px solid rgb(0, 153, 127);word-break: break-all !important;font-size: 16px !important;letter-spacing: 1px !important;word-spacing: 1px !important;\"><span leaf=\"\">定性比较</span></h4><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">下图对比了Holmes-VAU和其他MLLM输出的异常分析文本，Holmes-VAU表现出更准确的异常判断和分析能力，同时对长视频也表现出更完整的异常总结能力。</span></p><h6 style=\"font-family: Arial, Helvetica, sans-serif;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;color: rgb(143, 143, 143);text-align: center;margin: 0px 16px 0px 0px;line-height: 1.3;font-weight: 300;word-break: break-all !important;font-size: 13px !important;letter-spacing: 1px !important;word-spacing: 1px !important;\"><strong style=\"font-weight: bold;color: rgb(0, 153, 127);\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5611460517120894\" data-type=\"png\" data-w=\"1431\" style=\"margin: 0px auto; padding: 0px; max-width: 600px\" data-imgfileid=\"100303033\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCj15cgGmoLoKIO9prnjwuiczicsBKibgiayNp4icDOqw4B9mGfr5m1dpicianSNW5a56icKIcCocaoKVJAIQ/640?wx_fmt=png&amp;from=appmsg\"></span></strong></h6><h6 style=\"font-family: Arial, Helvetica, sans-serif;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;color: rgb(143, 143, 143);text-align: right;margin: 0px 16px 0px 0px;line-height: 1.3;font-weight: 300;word-break: break-all !important;font-size: 13px !important;letter-spacing: 1px !important;word-spacing: 1px !important;\"><strong style=\"font-weight: bold;color: rgb(0, 153, 127);\"><span leaf=\"\">△</span></strong><span leaf=\"\">Holmes-VAU和其他MLLM的异常分析文本质量对比</span></h6><p style=\"color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;white-space: normal;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 14px;color: rgb(136, 136, 136);\">论文：</span></span><span leaf=\"\"><br></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 14px;color: rgb(136, 136, 136);\">https://arxiv.org/abs/2412.06171</span></span><span leaf=\"\"><br></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 14px;color: rgb(136, 136, 136);\">代码：</span></span><span leaf=\"\"><br></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 14px;color: rgb(136, 136, 136);\">https://github.com/pipixin321/HolmesVAU</span></span></p><section style=\"margin-bottom: 0px;\"><section><section><section><section style=\"margin-top: 10px;margin-bottom: 10px;letter-spacing: 0.578px;color: rgb(62, 62, 62);font-size: 16px;text-align: right;justify-content: flex-end;display: flex;flex-flow: row;\"><section style=\"padding-right: 10px;display: inline-block;width: auto;vertical-align: middle;align-self: center;flex: 0 0 auto;min-width: 5%;height: auto;\"><section style=\"text-align: justify;font-size: 12px;\"><p style=\"text-align: right;\"><strong><span leaf=\"\">一键三连</span></strong><span style=\"color: rgb(0, 153, 127);\"><strong><span leaf=\"\">「点赞」「转发」「小心心」</span></strong></span></p><p style=\"text-align: right;\"><strong><span leaf=\"\">欢迎在评论区留下你的想法！</span></strong></p></section><section style=\"transform: perspective(0px);transform-style: flat;\"><section style=\"margin-top: 5px;margin-bottom: 10px;transform: rotateY(180deg);\"><section style=\"width: 201.828px;height: 5px;background-image: linear-gradient(90deg, rgba(0, 153, 127, 0.5) 13%, rgba(235, 25, 24, 0) 100%);\"><svg viewbox=\"0 0 1 1\" style=\"float:left;line-height:0;width:0;vertical-align:top;\"></svg></section></section></section></section></section></section></section></section><section style=\"margin-top: 15px;margin-bottom: 25px;letter-spacing: 0.578px;color: rgb(62, 62, 62);font-size: 16px;opacity: 0.8;\"><section style=\"text-align: center;\"><p><span style=\"font-size: 17px;\"><span leaf=\"\">— </span><strong><span leaf=\"\">完</span></strong><span leaf=\"\"> —</span></span></p></section></section><section powered-by=\"xiumi.us\" style=\"margin-bottom: 10px;font-size: 16px;letter-spacing: 0.578px;white-space: normal;background-color: rgb(239, 239, 239);\"><section style=\"font-size: 14px;line-height: 1.6;\"><p style=\"margin-bottom: 10px;text-align: center;\"><span style=\"letter-spacing: 0.578px;\"><span leaf=\"\"><br></span></span></p><p style=\"margin-bottom: 10px;text-align: center;\"><strong><span style=\"letter-spacing: 0.578px;color: rgb(0, 153, 127);\"><span leaf=\"\">学术</span></span></strong><span style=\"letter-spacing: 0.578px;\"><span leaf=\"\">投稿请于</span><span style=\"letter-spacing: 0.578px;color: rgb(0, 153, 127);\"><strong><span leaf=\"\">工作日</span></strong></span><span leaf=\"\">发邮件到：</span></span></p><p style=\"margin-bottom: 10px;text-align: center;\"><span style=\"color: rgb(0, 153, 127);\"><strong><span leaf=\"\">ai@qbitai.com</span></strong></span></p><p style=\"margin-bottom: 10px;text-align: center;\"><span leaf=\"\">标题注明【投稿】，告诉我们：</span></p><p style=\"margin-bottom: 10px;text-align: center;\"><span leaf=\"\">你是谁，从哪来，投稿内容</span><span style=\"display: none;line-height: 0px;\"><span leaf=\"\">‍</span></span></p><p style=\"margin-bottom: 10px;text-align: center;\"><span leaf=\"\">附上论文/项目主页链接，以及联系方式哦</span></p><p style=\"margin-bottom: 10px;text-align: center;\"><span leaf=\"\">我们会（尽量）及时回复你</span></p><p style=\"margin-bottom: 10px;text-align: center;\"><span leaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg __bg_gif\" data-ratio=\"0.81\" data-s=\"300,640\" data-type=\"gif\" data-w=\"300\" style=\"height: 104px; font-size: var(--articleFontsize); letter-spacing: 0.578px; text-align: center; white-space: normal; font-family: Arial; outline: 0px; width: 128px; visibility: visible !important; max-width: 600px\" data-imgfileid=\"100240780\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1\"></span></p><p style=\"margin-bottom: 10px;\"><span leaf=\"\"><br></span></p></section></section><p style=\"outline: 0px;\"><span leaf=\"\"><br></span></p><section style=\"margin-bottom: 0px;font-size: 14px;color: rgb(0, 153, 127);\"><section style=\"margin-bottom: 0px;font-size: 14px;color: rgb(0, 153, 127);\"><p style=\"text-align: center;\"><strong><strong style=\"color: rgb(0, 153, 127);font-size: 14px;letter-spacing: 0.578px;text-align: center;\"><span leaf=\"\">🌟 点亮星标 🌟</span></strong></strong></p><section style=\"margin-bottom: 16px;text-align: center;\"><strong><span leaf=\"\">科技前沿进展每日见</span></strong></section></section><section class=\"mp_profile_iframe_wrp\" style=\"margin-bottom: 0px;\"><span leaf=\"\"><mp-common-profile class=\"js_uneditable custom_select_card mp_profile_iframe\" data-pluginname=\"mpprofile\" data-nickname=\"量子位\" data-alias=\"QbitAI\" data-from=\"2\" data-headimg=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCEFSVW5ubo08Zfv1qB5iapricibTBdETkBNtolJxnSUib6UXhjWWz3aib8vETY00P2lKR1uG3qLHicSoWg/0?wx_fmt=png\" data-signature=\"追踪人工智能新趋势，关注科技行业新突破\" data-id=\"MzIzNjc1NzUzMw==\" data-is_biz_ban=\"0\" data-service_type=\"1\"></mp-common-profile></span></section></section></section><section><span leaf=\"\"><br></span></section><p style=\"display: none;\"><mp-style-type data-value=\"10000\"></mp-style-type></p></div>\n    \n\n    \n    <br>\n\n    \n        <a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&amp;mid=2247786774&amp;idx=4&amp;sn=3d2d3c76e08f136240c6305cb502c31e&amp;chksm=e9c1e2170bd17ff24aba5cd0711abb39e7d9e612bdf0070fcdd5edf0f173fa53df6558b2c4e3&amp;scene=0#rd\" style=\"color: blue\" class=\"media_tool_meta meta_primary\">文章原文</a>\n        <br>\n    \n\n    \n\n    <img alt=\"\" width=\"1px\" height=\"1px\" class=\"\" style=\"width:1px;height:1px;display:none\" src=\"http://www.jintiankansha.me/rss_static/97720/qRBCK99yL1\">\n\n",
          "contentSnippet": "HolmesVAU团队 投稿\n量子位 | 公众号 QbitAI\n多模态视频异常理解任务，又有新突破！\n“异常理解”是指在视频监控、自动驾驶等场景中，利用模型发现视频中的异常内容，从而预判危险，以便及时做出决策。\n来自华中科大等机构的研究人员，提出了新的视频异常理解模型Holmes-VAU，以及相关数据集。\n与通用多模态大模型对比，Holmes-VAU在各种时序粒度的视频异常理解上都展现出显著优势。\n\n为了实现开放世界的多模态视频异常理解（VAU），已有的VAU benchmark只有短视频的caption标注或长视频的instruction标注，忽略了视频异常事件的时序复杂性。\n为同时促进模型对短视频的感知能力和对长视频的推理能力，作者提出了一种高效半自动数据引擎并构建了HIVAU-70k数据集，包含超7万视频异常理解任务的多时序尺度指令数据。\n同时作者提出了一种基于异常分数的时序采样器，从长视频中动态稀疏采样关键帧到后续多模态大模型中，显著提升了异常分析的准确性和推理效率。\n多层级视频异常理解指令数据集\n针对视频异常理解任务(Video Anomaly Understanding)，以往的一些异常视频指令数据集主要有两方面问题：\n\n数据集中的视频时长较短，导致模型缺乏对长视频的异常理解能力；\n\n即便包含长视频，也缺乏对长视频的细粒度和结构化的标注，导致模型的异常理解空间难以对齐。\n\n为此，作者提出了一个大型多模态指令数据集HIVAU-70k，其中包含多种时间粒度的视频异常标注，由粗到细分别为：\n\nvideo-level：未裁剪长视频，包括视频中所有异常事件的文本描述分析；\n\nevent-level：从长视频中裁剪出的异常事件片段，包括单个异常事件的文本描述分析；\n\nclip-level：从event中进一步裁剪出的视频片段，包括视频片段的文本描述。\n\nHIVAU-70k中的指令数据包括视频描述、异常判断、异常描述和异常分析等任务，为视频异常理解多模态大模型提供了丰富多样的数据来源。\n\n这样的多层级指令数据集是怎么构造的呢？从一个未裁剪的长视频开始，需要依次经过以下三个步骤：\n\n分层视频解耦（Hierarchical Video Decoupling）：将video-level视频中的异常事件标注并裁剪出来，得到event-level视频, 再对event-level视频进一步平均切分得到clip-level视频；\n\n分层自由文本注释（Hierarchical Free-text Annotation）：对于clip-level视频，使用人工或caption model得到clip caption；对于event-level视频，结合所包含的clip-level caption和异常类别，提示LLM得到事件总结；对于video-level视频，结合所包含的事件总结和异常类别，提示LLM得到视频总结；\n\n层次化指令数据构建（Hierarchical Instruction Data Construction）：针对不同层级的视频及其文本标注，设计不同的任务，构造任务相关的问题并与文本注释组合，得到最终的指令数据。\n\n\n与其他相关的数据集相比，HIVAU-70k不仅有数量上的优势，还提供了多粒度的文本标注以及时序上的异常边界标注。\n\n动态稀疏采样的视频异常理解模型\n长视频异常理解在使用大型语言模型（LLMs）或视觉语言模型（VLMs）时，常因帧冗余问题而受到限制，导致异常检测的准确性变得复杂。\n以往的VAU（视频异常理解）方法难以聚焦异常。\n例如，密集窗口采样方法会增加大量冗余帧的计算量，而均匀帧采样方法常常错过关键异常帧，使其应用范围局限于短视频。\n为此，作者提出了Anomaly-focused Temporal Sampler (ATS)，并将其集成到VLM中，通过在HIVAU-70k上的指令微调，构建了Holmes-VAU模型。\n异常帧通常比正常帧包含更多信息，并表现出更大的变化，基于这一观察，作者设计了一种采样策略，在异常分数较高的区域采样更多帧，同时在分数较低的区域减少采样。\n为实现非均匀采样，作者提出了一种“密度感知采样器”（density-aware sampler），用于从总共T个输入帧中选择N个帧。\n具体来说，作者将异常分数S视为概率质量函数，并首先沿时间维度累积它们，得到累积分布函数（CDF），记为 S_cumsum：\n\n接着，在累积轴上均匀采样N个点，并将这些点映射到累积分布S_cumsum上。相应的时间轴上的N个时间戳会被映射到最接近的帧索引，最终形成采样的帧索引集合G。\n\n△Holmes-VAU模型框架图\n下入展示了测试集上的异常分数和采样帧的可视化结果。这些结果表明了ATS的准确异常检测能力，最终输入到多模态大模型的采样帧也集中于异常区域。\n\n△Anomly-focused Temporal Sampler (ATS) 异常分数及采样帧示意图\n实验结果\n异常推理性能评估\n作者在HIVAU-70k的测试集上，将模型输出的推理文本与注释的真实文本进行比较，计算了包括BLEU、CIDEr、METEOR和ROUGE等指标来衡量模型输出的异常理解文本质量。\n与通用多模态大模型对比，Holmes-VAU在各种时序粒度的视频异常理解上都展现出显著优势。\n\n在多层级标注中，对不同层级指令数据集的组合，可以观察发现，单一层级的标注只能提升单一层级任务的性能。\n不同层级的标注组合可以相互补充，实现从clip-level的基础视觉感知, 到event-level单一异常事件的分析，再到video-level的长时序异常总结和推理等方面的全面提升，达到更细粒度和完整的多模态异常空间对齐。\n\n对于非均匀采样器的作用，作者也对比了不同帧采样方式，包括本文提出的ATS、之前方法用的Top-K采样和Uniform采样。\n结果表明在相同的采样帧数下，ATS展现出更优越的长视频异常理解能力，这是由于Top-K采样过于集中在异常帧，忽略了视频上下文的参考，Uniform采样则容易忽略关键的异常帧。\n而作者提出的ATS则有效结合了这两者的优势，关注异常帧的同时，能够保留部分上下文帧的采样。\n\n定性比较\n下图对比了Holmes-VAU和其他MLLM输出的异常分析文本，Holmes-VAU表现出更准确的异常判断和分析能力，同时对长视频也表现出更完整的异常总结能力。\n\n△Holmes-VAU和其他MLLM的异常分析文本质量对比\n论文：\nhttps://arxiv.org/abs/2412.06171\n代码：\nhttps://github.com/pipixin321/HolmesVAU\n\n\n\n\n一键三连「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n\n\n\n\n\n\n\n\n— 完 —\n\n\n\n\n学术投稿请于工作日发邮件到：\nai@qbitai.com\n标题注明【投稿】，告诉我们：\n你是谁，从哪来，投稿内容‍\n附上论文/项目主页链接，以及联系方式哦\n我们会（尽量）及时回复你\n\n\n\n\n\n\n\n🌟 点亮星标 🌟\n科技前沿进展每日见\n\n\n\n\n\n\n\n    \n\n    \n    \n文章原文",
          "guid": "http://www.jintiankansha.me/t/qRBCK99yL1",
          "categories": [
            "无"
          ],
          "isoDate": "2025-04-08T04:46:00.000Z"
        }
      },
      {
        "json": {
          "title": "速戳报名 ‼️ MSRA华为百度齐聚，AIGC峰会等你来AI",
          "link": "http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247786774&idx=3&sn=a24e112e2cc2e00a8c7749183c776934&chksm=e97d87770ec19bbed4fa23050fe9c9214066504181a90efaa597d18427f7b493a40b767b5f13&scene=0#rd",
          "pubDate": "Tue, 08 Apr 2025 12:46:00 +0800",
          "enclosure": {
            "url": "http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDlnKPvty2fvyx07VGZ9hyuj6UEqoZzGAyvfzWVrUiavVL1b6Nc7LG9PeVIL9l6icDZZIpV0pDX2qWA/0?wx_fmt=jpeg",
            "length": "0",
            "type": "image/jpeg"
          },
          "content": "\n\n    \n\n    \n\n    \n         <div class=\"rich_media_content\" id=\"js_content\"><h5 style=\"font-family: ExtraLight-0;background-color: rgb(248, 248, 248);border-radius: 3px;overflow-wrap: break-word;margin: 10px 0px 30px;padding: 10px;color: rgb(51, 51, 51);font-size: 14px;text-align: left;line-height: 2;font-weight: 300;word-break: break-all !important;letter-spacing: 1px !important;word-spacing: 1px !important;\" data-pm-slice=\"0 0 []\"><span leaf=\"\">组委会 发自 凹非寺</span><span leaf=\"\"><br></span><span leaf=\"\">量子位｜公众号 QbitAI</span></h5><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">4月16日</span><span leaf=\"\" style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;\">，北京金茂万丽酒店，</span><span leaf=\"\" style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;\"><span textstyle=\"\" style=\"color: rgb(0, 153, 127);font-weight: bold;\">第三届中国AIGC产业峰会</span></span><span leaf=\"\" style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;\">就要来啦！</span><span leaf=\"\" data-pm-slice=\"1 1 [\" para rgb arial left>观众报名通道<span textstyle=\"\" style=\"font-size: 16px;\">已开启 👉 </span><a class=\"weapp_text_link js_weapp_entry\" data-miniprogram-type=\"text\" style=\"\" data-miniprogram-appid=\"wxe8a015203d67e81c\" data-miniprogram-path=\"pages/event-detail/event-detail?id=9798007926900\" data-miniprogram-nickname=\"活动行\" data-miniprogram-servicetype=\"\" data-miniprogram-applink=\"\"><span textstyle=\"\" style=\"font-size: 16px;\">点击报名参会</span></a></span></p><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">今年峰会主题是</span><span leaf=\"\" style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;\"><span textstyle=\"\" style=\"color: rgb(0, 153, 127);font-weight: bold;\">「万物皆可AI」</span></span><span leaf=\"\">，我们看到随着基础模型的深入发展，更多的</span><span leaf=\"\" style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;\"><span textstyle=\"\" style=\"color: rgb(0, 153, 127);font-weight: bold;\">AI新产品</span></span><span leaf=\"\">、</span><span leaf=\"\" style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;\"><span textstyle=\"\" style=\"color: rgb(0, 153, 127);font-weight: bold;\">新物种</span></span><span leaf=\"\">正在涌现。</span></p><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-weight: bold;\">我们希望让更多的AI落地被看见，让更多人用上AI、用好AI，与AI一同加速成长。</span></span></p><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\" data-pm-slice=\"0 0 []\"><span leaf=\"\" style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;\">为此，我们邀请到了</span><span leaf=\"\" style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;\">百度、</span><span style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;\"><span leaf=\"\">华为、AWS、MSRA、</span></span><span leaf=\"\" style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;\">无问芯穹、数势科技、面壁智能、生数科技等十数位AI领域创变</span><span leaf=\"\">者，一起聊聊</span><span leaf=\"\" data-pm-slice=\"1 1 [\" para rgb arial left>AI算力、AI Agent、AI安全、AI+教育，以及更多热门AI话题。</span></p><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\" data-pm-slice=\"0 0 []\"><span leaf=\"\" data-pm-slice=\"1 1 [\" para rgb arial left>峰会正在火热报名中 🔥 <a class=\"weapp_text_link js_weapp_entry\" data-miniprogram-type=\"text\" style=\"font-size: 16px;\" data-miniprogram-appid=\"wxe8a015203d67e81c\" data-miniprogram-path=\"pages/event-detail/event-detail?id=9798007926900&amp;channel_code=4328363122557\" data-miniprogram-nickname=\"活动行\" data-miniprogram-servicetype=\"\" data-miniprogram-applink=\"\">点击即刻报名参会</a>！你也可以扫描下方二维</span><span style=\"color: rgb(64, 64, 64);font-family: DeepSeek-CJK-patch, Inter, system-ui, -apple-system, \" system-ui ui roboto sans ubuntu cantarell neue oxygen sans-serif normal start none initial inline data-pm-slice=\"0 0 []\"><span leaf=\"\" style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;\">码，</span><span style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;\"><strong><span leaf=\"\" style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;\"><span textstyle=\"\" style=\"color: rgb(0, 153, 127);font-weight: bold;\">报名参会</span></span></strong></span><span leaf=\"\" style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;\">或</span><strong style=\"font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;box-sizing: border-box !important;overflow-wrap: break-word !important;display: inline !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;\"><span leaf=\"\" style=\"font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;display: inline !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;\"><span textstyle=\"\" style=\"color: rgb(0, 153, 127);font-weight: bold;\">预约直播</span></span></strong><span leaf=\"\" style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;\"> ⬇️</span></span></p><section style=\"text-align: center;margin-top: 16px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.4\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" data-imgfileid=\"100299483\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDLO9mk1pHk6mQYicNWntedcOqbvl8TGiadXyqM4bIibf8RSwTYIXTF1S87e5de8y6ArlPibiaGKL9CHiaw/640?wx_fmt=jpeg&amp;from=appmsg\" style=\"max-width: 600px\"></section><h2 style=\"text-align: left;margin: 40px 0px;line-height: 1.5;font-weight: bold;padding-left: 15px;word-break: break-all !important;border-left: 6px solid rgb(0, 153, 127) !important;font-size: 20px !important;letter-spacing: 1px !important;word-spacing: 1px !important;\"><span leaf=\"\">新增嘉宾</span></h2><section style=\"text-align: center;margin-left: 48px;margin-right: 48px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.7777777777777777\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"100302996\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCj15cgGmoLoKIO9prnjwuiccdlVvvOLE6QruHaKFdvicz3KiaaHDjP026VSuMv1OB2uK1ZR90Tb6Oqw/640?wx_fmt=jpeg&amp;from=appmsg\" style=\"max-width: 600px\"></section><section style=\"text-align: center;\"><font color=\"#00997f\"><b><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;\">刘炜清</span></span><span leaf=\"\"><br></span></b></font><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">微软亚洲研究院首席研究员</span></span></section><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">刘炜清，微软亚洲研究院机器学习组首席研究员。他领导的团队多年来专注于人工智能在金融领域的应用研究。他目前的研究重点是RD-Agent（https://github.com/microsoft/rd-agent）和MarS（https://github.com/microsoft/mars）项目。他在顶级会议上发表了数十篇论文。</span></p><h2 style=\"text-align: left;margin: 40px 0px;line-height: 1.5;font-weight: bold;padding-left: 15px;word-break: break-all !important;border-left: 6px solid rgb(0, 153, 127) !important;font-size: 20px !important;letter-spacing: 1px !important;word-spacing: 1px !important;\"><span leaf=\"\">最新嘉宾阵容在此</span></h2><section><span style=\"color: rgb(64, 64, 64);font-family: DeepSeek-CJK-patch, Inter, system-ui, -apple-system, \" system-ui ui roboto sans ubuntu cantarell neue oxygen sans-serif normal start none initial inline data-pm-slice=\"0 0 []\"><section style=\"text-align: center;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"6.718196457326892\" data-s=\"300,640\" data-type=\"png\" data-w=\"1242\" type=\"block\" data-imgfileid=\"100302997\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCj15cgGmoLoKIO9prnjwuic0WicicBJUJMIN6nbyD1uG3dcKgFK5AuONFibD2mqavsOaLGianCQ9CDbJA/640?wx_fmt=jpeg&amp;from=appmsg\" style=\"max-width: 600px\"></section><section style=\"font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\" style=\"font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;display: inline !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;\">了解更多嘉宾详情：</span><span leaf=\"\" style=\"font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;-webkit-text-stroke-width: 0px;text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;box-sizing: border-box !important;overflow-wrap: break-word !important;display: inline !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;\"><br></span></section><section style=\"text-align: center;text-indent: 0em;margin-left: 48px;margin-right: 48px;\" nodeleaf=\"\" data-pm-slice=\"1 2 []\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.7777777777777777\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" data-imgfileid=\"100299256\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBL4sic8LkrgQ1ibRG2q7yN21iafMwIwicUTBds00ibE9gbRasNxlLeFhlT07P5YcXQPmgSBQOQ15yxMFw/640?wx_fmt=jpeg&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">阮瑜</span><span leaf=\"\"><br></span></strong><strong><span leaf=\"\">百度副总裁</span></strong></p><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">阮瑜，现任百度副总裁，百度智能云应用产品事业部总经理。阮瑜从事互联网产品运营工作十余年，是产品、运营、品牌营销等多个领域的行业专家，管理经验丰富，带领团队实现了多项业务突破和创新方向的变革。</span></p><section style=\"text-align: center;margin-left: 48px;margin-right: 48px;\" nodeleaf=\"\" data-pm-slice=\"1 2 []\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.7777777777777777\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"100302136\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtA3iajRcMfg14CPfWvPe4cTNZupia7mrXb7oJV4IJB6r0k33eTb7tFdlb9Yd4BKfruw9GuVBnEZnS8Q/640?wx_fmt=jpeg&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"font-size: 16px;font-family: Arial;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><font color=\"#00997f\"><b><span leaf=\"\">王辉</span><span leaf=\"\"><br></span></b></font><b><span leaf=\"\">华为NCE数据通信领域总裁</span></b></p><p style=\"font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">王辉，华为NCE数据通信领域总裁。负责华为数据通信产品线人工智能的战略规划、产业布局、技术研发和产品运营，致力于打造业界领先的AI自动驾驶网络解决方案，带领团队发布了业界首个网络大模型NetMaster产品。</span></p><section style=\"text-align: center;margin-left: 48px;margin-right: 48px;\" nodeleaf=\"\" data-pm-slice=\"1 2 []\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.7777777777777777\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" data-imgfileid=\"100299265\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBL4sic8LkrgQ1ibRG2q7yN218siaWCUIqQhYGKL79WT6ENHgBZBmibngibBuJIhj9icezh5N7MBvibMyOqA/640?wx_fmt=jpeg&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">夏立雪</span><span leaf=\"\"><br></span></strong><strong><span leaf=\"\">无问芯穹联合创始人、CEO</span></strong></p><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">夏立雪是无问芯穹联合创始人兼首席执行官，学士、博士均毕业于清华大学电子工程系。</span><span leaf=\"\"><br></span><span leaf=\"\">他入选AI2000人工智能全球最具影响力学者榜单(芯片方向Top100)、斯坦福学科Top2%科学家榜单，任上海市徐汇区第十七届人大代表、第十一届青联委员，获宁夏算力枢纽人工智能领域领军人才、2024福布斯中国新时代颠覆力创始人等表彰。</span><span leaf=\"\"><br></span><span leaf=\"\">夏立雪长期致力于深度学习系统的设计方法学研究，已发表30余篇学术论文，谷歌学术引用2800余次。他在大语言模型的压缩加速、生成式AI模型芯片等领域的相关工作，是世界首个面向深度学习语音合成领域的定制化硬件设计，在国际上处于领先地位。</span><span leaf=\"\"><br></span><span leaf=\"\">在夏立雪的带领下，无问芯穹已发展成为AI算力领域最具代表性的高新技术企业之一。</span></p><section style=\"text-align: center;margin-left: 48px;margin-right: 48px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.7777777777777777\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" data-imgfileid=\"100299264\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBL4sic8LkrgQ1ibRG2q7yN21ic7WM2iawA0OB3AUeGFbk3bYfpicdQ5vkMuLdDdo1t11Qcpawv1D31Qtg/640?wx_fmt=jpeg&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">谭李</span><span leaf=\"\"><br></span></strong><strong><span leaf=\"\">数势科技联合创始人</span></strong></p><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">谭李，数势科技联合创始人。他带领数势团队打造了行业首个企业级数据智能分析AI Agent - SwiftAgent，服务了中金、平安、沃尔玛、宝洁、博世等众多行业领军企业的数字化能力建设，在数字化转型规划、指标体系设计、指标平台建设、数据价值业务化方面有丰富经验。曾任职于京东技术与数据中台、百度深度学习实验室、德勤管理咨询。</span></p><section style=\"text-align: center;margin-left: 48px;margin-right: 48px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.7777777777777777\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" data-imgfileid=\"100299257\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBL4sic8LkrgQ1ibRG2q7yN21GbgX8PPvo9H7FN3SOOpU1bxBEhUDU26Kk5zib2qxIickL5D4A64iaozbA/640?wx_fmt=jpeg&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">喻友平</span><span leaf=\"\"><br></span></strong><strong><span leaf=\"\">中关村科金总裁</span></strong></p><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">喻友平，北京中关村科金技术有限公司总裁， 中国(广西)东盟大模型应用实验室专家顾问委员会特聘专家。</span><span leaf=\"\"><br></span><span leaf=\"\">毕业于华中科技大学并获得博士学位，北京大学光华管理学院EMBA。具有17年领先科技公司的产品研发和管理经验，在业界有着广泛的影响力。</span><span leaf=\"\"><br></span><span leaf=\"\">原百度智能云副总裁，先后负责百度商业搜索、百度统计、百度商业增值产品、大数据系列产品、Al开放平台、深度学习平台、Al商业产品、百度智能云大模型应用产品研发和运营。在云和AI的ToB商业体系搭建、战略、产品、销售、生态管理等方面，有全面深入的运营和管理经验。</span></p><section style=\"text-align: center;margin-left: 48px;margin-right: 48px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.7777777777777777\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" data-imgfileid=\"100299628\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDS51xLIsPXUu0kpjUwbn3fskFSLOn6xZagOcW039p1nCgDqn5TmJfCLCIMXhHhAfmFHVQ0KZWOqw/640?wx_fmt=jpeg&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">姚欣</span><span leaf=\"\"><br></span></strong><strong><span leaf=\"\">PPIO派欧云联合创始人兼CEO</span></strong></p><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">姚欣，PPIO派欧云联合创始人、董事长兼CEO。</span><span leaf=\"\"><br></span><span leaf=\"\">2004 年，华中科技大学读研期间休学创业。作为P2P-Streaming协议的发明人，创办了覆盖全球4.5亿用户的网络电视平台PPTV，期间获得6轮国际资本投资，并于2014年将公司出售。2016-2018年，在硅谷访学期间，联合多名企业家共同发起中国首家聚焦科技创业的Non-Profit组织AI创业营。同时，作为蓝驰创投中国的投资合伙人，用投资和孵化的形式，积极参与了正在发生的新一轮科技创新浪潮。</span><span leaf=\"\"><br></span><span leaf=\"\">2018年，和原PPTV首席架构师王闻宇，共同创办PPIO派欧云进行二次创业。聚焦在分布式云计算领域为一系列头部互联网、AIGC、音视频公司提供大规模AI推理、音视频传输、实时云渲染等分布式云服务。</span></p><section style=\"text-align: center;margin-left: 48px;margin-right: 48px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.7777777777777777\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" data-imgfileid=\"100299262\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBL4sic8LkrgQ1ibRG2q7yN21Ro0QxovT4HSm3bllja67tsPFYlbQmLrxGA6Ey7e20wl4NDcyP5tGjg/640?wx_fmt=jpeg&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">田天</span><span leaf=\"\"><br></span></strong><strong><span leaf=\"\">瑞莱智慧创始人、CEO</span></strong></p><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">田天，瑞莱智慧CEO，清华大学计算机系本硕博，在校期间荣获清华学子最高荣誉“特等奖学金”及“西贝尔学者”称号，2021年度吴文俊人工智能优秀青年奖获得者，2023年荣获第五届“杰出工程师青年奖”。</span></p><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">作为AI领域青年科学家入选2021年北京市科技新星计划、福布斯中国“30岁以下精英榜” ，同时担任北京市海淀区工商联副主席、新一代人工智能产业技术创新战略联盟专家委员。</span></p><section style=\"text-align: center;margin-left: 48px;margin-right: 48px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.7777777777777777\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" data-imgfileid=\"100299267\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBL4sic8LkrgQ1ibRG2q7yN21GJE5hjTKQiaxhdyb1F1rUxsBWlYfva4mogqDnFOibCmUQvYcYIicoQqibw/640?wx_fmt=jpeg&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">陈建华</span><span leaf=\"\"><br></span></strong><strong><span leaf=\"\">粉笔CTO</span></strong></p><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">陈建华，粉笔CTO，2012年毕业于中国科学院，深耕产品技术研发十余年，擅长大规模高性能系统的架构设计和开发。</span><span leaf=\"\"><br></span><span leaf=\"\">2015年加入粉笔，始终践行“技术改变教育”的理念，致力于用前沿科技驱动在线教育创新。带领团队打造了粉笔 APP、低延迟互动直播系统、智能批改技术，并构建了集“教、学、练、评、测”于一体的个性化在线学习系统——精品班，助力数千万学员高效学习。</span><span leaf=\"\"><br></span><span leaf=\"\">2024年8月，团队成功推出国内首个职教领域垂类大模型，并发布面向C端的AI产品——粉笔AI老师，推动职业教育迈向智能化新时代。2025年，进一步探索AI原生的系统性培训课程——AI系统班，重新定义智能教育的边界。</span></p><section style=\"text-align: center;margin-left: 48px;margin-right: 48px;\" nodeleaf=\"\" data-pm-slice=\"1 2 []\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.7777777777777777\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"100302137\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtA3iajRcMfg14CPfWvPe4cTNae9JtSS0DhKl9N27pI8QxG1ia8pv8aibuGTukV2PcXhxpGVloJZsAib2Q/640?wx_fmt=jpeg&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"font-size: 16px;font-family: Arial;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><font color=\"#00997f\"><b><span leaf=\"\">李大海</span><span leaf=\"\"><br></span></b></font><b><span leaf=\"\">面壁智能联合创始人、CEO</span></b></p><p style=\"font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">李大海，面壁智能联合创始人、CEO。他具备丰富的企业组织领导、开发管理、产品商业化落地经验。曾任知乎合伙人兼CTO，以AI技术赋能知乎的内容业务，带来用户量和收入的高速增长，引领公司实现纽交所和联交所的双重独立上市。</span><span leaf=\"\"><br></span><span leaf=\"\">出任面壁智能CEO后，他带领面壁成为全球知名的端侧智能代表性企业。面壁智能凭借以小博大的模型特色在中国大模型「6+2」格局中占据一席之地，并且成功入选《财富》全球人工智能创新50强企业。</span></p><section style=\"text-align: center;margin-left: 48px;margin-right: 48px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.7777777777777777\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" data-imgfileid=\"100299665\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDS51xLIsPXUu0kpjUwbn3fyg6HuuNib1I6Wg4lJwA0NyJlaibcxd5uJWuPbhlg392FhqTxc3sdg9nw/640?wx_fmt=jpeg&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: center;margin: 20px 16px !important;min-height: 1.5em !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">廖谦</span><span leaf=\"\"><br></span></strong><strong><span leaf=\"\">生数科技产品副总裁</span></strong></p><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">廖谦，生数科技产品副总裁，Vidu产品负责人。</span><span leaf=\"\"><br></span><span leaf=\"\">本硕毕业于西安电子科技大学，深耕AI领域多年。</span><span style=\"text-indent: 0em;font-family: mp-quote, \" pingfang sc system-ui blinkmacsystemfont neue sans gb yahei ui arial sans-serif><span leaf=\"\">曾任职于字节跳动剪映&amp;Capcut和火山引擎业务，推动AI赋能内容创作。</span></span><span leaf=\"\">此前亦曾任职于腾讯云AI及天美游戏，具备丰富的产品研发、运营、商业化经验，覆盖ToB与ToC业务全链路。</span></p><section style=\"text-align: center;margin-left: 48px;margin-right: 48px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.7777777777777777\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"100302138\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtA3iajRcMfg14CPfWvPe4cTNADrjxzG94rVdxUCM3Xg62KqVGAsYcD435mMcibTJpm6TWNg3T1icaicVw/640?wx_fmt=jpeg&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"font-size: 16px;font-family: Arial;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><font color=\"#00997f\"><b><span leaf=\"\">贾朔</span><span leaf=\"\"><br></span></b></font><b><span leaf=\"\">趣丸科技副总裁</span></b></p><p style=\"font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">贾朔，趣丸科技副总裁，伦敦艺术大学硕士。贾朔带领团队孵化的唱鸭APP首次普及了无弦“弹唱”玩法，降低了“玩音乐”门槛，获得华为最佳应用、小米年度应用，入选文旅部“文化和旅游数字化创新实践十佳案例”。</span><span leaf=\"\"><br></span><span leaf=\"\">2024年，贾朔带领团队自研的全球首个多模态音乐生成大模型——天谱乐AI，荣获中国人工智能学会主办的第三届琶洲算法大赛全球总冠军。</span></p><section style=\"text-align: center;margin-left: 48px;margin-right: 48px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.7777777777777777\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"100302139\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtA3iajRcMfg14CPfWvPe4cTNqIupFh2IAuiaibMtZL1Yg7LYN0kv0KeJQTiaf2C9QIoxLicDQBHy2grR2A/640?wx_fmt=jpeg&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"font-size: 16px;font-family: Arial;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><font color=\"#00997f\"><b><span leaf=\"\">徐达峰</span><span leaf=\"\"><br></span></b></font><b><span leaf=\"\">蚂蚁集团平台智能体验技术负责人</span></b></p><p style=\"font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">徐达峰，现任蚂蚁集团平台智能体验技术团队负责人，文档平台技术负责人，负责平台工程和智能平台前端技术。他主导了前端智能研发体系WeaveFox，致力于通过AI驱动的前端研发范式革新，实现企业级研发效能的突破，持续推动前端工程领域智能化升级进程。同时，他也是AI全栈工程师和开源实践者，跨端测试框架Macaca，自动布局autoresponsive-react等开源项目作者。</span></p><section style=\"text-align: center;margin-left: 48px;margin-right: 48px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.7777777777777777\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"100302143\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtA3iajRcMfg14CPfWvPe4cTNLmP3nvo8Clico1JZNPVko6a3V3rKC82oEaEwEPVHeWkfKEiaNu3dX9XA/640?wx_fmt=jpeg&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"font-size: 16px;font-family: Arial;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\"><span textstyle=\"\" style=\"color: rgb(0, 153, 127);font-weight: bold;\">Troy Cui</span></span><span leaf=\"\"><br></span><span leaf=\"\"><span textstyle=\"\" style=\"font-weight: bold;\">亚马逊云科技大中华区数据及存储产品总监</span></span></p><section style=\"font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span data-pm-slice=\"0 0 []\"><span leaf=\"\" data-pm-slice=\"1 1 [\" para font-family: arial text-align: left letter-spacing: word-spacing: line-height: min-height: box-sizing: border-box overflow-wrap: break-word margin:>Troy Cui，亚马逊云科技大中华区数据及存储产品总监，负责全栈数据产品在大中华区的产品管理和市场拓展等工作。拥有丰富的系统架构、数据架构、企业级中间件及人工智能平台研发和工程化经验，在企业级平台总体技术架构和项目方案上有丰富的经验积累。</span><span leaf=\"\"><br></span><span leaf=\"\">曾负责数据产品、中间件及高性能深度学习计算平台的专项研发工作，并且主导过大数据和人工智能平台在大健康、生命科学、零售快销，游戏文娱、生产制造和金融等行业的设计和落地工作。</span></span></section><section style=\"text-align: center;margin-left: 48px;margin-right: 48px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.7777777777777777\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"100302140\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtA3iajRcMfg14CPfWvPe4cTN6wdvNjRErAb95IYB7icq04qDx7GhO9QHEmOBhiaXUh2WicwJYXAtkL23A/640?wx_fmt=jpeg&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"font-size: 16px;font-family: Arial;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><font color=\"#00997f\"><b><span leaf=\"\">张艺</span><span leaf=\"\"><br></span></b></font><b><span leaf=\"\">网易有道智能应用事业部负责人</span></b></p><p style=\"font-size: 16px;font-family: Arial;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;box-sizing: border-box !important;overflow-wrap: break-word !important;margin: 20px 16px !important;\"><span leaf=\"\">张艺，网易有道智能应用事业部负责人，有道词典业务负责人，有道高级产品总监。负责有道旗下多款智能应用的开发和运营，包括有道词典、有道翻译、Hi Echo、有道小P等，总用户量超10亿。</span></p><section style=\"text-align: center;margin-left: 48px;margin-right: 48px;\" nodeleaf=\"\" data-pm-slice=\"1 2 []\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.7777777777777777\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" data-imgfileid=\"100299685\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDS51xLIsPXUu0kpjUwbn3fE4czYtbC2nR4GVrzTvRO5OibM2zTSgxbKCYq0MiaMyGAxiaMaMshjVRUA/640?wx_fmt=jpeg&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong><span style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">高玉石</span></span></strong><span leaf=\"\"><br></span><strong><span leaf=\"\">轻松健康集团技术副总裁</span></strong></p><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">高玉石，轻松健康集团技术副总裁，资深大数据和人工智能专家，曾先后在中国顶级互联网企业及美股上市企业担任核心技术管理岗位。</span><span leaf=\"\"><br></span><span leaf=\"\">他主导研发并成功构建了轻松健康集团的核心技术平台AIcare，该平台以集团自主研发的健康基座大模型Dr.GPT为核心，广泛赋能集团旗下各大核心业务版块，持续巩固并扩大了集团在行业内的领先优势。</span></p><section style=\"text-align: center;margin-left: 48px;margin-right: 48px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.7777777777777777\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" data-imgfileid=\"100299266\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBL4sic8LkrgQ1ibRG2q7yN21sCAPGic2sYkRgmt6Rib82nGhh0MT0pia4aBeHWfHf0h8Z5QO0jh0s5UHA/640?wx_fmt=jpeg&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">刘斌新</span><span leaf=\"\"><br></span></strong><strong><span leaf=\"\">心影随形科技创始人、CEO</span></strong></p><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">心影随形科技创始人、CEO，前bilibili副总裁，360、百度高管。创业项目逗逗AI游戏伙伴覆盖中国、日本等众多地区，广受好评。心影随形荣获硅谷The information2024年度最具潜力创业公司TOP 50，亚洲TOP 4。</span></p><section style=\"text-align: center;margin-left: 48px;margin-right: 48px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.7777777777777777\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" data-imgfileid=\"100299259\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBL4sic8LkrgQ1ibRG2q7yN21ia0crR7czQ9y6Jzic1GjByNxibf5qPr9aox2JbWlp1fxp02ZU5GWiaiaKsA/640?wx_fmt=jpeg&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">赵充</span><span leaf=\"\"><br></span></strong><strong><span leaf=\"\">像素绽放PixelBloom(AiPPT.com)CEO</span></strong></p><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">赵充，像素绽放PixelBloom(AiPPT.com)CEO ，微梦传媒董事长。清华大学五道口金融学院EMBA，北京交通大学硕士研究生导师，胡润U40，YPO北京分会会长，EO北京分会会长。</span><span leaf=\"\"><br></span><span leaf=\"\">2011年创办微梦传媒，服务500强企业，2016年新三板挂牌，并入选创新层。</span><span style=\"color: rgb(0, 0, 0);font-family: Arial;font-size: 16px;letter-spacing: 1px;text-align: left;word-spacing: 1px;background-color: rgb(255, 255, 255);\"><span leaf=\"\">微梦传媒是国家级⾼新技术企业，中关村⾼新技术企业，北京⽂化产业百强⺠营企业，北京专精特新“⼩巨⼈”企业。</span></span><span leaf=\"\">2017年孵化365微信编辑器。</span><span leaf=\"\"><br></span><span leaf=\"\">2018年孵化爱设计，并拆分独立融资，先后获得心元资本、A股上市公司视觉中国、神策数据、信天创投、策源创投、亚杰基金、智谱AI基金、36氪、小米联合创始人王川、北京市人工智能产业基金等机构投资。</span><span leaf=\"\"><br></span><span leaf=\"\">2023年推出AIGC产品：AiPPT.cn(国内)/AiPPT.com(海外)，目前是国内该赛道创业公司第一。</span></p><section style=\"text-align: center;margin-left: 48px;margin-right: 48px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.7777777777777777\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" data-imgfileid=\"100299261\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBL4sic8LkrgQ1ibRG2q7yN21TTzbF17YN46NG6UQUHmW39Sibm3vNuNBfytQIDj01EMELPCmjkT6aFg/640?wx_fmt=jpeg&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: center;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">一休</span><span leaf=\"\"><br></span></strong><strong><span leaf=\"\">狸谱App负责人</span></strong></p><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;min-height: 1.5em !important;margin: 20px 16px !important;\"><span leaf=\"\">一休，上海狸谱科技负责人，阶跃星辰生态合作伙伴。前字节跳动抖音特效、剪映产品负责人；前哔哩哔哩大动画业务负责人。</span></p></span></section><h2 style=\"text-align: left;margin: 40px 0px;line-height: 1.5;font-weight: bold;padding-left: 15px;word-break: break-all !important;border-left: 6px solid rgb(0, 153, 127) !important;font-size: 20px !important;letter-spacing: 1px !important;word-spacing: 1px !important;\"><span leaf=\"\">4月16日，欢迎报名参会 🙌</span></h2><p style=\"font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;margin: 20px 16px !important;min-height: 1.5em !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;\"><span style=\"color:#00997f;\"><strong><span leaf=\"\">时间</span></strong></span><span style=\"color: rgb(0, 0, 0);\"><span leaf=\"\">：2025年4月16日 </span><span leaf=\"\"><br></span><strong style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">地点</span></strong><span leaf=\"\">：北京·金茂万丽酒店</span></span></p><p style=\"font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;margin: 20px 16px !important;min-height: 1.5em !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;\"><span style=\"color: rgb(0, 0, 0);\"><span leaf=\"\">现在，中国AIGC产业峰会已经开启报名，欢迎点击链接报名</span></span><strong><span style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">线下参会</span></span></strong><span style=\"color: rgb(0, 0, 0);\"><span leaf=\"\"> 🎡</span></span></p><section><section nodeleaf=\"\"><mp-common-miniprogram class=\"js_uneditable custom_select_card mp_miniprogram_iframe\" data-pluginname=\"insertminiprogram\" data-miniprogram-path=\"pages/event-detail/event-detail?id=9798007926900&amp;channel_code=4328363122557\" data-miniprogram-nickname=\"活动行\" data-miniprogram-avatar=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/lpsJPmQ5Iy4y4klOyOMdiaI72oBBkK3L1thoDCDTuibKO9VZKJefAmKG9eHibKM86RrJgLG10fkLVjfPxYe6Gb3FA/640?wx_fmt=png&amp;wxfrom=200\" data-miniprogram-title=\"报名参会！中国AIGC产业峰会「万物皆可AI」\" data-miniprogram-imageurl=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDLO9mk1pHk6mQYicNWntedcSKs2JhbwG2bUMmlzhgrckXBB6ib8s0ABNCCEqcNibZvKJ17fBJc365tg/0?wx_fmt=jpeg\" data-miniprogram-type=\"card\" data-miniprogram-servicetype=\"0\" data-miniprogram-appid=\"wxe8a015203d67e81c\" data-miniprogram-imageurlback=\"http%3A%2F%2Fmmbiz.qpic.cn%2Fmmbiz_jpg%2FYicUhk5aAGtDLO9mk1pHk6mQYicNWntedcVvaOmM6W6CwNkLgqtDZCbfjxyHWuKlyh1KgkDRwBicUqCia44lU4lKVw%2F0%3Fwx_fmt%3Djpeg\" data-miniprogram-cropperinfo=\"%7B%22c%22%3A%7B%22x%22%3A0%2C%22y%22%3A0%2C%22x2%22%3A245%2C%22y2%22%3A196%2C%22w%22%3A245%2C%22h%22%3A196%7D%7D\"></mp-common-miniprogram></section></section><p style=\"font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;margin-top: 16px;margin-right: 16px !important;margin-bottom: 20px !important;margin-left: 16px !important;min-height: 1.5em !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;\"><span leaf=\"\">峰会也将同步在</span><span style=\"color: rgb(0, 153, 127);\"><strong><span leaf=\"\">线上直播</span></strong></span><span leaf=\"\">，点击下方按钮一键预约 🌟</span><span leaf=\"\"><br></span></p><section class=\"channels_iframe_wrp\" nodeleaf=\"\"><mp-common-videosnap class=\"js_uneditable custom_select_card channels_live_iframe\" data-pluginname=\"mpvideosnap\" data-headimgurl=\"https://wx.qlogo.cn/finderhead/PiajxSqBRaEJvvu3eKhq5l1Oib73Q3wYO4z4P6LJAibzpRjCiaq6aREU1A/0\" data-username=\"v2_060000231003b20faec8c7ea8e10c0d0cc02e535b0777911f2a26aa13518c7c2032ad76804d2@finder\" data-nickname=\"量子位\" data-desc=\"将在04月16日 09:15 直播\" data-type=\"live\" data-intro=\"2025 中国AIGC产业峰会\" data-noticeid=\"finderlivenotice-v2_060000231003b20faec8c7ea8e10c0d0cc02e535b0777911f2a26aa13518c7c2032ad76804d2@finder-1741862612596667-534079308\" data-status=\"0\"></mp-common-videosnap></section><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;margin: 20px 16px !important;min-height: 1.5em !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;\"><strong style=\"color: rgb(0, 0, 0);font-family: Arial;font-size: 16px;letter-spacing: 1px;text-align: left;word-spacing: 1px;\"><span style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">AI如何用起来？</span></span></strong><span style=\"color: rgb(0, 153, 127);\"><span style=\"color: rgb(0, 0, 0);font-family: Arial;font-size: 16px;letter-spacing: 1px;text-align: left;word-spacing: 1px;background-color: rgb(255, 255, 255);\"><span leaf=\"\">一起来中国AIGC产业峰会来寻找回答吧 🙋🏻‍♀️</span></span></span></p><section style=\"margin-bottom: 0px;\"><section><section><p><span leaf=\"\"><br></span></p><section style=\"margin-top: 10px;margin-bottom: 10px;color: rgb(62, 62, 62);font-size: 16px;letter-spacing: 0.578px;text-align: right;justify-content: flex-end;display: flex;flex-flow: row;\"><section style=\"padding-right: 10px;display: inline-block;width: auto;vertical-align: middle;align-self: center;flex: 0 0 auto;min-width: 5%;height: auto;\"><section style=\"text-align: justify;font-size: 12px;\"><p style=\"text-align: right;\"><strong><span leaf=\"\">一键三连</span></strong><span style=\"color: rgb(0, 153, 127);\"><strong><span leaf=\"\">「点赞」「转发」「小心心」</span></strong></span></p><p style=\"text-align: right;\"><strong><span leaf=\"\">欢迎在评论区留下你的想法！</span></strong></p></section><section style=\"transform: perspective(0px);transform-style: flat;\"><section style=\"margin-top: 5px;margin-bottom: 10px;transform: rotateY(180deg);\"><section style=\"width: 201.828px;height: 5px;background-image: linear-gradient(90deg, rgba(0, 153, 127, 0.5) 13%, rgba(235, 25, 24, 0) 100%);\"><svg viewbox=\"0 0 1 1\" style=\"float:left;line-height:0;width:0;vertical-align:top;\"></svg></section></section></section></section></section><section style=\"margin-top: 15px;margin-bottom: 25px;color: rgb(62, 62, 62);font-size: 16px;letter-spacing: 0.578px;opacity: 0.8;\"><section style=\"text-align: center;\"><p><span style=\"font-size: 17px;\"><span leaf=\"\">— </span><strong><span leaf=\"\">完</span></strong><span leaf=\"\"> —</span></span></p></section></section></section></section><section style=\"font-size: 14px;line-height: 2;\"><p><span style=\"color: rgb(0, 153, 127);\"><strong><span leaf=\"\">速抢席位！</span></strong></span><span style=\"color: rgb(0, 153, 127);\"><strong><span leaf=\"\">中国AIGC产业峰会</span></strong></span><strong><span leaf=\"\">观众报名通道已开启</span></strong><span leaf=\"\"> 🙋‍♀️</span></p><p style=\"\"><span leaf=\"\">最新嘉宾曝光啦</span><span style=\"font-size: 14px;letter-spacing: 0.578px;\"><span leaf=\"\"> 🔥 </span></span><span leaf=\"\">百度、</span><span style=\"font-family: \" pingfang sc system-ui neue sans gb yahei ui arial sans-serif rgb><span leaf=\"\">华为、AWS、MSRA、</span></span><span leaf=\"\">无问芯穹、数势科技、面壁智能、生数科技等十数位AI领域创变者将齐聚峰会，让更多人用上AI、用好AI，与AI一同加速成长～</span></p><p style=\"\"><strong><span style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">4月16日</span></span></strong><span leaf=\"\">，就在</span><strong><span style=\"color: rgb(0, 153, 127);\"><span leaf=\"\">北京</span></span></strong><span leaf=\"\">，</span><span style=\"font-size: 14px;letter-spacing: 0.578px;\"><span leaf=\"\">一起来深度求索AI怎么用</span></span><span style=\"font-size: 14px;letter-spacing: 0.578px;color: rgb(0, 153, 127);\"><strong><span leaf=\"\"> 🙌 <a class=\"weapp_text_link js_weapp_entry\" data-miniprogram-type=\"text\" style=\"font-size: 14px;\" data-miniprogram-appid=\"wxe8a015203d67e81c\" data-miniprogram-path=\"pages/event-detail/event-detail?id=9798007926900\" data-miniprogram-nickname=\"活动行\" data-miniprogram-servicetype=\"\" data-miniprogram-applink=\"\">点击报名参会</a></span></strong></span></p></section><section style=\"text-align: center;margin-top: 10px;margin-bottom: 10px;line-height: 0;\"><section style=\"vertical-align: middle;display: inline-block;line-height: 0;\"><span leaf=\"\"><br></span></section></section><section style=\"text-align: center;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.675\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"100303045\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDlnKPvty2fvyx07VGZ9hyu8rBiakbX6cHKkzliceLo6HU0xUhaPuQfUKndAdyynSwWW71lmPaVxFGw/640?wx_fmt=jpeg&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"\"><span leaf=\"\"><br></span></p><p style=\"\"><span leaf=\"\"><br></span></p><section style=\"font-size: 14px;color: rgb(0, 153, 127);\"><p style=\"text-align: center;\"><strong><span leaf=\"\">🌟 一键星标 🌟</span></strong></p><p style=\"text-align: center;\"><strong><span leaf=\"\">科技前沿进展每日见</span></strong></p></section><p style=\"\"><span leaf=\"\"><br></span></p><section class=\"mp_profile_iframe_wrp\"><span leaf=\"\"><mp-common-profile class=\"js_uneditable custom_select_card mp_profile_iframe\" data-pluginname=\"mpprofile\" data-nickname=\"量子位\" data-alias=\"QbitAI\" data-from=\"0\" data-headimg=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCEFSVW5ubo08Zfv1qB5iapricibTBdETkBNtolJxnSUib6UXhjWWz3aib8vETY00P2lKR1uG3qLHicSoWg/0?wx_fmt=png\" data-signature=\"追踪人工智能新趋势，关注科技行业新突破\" data-id=\"MzIzNjc1NzUzMw==\" data-is_biz_ban=\"0\" data-service_type=\"1\"></mp-common-profile></span></section></section><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;margin: 20px 16px !important;min-height: 1.5em !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;\"><span style=\"color: rgb(0, 153, 127);\"><span style=\"color: rgb(0, 0, 0);font-family: Arial;font-size: 16px;letter-spacing: 1px;text-align: left;word-spacing: 1px;background-color: rgb(255, 255, 255);\"><span leaf=\"\" data-pm-slice=\"1 1 [\" para arial rgb left><br></span></span></span></p><p style=\"color: rgb(0, 0, 0);font-family: Arial;background-color: rgb(255, 255, 255);font-size: 16px;text-align: left;margin: 20px 16px !important;min-height: 1.5em !important;letter-spacing: 1px !important;word-spacing: 1px !important;line-height: 2 !important;\"><span style=\"color: rgb(0, 153, 127);\"><span style=\"color: rgb(0, 0, 0);font-family: Arial;font-size: 16px;letter-spacing: 1px;text-align: left;word-spacing: 1px;background-color: rgb(255, 255, 255);\"><span leaf=\"\" data-pm-slice=\"1 1 [\" para arial rgb left>点击阅读原文，即刻报名峰会～</span></span></span></p><p style=\"display: none;\"><mp-style-type data-value=\"3\"></mp-style-type></p></div>\n    \n\n    \n        <br>\n        <div id=\"js_toobar3\" class=\"rich_media_tool\">\n            <a target=\"_blank\" href=\"https://www.huodongxing.com/event/9798007926900\" id=\"js_view_source\" class=\"media_tool_meta meta_primary\">阅读原文</a>\n        </div>\n    \n    <br>\n\n    \n        <a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&amp;mid=2247786774&amp;idx=3&amp;sn=a24e112e2cc2e00a8c7749183c776934&amp;chksm=e97d87770ec19bbed4fa23050fe9c9214066504181a90efaa597d18427f7b493a40b767b5f13&amp;scene=0#rd\" style=\"color: blue\" class=\"media_tool_meta meta_primary\">文章原文</a>\n        <br>\n    \n\n    \n\n    <img alt=\"\" width=\"1px\" height=\"1px\" class=\"\" style=\"width:1px;height:1px;display:none\" src=\"http://www.jintiankansha.me/rss_static/97720/tIcTcOJ7eN\">\n\n",
          "contentSnippet": "组委会 发自 凹非寺\n量子位｜公众号 QbitAI\n4月16日，北京金茂万丽酒店，第三届中国AIGC产业峰会就要来啦！观众报名通道已开启 👉 点击报名参会\n今年峰会主题是「万物皆可AI」，我们看到随着基础模型的深入发展，更多的AI新产品、新物种正在涌现。\n我们希望让更多的AI落地被看见，让更多人用上AI、用好AI，与AI一同加速成长。\n为此，我们邀请到了百度、华为、AWS、MSRA、无问芯穹、数势科技、面壁智能、生数科技等十数位AI领域创变者，一起聊聊AI算力、AI Agent、AI安全、AI+教育，以及更多热门AI话题。\n峰会正在火热报名中 🔥 点击即刻报名参会！你也可以扫描下方二维码，报名参会或预约直播 ⬇️\n\n新增嘉宾\n\n刘炜清\n微软亚洲研究院首席研究员\n刘炜清，微软亚洲研究院机器学习组首席研究员。他领导的团队多年来专注于人工智能在金融领域的应用研究。他目前的研究重点是RD-Agent（https://github.com/microsoft/rd-agent）和MarS（https://github.com/microsoft/mars）项目。他在顶级会议上发表了数十篇论文。\n最新嘉宾阵容在此\n\n\n了解更多嘉宾详情：\n\n\n阮瑜\n百度副总裁\n阮瑜，现任百度副总裁，百度智能云应用产品事业部总经理。阮瑜从事互联网产品运营工作十余年，是产品、运营、品牌营销等多个领域的行业专家，管理经验丰富，带领团队实现了多项业务突破和创新方向的变革。\n\n王辉\n华为NCE数据通信领域总裁\n王辉，华为NCE数据通信领域总裁。负责华为数据通信产品线人工智能的战略规划、产业布局、技术研发和产品运营，致力于打造业界领先的AI自动驾驶网络解决方案，带领团队发布了业界首个网络大模型NetMaster产品。\n\n夏立雪\n无问芯穹联合创始人、CEO\n夏立雪是无问芯穹联合创始人兼首席执行官，学士、博士均毕业于清华大学电子工程系。\n他入选AI2000人工智能全球最具影响力学者榜单(芯片方向Top100)、斯坦福学科Top2%科学家榜单，任上海市徐汇区第十七届人大代表、第十一届青联委员，获宁夏算力枢纽人工智能领域领军人才、2024福布斯中国新时代颠覆力创始人等表彰。\n夏立雪长期致力于深度学习系统的设计方法学研究，已发表30余篇学术论文，谷歌学术引用2800余次。他在大语言模型的压缩加速、生成式AI模型芯片等领域的相关工作，是世界首个面向深度学习语音合成领域的定制化硬件设计，在国际上处于领先地位。\n在夏立雪的带领下，无问芯穹已发展成为AI算力领域最具代表性的高新技术企业之一。\n\n谭李\n数势科技联合创始人\n谭李，数势科技联合创始人。他带领数势团队打造了行业首个企业级数据智能分析AI Agent - SwiftAgent，服务了中金、平安、沃尔玛、宝洁、博世等众多行业领军企业的数字化能力建设，在数字化转型规划、指标体系设计、指标平台建设、数据价值业务化方面有丰富经验。曾任职于京东技术与数据中台、百度深度学习实验室、德勤管理咨询。\n\n喻友平\n中关村科金总裁\n喻友平，北京中关村科金技术有限公司总裁， 中国(广西)东盟大模型应用实验室专家顾问委员会特聘专家。\n毕业于华中科技大学并获得博士学位，北京大学光华管理学院EMBA。具有17年领先科技公司的产品研发和管理经验，在业界有着广泛的影响力。\n原百度智能云副总裁，先后负责百度商业搜索、百度统计、百度商业增值产品、大数据系列产品、Al开放平台、深度学习平台、Al商业产品、百度智能云大模型应用产品研发和运营。在云和AI的ToB商业体系搭建、战略、产品、销售、生态管理等方面，有全面深入的运营和管理经验。\n\n姚欣\nPPIO派欧云联合创始人兼CEO\n姚欣，PPIO派欧云联合创始人、董事长兼CEO。\n2004 年，华中科技大学读研期间休学创业。作为P2P-Streaming协议的发明人，创办了覆盖全球4.5亿用户的网络电视平台PPTV，期间获得6轮国际资本投资，并于2014年将公司出售。2016-2018年，在硅谷访学期间，联合多名企业家共同发起中国首家聚焦科技创业的Non-Profit组织AI创业营。同时，作为蓝驰创投中国的投资合伙人，用投资和孵化的形式，积极参与了正在发生的新一轮科技创新浪潮。\n2018年，和原PPTV首席架构师王闻宇，共同创办PPIO派欧云进行二次创业。聚焦在分布式云计算领域为一系列头部互联网、AIGC、音视频公司提供大规模AI推理、音视频传输、实时云渲染等分布式云服务。\n\n田天\n瑞莱智慧创始人、CEO\n田天，瑞莱智慧CEO，清华大学计算机系本硕博，在校期间荣获清华学子最高荣誉“特等奖学金”及“西贝尔学者”称号，2021年度吴文俊人工智能优秀青年奖获得者，2023年荣获第五届“杰出工程师青年奖”。\n作为AI领域青年科学家入选2021年北京市科技新星计划、福布斯中国“30岁以下精英榜” ，同时担任北京市海淀区工商联副主席、新一代人工智能产业技术创新战略联盟专家委员。\n\n陈建华\n粉笔CTO\n陈建华，粉笔CTO，2012年毕业于中国科学院，深耕产品技术研发十余年，擅长大规模高性能系统的架构设计和开发。\n2015年加入粉笔，始终践行“技术改变教育”的理念，致力于用前沿科技驱动在线教育创新。带领团队打造了粉笔 APP、低延迟互动直播系统、智能批改技术，并构建了集“教、学、练、评、测”于一体的个性化在线学习系统——精品班，助力数千万学员高效学习。\n2024年8月，团队成功推出国内首个职教领域垂类大模型，并发布面向C端的AI产品——粉笔AI老师，推动职业教育迈向智能化新时代。2025年，进一步探索AI原生的系统性培训课程——AI系统班，重新定义智能教育的边界。\n\n李大海\n面壁智能联合创始人、CEO\n李大海，面壁智能联合创始人、CEO。他具备丰富的企业组织领导、开发管理、产品商业化落地经验。曾任知乎合伙人兼CTO，以AI技术赋能知乎的内容业务，带来用户量和收入的高速增长，引领公司实现纽交所和联交所的双重独立上市。\n出任面壁智能CEO后，他带领面壁成为全球知名的端侧智能代表性企业。面壁智能凭借以小博大的模型特色在中国大模型「6+2」格局中占据一席之地，并且成功入选《财富》全球人工智能创新50强企业。\n\n廖谦\n生数科技产品副总裁\n廖谦，生数科技产品副总裁，Vidu产品负责人。\n本硕毕业于西安电子科技大学，深耕AI领域多年。曾任职于字节跳动剪映&Capcut和火山引擎业务，推动AI赋能内容创作。此前亦曾任职于腾讯云AI及天美游戏，具备丰富的产品研发、运营、商业化经验，覆盖ToB与ToC业务全链路。\n\n贾朔\n趣丸科技副总裁\n贾朔，趣丸科技副总裁，伦敦艺术大学硕士。贾朔带领团队孵化的唱鸭APP首次普及了无弦“弹唱”玩法，降低了“玩音乐”门槛，获得华为最佳应用、小米年度应用，入选文旅部“文化和旅游数字化创新实践十佳案例”。\n2024年，贾朔带领团队自研的全球首个多模态音乐生成大模型——天谱乐AI，荣获中国人工智能学会主办的第三届琶洲算法大赛全球总冠军。\n\n徐达峰\n蚂蚁集团平台智能体验技术负责人\n徐达峰，现任蚂蚁集团平台智能体验技术团队负责人，文档平台技术负责人，负责平台工程和智能平台前端技术。他主导了前端智能研发体系WeaveFox，致力于通过AI驱动的前端研发范式革新，实现企业级研发效能的突破，持续推动前端工程领域智能化升级进程。同时，他也是AI全栈工程师和开源实践者，跨端测试框架Macaca，自动布局autoresponsive-react等开源项目作者。\n\nTroy Cui\n亚马逊云科技大中华区数据及存储产品总监\nTroy Cui，亚马逊云科技大中华区数据及存储产品总监，负责全栈数据产品在大中华区的产品管理和市场拓展等工作。拥有丰富的系统架构、数据架构、企业级中间件及人工智能平台研发和工程化经验，在企业级平台总体技术架构和项目方案上有丰富的经验积累。\n曾负责数据产品、中间件及高性能深度学习计算平台的专项研发工作，并且主导过大数据和人工智能平台在大健康、生命科学、零售快销，游戏文娱、生产制造和金融等行业的设计和落地工作。\n\n张艺\n网易有道智能应用事业部负责人\n张艺，网易有道智能应用事业部负责人，有道词典业务负责人，有道高级产品总监。负责有道旗下多款智能应用的开发和运营，包括有道词典、有道翻译、Hi Echo、有道小P等，总用户量超10亿。\n\n高玉石\n轻松健康集团技术副总裁\n高玉石，轻松健康集团技术副总裁，资深大数据和人工智能专家，曾先后在中国顶级互联网企业及美股上市企业担任核心技术管理岗位。\n他主导研发并成功构建了轻松健康集团的核心技术平台AIcare，该平台以集团自主研发的健康基座大模型Dr.GPT为核心，广泛赋能集团旗下各大核心业务版块，持续巩固并扩大了集团在行业内的领先优势。\n\n刘斌新\n心影随形科技创始人、CEO\n心影随形科技创始人、CEO，前bilibili副总裁，360、百度高管。创业项目逗逗AI游戏伙伴覆盖中国、日本等众多地区，广受好评。心影随形荣获硅谷The information2024年度最具潜力创业公司TOP 50，亚洲TOP 4。\n\n赵充\n像素绽放PixelBloom(AiPPT.com)CEO\n赵充，像素绽放PixelBloom(AiPPT.com)CEO ，微梦传媒董事长。清华大学五道口金融学院EMBA，北京交通大学硕士研究生导师，胡润U40，YPO北京分会会长，EO北京分会会长。\n2011年创办微梦传媒，服务500强企业，2016年新三板挂牌，并入选创新层。微梦传媒是国家级⾼新技术企业，中关村⾼新技术企业，北京⽂化产业百强⺠营企业，北京专精特新“⼩巨⼈”企业。2017年孵化365微信编辑器。\n2018年孵化爱设计，并拆分独立融资，先后获得心元资本、A股上市公司视觉中国、神策数据、信天创投、策源创投、亚杰基金、智谱AI基金、36氪、小米联合创始人王川、北京市人工智能产业基金等机构投资。\n2023年推出AIGC产品：AiPPT.cn(国内)/AiPPT.com(海外)，目前是国内该赛道创业公司第一。\n\n一休\n狸谱App负责人\n一休，上海狸谱科技负责人，阶跃星辰生态合作伙伴。前字节跳动抖音特效、剪映产品负责人；前哔哩哔哩大动画业务负责人。\n\n4月16日，欢迎报名参会 🙌\n时间：2025年4月16日 \n地点：北京·金茂万丽酒店\n现在，中国AIGC产业峰会已经开启报名，欢迎点击链接报名线下参会 🎡\n\n\n\n峰会也将同步在线上直播，点击下方按钮一键预约 🌟\n\n\nAI如何用起来？一起来中国AIGC产业峰会来寻找回答吧 🙋🏻‍♀️\n\n\n\n\n\n\n一键三连「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n\n\n\n\n\n\n— 完 —\n\n\n\n速抢席位！中国AIGC产业峰会观众报名通道已开启 🙋‍♀️\n最新嘉宾曝光啦 🔥 百度、华为、AWS、MSRA、无问芯穹、数势科技、面壁智能、生数科技等十数位AI领域创变者将齐聚峰会，让更多人用上AI、用好AI，与AI一同加速成长～\n4月16日，就在北京，一起来深度求索AI怎么用 🙌 点击报名参会\n\n\n\n\n\n\n\n\n\n\n🌟 一键星标 🌟\n科技前沿进展每日见\n\n\n\n\n\n\n\n点击阅读原文，即刻报名峰会～\n\n\n    \n\n    \n        \n阅读原文\n        \n文章原文",
          "guid": "http://www.jintiankansha.me/t/tIcTcOJ7eN",
          "categories": [
            "无"
          ],
          "isoDate": "2025-04-08T04:46:00.000Z"
        }
      }
    ],
    "新智元1": [
      {
        "json": {
          "title": "生图加入CoT，性能提升80%！微软港中文打造天才画手",
          "link": "http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652583537&idx=3&sn=7dffe32fc3b98e9b98aa4be08fbd4d36&chksm=f00803bad4887c9a267435fc6e3695d5415045c9aba3926eb9a50860d79999425dd8bd2b33b1&scene=0#rd",
          "pubDate": "Tue, 08 Apr 2025 12:00:00 +0800",
          "enclosure": {
            "url": "http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_jpg/UicQ7HgWiaUb0dvTBxhibYSBRocia5lqLS7b6egKJvNPpiaia19RDQcflpYia6GV63ckicia55vrrztK61F5luBYRHsEFWw/0?wx_fmt=jpeg",
            "length": "0",
            "type": "image/jpeg"
          },
          "content": "\n\n    \n\n    \n\n    \n         <div class=\"rich_media_content\" id=\"js_content\"><h3 data-mpa-powered-by=\"yiban.io\" style=\"margin: 0px;padding: 0px;outline: 0px;font-weight: 400;font-size: 16px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;letter-spacing: 0.544px;orphans: 2;text-align: justify;text-indent: 0px;text-transform: none;white-space: normal;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb visible><section data-tools=\"135编辑器\" data-id=\"88402\" style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;line-height: 27.2px;widows: 1;visibility: visible;\"><section data-tools=\"135编辑器\" data-id=\"88402\" style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;letter-spacing: 0.544px;line-height: 27.2px;visibility: visible;\"><section data-style=\"line-height: 1.8; text-align: justify; font-size: 15px; letter-spacing: 0px; color: rgb(117, 114, 114);white-space: normal;\" style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;\"><section style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;\"><section style=\"text-align: center;margin-bottom: 8px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.42578125\" data-s=\"300,640\" data-type=\"jpeg\" data-w=\"1280\" style=\"width:100%; max-width: 600px\" data-croporisrc=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_jpg/UicQ7HgWiaUb0dvTBxhibYSBRocia5lqLS7bOibycIB3fdf3qEqUo4b3sxwsYpPugH7E5JmacaUXQSJniculgP7zjibHg/0?wx_fmt=jpeg&amp;from=appmsg\" data-cropselx2=\"578\" data-cropsely2=\"247\" data-backw=\"578\" data-backh=\"246\" data-imgfileid=\"505097979\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_jpg/UicQ7HgWiaUb0dvTBxhibYSBRocia5lqLS7bOibycIB3fdf3qEqUo4b3sxwsYpPugH7E5JmacaUXQSJniculgP7zjibHg/640?wx_fmt=jpeg&amp;from=appmsg\"></span></section></section></section></section></section></h3><h3 style=\"margin: 0px;padding: 0px;outline: 0px;font-weight: 400;font-size: 16px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;letter-spacing: 0.544px;orphans: 2;text-align: justify;text-indent: 0px;text-transform: none;white-space: normal;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb visible><section data-tools=\"135编辑器\" data-id=\"88402\" style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;line-height: 27.2px;widows: 1;visibility: visible;\"><section data-tools=\"135编辑器\" data-id=\"88402\" style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;letter-spacing: 0.544px;line-height: 27.2px;visibility: visible;\"><section data-style=\"line-height: 1.8; text-align: justify; font-size: 15px; letter-spacing: 0px; color: rgb(117, 114, 114);white-space: normal;\" style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;\"><section style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;\"><section style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;\"><hr style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;font-size: 17px;letter-spacing: 0.544px;visibility: visible;\"><p style=\"margin: -1.2em 8px 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;clear: both;min-height: 1em;font-size: 17px;letter-spacing: 0.544px;line-height: 1.75em;visibility: visible;\"><span leaf=\"\"><br></span></p><p style=\"margin: -1.2em 8px 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;clear: both;min-height: 1em;font-size: 17px;letter-spacing: 0.544px;text-align: center;line-height: 1.75em;visibility: visible;\"><span style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;letter-spacing: 1px;visibility: visible;\"><strong style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;font-family: inherit;font-size: 1em;text-decoration: inherit;visibility: visible;\"><span style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;font-size: 18px;color: rgb(255, 255, 255);line-height: 1.4;font-family: inherit;font-weight: inherit;text-decoration: inherit;background-color: rgb(127, 127, 127);visibility: visible;\"><span leaf=\"\">  </span></span></strong><strong style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;font-size: 1em;font-family: inherit;text-decoration: inherit;visibility: visible;\"><span style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;font-size: 18px;color: rgb(255, 255, 255);line-height: 1.4;font-family: inherit;font-weight: inherit;text-decoration: inherit;background-color: rgb(127, 127, 127);visibility: visible;\"><span leaf=\"\">新智元报道  </span></span></strong></span></p></section></section></section></section></section></h3><section style=\"margin: 0px 8px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;color: rgb(34, 34, 34);font-size: 17px;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: 0.544px;orphans: 2;text-indent: 0px;text-transform: none;white-space: normal;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;min-height: 1em;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb center visible><span style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;font-size: 12px;color: rgb(136, 136, 136);font-family: \" helvetica neue sans gb yahei arial sans-serif visible><span leaf=\"\">编辑：英智</span></span></section><section powered-by=\"xiumi.us\" style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;color: rgb(34, 34, 34);font-size: 17px;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: 0.544px;orphans: 2;text-align: justify;text-indent: 0px;text-transform: none;white-space: normal;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb visible><section style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;\"><section style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;\"><h5 style=\"margin: 10px 8px 0px;padding: 10px;outline: 0px;font-weight: 400;font-size: 14px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;color: rgb(0, 0, 0);letter-spacing: 0.544px;font-family: Arial, Helvetica, sans-serif;border-radius: 3px;background-color: rgb(248, 248, 248);line-height: 1.75em;word-break: break-all !important;word-spacing: 1px !important;visibility: visible;\"><span style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;letter-spacing: 1px;font-size: 15px;visibility: visible;\"><strong style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;\"><span leaf=\"\">【新智元导读】</span><span leaf=\"\"><span textstyle=\"\" style=\"font-weight: normal;\">AI绘画总「翻车」，不是抓不住重点，就是细节崩坏？别愁！微软和港中文学者带来ImageGen-CoT技术，让AI像人一样思考推理，生成超惊艳画作，性能提升高达80%。</span></span></strong></span></h5></section></section></section><section style=\"max-width: 100%;min-height: 1em;white-space: normal;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb left border-box break-word><span style=\"letter-spacing: 1px;\"><span leaf=\"\"><br></span></span></section><p data-pm-slice=\"0 0 []\" style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">AI绘画火爆的当下，大家都有过这样的体验：满心欢喜地输入一段描述，满心期待着生成超酷炫的图像，结果AI给出的作品却差强人意，不是没get到重点，就是细节各种</span></span><span leaf=\"\" data-pm-slice=\"0 0 []\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: normal;\">「翻车」</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">今天要介绍的ImageGen-CoT技术，就像是给AI绘画开了「外挂」，让它变得超智能，创作更轻松！</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">来自微软和港中文的华人研究者提出了ImageGen-CoT，用思维链（CoT）推理提升文本到图像上下文学习能力。</span></span></p><section style=\"text-align: justify;margin: 0px 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-backh=\"153\" data-backw=\"562\" data-height=\"401\" data-imgfileid=\"505098004\" data-ratio=\"0.27241847826086957\" data-type=\"png\" data-w=\"1472\" data-width=\"1472\" style=\"width:100%; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb0dvTBxhibYSBRocia5lqLS7bDnwwibF8gzxUB1c5WK9C5sTyleUicfYxtcd11wic8J7sp9iaUICloIK7Iw/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"text-align: left;margin: 0px 8px 24px;line-height: 1.75em;\" data-mpa-action-id=\"m97yf5ozgqr\" data-pm-slice=\"0 0 []\"><span leaf=\"\" data-mpa-action-id=\"m97yf5ot1mpf\"><span textstyle=\"\" style=\"font-size: 14px;letter-spacing: 1px;color: rgb(136, 136, 136);\">论文链接：https://arxiv.org/abs/2503.1931</span></span><span mpa-font-style=\"m97yf5otmrb\" style=\"font-size: 13px;\"><span leaf=\"\" data-mpa-action-id=\"m97yf5oth85\"><span textstyle=\"\" style=\"letter-spacing: 1px;color: rgb(136, 136, 136);\">2</span></span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">它在AI绘画生成图像之前，先进行一番思考，梳理出推理步骤，再去创作图像，就像写作文前先列提纲一样。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">人类在面对多模态信息时，比如看到「皮革装订的书」「皮革苹果」，再被要求画「皮革盒子」，能轻松推断出 「皮革」这个关键特征，并应用到新的创作中。</span></span></p><section style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-backh=\"240\" data-backw=\"562\" data-height=\"700\" data-imgfileid=\"505098006\" data-ratio=\"0.4276114844227245\" data-type=\"png\" data-w=\"1637\" data-width=\"1637\" style=\"width:100%; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb0dvTBxhibYSBRocia5lqLS7bfKM28fkpr36a5nib1sFw4NBULSyHY91bOpEGB7kfDVnWqBn2FlHpO1Q/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">但现有的多模态大语言模型（MLLM）在处理这类文本到图像上下文学习（T2I-ICL）任务时，却表现得差强人意，经常抓不住重点，生成的图像和预期相差甚远。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">ImageGen-CoT的核心就是在图像生成之前引入思维链（CoT）推理。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">想象一下，AI就像一个小画家，以前画画的时候，拿到描述就直接动手，毫无规划，所以画得乱七八糟。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">现在有了ImageGen-CoT，小画家会先思考：「这个描述里有什么关键信息？之前有没有类似的描述，它们有什么共同点？」</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">想清楚这些之后，再开始画画，这样画出来的作品自然更符合期待。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">大量的实验表明，该方法显著提高了模型性能，SEED-X微调后在T2I-ICL任务上的性能提升高达80%。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">使用ImageGen-CoT进行微调的SEED-X在CoBSAT和DreamBench++上分别提高了89%和114%。</span></span></p><section style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-backh=\"408\" data-backw=\"562\" data-height=\"981\" data-imgfileid=\"505098005\" data-ratio=\"0.7272053372868792\" data-type=\"png\" data-w=\"1349\" data-width=\"1349\" style=\"width:100%; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb0dvTBxhibYSBRocia5lqLS7bFv9tC3picToctwuZnXs3JUha0Y4GcfUpPTIfFmKSEyD240VsFbiblUbw/640?wx_fmt=png&amp;from=appmsg\"></section><section style=\"text-align: center;margin-top: 0px;margin-bottom: 0px;\"><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-top: 0px;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 85px; height: 40px; max-width: 600px\" data-imgfileid=\"505095291\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span></section><section style=\"text-align: center;margin-bottom: 0px;margin-top: 8px;line-height: 1.75em;\"><span style=\"color: rgb(0, 0, 0);font-size: 19px;letter-spacing: 1px;\"><strong><span leaf=\"\">ImageGen-CoT如何构建</span></strong></span></section><p style=\"text-align: justify;margin: 24px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">接下来，详细介绍ImageGen-CoT框架，首先，介绍ImageGen-CoT的公式化表述。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">其次，描述用于收集高质量ImageGen-CoT数据集的自动流程。详细阐述数据集的公式化表述以及用于使用收集到的数据集对模型进行微调的损失函数。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">最后，探索在推理过程中提高模型性能的各种策略，提出一种新颖的混合扩展方法，应对上下文理解和生成方面的挑战。</span></span></p><section style=\"display: flex;align-items: center;text-align: left;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 45px; height: 24px; max-width: 600px\" data-imgfileid=\"505095301\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span><p style=\"font-size: 16px;font-family: mp-quote, \" pingfang sc system-ui blinkmacsystemfont neue sans gb yahei ui arial sans-serif><strong><span style=\"font-size: 17px;letter-spacing: 1px;\"><span leaf=\"\"> </span><span leaf=\"\">两阶段推理：稳扎稳打生成图像</span></span></strong></p></section><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">ImageGen-CoT 采用了两阶段推理的方式。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">第一阶段，模型会根据输入的文本和指令，生成ImageGen-CoT推理链R。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">这个推理链就像是画家画画前打的草稿，把图像的关键信息、创作思路都梳理清楚。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">第二阶段，模型把原始输入X、生成的推理链R，还有强制图像生成标记<image>结合起来，生成最终的目标图像I。</image></span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">用公式表示就是：</span></span></p><section style=\"text-align: center;margin: 0px 8px 24px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.22153369481022464\" data-type=\"png\" data-w=\"1291\" style=\"width:309px; height:68px; max-width: 600px\" data-width=\"1291\" data-height=\"286\" data-imgfileid=\"505098003\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb0dvTBxhibYSBRocia5lqLS7bnxg5yiaQFV0EWGriayLbO4icG2lIYFibwWCQN3dYK0ia53NjFkJMCzQS0AQ/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">这里，M代表统一的MLLM，⊕表示连接操作。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">这种两阶段的设计，能确保图像生成更稳定、更准确。</span></span></p><section style=\"display: flex;align-items: center;text-align: left;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 45px; height: 24px; max-width: 600px\" data-imgfileid=\"505095301\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span><p style=\"font-size: 16px;font-family: mp-quote, \" pingfang sc system-ui blinkmacsystemfont neue sans gb yahei ui arial sans-serif><strong><span style=\"font-size: 17px;letter-spacing: 1px;\"><span leaf=\"\"> </span><span leaf=\"\">数据集构建</span></span></strong></p></section><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">为了能更好地学习，ImageGen-CoT构建了高质量的数据集。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">首先，研究人员从现有的T2I-ICL任务训练数据集中收集各种指令，建立一个指令池。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">然后，开启自动数据集构建流程。在这个流程里，MLLM身兼数职。它先是作为生成器，生成N个包含ImageGen-CoT和下一幅图像提示的输出。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">然后，MLLM充当选择器，从N个候选图像中选择最佳图像。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">如果图像达到了质量标准，或者达到了最大迭代次数，流程终止并输出相应的ImageGen-CoT和图像对。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">要是没达标，MLLM就会化身为评论者，给这幅图像挑挑刺，指出哪里画得不好。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">最后，MLLM再作为优化器，根据评论修改提示，然后重新生成图像，这个过程不断循环，直到选出最完美的图像和对应的ImageGen-CoT。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-backh=\"344\" data-backw=\"562\" data-height=\"986\" data-imgfileid=\"505098007\" data-ratio=\"0.6131840796019901\" data-type=\"png\" data-w=\"1608\" data-width=\"1608\" style=\"width:100%; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb0dvTBxhibYSBRocia5lqLS7bOv3xyHWTfKuAwiamibtQYKYZic4l7DY2m1xAepiamiaXZ8PWwR91TEnjV3A/640?wx_fmt=png&amp;from=appmsg\"></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">通过这样严格的筛选，构建出的ImageGen-CoT数据集质量超高，每一个样本都是精心挑选出来的。</span></span></p><section style=\"display: flex;align-items: center;text-align: left;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 45px; height: 24px; max-width: 600px\" data-imgfileid=\"505095301\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span><p style=\"font-size: 16px;font-family: mp-quote, \" pingfang sc system-ui blinkmacsystemfont neue sans gb yahei ui arial sans-serif><strong><span style=\"font-size: 17px;letter-spacing: 1px;\"><span leaf=\"\"> </span><span leaf=\"\">训练与优化</span></span></strong></p><p style=\"font-size: 16px;font-family: mp-quote, \" pingfang sc system-ui blinkmacsystemfont neue sans gb yahei ui arial sans-serif><strong><span style=\"font-size: 17px;letter-spacing: 1px;\"><span leaf=\"\"><br></span></span></strong></p><p style=\"font-size: 16px;font-family: mp-quote, \" pingfang sc system-ui blinkmacsystemfont neue sans gb yahei ui arial sans-serif><strong><span style=\"font-size: 17px;letter-spacing: 1px;\"><span leaf=\"\"><br></span></span></strong></p></section><h3 style=\"text-align: justify;margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></h3><h3 style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">数据集构建好之后，就要用它来训练MLLM啦。</span></span></h3><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">训练时，研究人员把ImageGen-CoT数据集分成了两个部分。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">第一部分用来训练模型生成ImageGen-CoT文本，第二部分训练模型根据生成的ImageGen-CoT文本生成图像。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">如果模型使用的是离散视觉标记，就用和语言建模类似的损失函数：</span></span></p><section style=\"text-align: center;margin: 0px 8px 24px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.2204155374887082\" data-type=\"png\" data-w=\"1107\" style=\"width:257px; height:57px; max-width: 600px\" data-width=\"1107\" data-height=\"244\" data-imgfileid=\"505098010\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb0dvTBxhibYSBRocia5lqLS7bGuZ81CeQdIaVKVbcajuicM7vJz2QibDnVG6yycZ10SO6A4OaiaYxMucyQ/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">其中，y_i是ImageGen-CoT文本中的第i个标记，</span><img class=\"rich_pages wxw-img\" data-ratio=\"0.6699029126213593\" data-type=\"png\" data-w=\"206\" style=\"width:38px; height:25px; max-width: 600px\" data-width=\"206\" data-height=\"138\" data-imgfileid=\"505098009\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb0dvTBxhibYSBRocia5lqLS7bhYndHmoIHdEib4r3QSxBzibG7R2pQNLYohVO71DGcrBXc6zAN509ByWw/640?wx_fmt=png&amp;from=appmsg\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">表示前面的标记，X是输入，N是ImageGen-CoT序列中的标记总数。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">要是用的是连续视觉嵌入，就采用均方误差损失函数：</span></span></p><section style=\"text-align: center;margin: 0px 8px 24px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.2335216572504708\" data-type=\"png\" data-w=\"531\" style=\"width:190px; height:44px; max-width: 600px\" data-width=\"531\" data-height=\"124\" data-imgfileid=\"505098011\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb0dvTBxhibYSBRocia5lqLS7bia69Xplcn6Yz7BvNrzpiahw2xxteW6RibRJnxPJkUicfw2JuxSkWGRMtGg/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">其中，</span><img class=\"rich_pages wxw-img\" data-ratio=\"1.9387755102040816\" data-type=\"png\" data-w=\"49\" style=\"width:20px; height:39px; max-width: 600px\" data-width=\"49\" data-height=\"95\" data-imgfileid=\"505098008\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb0dvTBxhibYSBRocia5lqLS7b5Ln5Ung6Kiae2ibvb1ztEsoGta8yFVzibVozn2VLJpFtNWFmZzmjZldicA/640?wx_fmt=png&amp;from=appmsg\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">是生成的视觉嵌入，z是相应的目标视觉嵌入。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">通过训练，模型生成准确ImageGen-CoT的能力越来越强，图像生成的质量也大幅提升。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">研究人员在测试阶段也进行了优化，探索了三种测试时扩展策略：单CoT扩展、多CoT扩展和混合扩展。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">单CoT扩展就是从一个ImageGen-CoT生成多个图像变体；多CoT扩展则是生成多个不同的ImageGen-CoT思维链，每个思维链生成一幅图像。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">混合扩展更厉害，首先生成多个ImageGen-CoT思维链，然后为每个思维链创建多个图像变体。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">实验证明，混合扩展策略效果最好。在理解和生成图像两方面都能快速提升，为复杂多模态任务的性能优化开辟了新道路。</span></span></p><section style=\"text-align: center;margin-top: 0px;margin-bottom: 0px;\"><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-top: 0px;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 85px; height: 40px; max-width: 600px\" data-imgfileid=\"505095291\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span></section><section style=\"text-align: center;margin-bottom: 0px;margin-top: 8px;line-height: 1.75em;\"><span style=\"color: rgb(0, 0, 0);font-size: 19px;letter-spacing: 1px;\"><strong><span leaf=\"\">ImageGen-CoT效果有多惊艳？</span></strong></span></section><p style=\"text-align: justify;margin: 24px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">为了验证ImageGen-CoT，研究人员在CoBSAT和DreamBench++这两个权威的T2I-ICL基准测试中进行了实验。</span></span></p><section style=\"display: flex;align-items: center;text-align: left;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 45px; height: 24px; max-width: 600px\" data-imgfileid=\"505095301\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span><p style=\"font-size: 16px;font-family: mp-quote, \" pingfang sc system-ui blinkmacsystemfont neue sans gb yahei ui arial sans-serif><strong><span style=\"font-size: 17px;letter-spacing: 1px;\"><span leaf=\"\"> </span><span leaf=\"\">测试成绩亮眼</span></span></strong></p></section><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">在CoBSAT测试中，使用ImageGen-CoT后，SEED-LLaMA的平均分数从0.254提高到0.283，相对提升了11.4%。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">SEED-X的提升更明显，从0.349提高到0.439，相对提升25.8%。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">经过ImageGen-CoT数据集微调后，SEED-LLaMA的平均分数达到0.291，比基线提升了14.6%。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">SEED-X更是飙升到0.658，相对提升高达88.5%。</span></span></p><section style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-backh=\"197\" data-backw=\"562\" data-height=\"571\" data-imgfileid=\"505098012\" data-ratio=\"0.3505217925107428\" data-type=\"png\" data-w=\"1629\" data-width=\"1629\" style=\"width:100%; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb0dvTBxhibYSBRocia5lqLS7bgmBWMicYQeFEiaoahUzA3Qibctu6cFjgXicQQkXkzANYNlXdby9s68prdw/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">在DreamBench++测试中，同样成绩斐然。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">SEED-X使用ImageGen-CoT后，CP・PF分数从0.188提升到0.347，相对提升84.6%。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">微调后，SEED-X的CP・PF分数达到0.403，相对提升114.4%；SEED-LLaMA微调后的CP・PF分数也从0.078提升到0.101，相对提升29.5%。</span></span></p><section style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-backh=\"149\" data-backw=\"562\" data-height=\"431\" data-imgfileid=\"505098013\" data-ratio=\"0.2644171779141104\" data-type=\"png\" data-w=\"1630\" data-width=\"1630\" style=\"width:100%; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb0dvTBxhibYSBRocia5lqLS7b0lhR6pNic4vOg74oaib8iaIW5V78KOdeFwO4nza87hfURHEdMv7L62bPA/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">这充分证明了ImageGen-CoT在提升模型性能方面的强大实力。</span></span></p><section style=\"display: flex;align-items: center;text-align: left;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 45px; height: 24px; max-width: 600px\" data-imgfileid=\"505095301\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span><p style=\"font-size: 16px;font-family: mp-quote, \" pingfang sc system-ui blinkmacsystemfont neue sans gb yahei ui arial sans-serif><strong><span style=\"font-size: 17px;letter-spacing: 1px;\"><span leaf=\"\"> </span><span leaf=\"\">测试时扩展</span></span></strong></p></section><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">为了进一步提升模型性能，研究人员探索了各种测试时扩展策略。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">采用「N选优」方法，让模型生成多个图像变体，并通过真实指标评估（pass@N）。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">作为基线方法，首先对普通的SEED-X模型进行实验，通过改变种子值生成多个图像。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">然后，使用ImageGen-CoT 数据集微调后的SEED-X的三种高级扩展策略：</span></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li><p style=\"text-align: justify;margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">多CoT扩展，生成多个不同的ImageGen-CoT思维链，每个思维链生成一幅图像。</span></span></p></li><li><p style=\"text-align: justify;margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">单CoT扩展，从单个ImageGen-CoT思维链生成多个图像变体。</span></span></p></li><li><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">混合扩展，这是一种新颖的方法，结合了两种策略的优势，即首先生成多个ImageGen-CoT思维链，然后为每个思维链生成多个图像变体。</span></span></p></li></ul><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">实验揭示了三个关键发现。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">第一，普通的SEED-X@16基线（在CoBSAT上得分为 0.67，在Dreambench++上得分为0.312 ）甚至不如最简单的扩展策略（例如，在CoBSAT@2上得分为0.747 ），这凸显了整合ImageGen-CoT的必要性。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">第二，多CoT扩展在性能上与单CoT扩展相当，证明了生成多样化的推理路径与从单个CoT生成不同输出的效果相同。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">最后，混合扩展在各个基准测试中始终获得最高分数。在N=16时，混合扩展将CoBSAT的性能提高到0.909（比单CoT扩展高1.9% ），将Dreambench++的性能提高到0.543（比单CoT扩展高0.8% ）。</span></span></p><section style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-backh=\"242\" data-backw=\"562\" data-height=\"686\" data-imgfileid=\"505098014\" data-ratio=\"0.43036386449184444\" data-type=\"png\" data-w=\"1594\" data-width=\"1594\" style=\"width:100%; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb0dvTBxhibYSBRocia5lqLS7b3nyTwuM1VVibhp7fX8F5ibC3USTdvmO1VU2c2gTFw0ibMcicGe085fib3ew/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">ImageGen-CoT的整合实现了在理解和生成维度上的有效双向扩展。这种双轴可扩展性为优化复杂多模态任务中的 MLLM性能开辟了新途径。</span></span></p><section style=\"display: flex;align-items: center;text-align: left;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 45px; height: 24px; max-width: 600px\" data-imgfileid=\"505095301\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span><p style=\"font-size: 16px;font-family: mp-quote, \" pingfang sc system-ui blinkmacsystemfont neue sans gb yahei ui arial sans-serif><strong><span style=\"font-size: 17px;letter-spacing: 1px;\"><span leaf=\"\"> </span><span leaf=\"\">定性结果展示</span></span></strong></p></section><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">ImageGen-CoT的效果在实际生成的图像中也体现得淋漓尽致。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">比如在生成「带蕾丝图案的书」的图像时，基线SEED-X只能画出一个基本的书的形状，完全没注意到「蕾丝」这个关键属性。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">使用ImageGen-CoT提示后，由于模型理解能力有限，生成的图像质量反而更差了。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">但经过ImageGen-CoT数据集微调后，模型成功捕捉到了「蕾丝」属性，生成了一本精美的蕾丝书，细节满满。</span></span></p><section style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.395217117684078\" data-type=\"png\" data-w=\"1589\" style=\"width:100%; max-width: 600px\" data-width=\"1589\" data-height=\"628\" data-backw=\"562\" data-backh=\"222\" data-imgfileid=\"505098016\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb0dvTBxhibYSBRocia5lqLS7bejrxhotc3QzyickzIqZ3U6Q1XaHofmTIR45yk7UOnyKZUBH20nu5AicQ/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">生成「在石头上、在花园里、表情悲伤的鸡蛋」的图像时，基线SEED-X生成的鸡蛋只是简单张嘴，完全忽略了「在石头上」「在花园里」这些要求和特征。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">使用ImageGen-CoT提示后，虽然鸡蛋放在了石头上，但还是缺少面部表情和花园环境。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">而微调后的模型则完美理解了所有任务要求，生成的图像中，鸡蛋稳稳地放在石头上，周围是美丽的花园，鸡蛋还带着悲伤的表情，和输入的描述一模一样。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">这些对比，让我们清晰地看到了ImageGen-CoT如何让AI绘画从「青铜」变成「王者」。</span></span></p><section style=\"display: flex;align-items: center;text-align: left;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 45px; height: 24px; max-width: 600px\" data-imgfileid=\"505095301\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span><p style=\"font-size: 16px;font-family: mp-quote, \" pingfang sc system-ui blinkmacsystemfont neue sans gb yahei ui arial sans-serif><strong><span style=\"font-size: 17px;letter-spacing: 1px;\"><span leaf=\"\"> </span><span leaf=\"\">背后的秘密：提升理解能力</span></span></strong></p></section><p style=\"text-align: justify;margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">为什么ImageGen-CoT能够提升模型性能呢？关键在于它增强了模型的理解能力。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">研究人员让模型为下一幅图像生成文本描述，以此来评估模型的理解能力。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">以SEED-X为例，通过提示应用ImageGen-CoT时，其文本生成模式的平均分数从0.174提高到0.457，用ImageGen-CoT数据集微调后，更是提升到0.760。</span></span></p><section style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.29636591478696744\" data-type=\"png\" data-w=\"1596\" style=\"width:100%; max-width: 600px\" data-width=\"1596\" data-height=\"473\" data-backw=\"562\" data-backh=\"167\" data-imgfileid=\"505098015\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb0dvTBxhibYSBRocia5lqLS7bfXc9jgbnOxGEDz1uEeC4jOfFSfMSDeR3kdpmuBpHhrhws2SqSicASyg/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">同时，增强的理解能力也改善了图像生成，SEED-X的图像生成平均分数从0.349提升到0.439，微调后进一步提升到0.658。</span></span></p><p style=\"text-align: justify;margin: 0px 8px 24px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">理解能力的提升也直接带动了图像生成性能的提高，这说明ImageGen-CoT让模型更好地理解了输入内容，生成更符合要求的图像。</span></span></p><section style=\"max-width: 100%;min-height: 1em;white-space: normal;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb left border-box break-word><span style=\"font-size: 14px;color: rgb(136, 136, 136);letter-spacing: 1px;\"><span leaf=\"\">参考资料：</span><span leaf=\"\"><br></span></span></section><section style=\"max-width: 100%;min-height: 1em;white-space: normal;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb left border-box break-word><span style=\"font-size: 14px;color: rgb(136, 136, 136);letter-spacing: 1px;\"><span leaf=\"\">https://arxiv.org/abs/2503.19312</span></span></section><section style=\"max-width: 100%;min-height: 1em;white-space: normal;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb left border-box break-word><span style=\"font-size: 14px;color: rgb(136, 136, 136);letter-spacing: 1px;\"><span leaf=\"\">https://www.alphaxiv.org/overview/2503.19312</span></span></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;\"><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-backh=\"335\" data-backw=\"578\" data-imgfileid=\"505099887\" data-ratio=\"0.5796296296296296\" data-s=\"300,640\" data-type=\"jpeg\" data-w=\"1080\" style=\"width: 100%; max-width: 600px\" type=\"block\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_jpg/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEB2ibVO28QoKmhefaVibmvfHcgN4ib82J3kNARoC6jK19jUCLN3m23pwxw/640?wx_fmt=jpeg&amp;from=appmsg\"></section><p style=\"text-align: center;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><p style=\"display: none;\"><mp-style-type data-value=\"3\"></mp-style-type></p></div>\n    \n\n    \n    <br>\n\n    \n        <a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2652583537&amp;idx=3&amp;sn=7dffe32fc3b98e9b98aa4be08fbd4d36&amp;chksm=f00803bad4887c9a267435fc6e3695d5415045c9aba3926eb9a50860d79999425dd8bd2b33b1&amp;scene=0#rd\" style=\"color: blue\" class=\"media_tool_meta meta_primary\">文章原文</a>\n        <br>\n    \n\n    \n\n    <img alt=\"\" width=\"1px\" height=\"1px\" class=\"\" style=\"width:1px;height:1px;display:none\" src=\"http://www.jintiankansha.me/rss_static/83671/KhJUSxaS1W\">\n\n",
          "contentSnippet": "新智元报道  \n\n\n\n编辑：英智\n\n\n【新智元导读】AI绘画总「翻车」，不是抓不住重点，就是细节崩坏？别愁！微软和港中文学者带来ImageGen-CoT技术，让AI像人一样思考推理，生成超惊艳画作，性能提升高达80%。\n\n\n\n\nAI绘画火爆的当下，大家都有过这样的体验：满心欢喜地输入一段描述，满心期待着生成超酷炫的图像，结果AI给出的作品却差强人意，不是没get到重点，就是细节各种「翻车」。\n今天要介绍的ImageGen-CoT技术，就像是给AI绘画开了「外挂」，让它变得超智能，创作更轻松！\n来自微软和港中文的华人研究者提出了ImageGen-CoT，用思维链（CoT）推理提升文本到图像上下文学习能力。\n\n论文链接：https://arxiv.org/abs/2503.19312\n它在AI绘画生成图像之前，先进行一番思考，梳理出推理步骤，再去创作图像，就像写作文前先列提纲一样。\n人类在面对多模态信息时，比如看到「皮革装订的书」「皮革苹果」，再被要求画「皮革盒子」，能轻松推断出 「皮革」这个关键特征，并应用到新的创作中。\n\n但现有的多模态大语言模型（MLLM）在处理这类文本到图像上下文学习（T2I-ICL）任务时，却表现得差强人意，经常抓不住重点，生成的图像和预期相差甚远。\nImageGen-CoT的核心就是在图像生成之前引入思维链（CoT）推理。\n想象一下，AI就像一个小画家，以前画画的时候，拿到描述就直接动手，毫无规划，所以画得乱七八糟。\n现在有了ImageGen-CoT，小画家会先思考：「这个描述里有什么关键信息？之前有没有类似的描述，它们有什么共同点？」\n想清楚这些之后，再开始画画，这样画出来的作品自然更符合期待。\n大量的实验表明，该方法显著提高了模型性能，SEED-X微调后在T2I-ICL任务上的性能提升高达80%。\n使用ImageGen-CoT进行微调的SEED-X在CoBSAT和DreamBench++上分别提高了89%和114%。\n\n\n\n\nImageGen-CoT如何构建\n接下来，详细介绍ImageGen-CoT框架，首先，介绍ImageGen-CoT的公式化表述。\n其次，描述用于收集高质量ImageGen-CoT数据集的自动流程。详细阐述数据集的公式化表述以及用于使用收集到的数据集对模型进行微调的损失函数。\n最后，探索在推理过程中提高模型性能的各种策略，提出一种新颖的混合扩展方法，应对上下文理解和生成方面的挑战。\n\n 两阶段推理：稳扎稳打生成图像\n\n\n\nImageGen-CoT 采用了两阶段推理的方式。\n第一阶段，模型会根据输入的文本和指令，生成ImageGen-CoT推理链R。\n这个推理链就像是画家画画前打的草稿，把图像的关键信息、创作思路都梳理清楚。\n第二阶段，模型把原始输入X、生成的推理链R，还有强制图像生成标记结合起来，生成最终的目标图像I。\n用公式表示就是：\n\n这里，M代表统一的MLLM，⊕表示连接操作。\n这种两阶段的设计，能确保图像生成更稳定、更准确。\n\n 数据集构建\n\n\n\n为了能更好地学习，ImageGen-CoT构建了高质量的数据集。\n首先，研究人员从现有的T2I-ICL任务训练数据集中收集各种指令，建立一个指令池。\n然后，开启自动数据集构建流程。在这个流程里，MLLM身兼数职。它先是作为生成器，生成N个包含ImageGen-CoT和下一幅图像提示的输出。\n然后，MLLM充当选择器，从N个候选图像中选择最佳图像。\n如果图像达到了质量标准，或者达到了最大迭代次数，流程终止并输出相应的ImageGen-CoT和图像对。\n要是没达标，MLLM就会化身为评论者，给这幅图像挑挑刺，指出哪里画得不好。\n最后，MLLM再作为优化器，根据评论修改提示，然后重新生成图像，这个过程不断循环，直到选出最完美的图像和对应的ImageGen-CoT。\n\n通过这样严格的筛选，构建出的ImageGen-CoT数据集质量超高，每一个样本都是精心挑选出来的。\n\n 训练与优化\n\n\n\n\n\n\n\n数据集构建好之后，就要用它来训练MLLM啦。\n训练时，研究人员把ImageGen-CoT数据集分成了两个部分。\n第一部分用来训练模型生成ImageGen-CoT文本，第二部分训练模型根据生成的ImageGen-CoT文本生成图像。\n如果模型使用的是离散视觉标记，就用和语言建模类似的损失函数：\n\n其中，y_i是ImageGen-CoT文本中的第i个标记，表示前面的标记，X是输入，N是ImageGen-CoT序列中的标记总数。\n要是用的是连续视觉嵌入，就采用均方误差损失函数：\n\n其中，是生成的视觉嵌入，z是相应的目标视觉嵌入。\n通过训练，模型生成准确ImageGen-CoT的能力越来越强，图像生成的质量也大幅提升。\n研究人员在测试阶段也进行了优化，探索了三种测试时扩展策略：单CoT扩展、多CoT扩展和混合扩展。\n单CoT扩展就是从一个ImageGen-CoT生成多个图像变体；多CoT扩展则是生成多个不同的ImageGen-CoT思维链，每个思维链生成一幅图像。\n混合扩展更厉害，首先生成多个ImageGen-CoT思维链，然后为每个思维链创建多个图像变体。\n实验证明，混合扩展策略效果最好。在理解和生成图像两方面都能快速提升，为复杂多模态任务的性能优化开辟了新道路。\n\n\n\nImageGen-CoT效果有多惊艳？\n为了验证ImageGen-CoT，研究人员在CoBSAT和DreamBench++这两个权威的T2I-ICL基准测试中进行了实验。\n\n 测试成绩亮眼\n\n\n\n在CoBSAT测试中，使用ImageGen-CoT后，SEED-LLaMA的平均分数从0.254提高到0.283，相对提升了11.4%。\nSEED-X的提升更明显，从0.349提高到0.439，相对提升25.8%。\n经过ImageGen-CoT数据集微调后，SEED-LLaMA的平均分数达到0.291，比基线提升了14.6%。\nSEED-X更是飙升到0.658，相对提升高达88.5%。\n\n在DreamBench++测试中，同样成绩斐然。\nSEED-X使用ImageGen-CoT后，CP・PF分数从0.188提升到0.347，相对提升84.6%。\n微调后，SEED-X的CP・PF分数达到0.403，相对提升114.4%；SEED-LLaMA微调后的CP・PF分数也从0.078提升到0.101，相对提升29.5%。\n\n这充分证明了ImageGen-CoT在提升模型性能方面的强大实力。\n\n 测试时扩展\n\n\n\n为了进一步提升模型性能，研究人员探索了各种测试时扩展策略。\n采用「N选优」方法，让模型生成多个图像变体，并通过真实指标评估（pass@N）。\n作为基线方法，首先对普通的SEED-X模型进行实验，通过改变种子值生成多个图像。\n然后，使用ImageGen-CoT 数据集微调后的SEED-X的三种高级扩展策略：\n\n多CoT扩展，生成多个不同的ImageGen-CoT思维链，每个思维链生成一幅图像。\n\n单CoT扩展，从单个ImageGen-CoT思维链生成多个图像变体。\n\n混合扩展，这是一种新颖的方法，结合了两种策略的优势，即首先生成多个ImageGen-CoT思维链，然后为每个思维链生成多个图像变体。\n\n实验揭示了三个关键发现。\n第一，普通的SEED-X@16基线（在CoBSAT上得分为 0.67，在Dreambench++上得分为0.312 ）甚至不如最简单的扩展策略（例如，在CoBSAT@2上得分为0.747 ），这凸显了整合ImageGen-CoT的必要性。\n第二，多CoT扩展在性能上与单CoT扩展相当，证明了生成多样化的推理路径与从单个CoT生成不同输出的效果相同。\n最后，混合扩展在各个基准测试中始终获得最高分数。在N=16时，混合扩展将CoBSAT的性能提高到0.909（比单CoT扩展高1.9% ），将Dreambench++的性能提高到0.543（比单CoT扩展高0.8% ）。\n\nImageGen-CoT的整合实现了在理解和生成维度上的有效双向扩展。这种双轴可扩展性为优化复杂多模态任务中的 MLLM性能开辟了新途径。\n\n 定性结果展示\n\n\n\nImageGen-CoT的效果在实际生成的图像中也体现得淋漓尽致。\n比如在生成「带蕾丝图案的书」的图像时，基线SEED-X只能画出一个基本的书的形状，完全没注意到「蕾丝」这个关键属性。\n使用ImageGen-CoT提示后，由于模型理解能力有限，生成的图像质量反而更差了。\n但经过ImageGen-CoT数据集微调后，模型成功捕捉到了「蕾丝」属性，生成了一本精美的蕾丝书，细节满满。\n\n生成「在石头上、在花园里、表情悲伤的鸡蛋」的图像时，基线SEED-X生成的鸡蛋只是简单张嘴，完全忽略了「在石头上」「在花园里」这些要求和特征。\n使用ImageGen-CoT提示后，虽然鸡蛋放在了石头上，但还是缺少面部表情和花园环境。\n而微调后的模型则完美理解了所有任务要求，生成的图像中，鸡蛋稳稳地放在石头上，周围是美丽的花园，鸡蛋还带着悲伤的表情，和输入的描述一模一样。\n这些对比，让我们清晰地看到了ImageGen-CoT如何让AI绘画从「青铜」变成「王者」。\n\n 背后的秘密：提升理解能力\n\n\n\n为什么ImageGen-CoT能够提升模型性能呢？关键在于它增强了模型的理解能力。\n研究人员让模型为下一幅图像生成文本描述，以此来评估模型的理解能力。\n以SEED-X为例，通过提示应用ImageGen-CoT时，其文本生成模式的平均分数从0.174提高到0.457，用ImageGen-CoT数据集微调后，更是提升到0.760。\n\n同时，增强的理解能力也改善了图像生成，SEED-X的图像生成平均分数从0.349提升到0.439，微调后进一步提升到0.658。\n理解能力的提升也直接带动了图像生成性能的提高，这说明ImageGen-CoT让模型更好地理解了输入内容，生成更符合要求的图像。\n参考资料：\n\nhttps://arxiv.org/abs/2503.19312\nhttps://www.alphaxiv.org/overview/2503.19312\n\n\n\n\n\n\n\n    \n\n    \n    \n文章原文",
          "guid": "http://www.jintiankansha.me/t/KhJUSxaS1W",
          "categories": [
            "无"
          ],
          "isoDate": "2025-04-08T04:00:00.000Z"
        }
      },
      {
        "json": {
          "title": "三个LLM顶一个OpenAI？2亿条性能记录加持，路由n个「小」模型逆袭",
          "link": "http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652583537&idx=2&sn=2c33a7e1257be11bb858f424398a2612&chksm=f0e72c39c9b358001917d1fc63b1eeaa8562692ae5a946cfbaa0998944b2f9eed09d2ce492e9&scene=0#rd",
          "pubDate": "Tue, 08 Apr 2025 12:00:00 +0800",
          "enclosure": {
            "url": "http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_jpg/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvhWla4nriaFxfjWHyQiclMZrz5oyx0cV5mtAcWBSnT7HtibA2B5YkTRZBg/0?wx_fmt=jpeg",
            "length": "0",
            "type": "image/jpeg"
          },
          "content": "\n\n    \n\n    \n\n    \n         <div class=\"rich_media_content\" id=\"js_content\"><h3 data-mpa-powered-by=\"yiban.io\" style=\"margin: 0px;padding: 0px;outline: 0px;font-weight: 400;font-size: 16px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;letter-spacing: 0.544px;orphans: 2;text-align: justify;text-indent: 0px;text-transform: none;white-space: normal;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb visible data-pm-slice=\"0 0 []\"><section data-tools=\"135编辑器\" data-id=\"88402\" style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;line-height: 27.2px;widows: 1;visibility: visible;\"><section data-tools=\"135编辑器\" data-id=\"88402\" style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;letter-spacing: 0.544px;line-height: 27.2px;visibility: visible;\"><section data-style=\"line-height: 1.8; text-align: justify; font-size: 15px; letter-spacing: 0px; color: rgb(117, 114, 114);white-space: normal;\" style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;\"><section style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;\"><section style=\"margin: 0px 0px 8px;padding: 0px;outline: 0px;max-width: 100%;text-align: center;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.425\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" style=\"font-size: 16px; letter-spacing: 0.544px; widows: 1; color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); font-family: mp-quote, -apple-system-font, BlinkMacSystemFont,; max-width: 600px\" helvetica neue sc sans gb yahei ui arial sans-serif auto data-cropselx1=\"0\" data-cropselx2=\"578\" data-cropsely1=\"0\" data-cropsely2=\"246\" data-backw=\"578\" data-backh=\"246\" data-imgfileid=\"505095172\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_jpg/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVv4GOTJGBJk9IficgJ9KH6AGh7OTXwZ4fwtpkiadicHRTtGFribnz5vDCcBA/640?wx_fmt=jpeg&amp;from=appmsg\"></section></section></section></section></section></h3><h3 style=\"margin: 0px;padding: 0px;outline: 0px;font-weight: 400;font-size: 16px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;letter-spacing: 0.544px;orphans: 2;text-align: justify;text-indent: 0px;text-transform: none;white-space: normal;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb visible><section data-tools=\"135编辑器\" data-id=\"88402\" style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;line-height: 27.2px;widows: 1;visibility: visible;\"><section data-tools=\"135编辑器\" data-id=\"88402\" style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;letter-spacing: 0.544px;line-height: 27.2px;visibility: visible;\"><section data-style=\"line-height: 1.8; text-align: justify; font-size: 15px; letter-spacing: 0px; color: rgb(117, 114, 114);white-space: normal;\" style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;\"><section style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;\"><section style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;\"><hr style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;font-size: 17px;letter-spacing: 0.544px;visibility: visible;\"><p style=\"margin: -1.2em 8px 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;clear: both;min-height: 1em;font-size: 17px;letter-spacing: 0.544px;line-height: 1.75em;visibility: visible;\"><span leaf=\"\"><br></span></p><p style=\"margin: -1.2em 8px 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;clear: both;min-height: 1em;font-size: 17px;letter-spacing: 0.544px;text-align: center;line-height: 1.75em;visibility: visible;\"><span style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;letter-spacing: 1px;visibility: visible;\"><strong style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;font-family: inherit;font-size: 1em;text-decoration: inherit;visibility: visible;\"><span style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;font-size: 18px;color: rgb(255, 255, 255);line-height: 1.4;font-family: inherit;font-weight: inherit;text-decoration: inherit;background-color: rgb(127, 127, 127);visibility: visible;\"><span leaf=\"\">  </span></span></strong><strong style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;font-size: 1em;font-family: inherit;text-decoration: inherit;visibility: visible;\"><span style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;font-size: 18px;color: rgb(255, 255, 255);line-height: 1.4;font-family: inherit;font-weight: inherit;text-decoration: inherit;background-color: rgb(127, 127, 127);visibility: visible;\"><span leaf=\"\">新智元报道  </span></span></strong></span></p></section></section></section></section></section></h3><section style=\"margin: 0px 8px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;color: rgb(34, 34, 34);font-size: 17px;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: 0.544px;orphans: 2;text-indent: 0px;text-transform: none;white-space: normal;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;min-height: 1em;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb center visible><span style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;font-size: 12px;color: rgb(136, 136, 136);font-family: \" helvetica neue sans gb yahei arial sans-serif visible><span leaf=\"\">编辑：LRST 好困</span></span></section><section powered-by=\"xiumi.us\" style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;color: rgb(34, 34, 34);font-size: 17px;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: 0.544px;orphans: 2;text-align: justify;text-indent: 0px;text-transform: none;white-space: normal;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb visible><section style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;\"><section style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;\"><h5 style=\"margin: 10px 8px 0px;padding: 10px;outline: 0px;font-weight: 400;font-size: 14px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;color: rgb(0, 0, 0);letter-spacing: 0.544px;font-family: Arial, Helvetica, sans-serif;border-radius: 3px;background-color: rgb(248, 248, 248);line-height: 1.75em;word-break: break-all !important;word-spacing: 1px !important;visibility: visible;\"><span style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;letter-spacing: 1px;font-size: 15px;visibility: visible;\"><strong style=\"margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;\"><span leaf=\"\">【新智元导读】</span></strong><span leaf=\"\">路由LLM是指一种通过router动态分配请求到若干候选LLM的机制。论文提出且开源了针对router设计的全面RouterEval基准，通过整合8500+个LLM在12个主流Benchmark上的2亿条性能记录。将大模型路由问题转化为标准的分类任务，使研究者可在单卡甚至笔记本电脑上开展前沿研究。这一突破不仅为学术界提供了低门槛的研究工具，更为大模型性能优化提供了新的思路：通过智能调度实现异构模型的协同增效，以极低的计算成本突破单一模型的性能上限。</span></span></h5></section></section></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-top: 24px;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">当前大模型研究面临三大困境：算力垄断（顶尖成果集中于大厂）、成本壁垒（单次训练成本高，可能需要数千GPU小时）以及技术路径单一化（过度依赖单一模型的规模扩展）。</span></span></section><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">为突破这些限制，路由LLM（Routing LLM）范式应运而生——通过智能调度实现多个开源小模型的协同增效，以「组合创新」替代「规模竞赛」。</span></span></p><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.26867119301648884\" data-type=\"png\" data-w=\"1031\" style=\"width: 100%; height: auto; max-width: 600px\" data-width=\"1031\" data-height=\"277\" data-backw=\"562\" data-backh=\"151\" data-imgfileid=\"505093891\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb0PvPu2FKfVsOXCSCraNPD3d85nWGf3QSmO9WRrsIORP4G5rTicBLCDCcLhlqic63SBnbzgyRwP4Y9g/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;\"><span style=\"letter-spacing: 1px;font-size: 13px;color: rgb(136, 136, 136);\" data-mpa-action-id=\"m97yedr01qfk\"><span leaf=\"\">代码：</span></span><span style=\"letter-spacing: 1px;font-size: 13px;color: rgb(136, 136, 136);\"><span leaf=\"\">https://github.com/MilkThink-Lab/RouterEval</span></span></p><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;\"><span style=\"letter-spacing: 1px;font-size: 13px;color: rgb(136, 136, 136);\"><span leaf=\"\">论文: </span></span><span style=\"letter-spacing: 1px;font-size: 13px;color: rgb(136, 136, 136);\"><span leaf=\"\">https://arxiv.org/abs/2503.10657</span></span></p><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"letter-spacing: 1px;font-size: 13px;color: rgb(136, 136, 136);\"><span leaf=\"\">论文合集：</span></span><span style=\"letter-spacing: 1px;font-size: 13px;color: rgb(136, 136, 136);\" data-mpa-action-id=\"m97yedr01ggw\"><span leaf=\"\">https://github.com/MilkThink-Lab/Awesome-Routing-LLMs</span></span><span style=\"letter-spacing: 1px;font-size: 14px;\"></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">路由LLM实际上是model level的MoE（Mixture-of-Experts），传统MoE通过在模型内部扩展专家网络（如稀疏激活的FFN层）提升性能，而路由LLM将完整LLM视为独立「专家」，通过预训练Router动态分配任务输入。</span></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.6570605187319885\" data-type=\"png\" data-w=\"694\" style=\"width: 79%; height: auto !important; flex-basis: auto; max-width: 600px\" data-width=\"694\" data-height=\"456\" data-backw=\"562\" data-backh=\"369\" data-imgfileid=\"505093892\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb0PvPu2FKfVsOXCSCraNPD3GZxP9nrkzGVZia63weHpFcghuqNyua8aLicWiaYcwMIoSpCaesvfibukCA/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;font-size: 13px;\" mpa-font-style=\"m97yesuqo1o\" data-mpa-action-id=\"m97yesuz1au8\" data-pm-slice=\"0 0 []\"><span style=\"letter-spacing: 1px;color: rgb(136, 136, 136);\"><span leaf=\"\">三个大模型=OpenAI</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">这种范式具有三重优势：</span></span></p><ol style=\"margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li style=\"font-size: 15px;letter-spacing: 1px;\"><p style=\"text-align: justify;line-height: 1.75em;margin-bottom: 24px;\"><strong><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">异构兼容性：</span></span></strong><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">支持闭源模型（如GPT-4）、开源模型（如Llama系列）及专用微调模型的混合部署。</span></span></p></li><li style=\"font-size: 15px;letter-spacing: 1px;\"><p style=\"text-align: justify;line-height: 1.75em;margin-bottom: 24px;\"><strong><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">多目标优化：</span></span></strong><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">可根据场景需求，在性能、成本、风险控制等维度实现动态权衡</span></span></p></li><li style=\"font-size: 15px;letter-spacing: 1px;\"><p style=\"text-align: justify;line-height: 1.75em;margin-bottom: 24px;\"><strong><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">灵活部署：</span></span></strong><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">可根据实际需求动态调整候选模型池，针对特定场景（如代码生成、医疗问答）快速定制专属解决方案，而无需从头训练大模型</span></span><span style=\"letter-spacing: 1px;\"></span></p></li></ol><section style=\"text-align: center;margin-top: 0px;margin-bottom: 0px;\"><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-top: 0px;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 85px; height: 40px; max-width: 600px\" data-imgfileid=\"505095291\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span></section><section style=\"text-align: center;margin-bottom: 0px;margin-top: 8px;line-height: 1.75em;\"><span style=\"color: rgb(0, 0, 0);font-size: 19px;letter-spacing: 1px;\"><strong><span leaf=\"\">路由LLM范式的核心机制</span></strong></span></section><section style=\"text-align: center;margin: 24px 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.6092843326885881\" data-type=\"png\" data-w=\"517\" style=\"width: 79%; height: auto !important; flex-basis: auto; max-width: 600px\" data-width=\"517\" data-height=\"315\" data-backw=\"517\" data-backh=\"315\" data-imgfileid=\"505093890\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb0PvPu2FKfVsOXCSCraNPD30AI0AQZQW043LsuoicWBEozPucP8F30urpwvlcSFp2a3wy0Lvsl9I1w/640?wx_fmt=png&amp;from=appmsg\"></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">路由LLM系统采用「输入-路由-执行器」三级架构，其中路由层是系统的智能中枢，承担着任务分配与资源调度的核心功能：</span></span></section><ol style=\"margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li style=\"font-size: 15px;letter-spacing: 1px;\"><p style=\"text-align: justify;line-height: 1.75em;margin-bottom: 24px;\"><strong><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">输入层：</span></span></strong><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">接收多样化的用户请求，包括文本生成、文本摘要、代码补全等任务</span></span></p></li><li style=\"font-size: 15px;letter-spacing: 1px;\"><p style=\"text-align: justify;line-height: 1.75em;margin-bottom: 24px;\"><strong><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">路由层：</span></span></strong><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">通过预训练Router对输入进行深度分析，基于多维度特征选择最优LLM执行器</span></span></p></li></ol><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">性能优先模式：识别任务领域特征，匹配性能最优的LLM（当前版本核心目标）</span></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">成本优化模式：平衡性能与计算开销，选择性价比最高的LLM（后续版本特性）</span></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">风险控制模式：通过多模型交叉验证，降低单一模型的幻觉风险（后续版本特性）</span></span></section><ol style=\"margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li style=\"font-size: 15px;letter-spacing: 1px;\"><section style=\"text-align: justify;line-height: 1.75em;\"><strong><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">执行层：</span></span></strong><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">由候选LLM池中被选定的模型完成实际推理，并将结果返回给用户</span></span></section></li></ol><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">与MoE（Mixture-of-Experts）相比，路由LLM实现了两大突破：</span></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">协作粒度：在模型级实现专家协作，而非传统MoE的层间专家扩展</span></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">系统开放性：支持跨架构、跨训练阶段的LLM协同，包括闭源模型、开源模型及专用微调模型的混合部署</span></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">这种架构使得路由LLM既能继承MoE的动态优势，又突破了其封闭性限制，为构建开放、灵活的大模型协作系统奠定了基础。</span></span></section><section style=\"text-align: center;margin-top: 0px;margin-bottom: 0px;\"><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-top: 0px;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 85px; height: 40px; max-width: 600px\" data-imgfileid=\"505095291\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span></section><section style=\"text-align: center;margin-bottom: 0px;margin-top: 8px;line-height: 1.75em;\"><span style=\"color: rgb(0, 0, 0);font-size: 19px;letter-spacing: 1px;\"><strong><span leaf=\"\">RouterEval解决了什么问题？</span></strong><p><span style=\"letter-spacing: 1px;\"></span></p></span></section><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-top: 0px;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">研究人员系统性收集、整理并开源了涵盖8567个不同LLM在12个主流评测基准（包括MMLU、GSM8K等）下的2亿条性能记录，基于这些数据构建了面向 router的基准测试平台RouterEval，创新性体现在：</span></span></p><ol style=\"list-style-type: decimal;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li style=\"font-size: 15px;\"><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 24px;\"><span style=\"font-size: 15px;\"><strong><span style=\"letter-spacing: 1px;\"><span leaf=\"\">数据完备性：</span></span></strong><span style=\"letter-spacing: 1px;\"><span leaf=\"\">覆盖从7B到数百B参数规模的LLM，涵盖通用能力、领域专长等多维度的 Benchmark，为router设计提供了全面的训练与验证数据</span></span></span></p></li><li style=\"font-size: 15px;\"><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 24px;\"><span style=\"font-size: 15px;\"><strong><span style=\"letter-spacing: 1px;\"><span leaf=\"\">研究低门槛化：</span></span></strong><span style=\"letter-spacing: 1px;\"><span leaf=\"\">所有性能记录均已预处理完成，研究者只需训练一个分类器（即router）即可开展实验，支持在单卡GPU甚至笔记本电脑上运行，极大降低了参与门槛</span></span></span></p></li><li style=\"font-size: 15px;\"><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 24px;\"><span style=\"font-size: 15px;\"><strong><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">问题范式转化：</span></span></strong><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">将复杂的路由LLM问题转化为标准的分类任务，使研究者可复用成熟的机器学习方法（如few-shot learning、对比学习等）快速切入</span></span></span></p></li></ol><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5953757225433526\" data-type=\"png\" data-w=\"519\" style=\"width: 79%; height: auto !important; flex-basis: auto; max-width: 600px\" data-width=\"519\" data-height=\"309\" data-backw=\"519\" data-backh=\"309\" data-imgfileid=\"505093889\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb0PvPu2FKfVsOXCSCraNPD3dlvVu4xCLL4nJhglRKBiazRFXH1OEuE5Dfu6Vphq6LdVnLIHbKpcSWQ/640?wx_fmt=png&amp;from=appmsg\"></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;font-size: 13px;\" mpa-font-style=\"m97yen6d1ats\" data-mpa-action-id=\"m97yen6o1jq2\" data-pm-slice=\"0 0 []\"><span style=\"letter-spacing: 1px;color: rgb(136, 136, 136);\"><span leaf=\"\">8000+模型的参数量分布</span></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">基于RouterEval的海量数据，研究团队首次揭示了Model-level Scaling Up现象：在具备一定能力的router调度下，路由LLM系统的性能可随候选LLM池的扩大而快速提升。这一现象在以往研究中难以被观察到，主要受限于候选模型数量不足（通常&lt;20个）。</span></span></section><section style=\"text-align: center;margin-top: 0px;margin-bottom: 0px;\"><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-top: 0px;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 85px; height: 40px; max-width: 600px\" data-imgfileid=\"505095291\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span></section><section style=\"text-align: center;margin-bottom: 24px;margin-top: 8px;line-height: 1.75em;\"><span style=\"color: rgb(0, 0, 0);font-size: 19px;letter-spacing: 1px;\"><strong><span leaf=\"\">RouterEval的发现</span></strong></span></section><section style=\"display: flex;align-items: center;text-align: left;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 45px; height: 24px; max-width: 600px\" data-imgfileid=\"505095301\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span><p style=\"font-size: 16px;font-family: mp-quote, \" pingfang sc system-ui blinkmacsystemfont neue sans gb yahei ui arial sans-serif><strong><span style=\"font-size: 17px;letter-spacing: 1px;\"><span leaf=\"\">Model level scaling up现象</span></span></strong></p></section><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">利用RouterEval基准中的2亿条性能记录，研究团队构建了理论性能上限——Oracle Router（r_o）。Oracle Router是一种理想化的路由器，它能够始终为每个输入选择性能最佳的LLM，因此代表了路由LLM系统的性能上限。</span></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.7490234375\" data-type=\"png\" data-w=\"1024\" style=\"width: 100%; height: auto; max-width: 600px\" data-width=\"1024\" data-height=\"767\" data-backw=\"562\" data-backh=\"421\" data-imgfileid=\"505093893\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb0PvPu2FKfVsOXCSCraNPD3S8Xr8KMMYVwW56d0QWkaSBb5C0aOFCXQJB4I9d8jcjO89dzHzrgKlg/640?wx_fmt=png&amp;from=appmsg\"></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">为了系统研究router性能对系统整体表现的影响，研究人员定义了router性能的连续谱系r_o(p)：</span></span></section><ul style=\"margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li style=\"font-size: 15px;letter-spacing: 1px;\"><section style=\"text-align: justify;line-height: 1.75em;margin-bottom: 0px;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">当p→1时，r_o(p)趋近于Oracle Router，代表分类性能接近理论上限</span></span></section></li><li style=\"font-size: 15px;letter-spacing: 1px;\"><section style=\"text-align: justify;line-height: 1.75em;margin-bottom: 0px;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">当p→0时，r_o(p)退化为随机router，即随机选择候选LLM</span></span></section></li><li style=\"font-size: 15px;letter-spacing: 1px;\"><p style=\"text-align: justify;line-height: 1.75em;margin-bottom: 24px;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">中间状态r_o(p)（0<p router></p></span></span></p></li></ul><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">实验结果表明：</span></span></section><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li style=\"font-size: 15px;\"><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 24px;\"><span style=\"font-size: 15px;\"><strong><span style=\"letter-spacing: 1px;\"><span leaf=\"\">强router的scaling up效应：</span></span></strong><span style=\"letter-spacing: 1px;\"><span leaf=\"\">当p＞0.3时，系统性能随候选LLM数量呈明显快速上升</span></span></span></p></li><li style=\"font-size: 15px;\"><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 24px;\"><span style=\"font-size: 15px;\"><strong><span style=\"letter-spacing: 1px;\"><span leaf=\"\">弱router的性能瓶颈：</span></span></strong><span style=\"letter-spacing: 1px;\"><span leaf=\"\">随机router（p=0）几乎未表现出scaling up现象</span></span></span></p></li><li style=\"font-size: 15px;\"><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 24px;\"><span style=\"font-size: 15px;\"><strong><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">超越参考模型：</span></span></strong><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">一般候选LLM数量在3~10且p在0.5~0.7时，系统性能可以接近甚至超过参考模型（参考模型一般是GPT-4）</span></span></span></p></li></ul><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.253071253071253\" data-type=\"png\" data-w=\"407\" height=\"510\" style=\"width: 79%; height: auto !important; flex-basis: auto; max-width: 600px\" width=\"407\" data-width=\"409\" data-height=\"510\" data-backw=\"409\" data-backh=\"510\" data-imgfileid=\"505093894\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb1aaPmd5zY7tSVwSAegicrOHicPRJ6icHz9HuYlJEoheicsEndhns5k8BKFialRwMn6Dmvy0S6ebEABVog/640?\"></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;font-size: 13px;\" mpa-font-style=\"m97yeijp1wrj\" data-mpa-action-id=\"m97yeijylf0\" data-pm-slice=\"0 0 []\"><span style=\"letter-spacing: 1px;color: rgb(136, 136, 136);\"><span leaf=\"\">候选模型数量m = 5</span></span></section><section style=\"display: flex;align-items: center;text-align: left;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 45px; height: 24px; max-width: 600px\" data-imgfileid=\"505095301\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span><p style=\"font-size: 16px;font-family: mp-quote, \" pingfang sc system-ui blinkmacsystemfont neue sans gb yahei ui arial sans-serif><strong><span style=\"font-size: 17px;letter-spacing: 1px;\"><span leaf=\"\">弱模型逆袭效应</span></span></strong></p></section><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">通过智能路由调度，多个性能一般的LLM可以协同实现超越顶级单体模型的性能表现。例如，当使用Oracle Router（r_o）调度5个在MMLU基准上单独表现仅为0.2-0.3的弱模型时，系统整体性能可跃升至0.95，显著超越GPT-4（0.86）。</span></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">这一发现为资源有限的研究者提供了新的技术路径：无需追求单一超大模型，而是通过多个中小模型的智能组合实现性能突破。</span></span></section><section style=\"display: flex;align-items: center;text-align: left;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 45px; height: 24px; max-width: 600px\" data-imgfileid=\"505095301\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span><p style=\"font-size: 16px;font-family: mp-quote, \" pingfang sc system-ui blinkmacsystemfont neue sans gb yahei ui arial sans-serif><strong><span style=\"font-size: 17px;letter-spacing: 1px;\"><span leaf=\"\">候选池规模阈值</span></span></strong></p></section><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">从Model-level Scaling Up现象示意图可以看到3-10个LLM候选的时候已经可以达到非常不错的性能。而且此时的部署成本并不高，具有很高的性价比。</span></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">实验数据表明，路由LLM系统的性能提升存在明显的规模经济拐点：</span></span></section><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li style=\"font-size: 15px;\"><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 24px;\"><span style=\"font-size: 15px;\"><strong><span style=\"letter-spacing: 1px;\"><span leaf=\"\">3-5个候选LLM：</span></span></strong><span style=\"letter-spacing: 1px;\"><span leaf=\"\">可覆盖大部分常见任务需求，部署成本相比单一顶级模型低。</span></span></span></p></li><li style=\"font-size: 15px;\"><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 24px;\"><span style=\"font-size: 15px;\"><strong><span style=\"letter-spacing: 1px;\"><span leaf=\"\">5-10个候选LLM：</span></span></strong><span style=\"letter-spacing: 1px;\"><span leaf=\"\">性能进入稳定提升期，在多数基准上可超越GPT-4等顶级单体模型</span></span></span></p></li><li style=\"font-size: 15px;\"><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 24px;\"><span style=\"font-size: 15px;\"><strong><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">多于10个候选LLM：</span></span></strong><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">性能增益存在边际效应，每增加1个模型带来的性能提升并不大</span></span></span></p></li></ul><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">这一发现为实际部署提供了重要指导：在大多数应用场景下，维护一个5-10个模型的候选池即可实现性能与成本的最佳平衡。</span></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">例如，在智能客服系统中，组合使用GPT-4（复杂问题）、Llama-3-8B（常规问题）和Phi-3（意图识别）三个模型，即可在保证服务质量的同时将运营成本显著降低。</span></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.92\" data-type=\"png\" data-w=\"1050\" style=\"width: 100%; height: auto; max-width: 600px\" data-width=\"1050\" data-height=\"966\" data-backw=\"562\" data-backh=\"517\" data-imgfileid=\"505093896\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb0PvPu2FKfVsOXCSCraNPD3R4NMyho02r9qelCMQXhbFrdJECmWicnQ9nEczMnpUfE0QXbIFS0sibEw/640?wx_fmt=png&amp;from=appmsg\"></section><section style=\"text-align: center;margin-top: 0px;margin-bottom: 0px;\"><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-top: 0px;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 85px; height: 40px; max-width: 600px\" data-imgfileid=\"505095291\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span></section><section style=\"text-align: center;margin-bottom: 24px;margin-top: 8px;line-height: 1.75em;\"><span style=\"color: rgb(0, 0, 0);font-size: 19px;letter-spacing: 1px;\"><strong><span leaf=\"\">主要挑战</span></strong></span></section><section style=\"display: flex;align-items: center;text-align: left;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 45px; height: 24px; max-width: 600px\" data-imgfileid=\"505095301\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span><p style=\"font-size: 16px;font-family: mp-quote, \" pingfang sc system-ui blinkmacsystemfont neue sans gb yahei ui arial sans-serif><strong><span style=\"font-size: 17px;letter-spacing: 1px;\"><span leaf=\"\">数据壁垒</span></span></strong></p></section><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">要训练出高性能的router，当前可用的性能记录数据仍然远远不足。由于大多数LLM的性能数据掌握在少数科技公司手中且未开源，这需要整个研究社区的共同努力来构建更全面的数据集。目前，可以通过迁移学习、数据增强等算法技术在一定程度上缓解数据不足的问题；</span></span></section><section style=\"display: flex;align-items: center;text-align: left;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 45px; height: 24px; max-width: 600px\" data-imgfileid=\"505095301\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span><p style=\"font-size: 16px;font-family: mp-quote, \" pingfang sc system-ui blinkmacsystemfont neue sans gb yahei ui arial sans-serif><strong><span style=\"font-size: 17px;letter-spacing: 1px;\"><span leaf=\"\">多候选分类挑战</span></span></strong></p></section><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">随着候选LLM数量的增加，router需要处理的分类任务复杂度显著上升。这不仅增加了模型训练的难度，也对router的泛化能力提出了更高要求。如何在保证分类精度的同时控制计算开销，是未来研究的重点方向之一；</span></span></section><section style=\"display: flex;align-items: center;text-align: left;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 45px; height: 24px; max-width: 600px\" data-imgfileid=\"505095301\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span><p style=\"font-size: 16px;font-family: mp-quote, \" pingfang sc system-ui blinkmacsystemfont neue sans gb yahei ui arial sans-serif><strong><span style=\"font-size: 17px;letter-spacing: 1px;\"><span leaf=\"\">多目标权衡局限</span></span></strong></p></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"></span></section><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-top: 0px;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">虽然路由LLM理论上可以同时优化性能、计算成本和幻觉风险等多个目标，但RouterEval目前仅聚焦于性能优化。这是因为当前router的性能水平尚未达到理想状态，过早引入多目标优化可能会分散研究重点。此外，计算成本和幻觉风险等指标的数据采集难度较大，需要社区共同推动相关数据集的构建；</span></span></p><section style=\"display: flex;align-items: center;text-align: left;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 45px; height: 24px; max-width: 600px\" data-imgfileid=\"505095301\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span><p style=\"font-size: 16px;font-family: mp-quote, \" pingfang sc system-ui blinkmacsystemfont neue sans gb yahei ui arial sans-serif><strong><span style=\"font-size: 17px;letter-spacing: 1px;\"><span leaf=\"\">部署复杂度</span></span></strong></p></section><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span style=\"font-size: 15px;letter-spacing: 1px;\"><span leaf=\"\">即使获得了高性能的router，实际部署仍面临诸多挑战。多个LLM的协同运行需要解决计算负载均衡、资源动态分配、模型高效激活等系统级问题。幸运的是，实验表明仅需部署3-10个LLM即可获得优异性能，这大大降低了实际应用的复杂度。未来研究可借鉴分布式计算领域的技术成果，进一步优化部署方案。</span></span></section><section style=\"max-width: 100%;min-height: 1em;white-space: normal;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb left border-box break-word><span style=\"font-size: 14px;color: rgb(136, 136, 136);letter-spacing: 1px;\"><span leaf=\"\">参考资料：</span></span></section><section style=\"max-width: 100%;min-height: 1em;white-space: normal;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb left border-box break-word><span style=\"font-size: 14px;color: rgb(136, 136, 136);letter-spacing: 1px;\"><span style=\"color: rgb(136, 136, 136);font-size: 14px;letter-spacing: 1px;text-align: left;\"><span leaf=\"\">https://arxiv.org/abs/2503.10657</span></span></span></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;\"><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-backh=\"335\" data-backw=\"578\" data-imgfileid=\"505099886\" data-ratio=\"0.5796296296296296\" data-s=\"300,640\" data-type=\"jpeg\" data-w=\"1080\" style=\"width: 100%; max-width: 600px\" type=\"block\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_jpg/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEB2ibVO28QoKmhefaVibmvfHcgN4ib82J3kNARoC6jK19jUCLN3m23pwxw/640?wx_fmt=jpeg&amp;from=appmsg\"></section><p style=\"display: none;\"><mp-style-type data-value=\"3\"></mp-style-type></p></div>\n    \n\n    \n    <br>\n\n    \n        <a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2652583537&amp;idx=2&amp;sn=2c33a7e1257be11bb858f424398a2612&amp;chksm=f0e72c39c9b358001917d1fc63b1eeaa8562692ae5a946cfbaa0998944b2f9eed09d2ce492e9&amp;scene=0#rd\" style=\"color: blue\" class=\"media_tool_meta meta_primary\">文章原文</a>\n        <br>\n    \n\n    \n\n    <img alt=\"\" width=\"1px\" height=\"1px\" class=\"\" style=\"width:1px;height:1px;display:none\" src=\"http://www.jintiankansha.me/rss_static/83671/QwgxmC3ymb\">\n\n",
          "contentSnippet": "新智元报道  \n\n\n\n编辑：LRST 好困\n\n\n【新智元导读】路由LLM是指一种通过router动态分配请求到若干候选LLM的机制。论文提出且开源了针对router设计的全面RouterEval基准，通过整合8500+个LLM在12个主流Benchmark上的2亿条性能记录。将大模型路由问题转化为标准的分类任务，使研究者可在单卡甚至笔记本电脑上开展前沿研究。这一突破不仅为学术界提供了低门槛的研究工具，更为大模型性能优化提供了新的思路：通过智能调度实现异构模型的协同增效，以极低的计算成本突破单一模型的性能上限。\n\n\n当前大模型研究面临三大困境：算力垄断（顶尖成果集中于大厂）、成本壁垒（单次训练成本高，可能需要数千GPU小时）以及技术路径单一化（过度依赖单一模型的规模扩展）。\n为突破这些限制，路由LLM（Routing LLM）范式应运而生——通过智能调度实现多个开源小模型的协同增效，以「组合创新」替代「规模竞赛」。\n\n代码：https://github.com/MilkThink-Lab/RouterEval\n论文: https://arxiv.org/abs/2503.10657\n论文合集：https://github.com/MilkThink-Lab/Awesome-Routing-LLMs\n路由LLM实际上是model level的MoE（Mixture-of-Experts），传统MoE通过在模型内部扩展专家网络（如稀疏激活的FFN层）提升性能，而路由LLM将完整LLM视为独立「专家」，通过预训练Router动态分配任务输入。\n\n三个大模型=OpenAI\n这种范式具有三重优势：\n\n异构兼容性：支持闭源模型（如GPT-4）、开源模型（如Llama系列）及专用微调模型的混合部署。\n\n多目标优化：可根据场景需求，在性能、成本、风险控制等维度实现动态权衡\n\n灵活部署：可根据实际需求动态调整候选模型池，针对特定场景（如代码生成、医疗问答）快速定制专属解决方案，而无需从头训练大模型\n\n\n\n\n路由LLM范式的核心机制\n\n路由LLM系统采用「输入-路由-执行器」三级架构，其中路由层是系统的智能中枢，承担着任务分配与资源调度的核心功能：\n\n输入层：接收多样化的用户请求，包括文本生成、文本摘要、代码补全等任务\n\n路由层：通过预训练Router对输入进行深度分析，基于多维度特征选择最优LLM执行器\n\n性能优先模式：识别任务领域特征，匹配性能最优的LLM（当前版本核心目标）\n成本优化模式：平衡性能与计算开销，选择性价比最高的LLM（后续版本特性）\n风险控制模式：通过多模型交叉验证，降低单一模型的幻觉风险（后续版本特性）\n\n执行层：由候选LLM池中被选定的模型完成实际推理，并将结果返回给用户\n\n与MoE（Mixture-of-Experts）相比，路由LLM实现了两大突破：\n协作粒度：在模型级实现专家协作，而非传统MoE的层间专家扩展\n系统开放性：支持跨架构、跨训练阶段的LLM协同，包括闭源模型、开源模型及专用微调模型的混合部署\n这种架构使得路由LLM既能继承MoE的动态优势，又突破了其封闭性限制，为构建开放、灵活的大模型协作系统奠定了基础。\n\n\n\nRouterEval解决了什么问题？\n\n\n研究人员系统性收集、整理并开源了涵盖8567个不同LLM在12个主流评测基准（包括MMLU、GSM8K等）下的2亿条性能记录，基于这些数据构建了面向 router的基准测试平台RouterEval，创新性体现在：\n\n数据完备性：覆盖从7B到数百B参数规模的LLM，涵盖通用能力、领域专长等多维度的 Benchmark，为router设计提供了全面的训练与验证数据\n\n研究低门槛化：所有性能记录均已预处理完成，研究者只需训练一个分类器（即router）即可开展实验，支持在单卡GPU甚至笔记本电脑上运行，极大降低了参与门槛\n\n问题范式转化：将复杂的路由LLM问题转化为标准的分类任务，使研究者可复用成熟的机器学习方法（如few-shot learning、对比学习等）快速切入\n\n\n8000+模型的参数量分布\n基于RouterEval的海量数据，研究团队首次揭示了Model-level Scaling Up现象：在具备一定能力的router调度下，路由LLM系统的性能可随候选LLM池的扩大而快速提升。这一现象在以往研究中难以被观察到，主要受限于候选模型数量不足（通常<20个）。\n\n\n\nRouterEval的发现\n\nModel level scaling up现象\n\n\n\n利用RouterEval基准中的2亿条性能记录，研究团队构建了理论性能上限——Oracle Router（r_o）。Oracle Router是一种理想化的路由器，它能够始终为每个输入选择性能最佳的LLM，因此代表了路由LLM系统的性能上限。\n\n为了系统研究router性能对系统整体表现的影响，研究人员定义了router性能的连续谱系r_o(p)：\n\n当p→1时，r_o(p)趋近于Oracle Router，代表分类性能接近理论上限\n\n当p→0时，r_o(p)退化为随机router，即随机选择候选LLM\n\n中间状态r_o(p)（0\n\n\n实验结果表明：\n\n强router的scaling up效应：当p＞0.3时，系统性能随候选LLM数量呈明显快速上升\n\n弱router的性能瓶颈：随机router（p=0）几乎未表现出scaling up现象\n\n超越参考模型：一般候选LLM数量在3~10且p在0.5~0.7时，系统性能可以接近甚至超过参考模型（参考模型一般是GPT-4）\n\n\n候选模型数量m = 5\n\n弱模型逆袭效应\n\n\n\n通过智能路由调度，多个性能一般的LLM可以协同实现超越顶级单体模型的性能表现。例如，当使用Oracle Router（r_o）调度5个在MMLU基准上单独表现仅为0.2-0.3的弱模型时，系统整体性能可跃升至0.95，显著超越GPT-4（0.86）。\n这一发现为资源有限的研究者提供了新的技术路径：无需追求单一超大模型，而是通过多个中小模型的智能组合实现性能突破。\n\n候选池规模阈值\n\n\n\n从Model-level Scaling Up现象示意图可以看到3-10个LLM候选的时候已经可以达到非常不错的性能。而且此时的部署成本并不高，具有很高的性价比。\n实验数据表明，路由LLM系统的性能提升存在明显的规模经济拐点：\n\n3-5个候选LLM：可覆盖大部分常见任务需求，部署成本相比单一顶级模型低。\n\n5-10个候选LLM：性能进入稳定提升期，在多数基准上可超越GPT-4等顶级单体模型\n\n多于10个候选LLM：性能增益存在边际效应，每增加1个模型带来的性能提升并不大\n\n这一发现为实际部署提供了重要指导：在大多数应用场景下，维护一个5-10个模型的候选池即可实现性能与成本的最佳平衡。\n例如，在智能客服系统中，组合使用GPT-4（复杂问题）、Llama-3-8B（常规问题）和Phi-3（意图识别）三个模型，即可在保证服务质量的同时将运营成本显著降低。\n\n\n\n\n主要挑战\n\n数据壁垒\n\n\n\n要训练出高性能的router，当前可用的性能记录数据仍然远远不足。由于大多数LLM的性能数据掌握在少数科技公司手中且未开源，这需要整个研究社区的共同努力来构建更全面的数据集。目前，可以通过迁移学习、数据增强等算法技术在一定程度上缓解数据不足的问题；\n\n多候选分类挑战\n\n\n\n随着候选LLM数量的增加，router需要处理的分类任务复杂度显著上升。这不仅增加了模型训练的难度，也对router的泛化能力提出了更高要求。如何在保证分类精度的同时控制计算开销，是未来研究的重点方向之一；\n\n多目标权衡局限\n\n\n虽然路由LLM理论上可以同时优化性能、计算成本和幻觉风险等多个目标，但RouterEval目前仅聚焦于性能优化。这是因为当前router的性能水平尚未达到理想状态，过早引入多目标优化可能会分散研究重点。此外，计算成本和幻觉风险等指标的数据采集难度较大，需要社区共同推动相关数据集的构建；\n\n部署复杂度\n\n\n\n即使获得了高性能的router，实际部署仍面临诸多挑战。多个LLM的协同运行需要解决计算负载均衡、资源动态分配、模型高效激活等系统级问题。幸运的是，实验表明仅需部署3-10个LLM即可获得优异性能，这大大降低了实际应用的复杂度。未来研究可借鉴分布式计算领域的技术成果，进一步优化部署方案。\n参考资料：\nhttps://arxiv.org/abs/2503.10657\n\n\n\n\n\n    \n\n    \n    \n文章原文",
          "guid": "http://www.jintiankansha.me/t/QwgxmC3ymb",
          "categories": [
            "无"
          ],
          "isoDate": "2025-04-08T04:00:00.000Z"
        }
      },
      {
        "json": {
          "title": "斯坦福2025 AI指数出炉！中美AI终极对决差距仅剩0.3%，DeepSeek领衔",
          "link": "http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652583537&idx=1&sn=d16b93d277bd0d7b86fd903acf74cf21&chksm=f0f188d3862f87c789e44dab16b071e9f51fc249b0a5cdd067b7e19bed1c287d44ca5e711802&scene=0#rd",
          "pubDate": "Tue, 08 Apr 2025 12:00:00 +0800",
          "enclosure": {
            "url": "http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_jpg/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdE7HODcQemkEqerK5x9q5AGyamMRtSOJnFlhv994UnVTZhiczMI5D1cKg/0?wx_fmt=jpeg",
            "length": "0",
            "type": "image/jpeg"
          },
          "content": "\n\n    \n\n    \n\n    \n         <div class=\"rich_media_content\" id=\"js_content\"><h3 data-mpa-powered-by=\"yiban.io\" style=\"outline: 0px;color: rgb(34, 34, 34);letter-spacing: 0.544px;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb visible><section data-tools=\"135编辑器\" data-id=\"88402\" style=\"outline: 0px;line-height: 27.2px;widows: 1;visibility: visible;\"><section data-tools=\"135编辑器\" data-id=\"88402\" style=\"outline: 0px;letter-spacing: 0.544px;line-height: 27.2px;visibility: visible;\"><section data-style=\"line-height: 1.8; text-align: justify; font-size: 15px; letter-spacing: 0px; color: rgb(117, 114, 114);white-space: normal;\" style=\"outline: 0px;visibility: visible;\"><section style=\"outline: 0px;visibility: visible;\"><section style=\"text-align: center;margin-bottom: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.42643923240938164\" data-s=\"300,640\" data-type=\"jpeg\" data-w=\"2345\" style=\"width: 100%; max-width: 600px\" type=\"block\" data-backw=\"578\" data-backh=\"246\" data-imgfileid=\"505099882\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_jpg/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEiacPGQmxs9U34rGbEmz7XkscEicV4sHJ1ibZtAUpGFrLoDZr3BdGtCEsQ/640?wx_fmt=jpeg&amp;from=appmsg\"></section></section></section></section></section></h3><h3 style=\"outline: 0px;color: rgb(34, 34, 34);letter-spacing: 0.544px;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb visible><section data-tools=\"135编辑器\" data-id=\"88402\" style=\"outline: 0px;line-height: 27.2px;widows: 1;visibility: visible;\"><section data-tools=\"135编辑器\" data-id=\"88402\" style=\"outline: 0px;letter-spacing: 0.544px;line-height: 27.2px;visibility: visible;\"><section data-style=\"line-height: 1.8; text-align: justify; font-size: 15px; letter-spacing: 0px; color: rgb(117, 114, 114);white-space: normal;\" style=\"outline: 0px;visibility: visible;\"><section style=\"outline: 0px;visibility: visible;\"><section style=\"outline: 0px;visibility: visible;\"><hr style=\"outline: 0px;font-size: 17px;letter-spacing: 0.544px;visibility: visible;\"><p style=\"margin-top: -1.2em;margin-right: 8px;margin-left: 8px;outline: 0px;font-size: 17px;letter-spacing: 0.544px;line-height: 1.75em;visibility: visible;\"><span leaf=\"\"><br></span></p><p style=\"margin-top: -1.2em;margin-right: 8px;margin-left: 8px;outline: 0px;font-size: 17px;letter-spacing: 0.544px;text-align: center;line-height: 1.75em;visibility: visible;\"><span style=\"outline: 0px;letter-spacing: 1px;visibility: visible;\"><strong style=\"outline: 0px;font-family: inherit;font-size: 1em;text-decoration: inherit;visibility: visible;\"><span style=\"outline: 0px;font-size: 18px;color: rgb(255, 255, 255);line-height: 1.4;font-family: inherit;font-weight: inherit;text-decoration: inherit;background-color: rgb(127, 127, 127);visibility: visible;\"><span leaf=\"\">  </span></span></strong><strong style=\"outline: 0px;font-size: 1em;font-family: inherit;text-decoration: inherit;visibility: visible;\"><span style=\"outline: 0px;font-size: 18px;color: rgb(255, 255, 255);line-height: 1.4;font-family: inherit;font-weight: inherit;text-decoration: inherit;background-color: rgb(127, 127, 127);visibility: visible;\"><span leaf=\"\">新智元报道  </span></span></strong></span></p></section></section></section></section></section></h3><section style=\"margin-right: 8px;margin-bottom: 0px;margin-left: 8px;outline: 0px;color: rgb(34, 34, 34);letter-spacing: 0.544px;min-height: 1em;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb center visible><span style=\"outline: 0px;font-size: 12px;color: rgb(136, 136, 136);font-family: \" helvetica neue sans gb yahei arial sans-serif visible><span leaf=\"\">编辑：编辑部</span></span></section><section powered-by=\"xiumi.us\" style=\"margin-bottom: 0px;outline: 0px;color: rgb(34, 34, 34);letter-spacing: 0.544px;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb visible><section style=\"outline: 0px;visibility: visible;\"><section style=\"outline: 0px;visibility: visible;\"><h5 style=\"margin-top: 10px;margin-right: 8px;margin-left: 8px;padding: 10px;font-size: 14px;outline: 0px;color: rgb(0, 0, 0);letter-spacing: 0.544px;font-family: Arial, Helvetica, sans-serif;border-radius: 3px;background-color: rgb(248, 248, 248);line-height: 1.75em;visibility: visible;word-break: break-all !important;word-spacing: 1px !important;\"><span style=\"outline: 0px;letter-spacing: 1px;font-size: 15px;visibility: visible;\"><strong style=\"outline: 0px;visibility: visible;\"><span leaf=\"\">【新智元导读】<span textstyle=\"\" style=\"font-weight: normal;\">202</span></span><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal data-pm-slice=\"1 1 [\" para margin-right: line-height:><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">5年斯坦福HAI报告重磅发布，456页深度剖析全球AI领域的最新趋势：中美顶级模型性能差距缩至0.3%，以DeepSeek为代表的模型强势崛起，逼近闭源巨头；推理成本暴降，小模型性能飙升，AI正变得更高效、更普惠。</span></span></strong></span></h5></section></section></section><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-top: 24px;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">就在刚刚，每年都备受瞩目的斯坦福AI指数报告，重磅发布了！</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-top: 24px;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">这份报告由斯坦福大学以人为本AI研究员发布，代表着每年AI领域最核心和前沿的动向总结。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">今年，这份报告长达456页，抛出不少惊人观点。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-backh=\"375\" data-backw=\"562\" data-height=\"1333\" data-imgfileid=\"505099843\" data-ratio=\"0.6665\" data-type=\"png\" data-w=\"2000\" data-width=\"2000\" style=\"width:100%; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdESCeHdIuY6ibkHS69C3YD9wFicCics4ObnlZHGWFqZ4TmpqS1wic5H42Vng/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">比如，如今在2025年，中美顶级AI模型的性能差距已经缩小到了0.3%（2023年，这一数字还是20%），中国模型正在快速追赶美国的领先地位！</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">而DeepSeek领衔的开放权重模型，更是以1.7%之差，逼宫各大闭源巨头。前者和后者的差距，已经由2024年的8%，缩小至2025年的1.7%。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">当然，目前从行业主导企业来看，美国仍然领先于中国。在2024年，90%的知名AI模型来自企业，美国以40个模型领先，中国有15个。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">更明显的一个趋势，就是如今大模型的性能已经趋同！在2024年，TOP1和TOP10的模型的差距能有12%，但如今，它们的差距已经越来越小，锐减至5%。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.7323568575233023\" data-type=\"png\" data-w=\"751\" style=\"width:100%; max-width: 600px\" data-width=\"751\" data-height=\"550\" data-backw=\"562\" data-backh=\"412\" data-imgfileid=\"505099841\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEJ2ficyNFgw6l0LYRxmEA6UzpQTBnpyo4UKWHcJtGd3hTqiceicoggd5cA/640?wx_fmt=png&amp;from=appmsg\"></section><section style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-top: 0px;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 85px; height: 40px; max-width: 600px\" data-imgfileid=\"505095291\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span></section><section style=\"text-align: center;margin-bottom: 0px;margin-top: 8px;line-height: 1.75em;\"><span style=\"color: rgb(0, 0, 0);font-size: 19px;letter-spacing: 1px;\"><strong><span leaf=\"\">十二大亮点</span></strong></span></section><h2 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><br></span></h2><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 24px;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">最新的斯坦福HAI两篇博文中，浓缩了2025年AI指数报告的十二大亮点。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 24px;font-size: 16px;\" mpa-font-style=\"m97yyec81ppo\" data-mpa-action-id=\"m97yyeckw6b\" data-pm-slice=\"0 0 []\"><span leaf=\"\"><span textstyle=\"\" style=\"letter-spacing: 1px;color: rgb(255, 104, 39);font-weight: bold;\">1. AI性能再攀高峰，从基准测试到视频生成全面突破</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-top: 24px;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">2023年，研究人员推出了MMMU、GPQA和SWE-bench等新基准来测试先进AI系统的极限。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">仅一年后，性能便大幅提升：AI在三项基准得分分别飙升18.8%、48.9%和67.3%。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">不仅如此，AI在生成高质量视频方面取得重大突破，甚至，在某些场景下AI智能体甚至超越人类表现。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.7494736842105263\" data-type=\"png\" data-w=\"1900\" style=\"width:100%; max-width: 600px\" data-width=\"1900\" data-height=\"1424\" data-backw=\"562\" data-backh=\"421\" data-imgfileid=\"505099842\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEqDNADrkib6WnMPicvmy8mIsZhmX4bJwUjevDa6InWe4iaQ7iaSG7vTYJ2w/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;font-weight: bold;\">·</span></span></strong><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;font-weight: bold;\"> </span></span></strong><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;font-weight: bold;\">更有用智能体崛起 </span></span></strong></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">2024年发布的RE-Bench基准测试，为评估AI智能体复杂任务能力设立了严苛标准。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">数据显示：在短期任务（2小时内）场景下，顶级AI系统的表现可达人类专家的4倍；但当任务时限延长至32小时，人类则以2:1的优势反超。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">值得注意的是，AI已在特定领域，如编写特定类型代码，展现出与人类相当的专业水平，且执行效率更胜一筹。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5304437564499485\" data-type=\"png\" data-w=\"1938\" style=\"width: 100%; max-width: 600px\" data-width=\"1938\" data-height=\"1028\" data-backw=\"562\" data-backh=\"298\" data-imgfileid=\"505099839\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEXQ6qcuGmDPiaXOmicD7ZbYu0oia0xNn9Dx3EnvPVLUzNT6iam7XekqSCbQ/640?wx_fmt=png&amp;from=appmsg\"></section><h3 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><br></span></strong></h3><h3 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\"><span textstyle=\"\" style=\"letter-spacing: 1px;color: rgb(255, 104, 39);\">2. 美国领跑顶尖模型研发，但中国与之差距逐渐缩小</span></span></strong></h3><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-top: 24px;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">2024年，美国产出40个重要AI模型，远超中国的15个和欧洲的3个。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">然而，中国模型在性能上的差距正加速缩小：MMLU等基准测试中，中美AI差异从两位数缩小至近乎持平。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">同时，中国在AI学术论文和专利申请量上持续领跑，中东、拉美和东南亚地区也涌现出具有竞争力的模型。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5331465919701214\" data-type=\"png\" data-w=\"2142\" style=\"width:100%; max-width: 600px\" data-width=\"2142\" data-height=\"1142\" data-backw=\"562\" data-backh=\"300\" data-imgfileid=\"505099840\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEicogEq1MGxDgGK6CDmscDMXmkGLqkUSRrvV9huUgFXfI354j7PSrOcg/640?wx_fmt=png&amp;from=appmsg\"></section><h3 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><br></span></strong></h3><h3 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\"><span textstyle=\"\" style=\"letter-spacing: 1px;color: rgb(255, 104, 39);\">3. AI正变得高效且普惠，推理成本暴降280倍</span></span></strong></h3><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">随着小模型性能提升，达到GPT-3.5水平的推理成本在两年间下降280倍，硬件成本以每年30%的速度递减，能效年提升率达40%。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">更令人振奋的是，开源模型性能突飞猛进，部分基准测试中与闭源模型的差距从8%缩至1.7%。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;font-weight: bold;\">· 大模型使用成本持续走低</span></span></strong><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;font-weight: bold;\">，年降幅最高900倍</span></span></strong></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">在MMLU基准测试中达到GPT-3.5水平（MMLU准确率64.8%）的AI模型调用成本，已从2022年11月的20美元/每百万token，骤降至2024年10月的0.07美元/每百万token（谷歌DeepMind的Gemini-1.5-Flash-8B模型），18个月内AI成本下降280倍。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">视具体任务需求，LLM推理服务价格的年降幅可达9-900倍不等。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.531875\" data-type=\"png\" data-w=\"1600\" style=\"width:100%; max-width: 600px\" data-width=\"1600\" data-height=\"851\" data-backw=\"562\" data-backh=\"299\" data-imgfileid=\"505099848\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEKCpYmHGhTPbrgD3XfcFhdZ9bIJiaKdsCoOqyQZcpLNS4yTRgy1lEaYw/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;font-weight: bold;\">·</span></span></strong><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;font-weight: bold;\"> </span></span></strong><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;font-weight: bold;\">小模型性能显著提升</span></span></strong><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;font-weight: bold;\">，参数暴减142倍</span></span></strong></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">2022年，在大规模多任务语言理解（MMLU）基准测试中，得分超60%的最小模型是 PaLM，参数量为5400亿。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">到了2024年，微软Phi-3-mini仅用38亿参数，就取得了同样的实力。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">这代表，两年多的时间里模型参数减少了142倍。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5286506469500925\" data-type=\"png\" data-w=\"2164\" style=\"width:100%; max-width: 600px\" data-width=\"2164\" data-height=\"1144\" data-backw=\"562\" data-backh=\"297\" data-imgfileid=\"505099845\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEevia7Tret6C5Kx41AYgR4jibc7oORIco5g4pobhAqcpvdFiaRILbhveqA/640?wx_fmt=png&amp;from=appmsg\"></section><h3 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><br></span></strong></h3><h3 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\"><span textstyle=\"\" style=\"letter-spacing: 1px;color: rgb(255, 104, 39);\">4. 科技巨头称霸AI前沿，但竞争白热化</span></span></strong></h3><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">2024年，近90%的重要模型源自企业，学术界则保持基础研究优势。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">模型规模呈指数增长：训练算力每5个月翻番，数据集每8个月扩容一倍。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">值得注意的是，头部模型性能差距显著缩小，榜首与第十名得分差已从11.9%降至5.4%。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-backh=\"295\" data-backw=\"562\" data-height=\"1144\" data-imgfileid=\"505099849\" data-ratio=\"0.5242896425297892\" data-type=\"png\" data-w=\"2182\" data-width=\"2182\" style=\"width:100%; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdExicQ0viaH4TNibiadf3quysZlHRpZGnKaRqrVCkphC7gRTu01ib1dhFLyow/640?wx_fmt=png&amp;from=appmsg\"></section><h3 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><br></span></strong></h3><h3 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\"><span textstyle=\"\" style=\"color: rgb(255, 104, 39);\">5. AI逻辑短板，推理能力仍是瓶颈</span></span></strong></h3><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">采用符号推理方法的AI系统，能较好解决IMO问题（虽未达人类顶尖水平），但LLM在MMMU等复杂推理任务中表现欠佳，尤其不擅长算术推导和规划类强逻辑性任务。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">这一局限影响了其在医疗诊断等高风险场景的应用可靠性。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-backh=\"301\" data-backw=\"562\" data-height=\"1046\" data-imgfileid=\"505099846\" data-ratio=\"0.5364102564102564\" data-type=\"png\" data-w=\"1950\" data-width=\"1950\" style=\"width:100%; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdENN6Ijolz8kAlicABkq6G2ayhFR8nphMB3LLibawmn3HOGr2NXN4xma3w/640?wx_fmt=png&amp;from=appmsg\"></section><h3 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><br></span></strong></h3><h3 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\"><span textstyle=\"\" style=\"color: rgb(255, 104, 39);\">6. 大厂ALL in AI，投资与采用率创双纪录</span></span></strong></h3><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">科技大厂们，正全力押注AI。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">2024年，美国私营AI投资达1091亿美元，约为中国（93亿）的12倍、英国（45亿）的24倍。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">生成式AI势头尤猛，全球私募投资达339亿美元（同比增18.7%）。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">与此同时，企业AI采用率从55%升至78%。研究证实，AI不仅能提升生产力，多数情况下还可缩小劳动力技能差距。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">更引人注目的是，将生成式AI应用于至少一项业务职能的企业数量激增——从2023年的33%跃升至去年的71%，增幅超一倍。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-backh=\"298\" data-backw=\"562\" data-height=\"1024\" data-imgfileid=\"505099847\" data-ratio=\"0.5305699481865285\" data-type=\"png\" data-w=\"1930\" data-width=\"1930\" style=\"width:100%; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEJYtZlMiaWsIn95EK1rNUG8MCRAOgz7ibnCbWCu0Ew6vJvGNvdbuYibbibg/640?wx_fmt=png&amp;from=appmsg\"></section><h3 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><br></span></strong></h3><h3 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\"><span textstyle=\"\" style=\"color: rgb(255, 104, 39);\">7. AI荣膺科学界最高荣誉，摘诺奖桂冠</span></span></strong></h3><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">2024年，两项诺贝尔奖分别授予深度学习理论基础（物理学）和蛋白质折叠预测（化学）研究，图灵奖则花落强化学习领域。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-backh=\"300\" data-backw=\"562\" data-height=\"1038\" data-imgfileid=\"505099851\" data-ratio=\"0.5345005149330587\" data-type=\"png\" data-w=\"1942\" data-width=\"1942\" style=\"width:100%; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEOU4Y7wViaHrUiauEZ4uFCeWGrhRugUZBREDzcWeiaCdNbnWRqtbq3vjeQ/640?wx_fmt=png&amp;from=appmsg\"></section><h3 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><br></span></strong></h3><h3 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\"><span textstyle=\"\" style=\"color: rgb(255, 104, 39);\">8. AI教育普及加速，但资源差距仍存</span></span></strong></h3><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">全球2/3国家已或计划开展K-12计算机科学教育，但非洲地区受限于电力等基础设施，推进缓慢。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">美国81%的计算机教师认为AI应纳入基础课程，但仅47%具备相应教学能力。</span></span></p><h3 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><br></span></strong></h3><h3 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\"><span textstyle=\"\" style=\"letter-spacing: 1px;color: rgb(255, 104, 39);\">9. AI正深度融入日常生活</span></span></strong></h3><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">从医疗到交通，AI正快速从实验室走向现实。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">1995年，FDA批准了第一款AI赋能的医疗器械。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">截至2024年8月，FDA已批准950款AI医疗设备——较2015年的6款和2023年的221款，增长迅猛。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">而在自动驾驶领域，汽车已脱离实验阶段：美国头部运营商Waymo每周提供超15万次无人驾驶服务。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-backh=\"300\" data-backw=\"562\" data-height=\"1040\" data-imgfileid=\"505099850\" data-ratio=\"0.5344295991778006\" data-type=\"png\" data-w=\"1946\" data-width=\"1946\" style=\"width: 100%; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEfVbXfzBLPpQiazTOOz5ibVA4z4215v5X2PQlqrNr0ibUWaJq0IwZA3Miaw/640?wx_fmt=png&amp;from=appmsg\"></section><h3 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\"><br></span></strong></h3><h3 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\"><span textstyle=\"\" style=\"letter-spacing: 1px;color: rgb(255, 104, 39);\">10. 全球AI乐观情绪上升，但地区差异显著</span></span></strong></h3><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">中国（83%）、印尼（80%）和泰国（77%）民众对AI持积极态度，而加拿大（40%）、美国（39%）等发达国家则相对保守。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">值得关注的是，德国（+10%）、法国（+10%）等原怀疑论国家态度明显转变。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-backh=\"479\" data-backw=\"562\" data-height=\"1534\" data-imgfileid=\"505099854\" data-ratio=\"0.8522222222222222\" data-type=\"png\" data-w=\"1800\" data-width=\"1800\" style=\"width:100%; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdE8KjPIXq0e4hHiah8Ec3DrPcJuHibkvj9FEBLsDE2EsvYOaibCNujS4dQA/640?wx_fmt=png&amp;from=appmsg\"></section><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.3888888888888888\" data-type=\"png\" data-w=\"1152\" style=\"width:100%; max-width: 600px\" data-width=\"1152\" data-height=\"1600\" data-backw=\"562\" data-backh=\"781\" data-imgfileid=\"505099852\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEduR46tkAgeUKD8K05nUBZ1QZ0dVjBHbo7ZDNLYMuxXgmj6A2oIMfJQ/640?wx_fmt=png&amp;from=appmsg\"></section><h3 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><br></span></strong></h3><h3 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\"><span textstyle=\"\" style=\"letter-spacing: 1px;color: rgb(255, 104, 39);font-weight: bold;\">11. 负责任AI生态发展不均</span></span></strong></h3><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">虽然AI安全事件激增，但主流模型开发商仍缺乏标准化评估体系。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">HELM Safety、AIR-Bench和FACTS等新基准为事实性与安全性评估提供工具。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">企业普遍存在「认知与行动脱节」，而各国政府加速协作：2024年，经合组织、欧盟等国际机构相继发布聚焦透明度、可信度的治理框架。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-backh=\"194\" data-backw=\"562\" data-height=\"794\" data-imgfileid=\"505099853\" data-ratio=\"0.3452173913043478\" data-type=\"png\" data-w=\"2300\" data-width=\"2300\" style=\"width:100%; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEorZ6SyickJIKLs2Rrgzt6CfucicJ49lxzlA5siameaYXo2pFibJUKD2ibNA/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;font-weight: bold;\">·</span></span></strong><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;font-weight: bold;\"> 问题</span></span></strong><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;font-weight: bold;\">AI</span></span></strong><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;font-weight: bold;\">数量跃升</span></span></strong></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">根据权威AI危害追踪数据库「AI事件库」（AI Incidents Database）统计，2024年全球AI相关危害事件激增至233起，创下历史新高，较2023年暴涨56.4%。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">其中既包括深度伪造私密图像案件，也涉及聊天机器人疑似导致青少年自杀等恶性事件。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">尽管该统计未能涵盖全部案例，但已清晰揭示AI技术滥用正在呈现惊人增长态势。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-backh=\"301\" data-backw=\"562\" data-height=\"1002\" data-imgfileid=\"505099858\" data-ratio=\"0.5358288770053476\" data-type=\"png\" data-w=\"1870\" data-width=\"1870\" style=\"width:100%; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdE5xria6dUVUbSzd1uGyYSCSyeyCYjG4bGl78ib3Lw723dcRG4gqrAteGg/640?wx_fmt=png&amp;from=appmsg\"></section><h3 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\"><br></span></strong></h3><h3 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\"><span textstyle=\"\" style=\"letter-spacing: 1px;color: rgb(255, 104, 39);\">12. 全球监管力度持续加强</span></span></strong></h3><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">2024年美国联邦机构颁布59项AI法规，涉及部门数量翻倍。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">75个国家立法机构提及AI频次同比增长21.3%，较2016年增长九倍。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">投资方面：加拿大承诺24亿美元，中国设立475亿美元半导体基金，法国投入1090亿欧元，印度拨款12.5亿美元，沙特启动千亿美元级的「超越计划」。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-backh=\"302\" data-backw=\"562\" data-height=\"886\" data-imgfileid=\"505099859\" data-ratio=\"0.536969696969697\" data-type=\"png\" data-w=\"1650\" data-width=\"1650\" style=\"width:100%; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdE7WLt2zyWFm1W6NVh4FEYzqHbC29EQRgXTtWH7YB40rsicYHjkysedzw/640?wx_fmt=png&amp;from=appmsg\"></section><h2 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><br></span></h2><section style=\"text-align: center;margin-top: 0px;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 85px; height: 40px; max-width: 600px\" data-imgfileid=\"505095291\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span></section><section style=\"text-align: center;margin-bottom: 0px;margin-top: 8px;line-height: 1.75em;\"><span style=\"color: rgb(0, 0, 0);font-size: 19px;letter-spacing: 1px;\"><strong><span leaf=\"\">详细亮点解读</span></strong></span></section><h2 style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><br></span></h2><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">下面，我们将摘出报告中的亮点内容，提供更详细的解读。</span></span></p><section style=\"display: flex;align-items: center;text-align: left;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 45px; height: 24px; max-width: 600px\" data-imgfileid=\"505095301\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span><p style=\"font-size: 16px;font-family: mp-quote, \" pingfang sc system-ui blinkmacsystemfont neue sans gb yahei ui arial sans-serif><strong><span style=\"font-size: 17px;letter-spacing: 1px;\"><span leaf=\"\"> 中美差距仅剩0.3%</span></span></strong></p></section><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">翻开502页的报告，最吸睛的部分，莫过于中美AI差异这部分了。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-backh=\"81\" data-backw=\"562\" data-height=\"183\" data-imgfileid=\"505099856\" data-ratio=\"0.14341692789968652\" data-type=\"png\" data-w=\"1276\" data-width=\"1276\" style=\"width:100%; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEpEbk7qxITXhNxicRJxye743XWiawib91Z4Le8L0ARJ2mez4VQJWKUrADA/640?wx_fmt=png&amp;from=appmsg\"></section><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-backh=\"68\" data-backw=\"562\" data-height=\"130\" data-imgfileid=\"505099855\" data-ratio=\"0.12037037037037036\" data-type=\"png\" data-w=\"1080\" data-width=\"1080\" style=\"width:100%; max-width: 600px\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEddWMs6ntqWiaeRDibjvuKJyL6zzicTZQdPORcpTjHd8SsQ1JlZT8VuMqQ/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">报告中强调，虽然2024年，美国在顶尖AI模型的研发上依然领先，但中美模型之间的性能差距，正在迅速缩小！</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">为了衡量AI领域过去一年演变的全球格局，HAI特意用AI指数，列出了具有代表性的模型所属国家，美国依然居首。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">数据显示，在2024年，美国机构以拥有40个知名模型领先，远远超过中国的15个和欧洲的3个。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.4880803011292346\" data-type=\"png\" data-w=\"1594\" style=\"width:100%; max-width: 600px\" data-width=\"1594\" data-height=\"778\" data-backw=\"562\" data-backh=\"274\" data-imgfileid=\"505099857\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEAO144a7F1QOsaJRqbtEKzVY38xBzvKwtZBjO2TnL5fAceKHHv4H3KA/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">总体来说，模型发布总量已经下降，可能是多个因素共同导致的，比如训练规模日益庞大、AI技术日益复杂，开发新模型方法的难度也在增加。</span></span></p><section style=\"display: flex;align-items: center;text-align: left;margin-bottom: 0px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5267857142857143\" data-s=\"300,640\" data-type=\"png\" data-w=\"112\" style=\"width: 45px; height: 24px; max-width: 600px\" data-imgfileid=\"505095301\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3uEdSPKrwGNmZEOaaGyzVvZ8dTtE9jU1rFsda3llYbCZpmWfiazUYjWBLTGvlPpXucH8Q0lEUJN3Q/640?wx_fmt=png&amp;from=appmsg\"></span><p style=\"font-size: 16px;font-family: mp-quote, \" pingfang sc system-ui blinkmacsystemfont neue sans gb yahei ui arial sans-serif><strong><span style=\"font-size: 17px;letter-spacing: 1px;\"><span leaf=\"\">AI模型已成为算力巨兽</span></span></strong></p></section><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.1283720930232558\" data-type=\"png\" data-w=\"2150\" style=\"width:100%; max-width: 600px\" data-width=\"2150\" data-height=\"276\" data-backw=\"562\" data-backh=\"72\" data-imgfileid=\"505099860\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEC6XollwCicRD58e7HsUpia2vcU8JnicgL3vZH8O5ySdgOK9tf2XguAJ9A/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;font-weight: bold;\">· </span></span></strong><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;font-weight: bold;\">参数趋势</span></span></strong></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">简单的说，参数就是AI模型通过训练学到的一些数字，这些数字决定了模型如何理解输入和怎样输出。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">AI的参数越多需要的训练数据也越多，但同时性能也更厉害。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">从2010年代初开始，模型的参数量就蹭蹭往上涨，这背后是因为模型设计得越来越复杂、数据更容易获取、硬件算力也更强了。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">更重要的是，大模型确实效果好。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">下图用了对数刻度，方便大家看清楚AI模型参数和算力近年来的爆炸式增长。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5408593091828138\" data-type=\"png\" data-w=\"2374\" style=\"width:100%; max-width: 600px\" data-width=\"2374\" data-height=\"1284\" data-backw=\"562\" data-backh=\"304\" data-imgfileid=\"505099864\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEwjaH5znRCuVQAnECsYFlPF0Y9f7Ap46YpQ1bRVia3PmnBAqJyEr6ZyQ/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">随着模型参数数量的增加，训练所需的数据量也在暴涨。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">2017年发布的Transformer模型，掀起了大型语言模型的热潮，当时它用了大约20亿个token来训练。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">到了2020年，GPT-3 175B模型的训练数据已经飙到了约3740亿个token。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">而Meta在2024年夏天发布的模型Llama 3.3，更是用了大约15万亿个token来训练。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">根据Epoch AI的数据，大型语言模型的训练数据集规模大约每八个月翻一倍。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5528317836010144\" data-type=\"png\" data-w=\"2366\" style=\"width:100%; max-width: 600px\" data-width=\"2366\" data-height=\"1308\" data-backw=\"562\" data-backh=\"311\" data-imgfileid=\"505099862\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEiaxDTgwhoibl6iaUiapUrwIr5MLINYyHrfds2TeHMIIWJo820aQlZgenMw/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">训练数据集越来越大，导致的训练时间也变得越来越长。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">像Llama 3.1-405B这样的模型，训练大概需要90天，这在如今已经算是「正常」的了。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">谷歌在2023年底发布的Gemini 1.0 Ultra，训练时间大约是100天。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">相比之下，2012年的AlexNet就显得快多了，训练只花了五六天，而且AlexNet当时用的硬件还远没有现在的先进。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5554607508532423\" data-type=\"png\" data-w=\"2344\" style=\"width:100%; max-width: 600px\" data-width=\"2344\" data-height=\"1302\" data-backw=\"562\" data-backh=\"312\" data-imgfileid=\"505099861\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdE7mBd7RbojoibSAlAcRZRgfw1tZaOgRaXAzWeIMO8oUy7ufAVfO3qGPg/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;font-weight: bold;\">· </span></span></strong><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;font-weight: bold;\">算力趋势</span></span></strong></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">「算力」指的是训练和运行AI模型所需的计算资源。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">最近，知名AI模型的算力消耗呈指数级增长。据Epoch AI估计，知名AI模型的训练算力大约每五个月翻一番。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">这种趋势在过去五年尤为明显。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5497872340425531\" data-type=\"png\" data-w=\"2350\" style=\"width:100%; max-width: 600px\" data-width=\"2350\" data-height=\"1292\" data-backw=\"562\" data-backh=\"309\" data-imgfileid=\"505099863\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdE4ZtKPlqdRJuiakjJwWQZO5vwvbobNAsgTddHAuicQaSjx1fL8sh7gllg/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">去年12月，DeepSeek V3一经推出就引发了广泛关注，主要就是因为它在性能上极其出色，但用的计算资源却比许多顶尖大型语言模型少得多。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">下图1.3.17比较了中国和美国知名AI模型的训练算力，揭示了一个重要趋势：美国的顶级AI模型通常比中国模型需要多得多的计算资源。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5425894378194208\" data-type=\"png\" data-w=\"2348\" style=\"width:100%; max-width: 600px\" data-width=\"2348\" data-height=\"1274\" data-backw=\"562\" data-backh=\"305\" data-imgfileid=\"505099865\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEvQNmp68gA0xpmPqNMLRc2jValia8ZeW00NTiaeeWRrVh6pnFQ7lKFw7g/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;font-weight: bold;\">· </span></span></strong><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;font-weight: bold;\">推理成本</span></span></strong></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">推理成本，指的是对一个已训练模型进行查询所需的费用，通常以「每百万tokens的美元价格」来衡量。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">这份报告中AI token的价格数据，来源于Artificial Analysis和Epoch AI的API定价专有数据库，而价格是根据输入与输出token的价格按3:1的权重平均计算得出的。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">可以看出，单位性能的AI成本正在显著下降。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">而Epoch AI估计，根据不同任务类型，大型语言模型的推理成本每年下降幅度可达9倍至900倍不等。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal data-pm-slice=\"1 1 [\" para><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">虽然如此，想要获得来自OpenAI、Meta和Anthropic的模型，仍需支付不小的溢价。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5486432825943084\" data-type=\"png\" data-w=\"1511\" style=\"width:100%; max-width: 600px\" data-width=\"1511\" data-height=\"829\" data-backw=\"562\" data-backh=\"308\" data-imgfileid=\"505099868\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEWSk3MgCia8eGlJM2C7XgesZdSHP1fZQOEAwvsibPtWEiaO43ICwpFJFEA/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;font-weight: bold;\">· </span></span></strong><strong><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;font-weight: bold;\">训练成本</span></span></strong></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">虽然很少有AI公司披露具体的训练成本，但这个数字普遍已达到数百位美元。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">OpenAI CEO奥特曼曾表示，训练GPT-4的训练成本超过了1亿美元。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">Anthropic的CEO Dario Amodei指出，目前正在训练的模型，成本约为10亿美元。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">DeepSeek-V3的600万美元，则打破了新低。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5465961665565102\" data-type=\"png\" data-w=\"1513\" style=\"width: 100%; max-width: 600px\" data-width=\"1513\" data-height=\"827\" data-backw=\"562\" data-backh=\"307\" data-imgfileid=\"505099867\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEBacVxWXBBqCVjrnFHlJ1WD27ZVZ5JDdt2XiaGAiavAmpnvlyrkqTWUEQ/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">图1.3.24展示了基于云计算租赁价格的部分AI模型的训练成本估算。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5733249051833123\" data-type=\"png\" data-w=\"1582\" style=\"width:100%; max-width: 600px\" data-width=\"1582\" data-height=\"907\" data-backw=\"562\" data-backh=\"322\" data-imgfileid=\"505099866\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEh1oCFsyTvOXuicTvZvKFvgy0GOp3g5Gm3ID07JWycOZCqS6AubhXt9Q/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">图1.3.25展示了AI指数所估算的所有AI模型的训练成本。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5493333333333333\" data-type=\"png\" data-w=\"1500\" style=\"width:100%; max-width: 600px\" data-width=\"1500\" data-height=\"824\" data-backw=\"562\" data-backh=\"309\" data-imgfileid=\"505099869\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEJBdYhKKLl0aicgVlmYLZOeMowOrCexGRSruAOJul4KsXk8m4ZJCMnGg/640?wx_fmt=png&amp;from=appmsg\"></section><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">在2024年，Epoch能估算的少数模型之一，就是Llama 3.1-405B，训练成本约为1.7亿美元。</span></span></p><p style=\"margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\" style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal><span textstyle=\"\" style=\"font-size: 15px;letter-spacing: 1px;\">另外，AI模型的训练成本与其计算需求之间存在直接的关联。如图1.3.26所示，计算需求更大的模型训练成本显著更高。</span></span></p><section style=\"color: rgba(0, 0, 0, 0.9);font-size: 17px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif normal nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.54\" data-type=\"png\" data-w=\"1500\" style=\"width:100%; max-width: 600px\" data-width=\"1500\" data-height=\"810\" data-backw=\"562\" data-backh=\"303\" data-imgfileid=\"505099873\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEny86Kr6A4p9JQrNsazP25mtL9TDbsZKg0aqA0ezrNhwGmj6gZxV05g/640?wx_fmt=png&amp;from=appmsg\"></section><section style=\"margin-right: 8px;margin-bottom: 0px;margin-left: 8px;min-height: 1em;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb left><span style=\"font-size: 14px;color: rgb(136, 136, 136);letter-spacing: 1px;\" data-mpa-action-id=\"m97y6gr7jfz\" data-pm-slice=\"0 0 []\"><span leaf=\"\">参考资料：</span><span leaf=\"\" mpa-font-style=\"m97y6gqo1jyt\" style=\"font-size: 12px;\">YZNH</span></span></section><section style=\"margin-right: 8px;margin-bottom: 0px;margin-left: 8px;min-height: 1em;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb left><span style=\"font-size: 14px;color: rgb(136, 136, 136);letter-spacing: 1px;\"><span leaf=\"\">https://www.nature.com/articles/d41586-025-01033-y</span></span></section><section style=\"margin-right: 8px;margin-bottom: 0px;margin-left: 8px;min-height: 1em;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb left><span style=\"font-size: 14px;color: rgb(136, 136, 136);letter-spacing: 1px;\"><span leaf=\"\">https://hai.stanford.edu/ai-index/2025-ai-index-report</span></span></section><section style=\"margin-right: 8px;margin-bottom: 0px;margin-left: 8px;min-height: 1em;font-family: -apple-system-font, system-ui, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb left><span style=\"font-size: 14px;color: rgb(136, 136, 136);letter-spacing: 1px;\"><span leaf=\"\">https://hai.stanford.edu/news/ai-index-2025-state-of-ai-in-10-charts</span></span></section><section style=\"margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;text-align: center;\"><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5796296296296296\" data-s=\"300,640\" data-type=\"jpeg\" data-w=\"1080\" style=\"width: 100%; max-width: 600px\" type=\"block\" data-backw=\"578\" data-backh=\"335\" data-imgfileid=\"505099885\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_jpg/UicQ7HgWiaUb2rB9NPHibT2F0UTgEyXLfdEB2ibVO28QoKmhefaVibmvfHcgN4ib82J3kNARoC6jK19jUCLN3m23pwxw/640?wx_fmt=jpeg&amp;from=appmsg\"></section><p style=\"display: none;\"><mp-style-type data-value=\"3\"></mp-style-type></p></div>\n    \n\n    \n    <br>\n\n    \n        <a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2652583537&amp;idx=1&amp;sn=d16b93d277bd0d7b86fd903acf74cf21&amp;chksm=f0f188d3862f87c789e44dab16b071e9f51fc249b0a5cdd067b7e19bed1c287d44ca5e711802&amp;scene=0#rd\" style=\"color: blue\" class=\"media_tool_meta meta_primary\">文章原文</a>\n        <br>\n    \n\n    \n\n    <img alt=\"\" width=\"1px\" height=\"1px\" class=\"\" style=\"width:1px;height:1px;display:none\" src=\"http://www.jintiankansha.me/rss_static/83671/w8AOCxCHQB\">\n\n",
          "contentSnippet": "新智元报道  \n\n\n\n编辑：编辑部\n\n\n【新智元导读】2025年斯坦福HAI报告重磅发布，456页深度剖析全球AI领域的最新趋势：中美顶级模型性能差距缩至0.3%，以DeepSeek为代表的模型强势崛起，逼近闭源巨头；推理成本暴降，小模型性能飙升，AI正变得更高效、更普惠。\n\n\n就在刚刚，每年都备受瞩目的斯坦福AI指数报告，重磅发布了！\n这份报告由斯坦福大学以人为本AI研究员发布，代表着每年AI领域最核心和前沿的动向总结。\n今年，这份报告长达456页，抛出不少惊人观点。\n\n比如，如今在2025年，中美顶级AI模型的性能差距已经缩小到了0.3%（2023年，这一数字还是20%），中国模型正在快速追赶美国的领先地位！\n而DeepSeek领衔的开放权重模型，更是以1.7%之差，逼宫各大闭源巨头。前者和后者的差距，已经由2024年的8%，缩小至2025年的1.7%。\n当然，目前从行业主导企业来看，美国仍然领先于中国。在2024年，90%的知名AI模型来自企业，美国以40个模型领先，中国有15个。\n更明显的一个趋势，就是如今大模型的性能已经趋同！在2024年，TOP1和TOP10的模型的差距能有12%，但如今，它们的差距已经越来越小，锐减至5%。\n\n\n\n\n十二大亮点\n\n\n最新的斯坦福HAI两篇博文中，浓缩了2025年AI指数报告的十二大亮点。\n1. AI性能再攀高峰，从基准测试到视频生成全面突破\n2023年，研究人员推出了MMMU、GPQA和SWE-bench等新基准来测试先进AI系统的极限。\n仅一年后，性能便大幅提升：AI在三项基准得分分别飙升18.8%、48.9%和67.3%。\n不仅如此，AI在生成高质量视频方面取得重大突破，甚至，在某些场景下AI智能体甚至超越人类表现。\n\n· 更有用智能体崛起 \n2024年发布的RE-Bench基准测试，为评估AI智能体复杂任务能力设立了严苛标准。\n数据显示：在短期任务（2小时内）场景下，顶级AI系统的表现可达人类专家的4倍；但当任务时限延长至32小时，人类则以2:1的优势反超。\n值得注意的是，AI已在特定领域，如编写特定类型代码，展现出与人类相当的专业水平，且执行效率更胜一筹。\n\n\n\n2. 美国领跑顶尖模型研发，但中国与之差距逐渐缩小\n2024年，美国产出40个重要AI模型，远超中国的15个和欧洲的3个。\n然而，中国模型在性能上的差距正加速缩小：MMLU等基准测试中，中美AI差异从两位数缩小至近乎持平。\n同时，中国在AI学术论文和专利申请量上持续领跑，中东、拉美和东南亚地区也涌现出具有竞争力的模型。\n\n\n\n3. AI正变得高效且普惠，推理成本暴降280倍\n\n\n随着小模型性能提升，达到GPT-3.5水平的推理成本在两年间下降280倍，硬件成本以每年30%的速度递减，能效年提升率达40%。\n更令人振奋的是，开源模型性能突飞猛进，部分基准测试中与闭源模型的差距从8%缩至1.7%。\n· 大模型使用成本持续走低，年降幅最高900倍\n在MMLU基准测试中达到GPT-3.5水平（MMLU准确率64.8%）的AI模型调用成本，已从2022年11月的20美元/每百万token，骤降至2024年10月的0.07美元/每百万token（谷歌DeepMind的Gemini-1.5-Flash-8B模型），18个月内AI成本下降280倍。\n视具体任务需求，LLM推理服务价格的年降幅可达9-900倍不等。\n\n· 小模型性能显著提升，参数暴减142倍\n2022年，在大规模多任务语言理解（MMLU）基准测试中，得分超60%的最小模型是 PaLM，参数量为5400亿。\n到了2024年，微软Phi-3-mini仅用38亿参数，就取得了同样的实力。\n这代表，两年多的时间里模型参数减少了142倍。\n\n\n\n4. 科技巨头称霸AI前沿，但竞争白热化\n\n\n2024年，近90%的重要模型源自企业，学术界则保持基础研究优势。\n模型规模呈指数增长：训练算力每5个月翻番，数据集每8个月扩容一倍。\n值得注意的是，头部模型性能差距显著缩小，榜首与第十名得分差已从11.9%降至5.4%。\n\n\n\n5. AI逻辑短板，推理能力仍是瓶颈\n\n\n采用符号推理方法的AI系统，能较好解决IMO问题（虽未达人类顶尖水平），但LLM在MMMU等复杂推理任务中表现欠佳，尤其不擅长算术推导和规划类强逻辑性任务。\n这一局限影响了其在医疗诊断等高风险场景的应用可靠性。\n\n\n\n6. 大厂ALL in AI，投资与采用率创双纪录\n\n\n科技大厂们，正全力押注AI。\n2024年，美国私营AI投资达1091亿美元，约为中国（93亿）的12倍、英国（45亿）的24倍。\n生成式AI势头尤猛，全球私募投资达339亿美元（同比增18.7%）。\n与此同时，企业AI采用率从55%升至78%。研究证实，AI不仅能提升生产力，多数情况下还可缩小劳动力技能差距。\n更引人注目的是，将生成式AI应用于至少一项业务职能的企业数量激增——从2023年的33%跃升至去年的71%，增幅超一倍。\n\n\n\n7. AI荣膺科学界最高荣誉，摘诺奖桂冠\n\n\n2024年，两项诺贝尔奖分别授予深度学习理论基础（物理学）和蛋白质折叠预测（化学）研究，图灵奖则花落强化学习领域。\n\n\n\n8. AI教育普及加速，但资源差距仍存\n\n\n全球2/3国家已或计划开展K-12计算机科学教育，但非洲地区受限于电力等基础设施，推进缓慢。\n美国81%的计算机教师认为AI应纳入基础课程，但仅47%具备相应教学能力。\n\n\n9. AI正深度融入日常生活\n\n\n从医疗到交通，AI正快速从实验室走向现实。\n1995年，FDA批准了第一款AI赋能的医疗器械。\n截至2024年8月，FDA已批准950款AI医疗设备——较2015年的6款和2023年的221款，增长迅猛。\n而在自动驾驶领域，汽车已脱离实验阶段：美国头部运营商Waymo每周提供超15万次无人驾驶服务。\n\n\n\n10. 全球AI乐观情绪上升，但地区差异显著\n\n\n中国（83%）、印尼（80%）和泰国（77%）民众对AI持积极态度，而加拿大（40%）、美国（39%）等发达国家则相对保守。\n值得关注的是，德国（+10%）、法国（+10%）等原怀疑论国家态度明显转变。\n\n\n\n\n11. 负责任AI生态发展不均\n\n\n虽然AI安全事件激增，但主流模型开发商仍缺乏标准化评估体系。\nHELM Safety、AIR-Bench和FACTS等新基准为事实性与安全性评估提供工具。\n企业普遍存在「认知与行动脱节」，而各国政府加速协作：2024年，经合组织、欧盟等国际机构相继发布聚焦透明度、可信度的治理框架。\n\n· 问题AI数量跃升\n根据权威AI危害追踪数据库「AI事件库」（AI Incidents Database）统计，2024年全球AI相关危害事件激增至233起，创下历史新高，较2023年暴涨56.4%。\n其中既包括深度伪造私密图像案件，也涉及聊天机器人疑似导致青少年自杀等恶性事件。\n尽管该统计未能涵盖全部案例，但已清晰揭示AI技术滥用正在呈现惊人增长态势。\n\n\n\n12. 全球监管力度持续加强\n\n\n2024年美国联邦机构颁布59项AI法规，涉及部门数量翻倍。\n75个国家立法机构提及AI频次同比增长21.3%，较2016年增长九倍。\n投资方面：加拿大承诺24亿美元，中国设立475亿美元半导体基金，法国投入1090亿欧元，印度拨款12.5亿美元，沙特启动千亿美元级的「超越计划」。\n\n\n\n\n详细亮点解读\n\n\n下面，我们将摘出报告中的亮点内容，提供更详细的解读。\n\n 中美差距仅剩0.3%\n\n\n\n翻开502页的报告，最吸睛的部分，莫过于中美AI差异这部分了。\n\n\n报告中强调，虽然2024年，美国在顶尖AI模型的研发上依然领先，但中美模型之间的性能差距，正在迅速缩小！\n为了衡量AI领域过去一年演变的全球格局，HAI特意用AI指数，列出了具有代表性的模型所属国家，美国依然居首。\n数据显示，在2024年，美国机构以拥有40个知名模型领先，远远超过中国的15个和欧洲的3个。\n\n总体来说，模型发布总量已经下降，可能是多个因素共同导致的，比如训练规模日益庞大、AI技术日益复杂，开发新模型方法的难度也在增加。\n\nAI模型已成为算力巨兽\n\n\n\n\n· 参数趋势\n简单的说，参数就是AI模型通过训练学到的一些数字，这些数字决定了模型如何理解输入和怎样输出。\nAI的参数越多需要的训练数据也越多，但同时性能也更厉害。\n从2010年代初开始，模型的参数量就蹭蹭往上涨，这背后是因为模型设计得越来越复杂、数据更容易获取、硬件算力也更强了。\n更重要的是，大模型确实效果好。\n下图用了对数刻度，方便大家看清楚AI模型参数和算力近年来的爆炸式增长。\n\n随着模型参数数量的增加，训练所需的数据量也在暴涨。\n2017年发布的Transformer模型，掀起了大型语言模型的热潮，当时它用了大约20亿个token来训练。\n到了2020年，GPT-3 175B模型的训练数据已经飙到了约3740亿个token。\n而Meta在2024年夏天发布的模型Llama 3.3，更是用了大约15万亿个token来训练。\n根据Epoch AI的数据，大型语言模型的训练数据集规模大约每八个月翻一倍。\n\n训练数据集越来越大，导致的训练时间也变得越来越长。\n像Llama 3.1-405B这样的模型，训练大概需要90天，这在如今已经算是「正常」的了。\n谷歌在2023年底发布的Gemini 1.0 Ultra，训练时间大约是100天。\n相比之下，2012年的AlexNet就显得快多了，训练只花了五六天，而且AlexNet当时用的硬件还远没有现在的先进。\n\n· 算力趋势\n「算力」指的是训练和运行AI模型所需的计算资源。\n最近，知名AI模型的算力消耗呈指数级增长。据Epoch AI估计，知名AI模型的训练算力大约每五个月翻一番。\n这种趋势在过去五年尤为明显。\n\n去年12月，DeepSeek V3一经推出就引发了广泛关注，主要就是因为它在性能上极其出色，但用的计算资源却比许多顶尖大型语言模型少得多。\n下图1.3.17比较了中国和美国知名AI模型的训练算力，揭示了一个重要趋势：美国的顶级AI模型通常比中国模型需要多得多的计算资源。\n\n· 推理成本\n推理成本，指的是对一个已训练模型进行查询所需的费用，通常以「每百万tokens的美元价格」来衡量。\n这份报告中AI token的价格数据，来源于Artificial Analysis和Epoch AI的API定价专有数据库，而价格是根据输入与输出token的价格按3:1的权重平均计算得出的。\n可以看出，单位性能的AI成本正在显著下降。\n而Epoch AI估计，根据不同任务类型，大型语言模型的推理成本每年下降幅度可达9倍至900倍不等。\n虽然如此，想要获得来自OpenAI、Meta和Anthropic的模型，仍需支付不小的溢价。\n\n· 训练成本\n虽然很少有AI公司披露具体的训练成本，但这个数字普遍已达到数百位美元。\nOpenAI CEO奥特曼曾表示，训练GPT-4的训练成本超过了1亿美元。\nAnthropic的CEO Dario Amodei指出，目前正在训练的模型，成本约为10亿美元。\nDeepSeek-V3的600万美元，则打破了新低。\n\n图1.3.24展示了基于云计算租赁价格的部分AI模型的训练成本估算。\n\n图1.3.25展示了AI指数所估算的所有AI模型的训练成本。\n\n在2024年，Epoch能估算的少数模型之一，就是Llama 3.1-405B，训练成本约为1.7亿美元。\n另外，AI模型的训练成本与其计算需求之间存在直接的关联。如图1.3.26所示，计算需求更大的模型训练成本显著更高。\n\n参考资料：YZNH\nhttps://www.nature.com/articles/d41586-025-01033-y\nhttps://hai.stanford.edu/ai-index/2025-ai-index-report\nhttps://hai.stanford.edu/news/ai-index-2025-state-of-ai-in-10-charts\n\n\n\n\n\n    \n\n    \n    \n文章原文",
          "guid": "http://www.jintiankansha.me/t/w8AOCxCHQB",
          "categories": [
            "无"
          ],
          "isoDate": "2025-04-08T04:00:00.000Z"
        }
      }
    ],
    "机器之心1": [
      {
        "json": {
          "title": "颠覆传统信息搜索，效果是之前SOTA的三倍？UIUC韩家炜、孙冀萌团队开源DeepRetrieval，让模型端到端地学会搜索！",
          "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650963731&idx=4&sn=28f1d2a68c5b9f23f435f7aa66335473&chksm=8593ba76d088c1c15fa73b18bb65dd1a3248edc9f61f7ff321f751bebb6b8a4ad40e1d126749&scene=0#rd",
          "pubDate": "Tue, 08 Apr 2025 12:48:00 +0800",
          "enclosure": {
            "url": "http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXNUMFw5WKdZ2wK23QFWTia30IKE9E7p9aj8Za1nX2493SObukR3YsrYQ/0?wx_fmt=jpeg",
            "length": "0",
            "type": "image/jpeg"
          },
          "content": "\n\n    \n\n    \n\n    \n         <div class=\"rich_media_content\" id=\"js_content\"><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><img alt=\"图片\" class=\"rich_pages wxw-img\" data-ratio=\"0.5703703703703704\" data-w=\"1080\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4qxCCBDwsURwYQxQzqtnNcfgBE6kDVeb9ib93vNCvo6N7OCH5mhZ91Qq3LFH2n8ku4sfbWdBA6iag/640?wx_fmt=png&amp;from=appmsg&amp;tp=wxpic&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1\" style=\"max-width: 600px\"></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">在信息检索系统中，搜索引擎的能力只是影响结果的一个方面，</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">真正的瓶颈往往在于：用户的原始 query 本身不够好</span><span textstyle=\"\" style=\"font-size: 15px;\">。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">尤其在专业搜索场景（如文献、数据库查询）中，用户往往无法用精确、完整的表达描述他们的需求。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">那么问题来了：</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">能不能教大模型优化原始 query 的表达方式，从而让已有检索系统的能力被最大化激发？</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">来自 UIUC 的 Jiawei Han 和 Jimeng Sun 团队的一项最新工作 </span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">DeepRetrieval </span><span textstyle=\"\" style=\"font-size: 15px;\">就是针对这个问题提出了系统性解法，只需 </span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">3B 的 LLM </span><span textstyle=\"\" style=\"font-size: 15px;\">即可实现 50 个点以上的提升。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.29259259259259257\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503479539\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXBspLlhjWN6Dhlboydic2Vy2BQSKmyse7OVXbKibFzKRXkwkW240PSmNQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li style=\"color: rgb(123, 12, 0);font-size: 15px;\"><section style=\"text-align: left;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: normal;\">论文标题：</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: normal;\">DeepRetrieval: Hacking Real Search Engines and Retrievers with Large Language Models via Reinforcement Learning</span></span></section></li><li style=\"color: rgb(123, 12, 0);\"><section style=\"text-align: left;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);font-weight: normal;\">论文地址：https://arxiv.org/pdf/2503.00223</span></span></section></li><li style=\"color: rgb(123, 12, 0);\"><section style=\"text-align: left;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);font-weight: normal;\">开源代码：https://github.com/pat-jj/DeepRetrieval</span></span></section></li><li style=\"color: rgb(123, 12, 0);\"><p style=\"padding: 0pt;text-align: left;line-height: 1.75em;\"><span style=\"font-family: Arial;color: rgb(255, 0, 0);font-size: 11pt;\"><font face=\"微软雅黑\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);font-weight: normal;text-decoration: none;\">开源模型：</span></span></font></span><span style=\"font-family: Arial;color: rgb(255, 0, 0);\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);font-weight: normal;text-decoration: none;\">https://huggingface.co/DeepRetrieval</span></span></span><span style=\"font-family: Arial;color: rgb(255, 0, 0);font-size: 11pt;\"><p></p></span></p><section style=\"text-align: left;line-height: 1.75em;\"><span leaf=\"\"><br></span></section></li></ul><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">一句话概括</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">：</span><span textstyle=\"\" style=\"font-size: 15px;\">DeepRetrieval 是一个基于强化学习（RL）的 query 优化系统，训练 LLM 在不同检索任务中优化原始查询，以最大化真实系统的检索效果。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">它不是训练一个新的 retriever，也不是让模型直接回答问题，而是：</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">在不改变现有搜索系统的前提下，通过优化原始 query，让「提问方式」变得更聪明，从而获取更好的结果。</span></span><span leaf=\"\"><br></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">更多有意义的讨论请读原文正文和附录的 Discussion 部分。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.537962962962963\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503479540\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXCBLibudFoia00WzQat7q3SFAH1NtZ9GcqgLEdoh8BbdXWZibJia7sJljoA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">方法细节</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5046296296296297\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503479541\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXecAuVNUgm8icOtOV9rBMuPl3tFhicw3Lp3MBUK6copqcL4GkUhicsw2Kg/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">方法要点</span></span></section><section><span leaf=\"\"><br></span></section><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li style=\"font-size: 15px;\"><section style=\"text-align: justify;line-height: 1.75em;\"><span leaf=\"\" style=\"text-align: justify;\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">输入</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">：原始查询 q</span></span></section></li><li style=\"font-size: 15px;\"><section style=\"text-align: justify;line-height: 1.75em;\"><span leaf=\"\" style=\"text-align: justify;\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">输出</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">：改写后的查询 q′（自然语言、布尔表达式或 SQL）</span></span></section></li><li style=\"font-size: 15px;\"><section style=\"text-align: justify;line-height: 1.75em;\"><span leaf=\"\" style=\"text-align: justify;\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">环境反馈</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">：使用 q′ 去检索系统中查询 → 返回结果 → 与 groundtruth 对比，计算 reward，reward 为 task-specific 检索表现（如 Recall@K、NDCG@K、SQL accuracy）使用 PPO 进行训练，并加入格式奖励（format correctness）与 KL-regularization 保证训练稳定，优化目标如下：</span></span></section></li></ul><section><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.14432989690721648\" data-s=\"300,640\" data-type=\"png\" data-w=\"485\" type=\"block\" data-imgfileid=\"503479542\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJX28KVkdOuDZOunZOQ1wa1D05tsO6ATdTJcGTk3n28GWV9xkq4fgNTEA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">其中，π_ref 是参考策略（reference policy），通常指的是</span></span><span leaf=\"\" style=\"text-align: justify;\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">在强化学习开始之前的初始模型</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">。β 是一个合适的 KL 惩罚系数，用于</span></span><span leaf=\"\" style=\"text-align: justify;\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">控制正则化的强度</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">。KL 散度项的作用是</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">惩罚当前策略与参考策略之间的过大偏离</span><span textstyle=\"\" style=\"font-size: 15px;\">，从而在强化学习训练过程中</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">保证策略更新的稳定性</span><span textstyle=\"\" style=\"font-size: 15px;\">。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">实验结果</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">真实搜索引擎的文献搜索</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.7175925925925926\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503479544\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXxd9EbD2Iu4qmHbBLmJLx4jseH059z3bDMM79CzEwZe5bk7YNtJCr1Q/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span data-pm-slice=\"0 0 []\"><span leaf=\"\" style=\"text-align: justify;\"><span textstyle=\"\" style=\"font-size: 15px;\">首先在真实的搜索引擎上进行实验，文中用到了专业搜索引擎 PubMed 和 ClinicalTrials.gov。无需改动搜索引擎或其它任何检索器，仅通过端到端地优化 query 表达，DeepRetrieval 就可以让结果获得 10 倍提升，远超各个商业大模型和之前的 SO</span></span><span leaf=\"\" style=\"text-align: justify;\"><span textstyle=\"\" style=\"font-size: 15px;\">TA 方法 LEADS（蒸馏 + SFT 方法）。</span></span></span><span style=\"font-family: Arial;color: rgb(0, 0, 0);font-size: 11pt;\"><p></p></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">Evidence-Seeking 检索：通用搜索引擎的革新潜力</span></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></section><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">DeepRetrieval 在 Evidence-Seeking 检索任务上的优异表现令人瞩目。如表 1 所示，结合简单 BM25，这个仅有 3B 参数的模型在 SQuAD、TriviaQA 和 NQ 数据集上超越了 GPT-4o 和 Claude-3.5 等大型商业模型。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">Evidence-Seeking 任务的核心是找到支持特定事实性问题答案的确切文档证据，在通用搜索引擎环境中，这一能力尤为关键。作者团队指出，将 DeepRetrieval 应用到 Google、Bing 等通用搜索引擎的 Evidence-Seeking 场景将带来显著优势：</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li><p style=\"text-align: justify;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">精准定位事实文档：</span><span textstyle=\"\" style=\"font-size: 15px;\">通用搜索引擎包含海量信息，用户难以构建能精确定位证据段落的查询。DeepRetrieval 可将简单问题转化为包含关键术语、同义词和限定符的复杂查询，显著提高找到权威证据的概率。</span></span></p></li></ul><p style=\"text-align:justify;margin-left:8px;margin-right:8px;line-height:1.75em;\"><span leaf=\"\"><br></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li><p style=\"text-align: justify;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">克服知识时效性限制：</span><span textstyle=\"\" style=\"font-size: 15px;\">模型能够将「2024 年奥运会金牌榜前三名」等超出 LLM 知识截止日期的问题转化为精确搜索表达，使检索系统能够找到最新事实证据。</span></span></p></li></ul><p style=\"text-align:justify;margin-left:8px;margin-right:8px;line-height:1.75em;\"><span leaf=\"\"><br></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li><p style=\"text-align: justify;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">多源验证能力：</span><span textstyle=\"\" style=\"font-size: 15px;\">通过优化查询帮助搜索引擎找到多个独立来源的事实证据，从而交叉验证信息准确性，这是纯 LLM 问答无法实现的关键优势。</span></span></p></li></ul><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">作者团队表示会将这部分的延伸作为 DeepRetrieval </span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">未来主要的探索方向之一</span><span textstyle=\"\" style=\"font-size: 15px;\">。</span></span></p><p><span leaf=\"\"><br></span></p><section style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">Classic IR（Sparse / Dense）</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5462962962962963\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503479545\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXia8iaXYBqCS7H8cdxteJM8wX7INncMibWO9UnrDh6ebPFOmlkpHVBxtwA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">在 BM25 和 dense retriever 下，DeepRetrieval 提供了平均 5~10 点 NDCG 提升，并且：</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">BM25 + DeepRetrieval 和多数 dense baseline 水平相当</span><span textstyle=\"\" style=\"font-size: 15px;\">。</span></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">结合极快的检索速度（BM25 vs dense：352s vs 12,232s），展示了一个现实可部署、性能不俗的高效方案。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">SQL 检索任务</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">在 SQL 检索任务中，DeepRetrieval 摆脱了对 groundtruth SQL 的依赖，直接利用生成 SQL 的执行成功率优化模型，通过生成更精准的 SQL 语句，使得模型在 Spider、BIRD 等数据集上的执行正确率均超过对比模型（包括 GPT-4o 和基于 SFT 的大模型）。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"2.0232558139534884\" data-s=\"300,640\" data-type=\"png\" data-w=\"688\" type=\"block\" data-imgfileid=\"503479546\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJX7dIvL7e2KGSebJUG4XtkuHafTsYt3R2B47Ricj40RgEcD20blfQribew/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><p style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">探索胜于模仿：RL 为何超越 SFT</span></span></p><p style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">DeepRetrieval 的实验揭示了强化学习（RL）在搜索优化上相比监督微调（SFT）的独特优势。实验数据令人信服：在文献搜索上，RL 方法的 DeepRetrieval（65.07%）超过 SFT 方法 LEADS（24.68%）近三倍；在 SQL 任务上，从零开始的 RL 训练（无需任何 gold SQL 语句的监督）也优于使用 GPT-4o 蒸馏数据的 SFT 模型。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">这种显著差异源于两种方法的本质区别：SFT 是「模仿学习」，试图复制参考查询，而 RL 是「直接优化」，通过环境反馈学习最优查询策略。SFT 方法的局限在于参考查询本身可能不是最优的，即使是人类专家或大模型也难以直观设计出最适合特定搜索引擎的查询表达。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">论文中的案例分析进一步证实了这一点。例如，在 PubMed 搜索中，DeepRetrieval 生成的查询如「((DDAVP) AND (Perioperative Procedures OR Blood Transfusion OR Desmopressin OR Anticoagulant)) AND (Randomized Controlled Trial)」融合了医学领域的专业术语和 PubMed 搜索引擎偏好的布尔结构，这种组合很难通过简单模仿预定义的查询模板获得。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">相反，RL 允许模型通过尝试与错误来探索查询空间，发现人类甚至未考虑的有效模式，并直接针对最终目标（如 Recall 或执行准确率）进行优化。这使 DeepRetrieval 能够生成高度适合特定搜索引擎特性的查询，适应不同检索环境的独特需求。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">这一发现具有重要启示：在追求最佳检索性能时，让模型通过反馈学习如何与检索系统「对话」，比简单模仿既定模式更为有效，这也解释了为何参数量较小的 DeepRetrieval 能在多项任务上超越拥有更多参数的商业模型。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">模型 Think&amp;Query 长度分析</span></span></p><p style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-imgfileid=\"503479991\" data-ratio=\"2.541471048513302\" data-s=\"300,640\" data-type=\"png\" data-w=\"639\" type=\"block\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8apWjQibSDGflicVKV7CAsLLjiaQhPuem4SZ9FNO1fwz7OncZH9pEmcbfnS5LqYLuAyx5PdAVjJZjibA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">通过分析 DeepRetrieval 在训练过程中模型思考链和查询长度的变化，可以发现以下</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">关键洞见</span><span textstyle=\"\" style=\"font-size: 15px;\">：</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">思考链长度演变</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">与「aha moment」相反</span><span textstyle=\"\" style=\"font-size: 15px;\">，DeepRetrieval 的思考链长度随训练呈</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">下降趋势</span><span textstyle=\"\" style=\"font-size: 15px;\">，而非增长。这与 DeepSeek-R1 报告的「aha moment」现象形成鲜明对比，后者的思考链会随训练进展变得更长。图 4(a) 清晰地展示了 Qwen 模型思考链从初始约 150 tokens 逐渐降至稳定的 50 tokens 左右，而 Llama 模型的思考链更短，甚至降至接近 25 tokens。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">查询长度特征</span></span></p><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">实验揭示了思考过程对查询长度的显著影响。</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">无思考过程的模型容易陷入次优解</span><span textstyle=\"\" style=\"font-size: 15px;\">，如图 4(b) 所示，Qwen 无思考版本生成极长查询（500-600 tokens），表现出过度扩展的倾向。相比之下，有思考过程的模型保持更为适中的查询长度，Qwen 约 150 tokens，Llama 约 100 tokens。有趣的是，不同模型采用不同长度策略，但能达到相似性能，表明查询生成存在多样有效路径。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">性能与思考过程关系</span></span></p><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">思考过程对检索性能有决定性影响。图 4(c) 表明，</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">具备思考能力的模型性能显著提升</span><span textstyle=\"\" style=\"font-size: 15px;\">，有思考的模型 Recall@3K 能达到 65%，而无思考模型仅 50% 左右。此外，</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">训练效率也明显提高</span><span textstyle=\"\" style=\"font-size: 15px;\">，有思考的模型更快达到高性能并保持稳定。论文附录 D.1 的分析表明，思考过程帮助模型避免简单地通过增加查询长度和重复术语来提升性能，而是引导模型学习更有效的语义组织策略。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">关键结论</span></span></p><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">DeepRetrieval 展示了思考过程在信息检索中扮演「探索促进器」</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">的关键角色。与数学或编程问题不同，检索任务不需要像「aha moment」那样的突然顿悟现象。相反，检索优化遵循</span><span textstyle=\"\" style=\"font-size: 15px;\">「先详细思考，后逐渐精简」</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">的模式，模型在内化有效策略后，不再需要冗长思考。这表明</span><span textstyle=\"\" style=\"font-size: 15px;\">检索任务中思考链的主要功能是探索，一旦策略稳定便可简化。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">这种分析表明，适当的思考过程设计对于构建高效的检索优化系统至关重要，能够在不增加模型参数的情况下显著提升性能，为未来的 LLM 应用于搜索任务提供了重要设计思路。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">结论</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">DeepRetrieval 的贡献在于揭示了一个常被忽视但至关重要的事实：</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">检索效果的上限不仅在于检索器本身，更在于如何「提问」</span><span textstyle=\"\" style=\"font-size: 15px;\">。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">通过强化学习教 LLM 改写原始查询，DeepRetrieval 不仅摆脱了对人工标注数据和大模型蒸馏的依赖，还在多个任务上证明了改写 query 的巨大潜力。这项工作为搜索与信息检索领域带来了新的思考：未来的检索优化，不仅是提升引擎算法，更是如何让用户「问得更好」，从而激发出检索系统的全部潜力。</span></span></section><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" style=\"margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb auto center><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif><span leaf=\"\"><br></span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" style=\"margin: 5px 8px 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb auto center><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;\">© THE END </span></span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" style=\"margin: 5px 8px 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb auto center><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"outline: 0px;font-size: 12px;color: rgb(136, 136, 136);\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;\">转载请联系本公众号获得授权</span></span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" style=\"margin: 5px 8px 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb auto center><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"outline: 0px;font-size: 12px;color: rgb(136, 136, 136);\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;\">投稿或寻求报道：liyazhou@jiqizhixin.com</span></span></span></p><p style=\"display: none;\"><mp-style-type data-value=\"10000\"></mp-style-type></p></div>\n    \n\n    \n    <br>\n\n    \n        <a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963731&amp;idx=4&amp;sn=28f1d2a68c5b9f23f435f7aa66335473&amp;chksm=8593ba76d088c1c15fa73b18bb65dd1a3248edc9f61f7ff321f751bebb6b8a4ad40e1d126749&amp;scene=0#rd\" style=\"color: blue\" class=\"media_tool_meta meta_primary\">文章原文</a>\n        <br>\n    \n\n    \n\n    <img alt=\"\" width=\"1px\" height=\"1px\" class=\"\" style=\"width:1px;height:1px;display:none\" src=\"http://www.jintiankansha.me/rss_static/4365/mh3IOHrP5I\">\n\n",
          "contentSnippet": "在信息检索系统中，搜索引擎的能力只是影响结果的一个方面，真正的瓶颈往往在于：用户的原始 query 本身不够好。\n\n\n尤其在专业搜索场景（如文献、数据库查询）中，用户往往无法用精确、完整的表达描述他们的需求。\n\n\n那么问题来了：能不能教大模型优化原始 query 的表达方式，从而让已有检索系统的能力被最大化激发？\n\n\n来自 UIUC 的 Jiawei Han 和 Jimeng Sun 团队的一项最新工作 DeepRetrieval 就是针对这个问题提出了系统性解法，只需 3B 的 LLM 即可实现 50 个点以上的提升。\n\n\n\n\n\n\n论文标题：DeepRetrieval: Hacking Real Search Engines and Retrievers with Large Language Models via Reinforcement Learning\n\n论文地址：https://arxiv.org/pdf/2503.00223\n\n开源代码：https://github.com/pat-jj/DeepRetrieval\n\n开源模型：https://huggingface.co/DeepRetrieval\n\n\n\n\n一句话概括：DeepRetrieval 是一个基于强化学习（RL）的 query 优化系统，训练 LLM 在不同检索任务中优化原始查询，以最大化真实系统的检索效果。\n\n\n它不是训练一个新的 retriever，也不是让模型直接回答问题，而是：\n\n\n在不改变现有搜索系统的前提下，通过优化原始 query，让「提问方式」变得更聪明，从而获取更好的结果。\n\n\n\n更多有意义的讨论请读原文正文和附录的 Discussion 部分。\n\n\n\n\n\n方法细节\n\n\n\n\n\n方法要点\n\n\n\n输入：原始查询 q\n\n输出：改写后的查询 q′（自然语言、布尔表达式或 SQL）\n\n环境反馈：使用 q′ 去检索系统中查询 → 返回结果 → 与 groundtruth 对比，计算 reward，reward 为 task-specific 检索表现（如 Recall@K、NDCG@K、SQL accuracy）使用 PPO 进行训练，并加入格式奖励（format correctness）与 KL-regularization 保证训练稳定，优化目标如下：\n\n\n\n\n\n\n其中，π_ref 是参考策略（reference policy），通常指的是在强化学习开始之前的初始模型。β 是一个合适的 KL 惩罚系数，用于控制正则化的强度。KL 散度项的作用是惩罚当前策略与参考策略之间的过大偏离，从而在强化学习训练过程中保证策略更新的稳定性。\n\n\n实验结果\n\n\n真实搜索引擎的文献搜索\n\n\n\n\n\n首先在真实的搜索引擎上进行实验，文中用到了专业搜索引擎 PubMed 和 ClinicalTrials.gov。无需改动搜索引擎或其它任何检索器，仅通过端到端地优化 query 表达，DeepRetrieval 就可以让结果获得 10 倍提升，远超各个商业大模型和之前的 SOTA 方法 LEADS（蒸馏 + SFT 方法）。\n\n\n\nEvidence-Seeking 检索：通用搜索引擎的革新潜力\n\n\nDeepRetrieval 在 Evidence-Seeking 检索任务上的优异表现令人瞩目。如表 1 所示，结合简单 BM25，这个仅有 3B 参数的模型在 SQuAD、TriviaQA 和 NQ 数据集上超越了 GPT-4o 和 Claude-3.5 等大型商业模型。\n\n\nEvidence-Seeking 任务的核心是找到支持特定事实性问题答案的确切文档证据，在通用搜索引擎环境中，这一能力尤为关键。作者团队指出，将 DeepRetrieval 应用到 Google、Bing 等通用搜索引擎的 Evidence-Seeking 场景将带来显著优势：\n\n\n\n精准定位事实文档：通用搜索引擎包含海量信息，用户难以构建能精确定位证据段落的查询。DeepRetrieval 可将简单问题转化为包含关键术语、同义词和限定符的复杂查询，显著提高找到权威证据的概率。\n\n\n\n\n克服知识时效性限制：模型能够将「2024 年奥运会金牌榜前三名」等超出 LLM 知识截止日期的问题转化为精确搜索表达，使检索系统能够找到最新事实证据。\n\n\n\n\n多源验证能力：通过优化查询帮助搜索引擎找到多个独立来源的事实证据，从而交叉验证信息准确性，这是纯 LLM 问答无法实现的关键优势。\n\n\n\n作者团队表示会将这部分的延伸作为 DeepRetrieval 未来主要的探索方向之一。\n\n\nClassic IR（Sparse / Dense）\n\n\n\n\n\n在 BM25 和 dense retriever 下，DeepRetrieval 提供了平均 5~10 点 NDCG 提升，并且：BM25 + DeepRetrieval 和多数 dense baseline 水平相当。\n\n\n结合极快的检索速度（BM25 vs dense：352s vs 12,232s），展示了一个现实可部署、性能不俗的高效方案。\n\n\nSQL 检索任务\n\n\n在 SQL 检索任务中，DeepRetrieval 摆脱了对 groundtruth SQL 的依赖，直接利用生成 SQL 的执行成功率优化模型，通过生成更精准的 SQL 语句，使得模型在 Spider、BIRD 等数据集上的执行正确率均超过对比模型（包括 GPT-4o 和基于 SFT 的大模型）。\n\n\n\n\n\n探索胜于模仿：RL 为何超越 SFT\n\n\nDeepRetrieval 的实验揭示了强化学习（RL）在搜索优化上相比监督微调（SFT）的独特优势。实验数据令人信服：在文献搜索上，RL 方法的 DeepRetrieval（65.07%）超过 SFT 方法 LEADS（24.68%）近三倍；在 SQL 任务上，从零开始的 RL 训练（无需任何 gold SQL 语句的监督）也优于使用 GPT-4o 蒸馏数据的 SFT 模型。\n\n\n这种显著差异源于两种方法的本质区别：SFT 是「模仿学习」，试图复制参考查询，而 RL 是「直接优化」，通过环境反馈学习最优查询策略。SFT 方法的局限在于参考查询本身可能不是最优的，即使是人类专家或大模型也难以直观设计出最适合特定搜索引擎的查询表达。\n\n\n论文中的案例分析进一步证实了这一点。例如，在 PubMed 搜索中，DeepRetrieval 生成的查询如「((DDAVP) AND (Perioperative Procedures OR Blood Transfusion OR Desmopressin OR Anticoagulant)) AND (Randomized Controlled Trial)」融合了医学领域的专业术语和 PubMed 搜索引擎偏好的布尔结构，这种组合很难通过简单模仿预定义的查询模板获得。\n\n\n相反，RL 允许模型通过尝试与错误来探索查询空间，发现人类甚至未考虑的有效模式，并直接针对最终目标（如 Recall 或执行准确率）进行优化。这使 DeepRetrieval 能够生成高度适合特定搜索引擎特性的查询，适应不同检索环境的独特需求。\n\n\n这一发现具有重要启示：在追求最佳检索性能时，让模型通过反馈学习如何与检索系统「对话」，比简单模仿既定模式更为有效，这也解释了为何参数量较小的 DeepRetrieval 能在多项任务上超越拥有更多参数的商业模型。\n\n\n模型 Think&Query 长度分析\n\n\n\n\n\n通过分析 DeepRetrieval 在训练过程中模型思考链和查询长度的变化，可以发现以下关键洞见：\n\n\n思考链长度演变\n\n\n与「aha moment」相反，DeepRetrieval 的思考链长度随训练呈下降趋势，而非增长。这与 DeepSeek-R1 报告的「aha moment」现象形成鲜明对比，后者的思考链会随训练进展变得更长。图 4(a) 清晰地展示了 Qwen 模型思考链从初始约 150 tokens 逐渐降至稳定的 50 tokens 左右，而 Llama 模型的思考链更短，甚至降至接近 25 tokens。\n\n\n查询长度特征\n\n\n实验揭示了思考过程对查询长度的显著影响。无思考过程的模型容易陷入次优解，如图 4(b) 所示，Qwen 无思考版本生成极长查询（500-600 tokens），表现出过度扩展的倾向。相比之下，有思考过程的模型保持更为适中的查询长度，Qwen 约 150 tokens，Llama 约 100 tokens。有趣的是，不同模型采用不同长度策略，但能达到相似性能，表明查询生成存在多样有效路径。\n\n\n性能与思考过程关系\n\n\n思考过程对检索性能有决定性影响。图 4(c) 表明，具备思考能力的模型性能显著提升，有思考的模型 Recall@3K 能达到 65%，而无思考模型仅 50% 左右。此外，训练效率也明显提高，有思考的模型更快达到高性能并保持稳定。论文附录 D.1 的分析表明，思考过程帮助模型避免简单地通过增加查询长度和重复术语来提升性能，而是引导模型学习更有效的语义组织策略。\n\n\n关键结论\n\n\nDeepRetrieval 展示了思考过程在信息检索中扮演「探索促进器」的关键角色。与数学或编程问题不同，检索任务不需要像「aha moment」那样的突然顿悟现象。相反，检索优化遵循「先详细思考，后逐渐精简」的模式，模型在内化有效策略后，不再需要冗长思考。这表明检索任务中思考链的主要功能是探索，一旦策略稳定便可简化。\n\n\n这种分析表明，适当的思考过程设计对于构建高效的检索优化系统至关重要，能够在不增加模型参数的情况下显著提升性能，为未来的 LLM 应用于搜索任务提供了重要设计思路。\n\n\n结论\n\n\nDeepRetrieval 的贡献在于揭示了一个常被忽视但至关重要的事实：检索效果的上限不仅在于检索器本身，更在于如何「提问」。\n\n\n通过强化学习教 LLM 改写原始查询，DeepRetrieval 不仅摆脱了对人工标注数据和大模型蒸馏的依赖，还在多个任务上证明了改写 query 的巨大潜力。这项工作为搜索与信息检索领域带来了新的思考：未来的检索优化，不仅是提升引擎算法，更是如何让用户「问得更好」，从而激发出检索系统的全部潜力。\n\n\n© THE END \n转载请联系本公众号获得授权\n投稿或寻求报道：liyazhou@jiqizhixin.com\n\n\n    \n\n    \n    \n文章原文",
          "guid": "http://www.jintiankansha.me/t/mh3IOHrP5I",
          "categories": [
            "无"
          ],
          "isoDate": "2025-04-08T04:48:00.000Z"
        }
      },
      {
        "json": {
          "title": "类R1强化学习迁移到视觉定位！全开源Vision-R1将图文大模型性能提升50％",
          "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650963731&idx=3&sn=7c62398a729785a7d02da7b9d47fab3a&chksm=8525221905860a7ee31228d160e4f9c43b94d60c8acde57393a69b9a129332cc7c29446bba77&scene=0#rd",
          "pubDate": "Tue, 08 Apr 2025 12:48:00 +0800",
          "enclosure": {
            "url": "http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vX2GR4SOzMayrnjia6a0Op2Ec4BvGASYZanMpyJQL3OzdhLn6wjibgCyg/0?wx_fmt=jpeg",
            "length": "0",
            "type": "image/jpeg"
          },
          "content": "\n\n    \n\n    \n\n    \n         <div class=\"rich_media_content\" id=\"js_content\"><section style=\"text-align: center;margin: 0px 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5703125\" data-s=\"300,640\" data-type=\"png\" data-w=\"1280\" type=\"block\" data-imgfileid=\"503474618\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">图文大模型通常采用</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">「预训练 + 监督微调</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">」的两阶段范式进行训练，以强化其指令跟随能力。受语言领域的启发，多模态偏好优化技术凭借其在数据效率和性能增益方面的优势，被广泛用于对齐人类偏好。目前，该技术主要依赖高质量的偏好数据标注和精准的奖励模型训练来提升模型表现。然而，这一方法不仅资源消耗巨大，训练过程仍然极具挑战。</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">受到基于规则的强化学习（Rule-Based Reinforcement Learning）在 R1 上成功应用的启发，</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">中科院自动化研究所与中科紫东太初团队探索了如何结合高质量指令对齐数据与类 R1 的强化学习方法，进一步增强图文大模型的视觉定位能力</span><span textstyle=\"\" style=\"font-size: 15px;\">。该方法首次在 Object Detection、Visual Grounding 等复杂视觉任务上，使 Qwen2.5-VL 模型实现了最高 50% 的性能提升，超越了参数规模超过 10 倍的 SOTA 模型。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">目前，相关工作论文、模型及数据集代码均已开源。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.3055555555555556\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480005\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v2e77kvXDNLSZUg2LNXaRBlus0430lDHwnlVYWfYb5TJO4PQjEAQaHQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p><span leaf=\"\"><br></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li style=\"color: rgb(123, 12, 0);\"><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);\">论文标题：Vision-R1: Evolving Human-Free Alignment in Large Vision-Language Models via Vision-Guided Reinforcement Learning</span></span></p></li><li style=\"color: rgb(123, 12, 0);\"><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);\">论文地址：https://arxiv.org/pdf/2503.18013</span></span></p></li><li style=\"color: rgb(123, 12, 0);\"><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);\">Github 仓库：https://github.com/jefferyZhan/Griffon/tree/master/Vision-R1</span></span></p></li><li style=\"color: rgb(123, 12, 0);\"><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);\">Huggingface 仓库：https://huggingface.co/collections/JefferyZhan/vision-r1-67e166f8b6a9ec3f6a664262</span></span></p></li></ul><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">引言</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">目标定位任务要求模型能够精准识别用户输入的任意感兴趣目标，并给出精确的目标框，对图文大模型的细粒度感知和空间理解能力提出了严峻挑战。当前，图文大模型通常将目标定位建模为文本序列预测任务，并通过大规模预训练和指令数据的监督微调，以 Next Token Prediction 实现对不同粒度目标描述的精准定位。尽管在指代表达理解等任务上已超越传统视觉专家模型，但在更复杂、目标密集的场景中，其视觉定位与目标检测能力仍与专家模型存在显著差距。</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">R1 的成功应用推动了对基于规则的任务级别奖励监督的探索，使模型摆脱了对人工偏好数据标注和奖励模型训练的依赖。值得注意的是，视觉定位指令数据本身具有精准的空间位置标注，并与与人类对精准目标定位偏好高度一致。基于这些优势，Vision-R1 通过设计类 R1 的强化学习后训练框架，在任务级别监督中引入基于视觉任务评价指标的反馈奖励信号，为增强图文大模型的细粒度视觉定位能力提供了创新突破方向。</span></span></p><p><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5472222222222223\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480006\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vJDCID3GgZyWTM8ChASD740oNgKot2lsgVYfxXvI8XjOJicpddVXJqCQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin-left: 8px;margin-right: 8px;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;color: rgb(136, 136, 136);font-style: italic;\">Vision-R1 关键设计示意图</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">Vision Criteria-Driven Reward Function</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">聚焦图文大模型目标定位问题</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">在文本序列的统一建模和大规模数据的自回归训练下，图文大模型在目标定位任务上取得了显著的性能提升。然而，其进一步发展仍受到三大关键问题的限制：（1）密集场景中的长序列预测易出现格式错误，（2）有效预测目标的召回率较低，（3）目标定位精度不足。 </span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">这些问题制约了模型在更复杂视觉任务上的表现。在自回归 Token 级别的监督机制下，模型无法获得实例级别的反馈，而直接在单目标场景下应用 GRPO 训练方法又忽视了视觉定位任务的特性及 Completion 级别监督的优势。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">为此，研究团队结合图文大模型在视觉定位任务中面临的挑战，提出了一种基于视觉任务评价准则驱动的奖励函数，其设计包括以下四个核心部分：</span></span></p><p><span leaf=\"\"><br></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">框优先的预测匹配</span><span textstyle=\"\" style=\"font-size: 15px;\">：与仅针对单个目标进行设计的方法不同，Vision-R1 采用多目标预测的统一建模方式。为了计算包含多个目标预测的奖励，Vision-R1 首先对文本序列化的预测结果进行反序列化，提取出每个目标的预测框及其标签，并将预测结果与真实标注进行匹配，以确保奖励机制能够全面衡量多目标场景下的定位质量。</span></span></p></li><li><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">双重格式奖励</span><span textstyle=\"\" style=\"font-size: 15px;\">：该奖励项旨在解决密集场景下长序列预测的格式错误问题。对于每个预测文本序列，模型需满足指定的模板格式（如 Qwen2.5-VL 采用的 JSON 格式），并确保目标坐标的数值正确性。仅当预测结果同时满足格式和内容要求时，模型才能获得奖励 1，从而引导其生成符合标准的预测输出。</span></span></p></li><li><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">召回奖励</span><span textstyle=\"\" style=\"font-size: 15px;\">：该奖励项针对有效预测目标召回率低的问题，鼓励模型尽可能多地识别目标。具体而言，针对每个预测目标及其匹配的真实目标（GT），当两者的 IoU 超过预设阈值 ζ 时，视为该预测有效。对于一个预测序列，其召回奖励定义为有效预测目标数量与实际需要预测目标数量的比例，以此激励模型提高目标的覆盖率。</span></span></p></li></ul><p style=\"margin:0px 8px;line-height:1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.1675925925925926\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480007\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vCwasgjnKomk6Y4icCY3w8iadAvX1bLIllQo7VO1hJyVN6icYiciaQyn3ekw/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin:0px 8px;line-height:1.75em;\"><span leaf=\"\"><br></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">精度奖励</span><span textstyle=\"\" style=\"font-size: 15px;\">：精度奖励与召回奖励协同作用，形成</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">「1+1&gt;2</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">」的优化效果。其中，召回奖励提升模型对目标的全面识别能力，而精度奖励则确保预测的准确性。精度奖励从单实例角度衡量预测质量，其核心目标是鼓励模型生成高质量的边界框。具体地，精度奖励被定义为所有有效预测的平均 IoU 值，以直接激励模型优化目标框的精确度：</span></span></p></li></ul><p><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.17407407407407408\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480008\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v6WEzXicJpQdhhGQHXTM1kOfVZCpKVQx7qkiaqy9LriabGk2eHUkB664PQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5666666666666667\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480009\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vPov0VPHWruJWz9nH1JJicIRs3IaK8D2EnE7ZVUia1SXzsQ9NnI9mbAdA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin-left: 8px;margin-right: 8px;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;color: rgb(136, 136, 136);font-style: italic;\">Vision-R1 整体框架</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">Progressive Rule Refinement Strategy</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">实现持续性能提升</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">在目标定位任务中，预测高质量（高 IoU）的目标框始终是一个挑战，尤其是在密集场景和小目标情况下。这种困难可能导致模型在同组预测中奖励差异较小，从而影响优化效果。针对这一问题，研究团队提出了渐进式规则调整策略，该策略通过在训练过程中动态调整奖励计算规则，旨在实现模型的持续性能提升。该策略主要包括两个核心部分：</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">差异化策略</span><span textstyle=\"\" style=\"font-size: 15px;\">：该策略的目标是扩大预测结果与实际奖励之间的映射差异。具体而言，通过惩罚低召回率（Recall）和低平均 IoU 的预测，并对高召回率和高 IoU 的预测给予较高奖励，从而鼓励模型生成更高质量的预测，尤其是在当前能够达到的最佳预测上获得最大奖励。这一策略引导模型在训练过程中逐渐提高预测精度，同时避免低质量预测的奖励过高，促进其优化。具体实现如下：</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.3675925925925926\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480010\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v2y8Y6piclrWYXp5VsAicG2IfNdIpG2K4u9W6JrJWsQY4WsIoSXyPkUibQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">阶段渐近策略</span><span textstyle=\"\" style=\"font-size: 15px;\">：类似于许多有效的学习方法，给初学者设定容易实现的目标并逐步提升奖励难度是一个常见且行之有效的策略。在 Vision-R1 中，训练过程被划分为初学阶段和进阶阶段，并通过逐步调整阈值 ζ 来实现奖励规则的逐渐变化。具体来说：</span></span></p><p><span leaf=\"\"><br></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">初学阶段（Beginner Phase）</span><span textstyle=\"\" style=\"font-size: 15px;\">： 在这一阶段，设置较低的 ζ 阈值（0.5/0.75），给予模型相对宽松的奖励标准，帮助其快速入门并学习基础的定位能力。</span></span></p></li><li><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">进阶阶段（Advanced Phase）</span><span textstyle=\"\" style=\"font-size: 15px;\">： 随着训练的深入，逐步提高 ζ 阈值，增加标准要求，以促使模型达到更高的准确度，避免模型依赖简单策略，从而持续推动模型性能的提升。</span></span></p></li></ul><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">不同模型的域内外目标检测评测</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">为全面评估 Vision-R1 的效果，研究团队选择了近期定位能力大幅提升的 Qwen2.5-VL-7B 模型和定位能力突出的 Griffon-G-7B 模型，在更有挑战的经典目标检测数据集 COCO 和多样场景的 ODINW-13 上进行测试，以展现方法对不同定位水平模型的适用性。</span></span></p><p><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5305555555555556\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480011\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v0pVFPvKaKDYzhkqIpUicqvMuM8ibRYX4azDj5uVtOlhq1LqKVjoN0Fkw/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin-left: 8px;margin-right: 8px;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;color: rgb(136, 136, 136);font-style: italic;\">经典 COCO/ODINW 数据集上 Vision-R1 方法相较于基线模型性能的提升</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">实验结果表明，无论基础性能如何，与基线模型相比这些模型在 Vision-R1 训练后性能大幅提升，甚至超过同系列 SOTA 模型，进一步接近了定位专家模型。</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">研究团队还在模型没有训练的域外定位数据集上进行测试，Vision-R1 在不同模型的四个数据集上取得了平均 6% 的性能提升，充分论证了方法的泛化性。</span></span></p><p><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.27685185185185185\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480012\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v9Aicd4jfK3HdpRQjKTZia8Zvdiaiab0lzfx7G4xN7MsPgZ7k96efNrcIHg/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;color: rgb(136, 136, 136);font-style: italic;\">域外数据集上 Vision-R1 方法相较于基线模型性能的提升</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">模型通用问答能力评测</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">研究团队进一步评估了模型在非定位等通用任务上的性能，以验证方法是否能在少量影响模型通用能力的情况下，大幅度提升模型的视觉定位能力。研究团队发现，Vision-R1 近乎不损失模型的通用能力，在通用问答、图表问答等评测集上模型实现了与基准模型基本一致的性能。</span></span></p><p><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.2962962962962963\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480013\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vCvIaG3SPdER8CvEw5ibjvnpxGwf9pABOLzdRLnp64SeTUKgxYd1u00A/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;color: rgb(136, 136, 136);font-style: italic;\">通用问答数据集上 Vision-R1 方法与基线模型性能的比较</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">可视化分析</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">研究团队提供了在 Qwen2.5-VL-7B 模型上使用 Vision-R1 后在多个场景下的目标检测可视化结果。如结果所示，Vision-R1 训练后，模型能够更好召回所感兴趣的物体，并进一步提升定位的精度。</span></span></p><p><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-croporisrc=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vJ9DVoz1hlMAibMiatOBUWAbUo8PRIpFWgP3akTIiaRhNhHvAM54IguSqA/0?wx_fmt=png&amp;from=appmsg\" data-cropselx2=\"562\" data-cropsely2=\"208\" data-imgfileid=\"503480053\" data-ratio=\"0.3690828402366864\" data-s=\"300,640\" data-type=\"png\" data-w=\"2704\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vJ9DVoz1hlMAibMiatOBUWAbUo8PRIpFWgP3akTIiaRhNhHvAM54IguSqA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin-left: 8px;margin-right: 8px;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;color: rgb(136, 136, 136);font-style: italic;\">Vision-R1 训练模型与基准模型检测结果可视化</span></span></p><section><span leaf=\"\"><br></span></section><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" data-style=\"margin-top: 5px; outline: 0px; max-width: 100%; color: rgb(34, 34, 34); font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif letter-spacing: white-space: normal caret-color: rgb background-color: text-align: center line-height: margin-bottom: box-sizing: border-box overflow-wrap: break-word class=\"js_darkmode__6\" style=\"-webkit-tap-highlight-color: transparent;margin-top: 5px;margin-bottom: 0px;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);letter-spacing: 0.544px;text-wrap: wrap;font-family: -apple-system, BlinkMacSystemFont, \"><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif><span leaf=\"\">© THE END </span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" data-style=\"margin-top: 5px; outline: 0px; max-width: 100%; color: rgb(34, 34, 34); font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif letter-spacing: white-space: normal caret-color: rgb background-color: text-align: center line-height: margin-bottom: box-sizing: border-box overflow-wrap: break-word class=\"js_darkmode__7\" style=\"-webkit-tap-highlight-color: transparent;margin-top: 5px;margin-bottom: 0px;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);letter-spacing: 0.544px;text-wrap: wrap;font-family: -apple-system, BlinkMacSystemFont, \"><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;\"><span leaf=\"\">转载请联系本公众号获得授权</span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" data-style=\"margin-top: 5px; outline: 0px; max-width: 100%; color: rgb(34, 34, 34); font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif letter-spacing: white-space: normal caret-color: rgb background-color: text-align: center line-height: margin-bottom: box-sizing: border-box overflow-wrap: break-word class=\"js_darkmode__8\" style=\"-webkit-tap-highlight-color: transparent;margin-top: 5px;margin-bottom: 0px;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);letter-spacing: 0.544px;text-wrap: wrap;font-family: -apple-system, BlinkMacSystemFont, \"><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;\"><span leaf=\"\">投稿或寻求报道：liyazhou@jiqizhixin.com</span></span></p><p style=\"display: none;\"><mp-style-type data-value=\"10000\"></mp-style-type></p></div>\n    \n\n    \n    <br>\n\n    \n        <a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963731&amp;idx=3&amp;sn=7c62398a729785a7d02da7b9d47fab3a&amp;chksm=8525221905860a7ee31228d160e4f9c43b94d60c8acde57393a69b9a129332cc7c29446bba77&amp;scene=0#rd\" style=\"color: blue\" class=\"media_tool_meta meta_primary\">文章原文</a>\n        <br>\n    \n\n    \n\n    <img alt=\"\" width=\"1px\" height=\"1px\" class=\"\" style=\"width:1px;height:1px;display:none\" src=\"http://www.jintiankansha.me/rss_static/4365/n89LPmpAv7\">\n\n",
          "contentSnippet": "图文大模型通常采用「预训练 + 监督微调」的两阶段范式进行训练，以强化其指令跟随能力。受语言领域的启发，多模态偏好优化技术凭借其在数据效率和性能增益方面的优势，被广泛用于对齐人类偏好。目前，该技术主要依赖高质量的偏好数据标注和精准的奖励模型训练来提升模型表现。然而，这一方法不仅资源消耗巨大，训练过程仍然极具挑战。\n\n\n受到基于规则的强化学习（Rule-Based Reinforcement Learning）在 R1 上成功应用的启发，中科院自动化研究所与中科紫东太初团队探索了如何结合高质量指令对齐数据与类 R1 的强化学习方法，进一步增强图文大模型的视觉定位能力。该方法首次在 Object Detection、Visual Grounding 等复杂视觉任务上，使 Qwen2.5-VL 模型实现了最高 50% 的性能提升，超越了参数规模超过 10 倍的 SOTA 模型。\n\n\n目前，相关工作论文、模型及数据集代码均已开源。\n\n\n\n\n\n\n论文标题：Vision-R1: Evolving Human-Free Alignment in Large Vision-Language Models via Vision-Guided Reinforcement Learning\n\n论文地址：https://arxiv.org/pdf/2503.18013\n\nGithub 仓库：https://github.com/jefferyZhan/Griffon/tree/master/Vision-R1\n\nHuggingface 仓库：https://huggingface.co/collections/JefferyZhan/vision-r1-67e166f8b6a9ec3f6a664262\n\n\n\n引言\n\n\n目标定位任务要求模型能够精准识别用户输入的任意感兴趣目标，并给出精确的目标框，对图文大模型的细粒度感知和空间理解能力提出了严峻挑战。当前，图文大模型通常将目标定位建模为文本序列预测任务，并通过大规模预训练和指令数据的监督微调，以 Next Token Prediction 实现对不同粒度目标描述的精准定位。尽管在指代表达理解等任务上已超越传统视觉专家模型，但在更复杂、目标密集的场景中，其视觉定位与目标检测能力仍与专家模型存在显著差距。\n\n\nR1 的成功应用推动了对基于规则的任务级别奖励监督的探索，使模型摆脱了对人工偏好数据标注和奖励模型训练的依赖。值得注意的是，视觉定位指令数据本身具有精准的空间位置标注，并与与人类对精准目标定位偏好高度一致。基于这些优势，Vision-R1 通过设计类 R1 的强化学习后训练框架，在任务级别监督中引入基于视觉任务评价指标的反馈奖励信号，为增强图文大模型的细粒度视觉定位能力提供了创新突破方向。\n\n\n\nVision-R1 关键设计示意图\n\n\nVision Criteria-Driven Reward Function\n聚焦图文大模型目标定位问题\n\n\n在文本序列的统一建模和大规模数据的自回归训练下，图文大模型在目标定位任务上取得了显著的性能提升。然而，其进一步发展仍受到三大关键问题的限制：（1）密集场景中的长序列预测易出现格式错误，（2）有效预测目标的召回率较低，（3）目标定位精度不足。 \n\n\n这些问题制约了模型在更复杂视觉任务上的表现。在自回归 Token 级别的监督机制下，模型无法获得实例级别的反馈，而直接在单目标场景下应用 GRPO 训练方法又忽视了视觉定位任务的特性及 Completion 级别监督的优势。\n\n\n为此，研究团队结合图文大模型在视觉定位任务中面临的挑战，提出了一种基于视觉任务评价准则驱动的奖励函数，其设计包括以下四个核心部分：\n\n\n\n框优先的预测匹配：与仅针对单个目标进行设计的方法不同，Vision-R1 采用多目标预测的统一建模方式。为了计算包含多个目标预测的奖励，Vision-R1 首先对文本序列化的预测结果进行反序列化，提取出每个目标的预测框及其标签，并将预测结果与真实标注进行匹配，以确保奖励机制能够全面衡量多目标场景下的定位质量。\n\n双重格式奖励：该奖励项旨在解决密集场景下长序列预测的格式错误问题。对于每个预测文本序列，模型需满足指定的模板格式（如 Qwen2.5-VL 采用的 JSON 格式），并确保目标坐标的数值正确性。仅当预测结果同时满足格式和内容要求时，模型才能获得奖励 1，从而引导其生成符合标准的预测输出。\n\n召回奖励：该奖励项针对有效预测目标召回率低的问题，鼓励模型尽可能多地识别目标。具体而言，针对每个预测目标及其匹配的真实目标（GT），当两者的 IoU 超过预设阈值 ζ 时，视为该预测有效。对于一个预测序列，其召回奖励定义为有效预测目标数量与实际需要预测目标数量的比例，以此激励模型提高目标的覆盖率。\n\n\n\n\n\n\n\n精度奖励：精度奖励与召回奖励协同作用，形成「1+1>2」的优化效果。其中，召回奖励提升模型对目标的全面识别能力，而精度奖励则确保预测的准确性。精度奖励从单实例角度衡量预测质量，其核心目标是鼓励模型生成高质量的边界框。具体地，精度奖励被定义为所有有效预测的平均 IoU 值，以直接激励模型优化目标框的精确度：\n\n\n\n\n\n\n\nVision-R1 整体框架\n\n\nProgressive Rule Refinement Strategy\n实现持续性能提升\n\n\n在目标定位任务中，预测高质量（高 IoU）的目标框始终是一个挑战，尤其是在密集场景和小目标情况下。这种困难可能导致模型在同组预测中奖励差异较小，从而影响优化效果。针对这一问题，研究团队提出了渐进式规则调整策略，该策略通过在训练过程中动态调整奖励计算规则，旨在实现模型的持续性能提升。该策略主要包括两个核心部分：\n\n\n差异化策略：该策略的目标是扩大预测结果与实际奖励之间的映射差异。具体而言，通过惩罚低召回率（Recall）和低平均 IoU 的预测，并对高召回率和高 IoU 的预测给予较高奖励，从而鼓励模型生成更高质量的预测，尤其是在当前能够达到的最佳预测上获得最大奖励。这一策略引导模型在训练过程中逐渐提高预测精度，同时避免低质量预测的奖励过高，促进其优化。具体实现如下：\n\n\n\n\n\n阶段渐近策略：类似于许多有效的学习方法，给初学者设定容易实现的目标并逐步提升奖励难度是一个常见且行之有效的策略。在 Vision-R1 中，训练过程被划分为初学阶段和进阶阶段，并通过逐步调整阈值 ζ 来实现奖励规则的逐渐变化。具体来说：\n\n\n\n初学阶段（Beginner Phase）： 在这一阶段，设置较低的 ζ 阈值（0.5/0.75），给予模型相对宽松的奖励标准，帮助其快速入门并学习基础的定位能力。\n\n进阶阶段（Advanced Phase）： 随着训练的深入，逐步提高 ζ 阈值，增加标准要求，以促使模型达到更高的准确度，避免模型依赖简单策略，从而持续推动模型性能的提升。\n\n\n\n不同模型的域内外目标检测评测\n\n\n为全面评估 Vision-R1 的效果，研究团队选择了近期定位能力大幅提升的 Qwen2.5-VL-7B 模型和定位能力突出的 Griffon-G-7B 模型，在更有挑战的经典目标检测数据集 COCO 和多样场景的 ODINW-13 上进行测试，以展现方法对不同定位水平模型的适用性。\n\n\n\n经典 COCO/ODINW 数据集上 Vision-R1 方法相较于基线模型性能的提升\n\n\n实验结果表明，无论基础性能如何，与基线模型相比这些模型在 Vision-R1 训练后性能大幅提升，甚至超过同系列 SOTA 模型，进一步接近了定位专家模型。\n\n\n研究团队还在模型没有训练的域外定位数据集上进行测试，Vision-R1 在不同模型的四个数据集上取得了平均 6% 的性能提升，充分论证了方法的泛化性。\n\n\n\n域外数据集上 Vision-R1 方法相较于基线模型性能的提升\n\n\n模型通用问答能力评测\n\n\n研究团队进一步评估了模型在非定位等通用任务上的性能，以验证方法是否能在少量影响模型通用能力的情况下，大幅度提升模型的视觉定位能力。研究团队发现，Vision-R1 近乎不损失模型的通用能力，在通用问答、图表问答等评测集上模型实现了与基准模型基本一致的性能。\n\n\n\n通用问答数据集上 Vision-R1 方法与基线模型性能的比较\n\n\n可视化分析\n\n\n研究团队提供了在 Qwen2.5-VL-7B 模型上使用 Vision-R1 后在多个场景下的目标检测可视化结果。如结果所示，Vision-R1 训练后，模型能够更好召回所感兴趣的物体，并进一步提升定位的精度。\n\n\n\nVision-R1 训练模型与基准模型检测结果可视化\n\n\n© THE END \n转载请联系本公众号获得授权\n投稿或寻求报道：liyazhou@jiqizhixin.com\n\n\n    \n\n    \n    \n文章原文",
          "guid": "http://www.jintiankansha.me/t/n89LPmpAv7",
          "categories": [
            "无"
          ],
          "isoDate": "2025-04-08T04:48:00.000Z"
        }
      },
      {
        "json": {
          "title": "斯坦福2025 AI Index报告来了：DeepSeek在全文中被提到45次",
          "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650963731&idx=2&sn=9843c5010e27941cd6a9cc09bb2ef96f&chksm=8559d5f21da721c9e2ddbeb61eb74999a52b0f50db55cf6ccca09e7df353af7a2e2dcd33e091&scene=0#rd",
          "pubDate": "Tue, 08 Apr 2025 12:48:00 +0800",
          "enclosure": {
            "url": "http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vMXg96e3psNcAzExF8TVafXN4cOS4TpvecJaNLvYB1kzSpJ4daq507w/0?wx_fmt=jpeg",
            "length": "0",
            "type": "image/jpeg"
          },
          "content": "\n\n    \n\n    \n\n    \n         <div class=\"rich_media_content\" id=\"js_content\"><section data-mpa-powered-by=\"yiban.io\" data-style=\"white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: \" helvetica neue sans gb yahei arial sans-serif box-sizing: border-box overflow-wrap: break-word mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" data-pm-slice=\"0 0 []\" class=\"js_darkmode__0\" style=\"-webkit-tap-highlight-color: transparent;margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;color: rgba(0, 0, 0, 0.9);font-size: 17px;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: 0.544px;orphans: 2;text-align: justify;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;white-space: normal;text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px;background-color: rgb(255, 255, 255);text-size-adjust: inherit;caret-color: rgb(34, 34, 34);font-family: \" visible><section mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" class=\"js_darkmode__1\" style=\"-webkit-tap-highlight-color: transparent;margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px;visibility: visible;line-height: 27.2px;\"><section mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" class=\"js_darkmode__2\" style=\"-webkit-tap-highlight-color: transparent;margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px;visibility: visible;line-height: 27.2px;\"><section data-id=\"85660\" data-custom=\"rgb(117, 117, 118)\" data-color=\"rgb(117, 117, 118)\" mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" class=\"js_darkmode__3\" style=\"-webkit-tap-highlight-color: transparent;margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 27.2px;\"><section data-style=\"margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;\" mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" class=\"js_darkmode__4\" style=\"-webkit-tap-highlight-color: transparent;margin: 2em 0px 0px;padding: 0.5em 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px;border-top: 1px solid rgb(204, 204, 204);border-bottom: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;line-height: 27.2px;\"><p mp-original-font-size=\"17\" mp-original-line-height=\"29.75\" class=\"js_darkmode__5\" style=\"-webkit-tap-highlight-color: transparent;margin: -1.2em 8px 0px;padding: 0px;outline: 0px;max-width: 100%;clear: both;min-height: 1em;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 29.75px;box-sizing: border-box !important;overflow-wrap: break-word !important;color: rgb(163, 163, 163) !important;\"><span mp-original-font-size=\"15\" mp-original-line-height=\"29.75\" style=\"-webkit-tap-highlight-color: transparent;margin-top: 0px;margin-bottom: 0px;padding: 0px;outline: 0px;max-width: 100%;color: rgb(255, 255, 255);font-family: inherit;font-size: 15px;letter-spacing: 0.544px;background-color: rgb(117, 117, 118);text-decoration: inherit;visibility: visible;line-height: 29.75px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span leaf=\"\" style=\"-webkit-tap-highlight-color: transparent;margin-top: 0px;margin-bottom: 0px;padding: 0px;outline: 0px;max-width: 100%;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\">机器之心报道</span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"29.75\" style=\"-webkit-tap-highlight-color: transparent;margin: 0px 8px;padding: 0px;outline: 0px;max-width: 100%;clear: both;min-height: 1em;text-align: center;visibility: visible;line-height: 29.75px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span leaf=\"\" style=\"-webkit-tap-highlight-color: transparent;margin-top: 0px;margin-bottom: 0px;padding: 0px;outline: 0px;max-width: 100%;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span textstyle=\"\" style=\"font-size: 12px;color: rgb(136, 136, 136);font-weight: bold;\">编辑：蛋酱、+0</span></span></p></section></section></section></section></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">刚刚，斯坦福大学正式发布了《2025 AI Index》报告。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">在过去的一段时间里，人工智能领域经历了一场蓬勃的发展，但与此同时，也有人说「人工智能是一个泡沫」。其他的讨论话题包括但不限于：人工智能的现有技术和架构将不断取得突破；人工智能走在一条不可持续的道路上；人工智能将取代你的工作；人工智能最擅长的就是把你的家庭照片变成吉卜力工作室风格的动画图像……</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">每一年的斯坦福 AI Index 报告都会对领域的发展进行系统的梳理，今年也是如此。《2025 AI Index》报告总共 400 多页，涵盖了研发、技术性能、负责任的人工智能、经济影响、科学和医学、政策、教育和公众舆论等主题的图表和数据。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"1.3009259259259258\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480032\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vO3HwySDfK9xNJna7fkjBs86J1sghxibGMtrTrmRnsgR5ib6AcWib0M8yQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: left;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);\">报告地址：https://hai.stanford.edu/ai-index/2025-ai-index-report</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">目录如下：</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"1.2055555555555555\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480033\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v652VgoueXibyrzianukib2r3PBA3XtCr7RY0EhjqCKaVd8AXVuU8owGGw/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">除了谷歌、OpenAI 之外，中国公司 DeepSeek 也成为报告关注的焦点，在 PDF 全文中被提到了 45 次。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">关于今年 AI Index 报告的核心内容，我们通过 12 张图片来了解：</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">美国公司的遥遥领先</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.9355555555555556\" data-s=\"300,640\" data-type=\"png\" data-w=\"900\" type=\"block\" data-imgfileid=\"503480034\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0voOjZickZWdKMv7wYmKQwgibeqmicRkpFmic0XiaXCniazj0zvPJgyBAOhBMw/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">虽然衡量国家在人工智能竞赛中「领先」的方式多种多样（如期刊文章发表或引用数量、专利授权等），但一个直观的评估指标是观察哪些国家发布了具有影响力的模型。研究机构 Epoch AI 拥有一个从 1950 年至今的重要人工智能模型数据库，AI Index 从中提取了相关数据进行分析。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">数据显示，去年美国发布了 40 个知名模型，中国发布了 15 个，欧洲仅有 3 个（均来自法国）。另有数据表明，2024 年发布的这些模型几乎全部来自产业界，而非学术界或政府部门。关于 2023 年至 2024 年知名模型发布数量减少的现象，AI Index 认为可能是由于技术复杂度提高和训练成本持续攀升所致。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">说到训练成本……</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5842592592592593\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480035\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vyleg1v6XYmAFBtQfsoibahkAhcISOwkE2ogM2VeMBCR88Tia5ZXw2r1g/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">在这方面，AI Index 缺乏精确数据，因为许多领先的人工智能公司已停止公开其训练过程信息。斯坦福研究人员与 Epoch AI 合作，基于训练时长、硬件类型和数量等详细信息，估算了部分模型的成本。在可评估的模型中，最昂贵的是谷歌的 Gemini 1.0 Ultra，训练成本约达 1.92 亿美元。训练成本的全面上涨与报告中的其他发现相符：模型在参数数量、训练时间和训练数据量等方面持续规模化扩张。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">值得注意的是，DeepSeek 并未包含在这一分析中。这家公司在 2025 年 1 月声称仅用 600 万美元训练出了 DeepSeek-R1，引发金融市场震动，虽然部分行业专家对此说法持怀疑态度。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">AI Index 指导委员会联合主任 Yolanda Gil 在接受 IEEE Spectrum 采访时表示，她认为 DeepSeek「非常令人印象深刻」，并指出计算机科学历史上充满了早期低效技术被更优雅解决方案取代的案例。她补充道：「我不是唯一一个相信某个时点会出现更高效版本大语言模型的人。我们只是不知道谁会构建它以及如何构建。」</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">使用人工智能的成本正在下降</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5601851851851852\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480036\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vugYOHSCYguR6ZfYwPcQqqibZmoOIMcUkTrIB2DJ3Tg1prTyRkoAw91Q/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">尽管大多数 AI 模型的训练成本持续攀升，但报告中强调了几个积极趋势：硬件成本降低、硬件性能提升及能源效率提高。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">这使得推理成本（即查询已训练模型的费用）正在急剧下降。这张使用对数比例的图表展示了 AI 性能每美元的发展趋势。报告指出，蓝线表明每百万 tokens 的成本从 20 美元降至 0.07 美元；粉线则显示在不到一年时间内，成本从 15 美元降至 0.12 美元。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">人工智能的显著碳足迹</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5703703703703704\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480037\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vGOfD2FjJ9mFVCLUgdGfSN55eYVibNgBuAcaHk6dqpgweFic0gdvYSJEg/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">虽然能源效率提高是一个积极的趋势，但存在一个不容忽视的问题：尽管效率有所提升，整体能耗仍在增长，这意味着处于人工智能热潮中心的数据中心留下了巨大的碳足迹。AI Index 基于训练硬件、云服务提供商和地理位置等因素，估算了特定 AI 模型的碳排放，发现前沿人工智能模型的训练碳排放量呈稳步增长趋势 —— 其中 DeepSeek 模型是个例外。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">数据显示，最大的排放源是 Meta 的 Llama 3.1 模型，估计产生了 8930 吨二氧化碳排放，相当于约 496 个美国人一年的生活碳排放量。这一显著的环境影响解释了为何人工智能公司正积极采用核能作为可靠的零碳能源来源。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">人工智能模型性能差距持续缩小</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.575925925925926\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480038\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vMDib7Esrhia5vTPusl8xpVOcqK1BTR0cLbic0el334ycHicYtiaeutRQjAA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">美国在已发布的知名模型数量上仍然保持领先地位，但中国模型在质量方面正在迅速赶上。数据显示，在聊天机器人基准测试上的性能差距正在不断缩小。2024 年 1 月，顶尖美国模型的表现比最优中国模型高出 9.26%；到 2025 年 2 月，这一差距已缩小至仅 1.70%。报告在推理、数学和编程等其他基准测试中也发现了类似趋势。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">人类最后的考试</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5324074074074074\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480039\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vd5PZFOlexXtUqYqONHAJuOmMS1QnmBmjAJwGTSrlyNta154maHkESQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">今年的报告指出了一个不可忽视的事实：用于评估人工智能系统能力的众多基准测试已经「饱和」—— 人工智能系统在这些测试上获得的分数如此之高，以至于它们不再具有区分价值。这种现象已在多个领域出现：通用知识、图像推理、数学、编程等。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">Gil 表示，她惊讶地目睹一个又一个基准测试逐渐失去参考意义。她指出：「我一直认为性能会趋于平稳，会达到一个需要新技术或根本不同架构才能继续取得进展的临界点。但事实并非如此。」</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">面对这种局面，执着的研究人员不断设计新的基准测试，以期挑战人工智能系统。其中一项是「人类的最后考试」，它由来自全球 500 个机构的专业领域专家贡献的极具挑战性问题组成。到目前为止，即使对最顶尖的人工智能系统而言，这项测试仍然难以攻克：OpenAI 的推理模型 o1 目前以 8.8% 的正确答案率位居榜首。业界正密切关注这种局面能持续多久。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">公共数据面临的威胁</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5777777777777777\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480040\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v16BV9P3cbkGkWh2Nc9HkzFWIiaUatrhWLiaaFe7Mm132LPBv8vyOF7yA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">当今生成式 AI 系统通过训练海量从互联网抓取的数据获得智能，这导致了一个经常被提及的观点：「数据是 AI 经济的新石油」。随着人工智能公司不断挑战可输入模型的数据量极限，业界开始担忧「数据峰值」问题，以及何时会耗尽这种关键资源。一个问题是，越来越多的网站正在限制机器人爬取并抓取其数据（可能是因为担忧人工智能公司从其数据中获利，同时破坏其商业模式）。网站通过机器可读的 robots.txt 文件声明这些限制。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">数据显示，顶级网络域名中 48% 的数据现已被完全限制访问。然而，Gil 指出，人工智能领域可能会出现新方法，终结对庞大数据集的依赖。她认为：「预计在某些时候，数据量将不再如此关键。」</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">企业资金持续涌入人工智能领域</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5425925925925926\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480041\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vbPWSFtEFAybYRkAhRly9wrXLmAhst8rIhKxxXzPibtv4TkLOFBWibs5Q/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">过去五年，企业界已为人工智能投资敞开了资金闸门。虽然 2024 年的全球总体投资未能达到 2021 年的疯狂高峰，但值得注意的是，私人投资规模达到了前所未有的水平。在 2024 年 1500 亿美元的私人投资中，相关指数的另一项数据表明，约 330 亿美元流向了生成式 AI 领域。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">企业等待人工智能投资的巨大回报</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5416666666666666\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480042\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vDSe1ZI3znuCmibibCC3kuUnasMRLG9onc4aIwls7k1ibiaXNSmrDlAwesg/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">理论上，企业投资人工智能是因为期望获得可观的投资回报。在这个话题上，人们常以激昂语气讨论人工智能的变革性本质和前所未有的生产力提升。然而，企业尚未见到能带来显著成本节省或实质性新收益的转变。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">麦肯锡调查数据显示，在报告成本降低的企业中，大多数节省幅度不足 10%；在因人工智能获得收入增长的企业中，大多数报告的增长幅度不到 5%。巨大的回报可能仍在路上，从投资数据来看，众多企业正在押注于此，但目前尚未实现。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">AI 医生或将很快接诊</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-imgfileid=\"503480043\" data-ratio=\"1.0322222222222222\" data-s=\"300,640\" data-type=\"png\" data-w=\"900\" type=\"block\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vENogKWLf0u7UW75OKDvK1CLLyNRPUO7lrcHeAF7yKhRGYgoMibYibLFg/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">科学与医疗领域的人工智能应用是人工智能浪潮中的一个重要分支。报告列举了多个新发布的基础模型，这些模型旨在协助材料科学、天气预报和量子计算等领域的研究人员。众多公司正尝试将人工智能的预测和生成能力转化为盈利性药物研发。OpenAI 的 o1 推理模型最近在医学执照考试问题集 MedQA 的基准测试中取得了 96% 的得分。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">然而，这似乎仍是一个潜力巨大但尚未转化为显著实际影响的领域 —— 部分原因可能是人类尚未完全掌握如何有效使用这项技术。2024 年的一项研究测试了医生在使用 GPT-4 作为常规资源补充时是否能做出更准确的诊断。结果表明，这既未提高诊断准确性，也未加快诊断速度。值得注意的是，单独使用的 GPT-4 表现却优于人机团队和单独的人类医生。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">美国的人工智能政策行动转向州级层面</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-imgfileid=\"503480044\" data-ratio=\"0.5425925925925926\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vbRJkKD3BJL1W2OtKVNmEiaFfibSTeJP0OGhWGp3ryyicesPJslCv91vLQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">这张图表显示，美国国会虽有大量关于人工智能的讨论，但实际行动寥寥无几。报告指出，美国的政策制定已转移至州级层面，2024 年共有 131 项法案在各州获得通过。其中 56 项与深度伪造（deepfake）相关，禁止在选举中使用深度伪造技术或借此传播未经同意的私密图像。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">美国之外，欧洲已通过《人工智能法案》（AI Act），该法案要求开发被认定为高风险的人工智能系统的公司承担新的责任义务。然而，全球主要趋势是各国联合发表关于人工智能应在世界上扮演何种角色的全面但无约束力的声明。因此，实质性监管行动相对有限，而讨论却十分广泛。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">人类是乐观主义者</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5277777777777778\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480045\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vmdTB8Tlfa8bGJWaOeibG1ugAXORH1zyj5o4e1iaZIOlPgpT8T7EELt5w/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">无论你是股票摄影师、营销经理还是卡车司机，关于人工智能是否以及何时会取代你的工作，社会上已有广泛讨论。然而，最近一项关于人工智能态度的全球调查显示，大多数人并不感到受到人工智能的威胁。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">来自 32 个国家的 60% 受访者认为人工智能将改变他们的工作方式，但仅有 36% 的人预期会被替代。「这些调查结果确实让我感到惊讶，」Gil 表示，「人们认为『人工智能将改变我的工作，但我仍将创造价值』，这种观点非常令人鼓舞。」让我们拭目以待，看看我们能否都通过管理人工智能团队来持续创造价值。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">更多细节，可参考报告原文。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: center;margin-bottom: 0px;margin-left: 8px;margin-right: 8px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.8518518518518519\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" data-imgfileid=\"503478358\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibD4lCB7aJY0WoFGLCNz0tCh7FbEdJhtvUB5Y0TKawRI38FibjTdXdibM3bsf05HHvbN99GwB8GhOEQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></span></p><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;margin: 5px 8px 0px;outline: 0px;letter-spacing: 0.544px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb inherit center><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif><span leaf=\"\">© THE END </span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;margin: 5px 8px 0px;outline: 0px;letter-spacing: 0.544px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb inherit center><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;\"><span leaf=\"\">转载请联系本公众号获得授权</span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;margin: 5px 8px 0px;outline: 0px;letter-spacing: 0.544px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb inherit center><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;\"><span leaf=\"\">投稿或寻求报道：liyazhou@jiqizhixin.com</span></span></p><p style=\"display: none;\"><mp-style-type data-value=\"3\"></mp-style-type></p></div>\n    \n\n    \n    <br>\n\n    \n        <a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963731&amp;idx=2&amp;sn=9843c5010e27941cd6a9cc09bb2ef96f&amp;chksm=8559d5f21da721c9e2ddbeb61eb74999a52b0f50db55cf6ccca09e7df353af7a2e2dcd33e091&amp;scene=0#rd\" style=\"color: blue\" class=\"media_tool_meta meta_primary\">文章原文</a>\n        <br>\n    \n\n    \n\n    <img alt=\"\" width=\"1px\" height=\"1px\" class=\"\" style=\"width:1px;height:1px;display:none\" src=\"http://www.jintiankansha.me/rss_static/4365/GaNPqOtUez\">\n\n",
          "contentSnippet": "机器之心报道\n编辑：蛋酱、+0\n\n\n\n\n\n刚刚，斯坦福大学正式发布了《2025 AI Index》报告。\n\n\n在过去的一段时间里，人工智能领域经历了一场蓬勃的发展，但与此同时，也有人说「人工智能是一个泡沫」。其他的讨论话题包括但不限于：人工智能的现有技术和架构将不断取得突破；人工智能走在一条不可持续的道路上；人工智能将取代你的工作；人工智能最擅长的就是把你的家庭照片变成吉卜力工作室风格的动画图像……\n\n\n每一年的斯坦福 AI Index 报告都会对领域的发展进行系统的梳理，今年也是如此。《2025 AI Index》报告总共 400 多页，涵盖了研发、技术性能、负责任的人工智能、经济影响、科学和医学、政策、教育和公众舆论等主题的图表和数据。\n\n\n\n报告地址：https://hai.stanford.edu/ai-index/2025-ai-index-report\n\n\n目录如下：\n\n\n\n除了谷歌、OpenAI 之外，中国公司 DeepSeek 也成为报告关注的焦点，在 PDF 全文中被提到了 45 次。\n\n\n关于今年 AI Index 报告的核心内容，我们通过 12 张图片来了解：\n\n\n美国公司的遥遥领先\n\n\n\n虽然衡量国家在人工智能竞赛中「领先」的方式多种多样（如期刊文章发表或引用数量、专利授权等），但一个直观的评估指标是观察哪些国家发布了具有影响力的模型。研究机构 Epoch AI 拥有一个从 1950 年至今的重要人工智能模型数据库，AI Index 从中提取了相关数据进行分析。\n\n\n数据显示，去年美国发布了 40 个知名模型，中国发布了 15 个，欧洲仅有 3 个（均来自法国）。另有数据表明，2024 年发布的这些模型几乎全部来自产业界，而非学术界或政府部门。关于 2023 年至 2024 年知名模型发布数量减少的现象，AI Index 认为可能是由于技术复杂度提高和训练成本持续攀升所致。\n\n\n说到训练成本……\n\n\n\n在这方面，AI Index 缺乏精确数据，因为许多领先的人工智能公司已停止公开其训练过程信息。斯坦福研究人员与 Epoch AI 合作，基于训练时长、硬件类型和数量等详细信息，估算了部分模型的成本。在可评估的模型中，最昂贵的是谷歌的 Gemini 1.0 Ultra，训练成本约达 1.92 亿美元。训练成本的全面上涨与报告中的其他发现相符：模型在参数数量、训练时间和训练数据量等方面持续规模化扩张。\n\n\n值得注意的是，DeepSeek 并未包含在这一分析中。这家公司在 2025 年 1 月声称仅用 600 万美元训练出了 DeepSeek-R1，引发金融市场震动，虽然部分行业专家对此说法持怀疑态度。\n\n\nAI Index 指导委员会联合主任 Yolanda Gil 在接受 IEEE Spectrum 采访时表示，她认为 DeepSeek「非常令人印象深刻」，并指出计算机科学历史上充满了早期低效技术被更优雅解决方案取代的案例。她补充道：「我不是唯一一个相信某个时点会出现更高效版本大语言模型的人。我们只是不知道谁会构建它以及如何构建。」\n\n\n使用人工智能的成本正在下降\n\n\n\n尽管大多数 AI 模型的训练成本持续攀升，但报告中强调了几个积极趋势：硬件成本降低、硬件性能提升及能源效率提高。\n\n\n这使得推理成本（即查询已训练模型的费用）正在急剧下降。这张使用对数比例的图表展示了 AI 性能每美元的发展趋势。报告指出，蓝线表明每百万 tokens 的成本从 20 美元降至 0.07 美元；粉线则显示在不到一年时间内，成本从 15 美元降至 0.12 美元。\n\n\n人工智能的显著碳足迹\n\n\n\n虽然能源效率提高是一个积极的趋势，但存在一个不容忽视的问题：尽管效率有所提升，整体能耗仍在增长，这意味着处于人工智能热潮中心的数据中心留下了巨大的碳足迹。AI Index 基于训练硬件、云服务提供商和地理位置等因素，估算了特定 AI 模型的碳排放，发现前沿人工智能模型的训练碳排放量呈稳步增长趋势 —— 其中 DeepSeek 模型是个例外。\n\n\n数据显示，最大的排放源是 Meta 的 Llama 3.1 模型，估计产生了 8930 吨二氧化碳排放，相当于约 496 个美国人一年的生活碳排放量。这一显著的环境影响解释了为何人工智能公司正积极采用核能作为可靠的零碳能源来源。\n\n\n人工智能模型性能差距持续缩小\n\n\n\n美国在已发布的知名模型数量上仍然保持领先地位，但中国模型在质量方面正在迅速赶上。数据显示，在聊天机器人基准测试上的性能差距正在不断缩小。2024 年 1 月，顶尖美国模型的表现比最优中国模型高出 9.26%；到 2025 年 2 月，这一差距已缩小至仅 1.70%。报告在推理、数学和编程等其他基准测试中也发现了类似趋势。\n\n\n人类最后的考试\n\n\n\n今年的报告指出了一个不可忽视的事实：用于评估人工智能系统能力的众多基准测试已经「饱和」—— 人工智能系统在这些测试上获得的分数如此之高，以至于它们不再具有区分价值。这种现象已在多个领域出现：通用知识、图像推理、数学、编程等。\n\n\nGil 表示，她惊讶地目睹一个又一个基准测试逐渐失去参考意义。她指出：「我一直认为性能会趋于平稳，会达到一个需要新技术或根本不同架构才能继续取得进展的临界点。但事实并非如此。」\n\n\n面对这种局面，执着的研究人员不断设计新的基准测试，以期挑战人工智能系统。其中一项是「人类的最后考试」，它由来自全球 500 个机构的专业领域专家贡献的极具挑战性问题组成。到目前为止，即使对最顶尖的人工智能系统而言，这项测试仍然难以攻克：OpenAI 的推理模型 o1 目前以 8.8% 的正确答案率位居榜首。业界正密切关注这种局面能持续多久。\n\n\n公共数据面临的威胁\n\n\n\n当今生成式 AI 系统通过训练海量从互联网抓取的数据获得智能，这导致了一个经常被提及的观点：「数据是 AI 经济的新石油」。随着人工智能公司不断挑战可输入模型的数据量极限，业界开始担忧「数据峰值」问题，以及何时会耗尽这种关键资源。一个问题是，越来越多的网站正在限制机器人爬取并抓取其数据（可能是因为担忧人工智能公司从其数据中获利，同时破坏其商业模式）。网站通过机器可读的 robots.txt 文件声明这些限制。\n\n\n数据显示，顶级网络域名中 48% 的数据现已被完全限制访问。然而，Gil 指出，人工智能领域可能会出现新方法，终结对庞大数据集的依赖。她认为：「预计在某些时候，数据量将不再如此关键。」\n\n\n企业资金持续涌入人工智能领域\n\n\n\n过去五年，企业界已为人工智能投资敞开了资金闸门。虽然 2024 年的全球总体投资未能达到 2021 年的疯狂高峰，但值得注意的是，私人投资规模达到了前所未有的水平。在 2024 年 1500 亿美元的私人投资中，相关指数的另一项数据表明，约 330 亿美元流向了生成式 AI 领域。\n\n\n企业等待人工智能投资的巨大回报\n\n\n\n理论上，企业投资人工智能是因为期望获得可观的投资回报。在这个话题上，人们常以激昂语气讨论人工智能的变革性本质和前所未有的生产力提升。然而，企业尚未见到能带来显著成本节省或实质性新收益的转变。\n\n\n麦肯锡调查数据显示，在报告成本降低的企业中，大多数节省幅度不足 10%；在因人工智能获得收入增长的企业中，大多数报告的增长幅度不到 5%。巨大的回报可能仍在路上，从投资数据来看，众多企业正在押注于此，但目前尚未实现。\n\n\nAI 医生或将很快接诊\n\n\n\n科学与医疗领域的人工智能应用是人工智能浪潮中的一个重要分支。报告列举了多个新发布的基础模型，这些模型旨在协助材料科学、天气预报和量子计算等领域的研究人员。众多公司正尝试将人工智能的预测和生成能力转化为盈利性药物研发。OpenAI 的 o1 推理模型最近在医学执照考试问题集 MedQA 的基准测试中取得了 96% 的得分。\n\n\n然而，这似乎仍是一个潜力巨大但尚未转化为显著实际影响的领域 —— 部分原因可能是人类尚未完全掌握如何有效使用这项技术。2024 年的一项研究测试了医生在使用 GPT-4 作为常规资源补充时是否能做出更准确的诊断。结果表明，这既未提高诊断准确性，也未加快诊断速度。值得注意的是，单独使用的 GPT-4 表现却优于人机团队和单独的人类医生。\n\n\n美国的人工智能政策行动转向州级层面\n\n\n\n这张图表显示，美国国会虽有大量关于人工智能的讨论，但实际行动寥寥无几。报告指出，美国的政策制定已转移至州级层面，2024 年共有 131 项法案在各州获得通过。其中 56 项与深度伪造（deepfake）相关，禁止在选举中使用深度伪造技术或借此传播未经同意的私密图像。\n\n\n美国之外，欧洲已通过《人工智能法案》（AI Act），该法案要求开发被认定为高风险的人工智能系统的公司承担新的责任义务。然而，全球主要趋势是各国联合发表关于人工智能应在世界上扮演何种角色的全面但无约束力的声明。因此，实质性监管行动相对有限，而讨论却十分广泛。\n\n\n人类是乐观主义者\n\n\n\n无论你是股票摄影师、营销经理还是卡车司机，关于人工智能是否以及何时会取代你的工作，社会上已有广泛讨论。然而，最近一项关于人工智能态度的全球调查显示，大多数人并不感到受到人工智能的威胁。\n\n\n来自 32 个国家的 60% 受访者认为人工智能将改变他们的工作方式，但仅有 36% 的人预期会被替代。「这些调查结果确实让我感到惊讶，」Gil 表示，「人们认为『人工智能将改变我的工作，但我仍将创造价值』，这种观点非常令人鼓舞。」让我们拭目以待，看看我们能否都通过管理人工智能团队来持续创造价值。\n\n\n更多细节，可参考报告原文。\n\n\n\n\n\n© THE END \n转载请联系本公众号获得授权\n投稿或寻求报道：liyazhou@jiqizhixin.com\n\n\n    \n\n    \n    \n文章原文",
          "guid": "http://www.jintiankansha.me/t/GaNPqOtUez",
          "categories": [
            "无"
          ],
          "isoDate": "2025-04-08T04:48:00.000Z"
        }
      }
    ],
    "机器之心2": [
      {
        "json": {
          "title": "颠覆传统信息搜索，效果是之前SOTA的三倍？UIUC韩家炜、孙冀萌团队开源DeepRetrieval，让模型端到端地学会搜索！",
          "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650963731&idx=4&sn=28f1d2a68c5b9f23f435f7aa66335473&chksm=8593ba76d088c1c15fa73b18bb65dd1a3248edc9f61f7ff321f751bebb6b8a4ad40e1d126749&scene=0#rd",
          "pubDate": "Tue, 08 Apr 2025 12:48:00 +0800",
          "enclosure": {
            "url": "http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXNUMFw5WKdZ2wK23QFWTia30IKE9E7p9aj8Za1nX2493SObukR3YsrYQ/0?wx_fmt=jpeg",
            "length": "0",
            "type": "image/jpeg"
          },
          "content": "\n\n    \n\n    \n\n    \n         <div class=\"rich_media_content\" id=\"js_content\"><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><img alt=\"图片\" class=\"rich_pages wxw-img\" data-ratio=\"0.5703703703703704\" data-w=\"1080\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic4qxCCBDwsURwYQxQzqtnNcfgBE6kDVeb9ib93vNCvo6N7OCH5mhZ91Qq3LFH2n8ku4sfbWdBA6iag/640?wx_fmt=png&amp;from=appmsg&amp;tp=wxpic&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1\" style=\"max-width: 600px\"></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">在信息检索系统中，搜索引擎的能力只是影响结果的一个方面，</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">真正的瓶颈往往在于：用户的原始 query 本身不够好</span><span textstyle=\"\" style=\"font-size: 15px;\">。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">尤其在专业搜索场景（如文献、数据库查询）中，用户往往无法用精确、完整的表达描述他们的需求。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">那么问题来了：</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">能不能教大模型优化原始 query 的表达方式，从而让已有检索系统的能力被最大化激发？</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">来自 UIUC 的 Jiawei Han 和 Jimeng Sun 团队的一项最新工作 </span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">DeepRetrieval </span><span textstyle=\"\" style=\"font-size: 15px;\">就是针对这个问题提出了系统性解法，只需 </span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">3B 的 LLM </span><span textstyle=\"\" style=\"font-size: 15px;\">即可实现 50 个点以上的提升。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.29259259259259257\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503479539\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXBspLlhjWN6Dhlboydic2Vy2BQSKmyse7OVXbKibFzKRXkwkW240PSmNQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li style=\"color: rgb(123, 12, 0);font-size: 15px;\"><section style=\"text-align: left;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: normal;\">论文标题：</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: normal;\">DeepRetrieval: Hacking Real Search Engines and Retrievers with Large Language Models via Reinforcement Learning</span></span></section></li><li style=\"color: rgb(123, 12, 0);\"><section style=\"text-align: left;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);font-weight: normal;\">论文地址：https://arxiv.org/pdf/2503.00223</span></span></section></li><li style=\"color: rgb(123, 12, 0);\"><section style=\"text-align: left;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);font-weight: normal;\">开源代码：https://github.com/pat-jj/DeepRetrieval</span></span></section></li><li style=\"color: rgb(123, 12, 0);\"><p style=\"padding: 0pt;text-align: left;line-height: 1.75em;\"><span style=\"font-family: Arial;color: rgb(255, 0, 0);font-size: 11pt;\"><font face=\"微软雅黑\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);font-weight: normal;text-decoration: none;\">开源模型：</span></span></font></span><span style=\"font-family: Arial;color: rgb(255, 0, 0);\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);font-weight: normal;text-decoration: none;\">https://huggingface.co/DeepRetrieval</span></span></span><span style=\"font-family: Arial;color: rgb(255, 0, 0);font-size: 11pt;\"><p></p></span></p><section style=\"text-align: left;line-height: 1.75em;\"><span leaf=\"\"><br></span></section></li></ul><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">一句话概括</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">：</span><span textstyle=\"\" style=\"font-size: 15px;\">DeepRetrieval 是一个基于强化学习（RL）的 query 优化系统，训练 LLM 在不同检索任务中优化原始查询，以最大化真实系统的检索效果。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">它不是训练一个新的 retriever，也不是让模型直接回答问题，而是：</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">在不改变现有搜索系统的前提下，通过优化原始 query，让「提问方式」变得更聪明，从而获取更好的结果。</span></span><span leaf=\"\"><br></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">更多有意义的讨论请读原文正文和附录的 Discussion 部分。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.537962962962963\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503479540\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXCBLibudFoia00WzQat7q3SFAH1NtZ9GcqgLEdoh8BbdXWZibJia7sJljoA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">方法细节</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5046296296296297\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503479541\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXecAuVNUgm8icOtOV9rBMuPl3tFhicw3Lp3MBUK6copqcL4GkUhicsw2Kg/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">方法要点</span></span></section><section><span leaf=\"\"><br></span></section><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li style=\"font-size: 15px;\"><section style=\"text-align: justify;line-height: 1.75em;\"><span leaf=\"\" style=\"text-align: justify;\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">输入</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">：原始查询 q</span></span></section></li><li style=\"font-size: 15px;\"><section style=\"text-align: justify;line-height: 1.75em;\"><span leaf=\"\" style=\"text-align: justify;\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">输出</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">：改写后的查询 q′（自然语言、布尔表达式或 SQL）</span></span></section></li><li style=\"font-size: 15px;\"><section style=\"text-align: justify;line-height: 1.75em;\"><span leaf=\"\" style=\"text-align: justify;\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">环境反馈</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">：使用 q′ 去检索系统中查询 → 返回结果 → 与 groundtruth 对比，计算 reward，reward 为 task-specific 检索表现（如 Recall@K、NDCG@K、SQL accuracy）使用 PPO 进行训练，并加入格式奖励（format correctness）与 KL-regularization 保证训练稳定，优化目标如下：</span></span></section></li></ul><section><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.14432989690721648\" data-s=\"300,640\" data-type=\"png\" data-w=\"485\" type=\"block\" data-imgfileid=\"503479542\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJX28KVkdOuDZOunZOQ1wa1D05tsO6ATdTJcGTk3n28GWV9xkq4fgNTEA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">其中，π_ref 是参考策略（reference policy），通常指的是</span></span><span leaf=\"\" style=\"text-align: justify;\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">在强化学习开始之前的初始模型</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">。β 是一个合适的 KL 惩罚系数，用于</span></span><span leaf=\"\" style=\"text-align: justify;\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">控制正则化的强度</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">。KL 散度项的作用是</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">惩罚当前策略与参考策略之间的过大偏离</span><span textstyle=\"\" style=\"font-size: 15px;\">，从而在强化学习训练过程中</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">保证策略更新的稳定性</span><span textstyle=\"\" style=\"font-size: 15px;\">。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">实验结果</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">真实搜索引擎的文献搜索</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.7175925925925926\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503479544\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXxd9EbD2Iu4qmHbBLmJLx4jseH059z3bDMM79CzEwZe5bk7YNtJCr1Q/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span data-pm-slice=\"0 0 []\"><span leaf=\"\" style=\"text-align: justify;\"><span textstyle=\"\" style=\"font-size: 15px;\">首先在真实的搜索引擎上进行实验，文中用到了专业搜索引擎 PubMed 和 ClinicalTrials.gov。无需改动搜索引擎或其它任何检索器，仅通过端到端地优化 query 表达，DeepRetrieval 就可以让结果获得 10 倍提升，远超各个商业大模型和之前的 SO</span></span><span leaf=\"\" style=\"text-align: justify;\"><span textstyle=\"\" style=\"font-size: 15px;\">TA 方法 LEADS（蒸馏 + SFT 方法）。</span></span></span><span style=\"font-family: Arial;color: rgb(0, 0, 0);font-size: 11pt;\"><p></p></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">Evidence-Seeking 检索：通用搜索引擎的革新潜力</span></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></section><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">DeepRetrieval 在 Evidence-Seeking 检索任务上的优异表现令人瞩目。如表 1 所示，结合简单 BM25，这个仅有 3B 参数的模型在 SQuAD、TriviaQA 和 NQ 数据集上超越了 GPT-4o 和 Claude-3.5 等大型商业模型。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">Evidence-Seeking 任务的核心是找到支持特定事实性问题答案的确切文档证据，在通用搜索引擎环境中，这一能力尤为关键。作者团队指出，将 DeepRetrieval 应用到 Google、Bing 等通用搜索引擎的 Evidence-Seeking 场景将带来显著优势：</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li><p style=\"text-align: justify;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">精准定位事实文档：</span><span textstyle=\"\" style=\"font-size: 15px;\">通用搜索引擎包含海量信息，用户难以构建能精确定位证据段落的查询。DeepRetrieval 可将简单问题转化为包含关键术语、同义词和限定符的复杂查询，显著提高找到权威证据的概率。</span></span></p></li></ul><p style=\"text-align:justify;margin-left:8px;margin-right:8px;line-height:1.75em;\"><span leaf=\"\"><br></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li><p style=\"text-align: justify;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">克服知识时效性限制：</span><span textstyle=\"\" style=\"font-size: 15px;\">模型能够将「2024 年奥运会金牌榜前三名」等超出 LLM 知识截止日期的问题转化为精确搜索表达，使检索系统能够找到最新事实证据。</span></span></p></li></ul><p style=\"text-align:justify;margin-left:8px;margin-right:8px;line-height:1.75em;\"><span leaf=\"\"><br></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li><p style=\"text-align: justify;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">多源验证能力：</span><span textstyle=\"\" style=\"font-size: 15px;\">通过优化查询帮助搜索引擎找到多个独立来源的事实证据，从而交叉验证信息准确性，这是纯 LLM 问答无法实现的关键优势。</span></span></p></li></ul><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">作者团队表示会将这部分的延伸作为 DeepRetrieval </span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">未来主要的探索方向之一</span><span textstyle=\"\" style=\"font-size: 15px;\">。</span></span></p><p><span leaf=\"\"><br></span></p><section style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">Classic IR（Sparse / Dense）</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5462962962962963\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503479545\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXia8iaXYBqCS7H8cdxteJM8wX7INncMibWO9UnrDh6ebPFOmlkpHVBxtwA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">在 BM25 和 dense retriever 下，DeepRetrieval 提供了平均 5~10 点 NDCG 提升，并且：</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">BM25 + DeepRetrieval 和多数 dense baseline 水平相当</span><span textstyle=\"\" style=\"font-size: 15px;\">。</span></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">结合极快的检索速度（BM25 vs dense：352s vs 12,232s），展示了一个现实可部署、性能不俗的高效方案。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">SQL 检索任务</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">在 SQL 检索任务中，DeepRetrieval 摆脱了对 groundtruth SQL 的依赖，直接利用生成 SQL 的执行成功率优化模型，通过生成更精准的 SQL 语句，使得模型在 Spider、BIRD 等数据集上的执行正确率均超过对比模型（包括 GPT-4o 和基于 SFT 的大模型）。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"2.0232558139534884\" data-s=\"300,640\" data-type=\"png\" data-w=\"688\" type=\"block\" data-imgfileid=\"503479546\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJX7dIvL7e2KGSebJUG4XtkuHafTsYt3R2B47Ricj40RgEcD20blfQribew/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><p style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">探索胜于模仿：RL 为何超越 SFT</span></span></p><p style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">DeepRetrieval 的实验揭示了强化学习（RL）在搜索优化上相比监督微调（SFT）的独特优势。实验数据令人信服：在文献搜索上，RL 方法的 DeepRetrieval（65.07%）超过 SFT 方法 LEADS（24.68%）近三倍；在 SQL 任务上，从零开始的 RL 训练（无需任何 gold SQL 语句的监督）也优于使用 GPT-4o 蒸馏数据的 SFT 模型。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">这种显著差异源于两种方法的本质区别：SFT 是「模仿学习」，试图复制参考查询，而 RL 是「直接优化」，通过环境反馈学习最优查询策略。SFT 方法的局限在于参考查询本身可能不是最优的，即使是人类专家或大模型也难以直观设计出最适合特定搜索引擎的查询表达。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">论文中的案例分析进一步证实了这一点。例如，在 PubMed 搜索中，DeepRetrieval 生成的查询如「((DDAVP) AND (Perioperative Procedures OR Blood Transfusion OR Desmopressin OR Anticoagulant)) AND (Randomized Controlled Trial)」融合了医学领域的专业术语和 PubMed 搜索引擎偏好的布尔结构，这种组合很难通过简单模仿预定义的查询模板获得。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">相反，RL 允许模型通过尝试与错误来探索查询空间，发现人类甚至未考虑的有效模式，并直接针对最终目标（如 Recall 或执行准确率）进行优化。这使 DeepRetrieval 能够生成高度适合特定搜索引擎特性的查询，适应不同检索环境的独特需求。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">这一发现具有重要启示：在追求最佳检索性能时，让模型通过反馈学习如何与检索系统「对话」，比简单模仿既定模式更为有效，这也解释了为何参数量较小的 DeepRetrieval 能在多项任务上超越拥有更多参数的商业模型。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">模型 Think&amp;Query 长度分析</span></span></p><p style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-imgfileid=\"503479991\" data-ratio=\"2.541471048513302\" data-s=\"300,640\" data-type=\"png\" data-w=\"639\" type=\"block\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8apWjQibSDGflicVKV7CAsLLjiaQhPuem4SZ9FNO1fwz7OncZH9pEmcbfnS5LqYLuAyx5PdAVjJZjibA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">通过分析 DeepRetrieval 在训练过程中模型思考链和查询长度的变化，可以发现以下</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">关键洞见</span><span textstyle=\"\" style=\"font-size: 15px;\">：</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">思考链长度演变</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">与「aha moment」相反</span><span textstyle=\"\" style=\"font-size: 15px;\">，DeepRetrieval 的思考链长度随训练呈</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">下降趋势</span><span textstyle=\"\" style=\"font-size: 15px;\">，而非增长。这与 DeepSeek-R1 报告的「aha moment」现象形成鲜明对比，后者的思考链会随训练进展变得更长。图 4(a) 清晰地展示了 Qwen 模型思考链从初始约 150 tokens 逐渐降至稳定的 50 tokens 左右，而 Llama 模型的思考链更短，甚至降至接近 25 tokens。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">查询长度特征</span></span></p><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">实验揭示了思考过程对查询长度的显著影响。</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">无思考过程的模型容易陷入次优解</span><span textstyle=\"\" style=\"font-size: 15px;\">，如图 4(b) 所示，Qwen 无思考版本生成极长查询（500-600 tokens），表现出过度扩展的倾向。相比之下，有思考过程的模型保持更为适中的查询长度，Qwen 约 150 tokens，Llama 约 100 tokens。有趣的是，不同模型采用不同长度策略，但能达到相似性能，表明查询生成存在多样有效路径。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">性能与思考过程关系</span></span></p><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">思考过程对检索性能有决定性影响。图 4(c) 表明，</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">具备思考能力的模型性能显著提升</span><span textstyle=\"\" style=\"font-size: 15px;\">，有思考的模型 Recall@3K 能达到 65%，而无思考模型仅 50% 左右。此外，</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">训练效率也明显提高</span><span textstyle=\"\" style=\"font-size: 15px;\">，有思考的模型更快达到高性能并保持稳定。论文附录 D.1 的分析表明，思考过程帮助模型避免简单地通过增加查询长度和重复术语来提升性能，而是引导模型学习更有效的语义组织策略。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;font-weight: bold;\">关键结论</span></span></p><p style=\"text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">DeepRetrieval 展示了思考过程在信息检索中扮演「探索促进器」</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">的关键角色。与数学或编程问题不同，检索任务不需要像「aha moment」那样的突然顿悟现象。相反，检索优化遵循</span><span textstyle=\"\" style=\"font-size: 15px;\">「先详细思考，后逐渐精简」</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">的模式，模型在内化有效策略后，不再需要冗长思考。这表明</span><span textstyle=\"\" style=\"font-size: 15px;\">检索任务中思考链的主要功能是探索，一旦策略稳定便可简化。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">这种分析表明，适当的思考过程设计对于构建高效的检索优化系统至关重要，能够在不增加模型参数的情况下显著提升性能，为未来的 LLM 应用于搜索任务提供了重要设计思路。</span></span></p><p style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">结论</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">DeepRetrieval 的贡献在于揭示了一个常被忽视但至关重要的事实：</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">检索效果的上限不仅在于检索器本身，更在于如何「提问」</span><span textstyle=\"\" style=\"font-size: 15px;\">。</span></span></section><section><span leaf=\"\"><br></span></section><section style=\"text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">通过强化学习教 LLM 改写原始查询，DeepRetrieval 不仅摆脱了对人工标注数据和大模型蒸馏的依赖，还在多个任务上证明了改写 query 的巨大潜力。这项工作为搜索与信息检索领域带来了新的思考：未来的检索优化，不仅是提升引擎算法，更是如何让用户「问得更好」，从而激发出检索系统的全部潜力。</span></span></section><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" style=\"margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb auto center><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif><span leaf=\"\"><br></span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" style=\"margin: 5px 8px 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb auto center><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;\">© THE END </span></span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" style=\"margin: 5px 8px 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb auto center><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"outline: 0px;font-size: 12px;color: rgb(136, 136, 136);\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;\">转载请联系本公众号获得授权</span></span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" style=\"margin: 5px 8px 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb auto center><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"outline: 0px;font-size: 12px;color: rgb(136, 136, 136);\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;\">投稿或寻求报道：liyazhou@jiqizhixin.com</span></span></span></p><p style=\"display: none;\"><mp-style-type data-value=\"10000\"></mp-style-type></p></div>\n    \n\n    \n    <br>\n\n    \n        <a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963731&amp;idx=4&amp;sn=28f1d2a68c5b9f23f435f7aa66335473&amp;chksm=8593ba76d088c1c15fa73b18bb65dd1a3248edc9f61f7ff321f751bebb6b8a4ad40e1d126749&amp;scene=0#rd\" style=\"color: blue\" class=\"media_tool_meta meta_primary\">文章原文</a>\n        <br>\n    \n\n    \n\n    <img alt=\"\" width=\"1px\" height=\"1px\" class=\"\" style=\"width:1px;height:1px;display:none\" src=\"http://www.jintiankansha.me/rss_static/4365/mh3IOHrP5I\">\n\n",
          "contentSnippet": "在信息检索系统中，搜索引擎的能力只是影响结果的一个方面，真正的瓶颈往往在于：用户的原始 query 本身不够好。\n\n\n尤其在专业搜索场景（如文献、数据库查询）中，用户往往无法用精确、完整的表达描述他们的需求。\n\n\n那么问题来了：能不能教大模型优化原始 query 的表达方式，从而让已有检索系统的能力被最大化激发？\n\n\n来自 UIUC 的 Jiawei Han 和 Jimeng Sun 团队的一项最新工作 DeepRetrieval 就是针对这个问题提出了系统性解法，只需 3B 的 LLM 即可实现 50 个点以上的提升。\n\n\n\n\n\n\n论文标题：DeepRetrieval: Hacking Real Search Engines and Retrievers with Large Language Models via Reinforcement Learning\n\n论文地址：https://arxiv.org/pdf/2503.00223\n\n开源代码：https://github.com/pat-jj/DeepRetrieval\n\n开源模型：https://huggingface.co/DeepRetrieval\n\n\n\n\n一句话概括：DeepRetrieval 是一个基于强化学习（RL）的 query 优化系统，训练 LLM 在不同检索任务中优化原始查询，以最大化真实系统的检索效果。\n\n\n它不是训练一个新的 retriever，也不是让模型直接回答问题，而是：\n\n\n在不改变现有搜索系统的前提下，通过优化原始 query，让「提问方式」变得更聪明，从而获取更好的结果。\n\n\n\n更多有意义的讨论请读原文正文和附录的 Discussion 部分。\n\n\n\n\n\n方法细节\n\n\n\n\n\n方法要点\n\n\n\n输入：原始查询 q\n\n输出：改写后的查询 q′（自然语言、布尔表达式或 SQL）\n\n环境反馈：使用 q′ 去检索系统中查询 → 返回结果 → 与 groundtruth 对比，计算 reward，reward 为 task-specific 检索表现（如 Recall@K、NDCG@K、SQL accuracy）使用 PPO 进行训练，并加入格式奖励（format correctness）与 KL-regularization 保证训练稳定，优化目标如下：\n\n\n\n\n\n\n其中，π_ref 是参考策略（reference policy），通常指的是在强化学习开始之前的初始模型。β 是一个合适的 KL 惩罚系数，用于控制正则化的强度。KL 散度项的作用是惩罚当前策略与参考策略之间的过大偏离，从而在强化学习训练过程中保证策略更新的稳定性。\n\n\n实验结果\n\n\n真实搜索引擎的文献搜索\n\n\n\n\n\n首先在真实的搜索引擎上进行实验，文中用到了专业搜索引擎 PubMed 和 ClinicalTrials.gov。无需改动搜索引擎或其它任何检索器，仅通过端到端地优化 query 表达，DeepRetrieval 就可以让结果获得 10 倍提升，远超各个商业大模型和之前的 SOTA 方法 LEADS（蒸馏 + SFT 方法）。\n\n\n\nEvidence-Seeking 检索：通用搜索引擎的革新潜力\n\n\nDeepRetrieval 在 Evidence-Seeking 检索任务上的优异表现令人瞩目。如表 1 所示，结合简单 BM25，这个仅有 3B 参数的模型在 SQuAD、TriviaQA 和 NQ 数据集上超越了 GPT-4o 和 Claude-3.5 等大型商业模型。\n\n\nEvidence-Seeking 任务的核心是找到支持特定事实性问题答案的确切文档证据，在通用搜索引擎环境中，这一能力尤为关键。作者团队指出，将 DeepRetrieval 应用到 Google、Bing 等通用搜索引擎的 Evidence-Seeking 场景将带来显著优势：\n\n\n\n精准定位事实文档：通用搜索引擎包含海量信息，用户难以构建能精确定位证据段落的查询。DeepRetrieval 可将简单问题转化为包含关键术语、同义词和限定符的复杂查询，显著提高找到权威证据的概率。\n\n\n\n\n克服知识时效性限制：模型能够将「2024 年奥运会金牌榜前三名」等超出 LLM 知识截止日期的问题转化为精确搜索表达，使检索系统能够找到最新事实证据。\n\n\n\n\n多源验证能力：通过优化查询帮助搜索引擎找到多个独立来源的事实证据，从而交叉验证信息准确性，这是纯 LLM 问答无法实现的关键优势。\n\n\n\n作者团队表示会将这部分的延伸作为 DeepRetrieval 未来主要的探索方向之一。\n\n\nClassic IR（Sparse / Dense）\n\n\n\n\n\n在 BM25 和 dense retriever 下，DeepRetrieval 提供了平均 5~10 点 NDCG 提升，并且：BM25 + DeepRetrieval 和多数 dense baseline 水平相当。\n\n\n结合极快的检索速度（BM25 vs dense：352s vs 12,232s），展示了一个现实可部署、性能不俗的高效方案。\n\n\nSQL 检索任务\n\n\n在 SQL 检索任务中，DeepRetrieval 摆脱了对 groundtruth SQL 的依赖，直接利用生成 SQL 的执行成功率优化模型，通过生成更精准的 SQL 语句，使得模型在 Spider、BIRD 等数据集上的执行正确率均超过对比模型（包括 GPT-4o 和基于 SFT 的大模型）。\n\n\n\n\n\n探索胜于模仿：RL 为何超越 SFT\n\n\nDeepRetrieval 的实验揭示了强化学习（RL）在搜索优化上相比监督微调（SFT）的独特优势。实验数据令人信服：在文献搜索上，RL 方法的 DeepRetrieval（65.07%）超过 SFT 方法 LEADS（24.68%）近三倍；在 SQL 任务上，从零开始的 RL 训练（无需任何 gold SQL 语句的监督）也优于使用 GPT-4o 蒸馏数据的 SFT 模型。\n\n\n这种显著差异源于两种方法的本质区别：SFT 是「模仿学习」，试图复制参考查询，而 RL 是「直接优化」，通过环境反馈学习最优查询策略。SFT 方法的局限在于参考查询本身可能不是最优的，即使是人类专家或大模型也难以直观设计出最适合特定搜索引擎的查询表达。\n\n\n论文中的案例分析进一步证实了这一点。例如，在 PubMed 搜索中，DeepRetrieval 生成的查询如「((DDAVP) AND (Perioperative Procedures OR Blood Transfusion OR Desmopressin OR Anticoagulant)) AND (Randomized Controlled Trial)」融合了医学领域的专业术语和 PubMed 搜索引擎偏好的布尔结构，这种组合很难通过简单模仿预定义的查询模板获得。\n\n\n相反，RL 允许模型通过尝试与错误来探索查询空间，发现人类甚至未考虑的有效模式，并直接针对最终目标（如 Recall 或执行准确率）进行优化。这使 DeepRetrieval 能够生成高度适合特定搜索引擎特性的查询，适应不同检索环境的独特需求。\n\n\n这一发现具有重要启示：在追求最佳检索性能时，让模型通过反馈学习如何与检索系统「对话」，比简单模仿既定模式更为有效，这也解释了为何参数量较小的 DeepRetrieval 能在多项任务上超越拥有更多参数的商业模型。\n\n\n模型 Think&Query 长度分析\n\n\n\n\n\n通过分析 DeepRetrieval 在训练过程中模型思考链和查询长度的变化，可以发现以下关键洞见：\n\n\n思考链长度演变\n\n\n与「aha moment」相反，DeepRetrieval 的思考链长度随训练呈下降趋势，而非增长。这与 DeepSeek-R1 报告的「aha moment」现象形成鲜明对比，后者的思考链会随训练进展变得更长。图 4(a) 清晰地展示了 Qwen 模型思考链从初始约 150 tokens 逐渐降至稳定的 50 tokens 左右，而 Llama 模型的思考链更短，甚至降至接近 25 tokens。\n\n\n查询长度特征\n\n\n实验揭示了思考过程对查询长度的显著影响。无思考过程的模型容易陷入次优解，如图 4(b) 所示，Qwen 无思考版本生成极长查询（500-600 tokens），表现出过度扩展的倾向。相比之下，有思考过程的模型保持更为适中的查询长度，Qwen 约 150 tokens，Llama 约 100 tokens。有趣的是，不同模型采用不同长度策略，但能达到相似性能，表明查询生成存在多样有效路径。\n\n\n性能与思考过程关系\n\n\n思考过程对检索性能有决定性影响。图 4(c) 表明，具备思考能力的模型性能显著提升，有思考的模型 Recall@3K 能达到 65%，而无思考模型仅 50% 左右。此外，训练效率也明显提高，有思考的模型更快达到高性能并保持稳定。论文附录 D.1 的分析表明，思考过程帮助模型避免简单地通过增加查询长度和重复术语来提升性能，而是引导模型学习更有效的语义组织策略。\n\n\n关键结论\n\n\nDeepRetrieval 展示了思考过程在信息检索中扮演「探索促进器」的关键角色。与数学或编程问题不同，检索任务不需要像「aha moment」那样的突然顿悟现象。相反，检索优化遵循「先详细思考，后逐渐精简」的模式，模型在内化有效策略后，不再需要冗长思考。这表明检索任务中思考链的主要功能是探索，一旦策略稳定便可简化。\n\n\n这种分析表明，适当的思考过程设计对于构建高效的检索优化系统至关重要，能够在不增加模型参数的情况下显著提升性能，为未来的 LLM 应用于搜索任务提供了重要设计思路。\n\n\n结论\n\n\nDeepRetrieval 的贡献在于揭示了一个常被忽视但至关重要的事实：检索效果的上限不仅在于检索器本身，更在于如何「提问」。\n\n\n通过强化学习教 LLM 改写原始查询，DeepRetrieval 不仅摆脱了对人工标注数据和大模型蒸馏的依赖，还在多个任务上证明了改写 query 的巨大潜力。这项工作为搜索与信息检索领域带来了新的思考：未来的检索优化，不仅是提升引擎算法，更是如何让用户「问得更好」，从而激发出检索系统的全部潜力。\n\n\n© THE END \n转载请联系本公众号获得授权\n投稿或寻求报道：liyazhou@jiqizhixin.com\n\n\n    \n\n    \n    \n文章原文",
          "guid": "http://www.jintiankansha.me/t/mh3IOHrP5I",
          "categories": [
            "无"
          ],
          "isoDate": "2025-04-08T04:48:00.000Z"
        }
      },
      {
        "json": {
          "title": "类R1强化学习迁移到视觉定位！全开源Vision-R1将图文大模型性能提升50％",
          "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650963731&idx=3&sn=7c62398a729785a7d02da7b9d47fab3a&chksm=8525221905860a7ee31228d160e4f9c43b94d60c8acde57393a69b9a129332cc7c29446bba77&scene=0#rd",
          "pubDate": "Tue, 08 Apr 2025 12:48:00 +0800",
          "enclosure": {
            "url": "http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vX2GR4SOzMayrnjia6a0Op2Ec4BvGASYZanMpyJQL3OzdhLn6wjibgCyg/0?wx_fmt=jpeg",
            "length": "0",
            "type": "image/jpeg"
          },
          "content": "\n\n    \n\n    \n\n    \n         <div class=\"rich_media_content\" id=\"js_content\"><section style=\"text-align: center;margin: 0px 8px;line-height: 1.75em;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5703125\" data-s=\"300,640\" data-type=\"png\" data-w=\"1280\" type=\"block\" data-imgfileid=\"503474618\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic1GuW68DykycvknmG9tyBv6ax8e99N0eyLy4Qo7OzKR5sgwWkpGv1vxoygrqI14ssGoXb90ibG6Jw/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><section><span leaf=\"\"><br></span></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">图文大模型通常采用</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">「预训练 + 监督微调</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">」的两阶段范式进行训练，以强化其指令跟随能力。受语言领域的启发，多模态偏好优化技术凭借其在数据效率和性能增益方面的优势，被广泛用于对齐人类偏好。目前，该技术主要依赖高质量的偏好数据标注和精准的奖励模型训练来提升模型表现。然而，这一方法不仅资源消耗巨大，训练过程仍然极具挑战。</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">受到基于规则的强化学习（Rule-Based Reinforcement Learning）在 R1 上成功应用的启发，</span><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">中科院自动化研究所与中科紫东太初团队探索了如何结合高质量指令对齐数据与类 R1 的强化学习方法，进一步增强图文大模型的视觉定位能力</span><span textstyle=\"\" style=\"font-size: 15px;\">。该方法首次在 Object Detection、Visual Grounding 等复杂视觉任务上，使 Qwen2.5-VL 模型实现了最高 50% 的性能提升，超越了参数规模超过 10 倍的 SOTA 模型。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">目前，相关工作论文、模型及数据集代码均已开源。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.3055555555555556\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480005\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v2e77kvXDNLSZUg2LNXaRBlus0430lDHwnlVYWfYb5TJO4PQjEAQaHQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p><span leaf=\"\"><br></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li style=\"color: rgb(123, 12, 0);\"><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);\">论文标题：Vision-R1: Evolving Human-Free Alignment in Large Vision-Language Models via Vision-Guided Reinforcement Learning</span></span></p></li><li style=\"color: rgb(123, 12, 0);\"><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);\">论文地址：https://arxiv.org/pdf/2503.18013</span></span></p></li><li style=\"color: rgb(123, 12, 0);\"><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);\">Github 仓库：https://github.com/jefferyZhan/Griffon/tree/master/Vision-R1</span></span></p></li><li style=\"color: rgb(123, 12, 0);\"><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);\">Huggingface 仓库：https://huggingface.co/collections/JefferyZhan/vision-r1-67e166f8b6a9ec3f6a664262</span></span></p></li></ul><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">引言</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">目标定位任务要求模型能够精准识别用户输入的任意感兴趣目标，并给出精确的目标框，对图文大模型的细粒度感知和空间理解能力提出了严峻挑战。当前，图文大模型通常将目标定位建模为文本序列预测任务，并通过大规模预训练和指令数据的监督微调，以 Next Token Prediction 实现对不同粒度目标描述的精准定位。尽管在指代表达理解等任务上已超越传统视觉专家模型，但在更复杂、目标密集的场景中，其视觉定位与目标检测能力仍与专家模型存在显著差距。</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">R1 的成功应用推动了对基于规则的任务级别奖励监督的探索，使模型摆脱了对人工偏好数据标注和奖励模型训练的依赖。值得注意的是，视觉定位指令数据本身具有精准的空间位置标注，并与与人类对精准目标定位偏好高度一致。基于这些优势，Vision-R1 通过设计类 R1 的强化学习后训练框架，在任务级别监督中引入基于视觉任务评价指标的反馈奖励信号，为增强图文大模型的细粒度视觉定位能力提供了创新突破方向。</span></span></p><p><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5472222222222223\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480006\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vJDCID3GgZyWTM8ChASD740oNgKot2lsgVYfxXvI8XjOJicpddVXJqCQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin-left: 8px;margin-right: 8px;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;color: rgb(136, 136, 136);font-style: italic;\">Vision-R1 关键设计示意图</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">Vision Criteria-Driven Reward Function</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">聚焦图文大模型目标定位问题</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">在文本序列的统一建模和大规模数据的自回归训练下，图文大模型在目标定位任务上取得了显著的性能提升。然而，其进一步发展仍受到三大关键问题的限制：（1）密集场景中的长序列预测易出现格式错误，（2）有效预测目标的召回率较低，（3）目标定位精度不足。 </span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">这些问题制约了模型在更复杂视觉任务上的表现。在自回归 Token 级别的监督机制下，模型无法获得实例级别的反馈，而直接在单目标场景下应用 GRPO 训练方法又忽视了视觉定位任务的特性及 Completion 级别监督的优势。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">为此，研究团队结合图文大模型在视觉定位任务中面临的挑战，提出了一种基于视觉任务评价准则驱动的奖励函数，其设计包括以下四个核心部分：</span></span></p><p><span leaf=\"\"><br></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">框优先的预测匹配</span><span textstyle=\"\" style=\"font-size: 15px;\">：与仅针对单个目标进行设计的方法不同，Vision-R1 采用多目标预测的统一建模方式。为了计算包含多个目标预测的奖励，Vision-R1 首先对文本序列化的预测结果进行反序列化，提取出每个目标的预测框及其标签，并将预测结果与真实标注进行匹配，以确保奖励机制能够全面衡量多目标场景下的定位质量。</span></span></p></li><li><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">双重格式奖励</span><span textstyle=\"\" style=\"font-size: 15px;\">：该奖励项旨在解决密集场景下长序列预测的格式错误问题。对于每个预测文本序列，模型需满足指定的模板格式（如 Qwen2.5-VL 采用的 JSON 格式），并确保目标坐标的数值正确性。仅当预测结果同时满足格式和内容要求时，模型才能获得奖励 1，从而引导其生成符合标准的预测输出。</span></span></p></li><li><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">召回奖励</span><span textstyle=\"\" style=\"font-size: 15px;\">：该奖励项针对有效预测目标召回率低的问题，鼓励模型尽可能多地识别目标。具体而言，针对每个预测目标及其匹配的真实目标（GT），当两者的 IoU 超过预设阈值 ζ 时，视为该预测有效。对于一个预测序列，其召回奖励定义为有效预测目标数量与实际需要预测目标数量的比例，以此激励模型提高目标的覆盖率。</span></span></p></li></ul><p style=\"margin:0px 8px;line-height:1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.1675925925925926\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480007\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vCwasgjnKomk6Y4icCY3w8iadAvX1bLIllQo7VO1hJyVN6icYiciaQyn3ekw/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin:0px 8px;line-height:1.75em;\"><span leaf=\"\"><br></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">精度奖励</span><span textstyle=\"\" style=\"font-size: 15px;\">：精度奖励与召回奖励协同作用，形成</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">「1+1&gt;2</span></span><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">」的优化效果。其中，召回奖励提升模型对目标的全面识别能力，而精度奖励则确保预测的准确性。精度奖励从单实例角度衡量预测质量，其核心目标是鼓励模型生成高质量的边界框。具体地，精度奖励被定义为所有有效预测的平均 IoU 值，以直接激励模型优化目标框的精确度：</span></span></p></li></ul><p><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.17407407407407408\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480008\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v6WEzXicJpQdhhGQHXTM1kOfVZCpKVQx7qkiaqy9LriabGk2eHUkB664PQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5666666666666667\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480009\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vPov0VPHWruJWz9nH1JJicIRs3IaK8D2EnE7ZVUia1SXzsQ9NnI9mbAdA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin-left: 8px;margin-right: 8px;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;color: rgb(136, 136, 136);font-style: italic;\">Vision-R1 整体框架</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">Progressive Rule Refinement Strategy</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">实现持续性能提升</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">在目标定位任务中，预测高质量（高 IoU）的目标框始终是一个挑战，尤其是在密集场景和小目标情况下。这种困难可能导致模型在同组预测中奖励差异较小，从而影响优化效果。针对这一问题，研究团队提出了渐进式规则调整策略，该策略通过在训练过程中动态调整奖励计算规则，旨在实现模型的持续性能提升。该策略主要包括两个核心部分：</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">差异化策略</span><span textstyle=\"\" style=\"font-size: 15px;\">：该策略的目标是扩大预测结果与实际奖励之间的映射差异。具体而言，通过惩罚低召回率（Recall）和低平均 IoU 的预测，并对高召回率和高 IoU 的预测给予较高奖励，从而鼓励模型生成更高质量的预测，尤其是在当前能够达到的最佳预测上获得最大奖励。这一策略引导模型在训练过程中逐渐提高预测精度，同时避免低质量预测的奖励过高，促进其优化。具体实现如下：</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.3675925925925926\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480010\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v2y8Y6piclrWYXp5VsAicG2IfNdIpG2K4u9W6JrJWsQY4WsIoSXyPkUibQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">阶段渐近策略</span><span textstyle=\"\" style=\"font-size: 15px;\">：类似于许多有效的学习方法，给初学者设定容易实现的目标并逐步提升奖励难度是一个常见且行之有效的策略。在 Vision-R1 中，训练过程被划分为初学阶段和进阶阶段，并通过逐步调整阈值 ζ 来实现奖励规则的逐渐变化。具体来说：</span></span></p><p><span leaf=\"\"><br></span></p><ul style=\"list-style-type: disc;margin-left: 8px;margin-right: 8px;\" class=\"list-paddingleft-1\"><li><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">初学阶段（Beginner Phase）</span><span textstyle=\"\" style=\"font-size: 15px;\">： 在这一阶段，设置较低的 ζ 阈值（0.5/0.75），给予模型相对宽松的奖励标准，帮助其快速入门并学习基础的定位能力。</span></span></p></li><li><p style=\"margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(61, 170, 214);font-weight: bold;\">进阶阶段（Advanced Phase）</span><span textstyle=\"\" style=\"font-size: 15px;\">： 随着训练的深入，逐步提高 ζ 阈值，增加标准要求，以促使模型达到更高的准确度，避免模型依赖简单策略，从而持续推动模型性能的提升。</span></span></p></li></ul><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">不同模型的域内外目标检测评测</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">为全面评估 Vision-R1 的效果，研究团队选择了近期定位能力大幅提升的 Qwen2.5-VL-7B 模型和定位能力突出的 Griffon-G-7B 模型，在更有挑战的经典目标检测数据集 COCO 和多样场景的 ODINW-13 上进行测试，以展现方法对不同定位水平模型的适用性。</span></span></p><p><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.5305555555555556\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480011\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v0pVFPvKaKDYzhkqIpUicqvMuM8ibRYX4azDj5uVtOlhq1LqKVjoN0Fkw/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin-left: 8px;margin-right: 8px;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;color: rgb(136, 136, 136);font-style: italic;\">经典 COCO/ODINW 数据集上 Vision-R1 方法相较于基线模型性能的提升</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">实验结果表明，无论基础性能如何，与基线模型相比这些模型在 Vision-R1 训练后性能大幅提升，甚至超过同系列 SOTA 模型，进一步接近了定位专家模型。</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">研究团队还在模型没有训练的域外定位数据集上进行测试，Vision-R1 在不同模型的四个数据集上取得了平均 6% 的性能提升，充分论证了方法的泛化性。</span></span></p><p><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.27685185185185185\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480012\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v9Aicd4jfK3HdpRQjKTZia8Zvdiaiab0lzfx7G4xN7MsPgZ7k96efNrcIHg/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;color: rgb(136, 136, 136);font-style: italic;\">域外数据集上 Vision-R1 方法相较于基线模型性能的提升</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">模型通用问答能力评测</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">研究团队进一步评估了模型在非定位等通用任务上的性能，以验证方法是否能在少量影响模型通用能力的情况下，大幅度提升模型的视觉定位能力。研究团队发现，Vision-R1 近乎不损失模型的通用能力，在通用问答、图表问答等评测集上模型实现了与基准模型基本一致的性能。</span></span></p><p><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"0.2962962962962963\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480013\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vCvIaG3SPdER8CvEw5ibjvnpxGwf9pABOLzdRLnp64SeTUKgxYd1u00A/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;color: rgb(136, 136, 136);font-style: italic;\">通用问答数据集上 Vision-R1 方法与基线模型性能的比较</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">可视化分析</span></span></p><p><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">研究团队提供了在 Qwen2.5-VL-7B 模型上使用 Vision-R1 后在多个场景下的目标检测可视化结果。如结果所示，Vision-R1 训练后，模型能够更好召回所感兴趣的物体，并进一步提升定位的精度。</span></span></p><p><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img\" data-croporisrc=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vJ9DVoz1hlMAibMiatOBUWAbUo8PRIpFWgP3akTIiaRhNhHvAM54IguSqA/0?wx_fmt=png&amp;from=appmsg\" data-cropselx2=\"562\" data-cropsely2=\"208\" data-imgfileid=\"503480053\" data-ratio=\"0.3690828402366864\" data-s=\"300,640\" data-type=\"png\" data-w=\"2704\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vJ9DVoz1hlMAibMiatOBUWAbUo8PRIpFWgP3akTIiaRhNhHvAM54IguSqA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin-left: 8px;margin-right: 8px;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 12px;color: rgb(136, 136, 136);font-style: italic;\">Vision-R1 训练模型与基准模型检测结果可视化</span></span></p><section><span leaf=\"\"><br></span></section><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" data-style=\"margin-top: 5px; outline: 0px; max-width: 100%; color: rgb(34, 34, 34); font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif letter-spacing: white-space: normal caret-color: rgb background-color: text-align: center line-height: margin-bottom: box-sizing: border-box overflow-wrap: break-word class=\"js_darkmode__6\" style=\"-webkit-tap-highlight-color: transparent;margin-top: 5px;margin-bottom: 0px;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);letter-spacing: 0.544px;text-wrap: wrap;font-family: -apple-system, BlinkMacSystemFont, \"><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif><span leaf=\"\">© THE END </span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" data-style=\"margin-top: 5px; outline: 0px; max-width: 100%; color: rgb(34, 34, 34); font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif letter-spacing: white-space: normal caret-color: rgb background-color: text-align: center line-height: margin-bottom: box-sizing: border-box overflow-wrap: break-word class=\"js_darkmode__7\" style=\"-webkit-tap-highlight-color: transparent;margin-top: 5px;margin-bottom: 0px;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);letter-spacing: 0.544px;text-wrap: wrap;font-family: -apple-system, BlinkMacSystemFont, \"><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;\"><span leaf=\"\">转载请联系本公众号获得授权</span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" data-style=\"margin-top: 5px; outline: 0px; max-width: 100%; color: rgb(34, 34, 34); font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif letter-spacing: white-space: normal caret-color: rgb background-color: text-align: center line-height: margin-bottom: box-sizing: border-box overflow-wrap: break-word class=\"js_darkmode__8\" style=\"-webkit-tap-highlight-color: transparent;margin-top: 5px;margin-bottom: 0px;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);letter-spacing: 0.544px;text-wrap: wrap;font-family: -apple-system, BlinkMacSystemFont, \"><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;\"><span leaf=\"\">投稿或寻求报道：liyazhou@jiqizhixin.com</span></span></p><p style=\"display: none;\"><mp-style-type data-value=\"10000\"></mp-style-type></p></div>\n    \n\n    \n    <br>\n\n    \n        <a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963731&amp;idx=3&amp;sn=7c62398a729785a7d02da7b9d47fab3a&amp;chksm=8525221905860a7ee31228d160e4f9c43b94d60c8acde57393a69b9a129332cc7c29446bba77&amp;scene=0#rd\" style=\"color: blue\" class=\"media_tool_meta meta_primary\">文章原文</a>\n        <br>\n    \n\n    \n\n    <img alt=\"\" width=\"1px\" height=\"1px\" class=\"\" style=\"width:1px;height:1px;display:none\" src=\"http://www.jintiankansha.me/rss_static/4365/n89LPmpAv7\">\n\n",
          "contentSnippet": "图文大模型通常采用「预训练 + 监督微调」的两阶段范式进行训练，以强化其指令跟随能力。受语言领域的启发，多模态偏好优化技术凭借其在数据效率和性能增益方面的优势，被广泛用于对齐人类偏好。目前，该技术主要依赖高质量的偏好数据标注和精准的奖励模型训练来提升模型表现。然而，这一方法不仅资源消耗巨大，训练过程仍然极具挑战。\n\n\n受到基于规则的强化学习（Rule-Based Reinforcement Learning）在 R1 上成功应用的启发，中科院自动化研究所与中科紫东太初团队探索了如何结合高质量指令对齐数据与类 R1 的强化学习方法，进一步增强图文大模型的视觉定位能力。该方法首次在 Object Detection、Visual Grounding 等复杂视觉任务上，使 Qwen2.5-VL 模型实现了最高 50% 的性能提升，超越了参数规模超过 10 倍的 SOTA 模型。\n\n\n目前，相关工作论文、模型及数据集代码均已开源。\n\n\n\n\n\n\n论文标题：Vision-R1: Evolving Human-Free Alignment in Large Vision-Language Models via Vision-Guided Reinforcement Learning\n\n论文地址：https://arxiv.org/pdf/2503.18013\n\nGithub 仓库：https://github.com/jefferyZhan/Griffon/tree/master/Vision-R1\n\nHuggingface 仓库：https://huggingface.co/collections/JefferyZhan/vision-r1-67e166f8b6a9ec3f6a664262\n\n\n\n引言\n\n\n目标定位任务要求模型能够精准识别用户输入的任意感兴趣目标，并给出精确的目标框，对图文大模型的细粒度感知和空间理解能力提出了严峻挑战。当前，图文大模型通常将目标定位建模为文本序列预测任务，并通过大规模预训练和指令数据的监督微调，以 Next Token Prediction 实现对不同粒度目标描述的精准定位。尽管在指代表达理解等任务上已超越传统视觉专家模型，但在更复杂、目标密集的场景中，其视觉定位与目标检测能力仍与专家模型存在显著差距。\n\n\nR1 的成功应用推动了对基于规则的任务级别奖励监督的探索，使模型摆脱了对人工偏好数据标注和奖励模型训练的依赖。值得注意的是，视觉定位指令数据本身具有精准的空间位置标注，并与与人类对精准目标定位偏好高度一致。基于这些优势，Vision-R1 通过设计类 R1 的强化学习后训练框架，在任务级别监督中引入基于视觉任务评价指标的反馈奖励信号，为增强图文大模型的细粒度视觉定位能力提供了创新突破方向。\n\n\n\nVision-R1 关键设计示意图\n\n\nVision Criteria-Driven Reward Function\n聚焦图文大模型目标定位问题\n\n\n在文本序列的统一建模和大规模数据的自回归训练下，图文大模型在目标定位任务上取得了显著的性能提升。然而，其进一步发展仍受到三大关键问题的限制：（1）密集场景中的长序列预测易出现格式错误，（2）有效预测目标的召回率较低，（3）目标定位精度不足。 \n\n\n这些问题制约了模型在更复杂视觉任务上的表现。在自回归 Token 级别的监督机制下，模型无法获得实例级别的反馈，而直接在单目标场景下应用 GRPO 训练方法又忽视了视觉定位任务的特性及 Completion 级别监督的优势。\n\n\n为此，研究团队结合图文大模型在视觉定位任务中面临的挑战，提出了一种基于视觉任务评价准则驱动的奖励函数，其设计包括以下四个核心部分：\n\n\n\n框优先的预测匹配：与仅针对单个目标进行设计的方法不同，Vision-R1 采用多目标预测的统一建模方式。为了计算包含多个目标预测的奖励，Vision-R1 首先对文本序列化的预测结果进行反序列化，提取出每个目标的预测框及其标签，并将预测结果与真实标注进行匹配，以确保奖励机制能够全面衡量多目标场景下的定位质量。\n\n双重格式奖励：该奖励项旨在解决密集场景下长序列预测的格式错误问题。对于每个预测文本序列，模型需满足指定的模板格式（如 Qwen2.5-VL 采用的 JSON 格式），并确保目标坐标的数值正确性。仅当预测结果同时满足格式和内容要求时，模型才能获得奖励 1，从而引导其生成符合标准的预测输出。\n\n召回奖励：该奖励项针对有效预测目标召回率低的问题，鼓励模型尽可能多地识别目标。具体而言，针对每个预测目标及其匹配的真实目标（GT），当两者的 IoU 超过预设阈值 ζ 时，视为该预测有效。对于一个预测序列，其召回奖励定义为有效预测目标数量与实际需要预测目标数量的比例，以此激励模型提高目标的覆盖率。\n\n\n\n\n\n\n\n精度奖励：精度奖励与召回奖励协同作用，形成「1+1>2」的优化效果。其中，召回奖励提升模型对目标的全面识别能力，而精度奖励则确保预测的准确性。精度奖励从单实例角度衡量预测质量，其核心目标是鼓励模型生成高质量的边界框。具体地，精度奖励被定义为所有有效预测的平均 IoU 值，以直接激励模型优化目标框的精确度：\n\n\n\n\n\n\n\nVision-R1 整体框架\n\n\nProgressive Rule Refinement Strategy\n实现持续性能提升\n\n\n在目标定位任务中，预测高质量（高 IoU）的目标框始终是一个挑战，尤其是在密集场景和小目标情况下。这种困难可能导致模型在同组预测中奖励差异较小，从而影响优化效果。针对这一问题，研究团队提出了渐进式规则调整策略，该策略通过在训练过程中动态调整奖励计算规则，旨在实现模型的持续性能提升。该策略主要包括两个核心部分：\n\n\n差异化策略：该策略的目标是扩大预测结果与实际奖励之间的映射差异。具体而言，通过惩罚低召回率（Recall）和低平均 IoU 的预测，并对高召回率和高 IoU 的预测给予较高奖励，从而鼓励模型生成更高质量的预测，尤其是在当前能够达到的最佳预测上获得最大奖励。这一策略引导模型在训练过程中逐渐提高预测精度，同时避免低质量预测的奖励过高，促进其优化。具体实现如下：\n\n\n\n\n\n阶段渐近策略：类似于许多有效的学习方法，给初学者设定容易实现的目标并逐步提升奖励难度是一个常见且行之有效的策略。在 Vision-R1 中，训练过程被划分为初学阶段和进阶阶段，并通过逐步调整阈值 ζ 来实现奖励规则的逐渐变化。具体来说：\n\n\n\n初学阶段（Beginner Phase）： 在这一阶段，设置较低的 ζ 阈值（0.5/0.75），给予模型相对宽松的奖励标准，帮助其快速入门并学习基础的定位能力。\n\n进阶阶段（Advanced Phase）： 随着训练的深入，逐步提高 ζ 阈值，增加标准要求，以促使模型达到更高的准确度，避免模型依赖简单策略，从而持续推动模型性能的提升。\n\n\n\n不同模型的域内外目标检测评测\n\n\n为全面评估 Vision-R1 的效果，研究团队选择了近期定位能力大幅提升的 Qwen2.5-VL-7B 模型和定位能力突出的 Griffon-G-7B 模型，在更有挑战的经典目标检测数据集 COCO 和多样场景的 ODINW-13 上进行测试，以展现方法对不同定位水平模型的适用性。\n\n\n\n经典 COCO/ODINW 数据集上 Vision-R1 方法相较于基线模型性能的提升\n\n\n实验结果表明，无论基础性能如何，与基线模型相比这些模型在 Vision-R1 训练后性能大幅提升，甚至超过同系列 SOTA 模型，进一步接近了定位专家模型。\n\n\n研究团队还在模型没有训练的域外定位数据集上进行测试，Vision-R1 在不同模型的四个数据集上取得了平均 6% 的性能提升，充分论证了方法的泛化性。\n\n\n\n域外数据集上 Vision-R1 方法相较于基线模型性能的提升\n\n\n模型通用问答能力评测\n\n\n研究团队进一步评估了模型在非定位等通用任务上的性能，以验证方法是否能在少量影响模型通用能力的情况下，大幅度提升模型的视觉定位能力。研究团队发现，Vision-R1 近乎不损失模型的通用能力，在通用问答、图表问答等评测集上模型实现了与基准模型基本一致的性能。\n\n\n\n通用问答数据集上 Vision-R1 方法与基线模型性能的比较\n\n\n可视化分析\n\n\n研究团队提供了在 Qwen2.5-VL-7B 模型上使用 Vision-R1 后在多个场景下的目标检测可视化结果。如结果所示，Vision-R1 训练后，模型能够更好召回所感兴趣的物体，并进一步提升定位的精度。\n\n\n\nVision-R1 训练模型与基准模型检测结果可视化\n\n\n© THE END \n转载请联系本公众号获得授权\n投稿或寻求报道：liyazhou@jiqizhixin.com\n\n\n    \n\n    \n    \n文章原文",
          "guid": "http://www.jintiankansha.me/t/n89LPmpAv7",
          "categories": [
            "无"
          ],
          "isoDate": "2025-04-08T04:48:00.000Z"
        }
      },
      {
        "json": {
          "title": "斯坦福2025 AI Index报告来了：DeepSeek在全文中被提到45次",
          "link": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650963731&idx=2&sn=9843c5010e27941cd6a9cc09bb2ef96f&chksm=8559d5f21da721c9e2ddbeb61eb74999a52b0f50db55cf6ccca09e7df353af7a2e2dcd33e091&scene=0#rd",
          "pubDate": "Tue, 08 Apr 2025 12:48:00 +0800",
          "enclosure": {
            "url": "http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vMXg96e3psNcAzExF8TVafXN4cOS4TpvecJaNLvYB1kzSpJ4daq507w/0?wx_fmt=jpeg",
            "length": "0",
            "type": "image/jpeg"
          },
          "content": "\n\n    \n\n    \n\n    \n         <div class=\"rich_media_content\" id=\"js_content\"><section data-mpa-powered-by=\"yiban.io\" data-style=\"white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: \" helvetica neue sans gb yahei arial sans-serif box-sizing: border-box overflow-wrap: break-word mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" data-pm-slice=\"0 0 []\" class=\"js_darkmode__0\" style=\"-webkit-tap-highlight-color: transparent;margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;color: rgba(0, 0, 0, 0.9);font-size: 17px;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: 0.544px;orphans: 2;text-align: justify;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;white-space: normal;text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px;background-color: rgb(255, 255, 255);text-size-adjust: inherit;caret-color: rgb(34, 34, 34);font-family: \" visible><section mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" class=\"js_darkmode__1\" style=\"-webkit-tap-highlight-color: transparent;margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px;visibility: visible;line-height: 27.2px;\"><section mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" class=\"js_darkmode__2\" style=\"-webkit-tap-highlight-color: transparent;margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px;visibility: visible;line-height: 27.2px;\"><section data-id=\"85660\" data-custom=\"rgb(117, 117, 118)\" data-color=\"rgb(117, 117, 118)\" mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" class=\"js_darkmode__3\" style=\"-webkit-tap-highlight-color: transparent;margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 27.2px;\"><section data-style=\"margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;\" mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" class=\"js_darkmode__4\" style=\"-webkit-tap-highlight-color: transparent;margin: 2em 0px 0px;padding: 0.5em 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px;border-top: 1px solid rgb(204, 204, 204);border-bottom: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;line-height: 27.2px;\"><p mp-original-font-size=\"17\" mp-original-line-height=\"29.75\" class=\"js_darkmode__5\" style=\"-webkit-tap-highlight-color: transparent;margin: -1.2em 8px 0px;padding: 0px;outline: 0px;max-width: 100%;clear: both;min-height: 1em;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 29.75px;box-sizing: border-box !important;overflow-wrap: break-word !important;color: rgb(163, 163, 163) !important;\"><span mp-original-font-size=\"15\" mp-original-line-height=\"29.75\" style=\"-webkit-tap-highlight-color: transparent;margin-top: 0px;margin-bottom: 0px;padding: 0px;outline: 0px;max-width: 100%;color: rgb(255, 255, 255);font-family: inherit;font-size: 15px;letter-spacing: 0.544px;background-color: rgb(117, 117, 118);text-decoration: inherit;visibility: visible;line-height: 29.75px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span leaf=\"\" style=\"-webkit-tap-highlight-color: transparent;margin-top: 0px;margin-bottom: 0px;padding: 0px;outline: 0px;max-width: 100%;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\">机器之心报道</span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"29.75\" style=\"-webkit-tap-highlight-color: transparent;margin: 0px 8px;padding: 0px;outline: 0px;max-width: 100%;clear: both;min-height: 1em;text-align: center;visibility: visible;line-height: 29.75px;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span leaf=\"\" style=\"-webkit-tap-highlight-color: transparent;margin-top: 0px;margin-bottom: 0px;padding: 0px;outline: 0px;max-width: 100%;visibility: visible;box-sizing: border-box !important;overflow-wrap: break-word !important;\"><span textstyle=\"\" style=\"font-size: 12px;color: rgb(136, 136, 136);font-weight: bold;\">编辑：蛋酱、+0</span></span></p></section></section></section></section></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">刚刚，斯坦福大学正式发布了《2025 AI Index》报告。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">在过去的一段时间里，人工智能领域经历了一场蓬勃的发展，但与此同时，也有人说「人工智能是一个泡沫」。其他的讨论话题包括但不限于：人工智能的现有技术和架构将不断取得突破；人工智能走在一条不可持续的道路上；人工智能将取代你的工作；人工智能最擅长的就是把你的家庭照片变成吉卜力工作室风格的动画图像……</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">每一年的斯坦福 AI Index 报告都会对领域的发展进行系统的梳理，今年也是如此。《2025 AI Index》报告总共 400 多页，涵盖了研发、技术性能、负责任的人工智能、经济影响、科学和医学、政策、教育和公众舆论等主题的图表和数据。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"1.3009259259259258\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480032\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vO3HwySDfK9xNJna7fkjBs86J1sghxibGMtrTrmRnsgR5ib6AcWib0M8yQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: left;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;color: rgb(123, 12, 0);\">报告地址：https://hai.stanford.edu/ai-index/2025-ai-index-report</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">目录如下：</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"1.2055555555555555\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480033\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v652VgoueXibyrzianukib2r3PBA3XtCr7RY0EhjqCKaVd8AXVuU8owGGw/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">除了谷歌、OpenAI 之外，中国公司 DeepSeek 也成为报告关注的焦点，在 PDF 全文中被提到了 45 次。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">关于今年 AI Index 报告的核心内容，我们通过 12 张图片来了解：</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">美国公司的遥遥领先</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.9355555555555556\" data-s=\"300,640\" data-type=\"png\" data-w=\"900\" type=\"block\" data-imgfileid=\"503480034\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0voOjZickZWdKMv7wYmKQwgibeqmicRkpFmic0XiaXCniazj0zvPJgyBAOhBMw/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">虽然衡量国家在人工智能竞赛中「领先」的方式多种多样（如期刊文章发表或引用数量、专利授权等），但一个直观的评估指标是观察哪些国家发布了具有影响力的模型。研究机构 Epoch AI 拥有一个从 1950 年至今的重要人工智能模型数据库，AI Index 从中提取了相关数据进行分析。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">数据显示，去年美国发布了 40 个知名模型，中国发布了 15 个，欧洲仅有 3 个（均来自法国）。另有数据表明，2024 年发布的这些模型几乎全部来自产业界，而非学术界或政府部门。关于 2023 年至 2024 年知名模型发布数量减少的现象，AI Index 认为可能是由于技术复杂度提高和训练成本持续攀升所致。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">说到训练成本……</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5842592592592593\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480035\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vyleg1v6XYmAFBtQfsoibahkAhcISOwkE2ogM2VeMBCR88Tia5ZXw2r1g/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">在这方面，AI Index 缺乏精确数据，因为许多领先的人工智能公司已停止公开其训练过程信息。斯坦福研究人员与 Epoch AI 合作，基于训练时长、硬件类型和数量等详细信息，估算了部分模型的成本。在可评估的模型中，最昂贵的是谷歌的 Gemini 1.0 Ultra，训练成本约达 1.92 亿美元。训练成本的全面上涨与报告中的其他发现相符：模型在参数数量、训练时间和训练数据量等方面持续规模化扩张。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">值得注意的是，DeepSeek 并未包含在这一分析中。这家公司在 2025 年 1 月声称仅用 600 万美元训练出了 DeepSeek-R1，引发金融市场震动，虽然部分行业专家对此说法持怀疑态度。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">AI Index 指导委员会联合主任 Yolanda Gil 在接受 IEEE Spectrum 采访时表示，她认为 DeepSeek「非常令人印象深刻」，并指出计算机科学历史上充满了早期低效技术被更优雅解决方案取代的案例。她补充道：「我不是唯一一个相信某个时点会出现更高效版本大语言模型的人。我们只是不知道谁会构建它以及如何构建。」</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">使用人工智能的成本正在下降</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5601851851851852\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480036\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vugYOHSCYguR6ZfYwPcQqqibZmoOIMcUkTrIB2DJ3Tg1prTyRkoAw91Q/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">尽管大多数 AI 模型的训练成本持续攀升，但报告中强调了几个积极趋势：硬件成本降低、硬件性能提升及能源效率提高。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">这使得推理成本（即查询已训练模型的费用）正在急剧下降。这张使用对数比例的图表展示了 AI 性能每美元的发展趋势。报告指出，蓝线表明每百万 tokens 的成本从 20 美元降至 0.07 美元；粉线则显示在不到一年时间内，成本从 15 美元降至 0.12 美元。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">人工智能的显著碳足迹</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5703703703703704\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480037\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vGOfD2FjJ9mFVCLUgdGfSN55eYVibNgBuAcaHk6dqpgweFic0gdvYSJEg/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">虽然能源效率提高是一个积极的趋势，但存在一个不容忽视的问题：尽管效率有所提升，整体能耗仍在增长，这意味着处于人工智能热潮中心的数据中心留下了巨大的碳足迹。AI Index 基于训练硬件、云服务提供商和地理位置等因素，估算了特定 AI 模型的碳排放，发现前沿人工智能模型的训练碳排放量呈稳步增长趋势 —— 其中 DeepSeek 模型是个例外。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">数据显示，最大的排放源是 Meta 的 Llama 3.1 模型，估计产生了 8930 吨二氧化碳排放，相当于约 496 个美国人一年的生活碳排放量。这一显著的环境影响解释了为何人工智能公司正积极采用核能作为可靠的零碳能源来源。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">人工智能模型性能差距持续缩小</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.575925925925926\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480038\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vMDib7Esrhia5vTPusl8xpVOcqK1BTR0cLbic0el334ycHicYtiaeutRQjAA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">美国在已发布的知名模型数量上仍然保持领先地位，但中国模型在质量方面正在迅速赶上。数据显示，在聊天机器人基准测试上的性能差距正在不断缩小。2024 年 1 月，顶尖美国模型的表现比最优中国模型高出 9.26%；到 2025 年 2 月，这一差距已缩小至仅 1.70%。报告在推理、数学和编程等其他基准测试中也发现了类似趋势。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">人类最后的考试</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5324074074074074\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480039\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vd5PZFOlexXtUqYqONHAJuOmMS1QnmBmjAJwGTSrlyNta154maHkESQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">今年的报告指出了一个不可忽视的事实：用于评估人工智能系统能力的众多基准测试已经「饱和」—— 人工智能系统在这些测试上获得的分数如此之高，以至于它们不再具有区分价值。这种现象已在多个领域出现：通用知识、图像推理、数学、编程等。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">Gil 表示，她惊讶地目睹一个又一个基准测试逐渐失去参考意义。她指出：「我一直认为性能会趋于平稳，会达到一个需要新技术或根本不同架构才能继续取得进展的临界点。但事实并非如此。」</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">面对这种局面，执着的研究人员不断设计新的基准测试，以期挑战人工智能系统。其中一项是「人类的最后考试」，它由来自全球 500 个机构的专业领域专家贡献的极具挑战性问题组成。到目前为止，即使对最顶尖的人工智能系统而言，这项测试仍然难以攻克：OpenAI 的推理模型 o1 目前以 8.8% 的正确答案率位居榜首。业界正密切关注这种局面能持续多久。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">公共数据面临的威胁</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5777777777777777\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480040\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v16BV9P3cbkGkWh2Nc9HkzFWIiaUatrhWLiaaFe7Mm132LPBv8vyOF7yA/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">当今生成式 AI 系统通过训练海量从互联网抓取的数据获得智能，这导致了一个经常被提及的观点：「数据是 AI 经济的新石油」。随着人工智能公司不断挑战可输入模型的数据量极限，业界开始担忧「数据峰值」问题，以及何时会耗尽这种关键资源。一个问题是，越来越多的网站正在限制机器人爬取并抓取其数据（可能是因为担忧人工智能公司从其数据中获利，同时破坏其商业模式）。网站通过机器可读的 robots.txt 文件声明这些限制。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">数据显示，顶级网络域名中 48% 的数据现已被完全限制访问。然而，Gil 指出，人工智能领域可能会出现新方法，终结对庞大数据集的依赖。她认为：「预计在某些时候，数据量将不再如此关键。」</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">企业资金持续涌入人工智能领域</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5425925925925926\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480041\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vbPWSFtEFAybYRkAhRly9wrXLmAhst8rIhKxxXzPibtv4TkLOFBWibs5Q/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">过去五年，企业界已为人工智能投资敞开了资金闸门。虽然 2024 年的全球总体投资未能达到 2021 年的疯狂高峰，但值得注意的是，私人投资规模达到了前所未有的水平。在 2024 年 1500 亿美元的私人投资中，相关指数的另一项数据表明，约 330 亿美元流向了生成式 AI 领域。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">企业等待人工智能投资的巨大回报</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5416666666666666\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480042\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vDSe1ZI3znuCmibibCC3kuUnasMRLG9onc4aIwls7k1ibiaXNSmrDlAwesg/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">理论上，企业投资人工智能是因为期望获得可观的投资回报。在这个话题上，人们常以激昂语气讨论人工智能的变革性本质和前所未有的生产力提升。然而，企业尚未见到能带来显著成本节省或实质性新收益的转变。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">麦肯锡调查数据显示，在报告成本降低的企业中，大多数节省幅度不足 10%；在因人工智能获得收入增长的企业中，大多数报告的增长幅度不到 5%。巨大的回报可能仍在路上，从投资数据来看，众多企业正在押注于此，但目前尚未实现。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">AI 医生或将很快接诊</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-imgfileid=\"503480043\" data-ratio=\"1.0322222222222222\" data-s=\"300,640\" data-type=\"png\" data-w=\"900\" type=\"block\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vENogKWLf0u7UW75OKDvK1CLLyNRPUO7lrcHeAF7yKhRGYgoMibYibLFg/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">科学与医疗领域的人工智能应用是人工智能浪潮中的一个重要分支。报告列举了多个新发布的基础模型，这些模型旨在协助材料科学、天气预报和量子计算等领域的研究人员。众多公司正尝试将人工智能的预测和生成能力转化为盈利性药物研发。OpenAI 的 o1 推理模型最近在医学执照考试问题集 MedQA 的基准测试中取得了 96% 的得分。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">然而，这似乎仍是一个潜力巨大但尚未转化为显著实际影响的领域 —— 部分原因可能是人类尚未完全掌握如何有效使用这项技术。2024 年的一项研究测试了医生在使用 GPT-4 作为常规资源补充时是否能做出更准确的诊断。结果表明，这既未提高诊断准确性，也未加快诊断速度。值得注意的是，单独使用的 GPT-4 表现却优于人机团队和单独的人类医生。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">美国的人工智能政策行动转向州级层面</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-imgfileid=\"503480044\" data-ratio=\"0.5425925925925926\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vbRJkKD3BJL1W2OtKVNmEiaFfibSTeJP0OGhWGp3ryyicesPJslCv91vLQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">这张图表显示，美国国会虽有大量关于人工智能的讨论，但实际行动寥寥无几。报告指出，美国的政策制定已转移至州级层面，2024 年共有 131 项法案在各州获得通过。其中 56 项与深度伪造（deepfake）相关，禁止在选举中使用深度伪造技术或借此传播未经同意的私密图像。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">美国之外，欧洲已通过《人工智能法案》（AI Act），该法案要求开发被认定为高风险的人工智能系统的公司承担新的责任义务。然而，全球主要趋势是各国联合发表关于人工智能应在世界上扮演何种角色的全面但无约束力的声明。因此，实质性监管行动相对有限，而讨论却十分广泛。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 16px;font-weight: bold;\">人类是乐观主义者</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;text-align: center;\"><span leaf=\"\"><br></span></p><section style=\"text-align: center;margin-left: 8px;margin-right: 8px;\" nodeleaf=\"\"><img class=\"rich_pages wxw-img js_insertlocalimg\" data-ratio=\"0.5277777777777778\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" type=\"block\" data-imgfileid=\"503480045\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vmdTB8Tlfa8bGJWaOeibG1ugAXORH1zyj5o4e1iaZIOlPgpT8T7EELt5w/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></section><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">无论你是股票摄影师、营销经理还是卡车司机，关于人工智能是否以及何时会取代你的工作，社会上已有广泛讨论。然而，最近一项关于人工智能态度的全球调查显示，大多数人并不感到受到人工智能的威胁。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">来自 32 个国家的 60% 受访者认为人工智能将改变他们的工作方式，但仅有 36% 的人预期会被替代。「这些调查结果确实让我感到惊讶，」Gil 表示，「人们认为『人工智能将改变我的工作，但我仍将创造价值』，这种观点非常令人鼓舞。」让我们拭目以待，看看我们能否都通过管理人工智能团队来持续创造价值。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><span textstyle=\"\" style=\"font-size: 15px;\">更多细节，可参考报告原文。</span></span></p><p style=\"margin: 0px 8px;line-height: 1.75em;\"><span leaf=\"\"><br></span></p><p style=\"text-align: center;margin-bottom: 0px;margin-left: 8px;margin-right: 8px;\"><span leaf=\"\"><img class=\"rich_pages wxw-img\" data-ratio=\"1.8518518518518519\" data-s=\"300,640\" data-type=\"png\" data-w=\"1080\" data-imgfileid=\"503478358\" src=\"http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibD4lCB7aJY0WoFGLCNz0tCh7FbEdJhtvUB5Y0TKawRI38FibjTdXdibM3bsf05HHvbN99GwB8GhOEQ/640?wx_fmt=png&amp;from=appmsg\" style=\"max-width: 600px\"></span></p><p style=\"margin-bottom: 0px;\"><span leaf=\"\"><br></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;margin: 5px 8px 0px;outline: 0px;letter-spacing: 0.544px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb inherit center><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif><span leaf=\"\">© THE END </span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;margin: 5px 8px 0px;outline: 0px;letter-spacing: 0.544px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb inherit center><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;\"><span leaf=\"\">转载请联系本公众号获得授权</span></span></p><p mp-original-font-size=\"17\" mp-original-line-height=\"27.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;margin: 5px 8px 0px;outline: 0px;letter-spacing: 0.544px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, \" helvetica neue sc sans gb yahei ui arial sans-serif rgb inherit center><span mp-original-font-size=\"12\" mp-original-line-height=\"19.200000762939453\" style=\"-webkit-tap-highlight-color: transparent;outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;\"><span leaf=\"\">投稿或寻求报道：liyazhou@jiqizhixin.com</span></span></p><p style=\"display: none;\"><mp-style-type data-value=\"3\"></mp-style-type></p></div>\n    \n\n    \n    <br>\n\n    \n        <a target=\"_blank\" href=\"http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963731&amp;idx=2&amp;sn=9843c5010e27941cd6a9cc09bb2ef96f&amp;chksm=8559d5f21da721c9e2ddbeb61eb74999a52b0f50db55cf6ccca09e7df353af7a2e2dcd33e091&amp;scene=0#rd\" style=\"color: blue\" class=\"media_tool_meta meta_primary\">文章原文</a>\n        <br>\n    \n\n    \n\n    <img alt=\"\" width=\"1px\" height=\"1px\" class=\"\" style=\"width:1px;height:1px;display:none\" src=\"http://www.jintiankansha.me/rss_static/4365/GaNPqOtUez\">\n\n",
          "contentSnippet": "机器之心报道\n编辑：蛋酱、+0\n\n\n\n\n\n刚刚，斯坦福大学正式发布了《2025 AI Index》报告。\n\n\n在过去的一段时间里，人工智能领域经历了一场蓬勃的发展，但与此同时，也有人说「人工智能是一个泡沫」。其他的讨论话题包括但不限于：人工智能的现有技术和架构将不断取得突破；人工智能走在一条不可持续的道路上；人工智能将取代你的工作；人工智能最擅长的就是把你的家庭照片变成吉卜力工作室风格的动画图像……\n\n\n每一年的斯坦福 AI Index 报告都会对领域的发展进行系统的梳理，今年也是如此。《2025 AI Index》报告总共 400 多页，涵盖了研发、技术性能、负责任的人工智能、经济影响、科学和医学、政策、教育和公众舆论等主题的图表和数据。\n\n\n\n报告地址：https://hai.stanford.edu/ai-index/2025-ai-index-report\n\n\n目录如下：\n\n\n\n除了谷歌、OpenAI 之外，中国公司 DeepSeek 也成为报告关注的焦点，在 PDF 全文中被提到了 45 次。\n\n\n关于今年 AI Index 报告的核心内容，我们通过 12 张图片来了解：\n\n\n美国公司的遥遥领先\n\n\n\n虽然衡量国家在人工智能竞赛中「领先」的方式多种多样（如期刊文章发表或引用数量、专利授权等），但一个直观的评估指标是观察哪些国家发布了具有影响力的模型。研究机构 Epoch AI 拥有一个从 1950 年至今的重要人工智能模型数据库，AI Index 从中提取了相关数据进行分析。\n\n\n数据显示，去年美国发布了 40 个知名模型，中国发布了 15 个，欧洲仅有 3 个（均来自法国）。另有数据表明，2024 年发布的这些模型几乎全部来自产业界，而非学术界或政府部门。关于 2023 年至 2024 年知名模型发布数量减少的现象，AI Index 认为可能是由于技术复杂度提高和训练成本持续攀升所致。\n\n\n说到训练成本……\n\n\n\n在这方面，AI Index 缺乏精确数据，因为许多领先的人工智能公司已停止公开其训练过程信息。斯坦福研究人员与 Epoch AI 合作，基于训练时长、硬件类型和数量等详细信息，估算了部分模型的成本。在可评估的模型中，最昂贵的是谷歌的 Gemini 1.0 Ultra，训练成本约达 1.92 亿美元。训练成本的全面上涨与报告中的其他发现相符：模型在参数数量、训练时间和训练数据量等方面持续规模化扩张。\n\n\n值得注意的是，DeepSeek 并未包含在这一分析中。这家公司在 2025 年 1 月声称仅用 600 万美元训练出了 DeepSeek-R1，引发金融市场震动，虽然部分行业专家对此说法持怀疑态度。\n\n\nAI Index 指导委员会联合主任 Yolanda Gil 在接受 IEEE Spectrum 采访时表示，她认为 DeepSeek「非常令人印象深刻」，并指出计算机科学历史上充满了早期低效技术被更优雅解决方案取代的案例。她补充道：「我不是唯一一个相信某个时点会出现更高效版本大语言模型的人。我们只是不知道谁会构建它以及如何构建。」\n\n\n使用人工智能的成本正在下降\n\n\n\n尽管大多数 AI 模型的训练成本持续攀升，但报告中强调了几个积极趋势：硬件成本降低、硬件性能提升及能源效率提高。\n\n\n这使得推理成本（即查询已训练模型的费用）正在急剧下降。这张使用对数比例的图表展示了 AI 性能每美元的发展趋势。报告指出，蓝线表明每百万 tokens 的成本从 20 美元降至 0.07 美元；粉线则显示在不到一年时间内，成本从 15 美元降至 0.12 美元。\n\n\n人工智能的显著碳足迹\n\n\n\n虽然能源效率提高是一个积极的趋势，但存在一个不容忽视的问题：尽管效率有所提升，整体能耗仍在增长，这意味着处于人工智能热潮中心的数据中心留下了巨大的碳足迹。AI Index 基于训练硬件、云服务提供商和地理位置等因素，估算了特定 AI 模型的碳排放，发现前沿人工智能模型的训练碳排放量呈稳步增长趋势 —— 其中 DeepSeek 模型是个例外。\n\n\n数据显示，最大的排放源是 Meta 的 Llama 3.1 模型，估计产生了 8930 吨二氧化碳排放，相当于约 496 个美国人一年的生活碳排放量。这一显著的环境影响解释了为何人工智能公司正积极采用核能作为可靠的零碳能源来源。\n\n\n人工智能模型性能差距持续缩小\n\n\n\n美国在已发布的知名模型数量上仍然保持领先地位，但中国模型在质量方面正在迅速赶上。数据显示，在聊天机器人基准测试上的性能差距正在不断缩小。2024 年 1 月，顶尖美国模型的表现比最优中国模型高出 9.26%；到 2025 年 2 月，这一差距已缩小至仅 1.70%。报告在推理、数学和编程等其他基准测试中也发现了类似趋势。\n\n\n人类最后的考试\n\n\n\n今年的报告指出了一个不可忽视的事实：用于评估人工智能系统能力的众多基准测试已经「饱和」—— 人工智能系统在这些测试上获得的分数如此之高，以至于它们不再具有区分价值。这种现象已在多个领域出现：通用知识、图像推理、数学、编程等。\n\n\nGil 表示，她惊讶地目睹一个又一个基准测试逐渐失去参考意义。她指出：「我一直认为性能会趋于平稳，会达到一个需要新技术或根本不同架构才能继续取得进展的临界点。但事实并非如此。」\n\n\n面对这种局面，执着的研究人员不断设计新的基准测试，以期挑战人工智能系统。其中一项是「人类的最后考试」，它由来自全球 500 个机构的专业领域专家贡献的极具挑战性问题组成。到目前为止，即使对最顶尖的人工智能系统而言，这项测试仍然难以攻克：OpenAI 的推理模型 o1 目前以 8.8% 的正确答案率位居榜首。业界正密切关注这种局面能持续多久。\n\n\n公共数据面临的威胁\n\n\n\n当今生成式 AI 系统通过训练海量从互联网抓取的数据获得智能，这导致了一个经常被提及的观点：「数据是 AI 经济的新石油」。随着人工智能公司不断挑战可输入模型的数据量极限，业界开始担忧「数据峰值」问题，以及何时会耗尽这种关键资源。一个问题是，越来越多的网站正在限制机器人爬取并抓取其数据（可能是因为担忧人工智能公司从其数据中获利，同时破坏其商业模式）。网站通过机器可读的 robots.txt 文件声明这些限制。\n\n\n数据显示，顶级网络域名中 48% 的数据现已被完全限制访问。然而，Gil 指出，人工智能领域可能会出现新方法，终结对庞大数据集的依赖。她认为：「预计在某些时候，数据量将不再如此关键。」\n\n\n企业资金持续涌入人工智能领域\n\n\n\n过去五年，企业界已为人工智能投资敞开了资金闸门。虽然 2024 年的全球总体投资未能达到 2021 年的疯狂高峰，但值得注意的是，私人投资规模达到了前所未有的水平。在 2024 年 1500 亿美元的私人投资中，相关指数的另一项数据表明，约 330 亿美元流向了生成式 AI 领域。\n\n\n企业等待人工智能投资的巨大回报\n\n\n\n理论上，企业投资人工智能是因为期望获得可观的投资回报。在这个话题上，人们常以激昂语气讨论人工智能的变革性本质和前所未有的生产力提升。然而，企业尚未见到能带来显著成本节省或实质性新收益的转变。\n\n\n麦肯锡调查数据显示，在报告成本降低的企业中，大多数节省幅度不足 10%；在因人工智能获得收入增长的企业中，大多数报告的增长幅度不到 5%。巨大的回报可能仍在路上，从投资数据来看，众多企业正在押注于此，但目前尚未实现。\n\n\nAI 医生或将很快接诊\n\n\n\n科学与医疗领域的人工智能应用是人工智能浪潮中的一个重要分支。报告列举了多个新发布的基础模型，这些模型旨在协助材料科学、天气预报和量子计算等领域的研究人员。众多公司正尝试将人工智能的预测和生成能力转化为盈利性药物研发。OpenAI 的 o1 推理模型最近在医学执照考试问题集 MedQA 的基准测试中取得了 96% 的得分。\n\n\n然而，这似乎仍是一个潜力巨大但尚未转化为显著实际影响的领域 —— 部分原因可能是人类尚未完全掌握如何有效使用这项技术。2024 年的一项研究测试了医生在使用 GPT-4 作为常规资源补充时是否能做出更准确的诊断。结果表明，这既未提高诊断准确性，也未加快诊断速度。值得注意的是，单独使用的 GPT-4 表现却优于人机团队和单独的人类医生。\n\n\n美国的人工智能政策行动转向州级层面\n\n\n\n这张图表显示，美国国会虽有大量关于人工智能的讨论，但实际行动寥寥无几。报告指出，美国的政策制定已转移至州级层面，2024 年共有 131 项法案在各州获得通过。其中 56 项与深度伪造（deepfake）相关，禁止在选举中使用深度伪造技术或借此传播未经同意的私密图像。\n\n\n美国之外，欧洲已通过《人工智能法案》（AI Act），该法案要求开发被认定为高风险的人工智能系统的公司承担新的责任义务。然而，全球主要趋势是各国联合发表关于人工智能应在世界上扮演何种角色的全面但无约束力的声明。因此，实质性监管行动相对有限，而讨论却十分广泛。\n\n\n人类是乐观主义者\n\n\n\n无论你是股票摄影师、营销经理还是卡车司机，关于人工智能是否以及何时会取代你的工作，社会上已有广泛讨论。然而，最近一项关于人工智能态度的全球调查显示，大多数人并不感到受到人工智能的威胁。\n\n\n来自 32 个国家的 60% 受访者认为人工智能将改变他们的工作方式，但仅有 36% 的人预期会被替代。「这些调查结果确实让我感到惊讶，」Gil 表示，「人们认为『人工智能将改变我的工作，但我仍将创造价值』，这种观点非常令人鼓舞。」让我们拭目以待，看看我们能否都通过管理人工智能团队来持续创造价值。\n\n\n更多细节，可参考报告原文。\n\n\n\n\n\n© THE END \n转载请联系本公众号获得授权\n投稿或寻求报道：liyazhou@jiqizhixin.com\n\n\n    \n\n    \n    \n文章原文",
          "guid": "http://www.jintiankansha.me/t/GaNPqOtUez",
          "categories": [
            "无"
          ],
          "isoDate": "2025-04-08T04:48:00.000Z"
        }
      }
    ]
  },
  "connections": {
    "HTTP Request": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ],
        []
      ]
    },
    "Loop Over Items": {
      "main": [
        [],
        [
          {
            "node": "Notion",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code": {
      "main": [
        [
          {
            "node": "HTTP Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Notion": {
      "main": [
        [
          {
            "node": "Code",
            "type": "main",
            "index": 0
          }
        ],
        []
      ]
    },
    "Markdown2": {
      "main": [
        [
          {
            "node": "合并数据",
            "type": "main",
            "index": 2
          }
        ]
      ]
    },
    "Markdown1": {
      "main": [
        [
          {
            "node": "合并数据",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Markdown": {
      "main": [
        [
          {
            "node": "合并数据",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Schedule Trigger": {
      "main": [
        [
          {
            "node": "新智元",
            "type": "main",
            "index": 0
          },
          {
            "node": "机器之心",
            "type": "main",
            "index": 0
          },
          {
            "node": "量子位",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "机器之心": {
      "main": [
        [
          {
            "node": "Markdown",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "新智元": {
      "main": [
        [
          {
            "node": "Markdown1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "量子位": {
      "main": [
        [
          {
            "node": "Markdown2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "合并数据": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "机器之心1": {
      "main": [
        [
          {
            "node": "Markdown5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "新智元1": {
      "main": [
        [
          {
            "node": "Markdown4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "量子位1": {
      "main": [
        [
          {
            "node": "Markdown3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Markdown5": {
      "main": [
        [
          {
            "node": "Aggregate",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Markdown4": {
      "main": [
        [
          {
            "node": "Aggregate",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Markdown3": {
      "main": [
        [
          {
            "node": "Aggregate",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Schedule Trigger1": {
      "main": [
        [
          {
            "node": "机器之心1",
            "type": "main",
            "index": 0
          },
          {
            "node": "新智元1",
            "type": "main",
            "index": 0
          },
          {
            "node": "量子位1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Markdown6": {
      "main": [
        [
          {
            "node": "合并数据1",
            "type": "main",
            "index": 2
          }
        ]
      ]
    },
    "Markdown7": {
      "main": [
        [
          {
            "node": "合并数据1",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Markdown8": {
      "main": [
        [
          {
            "node": "合并数据1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "机器之心2": {
      "main": [
        [
          {
            "node": "Markdown8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "新智元2": {
      "main": [
        [
          {
            "node": "Markdown7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "量子位2": {
      "main": [
        [
          {
            "node": "Markdown6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "合并数据1": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 1
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1",
    "timezone": "Asia/Shanghai",
    "callerPolicy": "workflowsFromSameOwner"
  },
  "versionId": "e3be7813-52e6-4ff5-bd18-f3173cc4d9f4",
  "meta": {
    "templateId": "2748",
    "templateCredsSetupCompleted": true,
    "instanceId": "667f8e49cea6f05a4f2d4764a2ef083b44c681d7bcf3709cc71f85be90eeca2e"
  },
  "id": "Lwox6zje9oGnzsjK",
  "tags": []
}